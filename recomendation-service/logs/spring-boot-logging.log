2018-05-01 16:36:40.773  INFO 5508 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 16:36:40.784  INFO 5508 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@74072972: startup date [Tue May 01 16:36:40 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3197a157
2018-05-01 16:36:40.931  WARN 5508 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.jcombat.profile.ProfileMicroserviceServerApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
2018-05-01 16:36:40.941 ERROR 5508 --- [restartedMain] o.s.boot.SpringApplication               : Application startup failed

org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.jcombat.profile.ProfileMicroserviceServerApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:181) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:308) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:228) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:272) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:92) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:687) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:525) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]
Caused by: org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.checkCandidate(ClassPathBeanDefinitionScanner.java:345) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.doScan(ClassPathBeanDefinitionScanner.java:283) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ComponentScanAnnotationParser.parse(ComponentScanAnnotationParser.java:135) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.doProcessConfigurationClass(ConfigurationClassParser.java:287) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:245) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:198) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:167) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	... 18 common frames omitted

2018-05-01 16:37:38.890  INFO 17436 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 16:37:38.901  INFO 17436 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55fda42c: startup date [Tue May 01 16:37:38 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@629a8bd7
2018-05-01 16:37:38.967  WARN 17436 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.jcombat.profile.ProfileMicroserviceServerApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
2018-05-01 16:37:38.976 ERROR 17436 --- [restartedMain] o.s.boot.SpringApplication               : Application startup failed

org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.jcombat.profile.ProfileMicroserviceServerApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:181) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:308) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:228) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:272) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:92) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:687) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:525) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]
Caused by: org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.checkCandidate(ClassPathBeanDefinitionScanner.java:345) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.doScan(ClassPathBeanDefinitionScanner.java:283) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ComponentScanAnnotationParser.parse(ComponentScanAnnotationParser.java:135) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.doProcessConfigurationClass(ConfigurationClassParser.java:287) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:245) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:198) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:167) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	... 18 common frames omitted

2018-05-01 16:38:20.888  INFO 18064 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 16:38:20.899  INFO 18064 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b05d6e4: startup date [Tue May 01 16:38:20 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@54b0b8c1
2018-05-01 16:38:22.352  INFO 18064 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 16:38:22.377  INFO 18064 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 16:38:22.386  INFO 18064 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 16:38:22.619  INFO 18064 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 16:38:22.651  INFO 18064 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 16:38:22.759  INFO 18064 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$776de761] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 16:38:22.795  INFO 18064 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9387ea5e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 16:38:23.266  INFO 18064 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 2222 (http)
2018-05-01 16:38:23.274  INFO 18064 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 16:38:23.275  INFO 18064 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 16:38:23.328  INFO 18064 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 16:38:23.329  INFO 18064 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2430 ms
2018-05-01 16:38:23.610  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 16:38:23.611  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 16:38:23.617  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 16:38:23.618  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 16:38:23.618  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 16:38:23.618  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 16:38:23.619  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 16:38:23.619  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 16:38:23.619  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 16:38:23.940  INFO 18064 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:24.502  INFO 18064 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:25.006  INFO 18064 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 16:38:25.007  INFO 18064 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 16:38:25.061  INFO 18064 --- [cluster-ClusterId{value='5ae86dd1b11f8e4690d84829', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:60}] to localhost:27017
2018-05-01 16:38:25.065  INFO 18064 --- [cluster-ClusterId{value='5ae86dd1b11f8e4690d84829', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=640395}
2018-05-01 16:38:25.067  INFO 18064 --- [cluster-ClusterId{value='5ae86dd1b11f8e4690d84829', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 16:38:25.441  INFO 18064 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 16:38:25.597  WARN 18064 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 16:38:25.708  INFO 18064 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 16:38:25.720  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 16:38:25.721  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 16:38:25.722  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 16:38:25.723  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 16:38:25.724  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 16:38:26.026  INFO 18064 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 56950.
2018-05-01 16:38:26.042  INFO 18064 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 16:38:26.058  INFO 18064 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 16:38:26.061  INFO 18064 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 16:38:26.061  INFO 18064 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 16:38:26.069  INFO 18064 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-fc54495b-2f0b-4242-9094-88281bab85dd
2018-05-01 16:38:26.096  INFO 18064 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 16:38:26.133  INFO 18064 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 16:38:26.187  INFO 18064 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @7792ms
2018-05-01 16:38:26.232  INFO 18064 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 16:38:26.246  INFO 18064 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @7851ms
2018-05-01 16:38:26.259  WARN 18064 --- [restartedMain] org.apache.spark.util.Utils              : Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-05-01 16:38:26.266  INFO 18064 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@f42a1a3{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2018-05-01 16:38:26.266  INFO 18064 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4041.
2018-05-01 16:38:26.302  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@52174394{/jobs,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.303  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@76f14a4e{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.303  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@44181c91{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.304  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@765cffe2{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.306  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@744ddb2a{/stages,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.306  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@630551b1{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.307  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2f305012{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.308  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@46bf0446{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.308  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@553f843{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.308  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4365ca3a{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.309  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1018a707{/storage,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.309  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@332e4df6{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.311  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7263abe8{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.311  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@56b19469{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.312  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2ee74398{/environment,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.312  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6ad4716c{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.313  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1b0f3088{/executors,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.313  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@79e5ff6{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.314  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@68d13f64{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.314  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1381b2b7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.319  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3e909511{/static,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.320  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@92165e5{/,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.321  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@cb24070{/api,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.321  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74b081b1{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.322  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@117d7c18{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.323  INFO 18064 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4041
2018-05-01 16:38:26.407  INFO 18064 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 16:38:26.436  INFO 18064 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56965.
2018-05-01 16:38:26.437  INFO 18064 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:56965
2018-05-01 16:38:26.438  INFO 18064 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 16:38:26.439  INFO 18064 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 56965, None)
2018-05-01 16:38:26.443  INFO 18064 --- [dispatcher-event-loop-0] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:56965 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 56965, None)
2018-05-01 16:38:26.447  INFO 18064 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 56965, None)
2018-05-01 16:38:26.447  INFO 18064 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 56965, None)
2018-05-01 16:38:26.461  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5bdead75{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.511  INFO 18064 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 16:38:26.511  INFO 18064 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 16:38:26.516  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6c7a0628{/SQL,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.517  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@33cf606a{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.518  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@27bca603{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.518  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@262746cf{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.520  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3e537902{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 16:38:27.077  WARN 18064 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 16:38:27.285  INFO 18064 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 16:38:27.884  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 16:38:27.886  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 16:38:27.889  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 16:38:27.890  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 16:38:27.890  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 16:38:27.892  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 16:38:27.892  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 16:38:28.707  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 16:38:28.708  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.709  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:28.709  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:28.710  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 16:38:28.710  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.711  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 16:38:28.711  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.712  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.714  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.715  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 16:38:28.716  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.717  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 16:38:28.717  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.717  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 16:38:28.718  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 16:38:28.718  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.719  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 16:38:28.719  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.719  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.720  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 16:38:28.721  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 16:38:28.721  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.722  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 16:38:28.722  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.723  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:29.187  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b05d6e4: startup date [Tue May 01 16:38:20 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@54b0b8c1
2018-05-01 16:38:29.257  INFO 18064 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:29.257  INFO 18064 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:29.286  INFO 18064 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 16:38:29.320  INFO 18064 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:29.779  WARN 18064 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 16:38:29.865  WARN 18064 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 16:38:29.866  INFO 18064 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 16:38:29.871  WARN 18064 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 16:38:29.871  INFO 18064 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 16:38:29.954  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 16:38:29.964  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 16:38:29.965  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 16:38:29.969  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 16:38:29.970  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 16:38:29.971  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 16:38:29.974  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 16:38:29.988  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 16:38:29.999  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 16:38:30.016  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=6b05d6e4,type=ConfigurationPropertiesRebinder]
2018-05-01 16:38:30.024  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 16:38:30.400  INFO 18064 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 16:38:30.407  INFO 18064 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 16:38:30.497  INFO 18064 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 16:38:30.498  INFO 18064 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 16:38:30.602  INFO 18064 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 16:38:30.602  INFO 18064 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 16:38:30.897  INFO 18064 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:38:31.013  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 16:38:31.013  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 16:38:31.013  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 16:38:31.014  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 16:38:31.014  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 16:38:31.015  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 16:38:31.015  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 16:38:31.196  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 16:38:31.198  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 16:38:31.201  INFO 18064 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 16:38:31.205  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525181911205 with initial instances count: 1
2018-05-01 16:38:31.228  INFO 18064 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application qqqqqqq with eureka with status UP
2018-05-01 16:38:31.229  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525181911229, current=UP, previous=STARTING]
2018-05-01 16:38:31.232  INFO 18064 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222: registering service...
2018-05-01 16:38:31.279  INFO 18064 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222 - registration status: 204
2018-05-01 16:38:31.300  INFO 18064 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 16:38:31.300  INFO 18064 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 16:38:31.320  INFO 18064 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 16:38:31.337  INFO 18064 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 16:38:31.384 ERROR 18064 --- [restartedMain] o.a.coyote.http11.Http11NioProtocol      : Failed to start end point associated with ProtocolHandler ["http-nio-2222"]

java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method) ~[na:1.8.0_131]
	at sun.nio.ch.Net.bind(Net.java:433) ~[na:1.8.0_131]
	at sun.nio.ch.Net.bind(Net.java:425) ~[na:1.8.0_131]
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223) ~[na:1.8.0_131]
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74) ~[na:1.8.0_131]
	at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:210) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:990) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:635) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1022) [tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.core.StandardService.addConnector(StandardService.java:225) [tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.addPreviouslyRemovedConnectors(TomcatEmbeddedServletContainer.java:250) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.start(TomcatEmbeddedServletContainer.java:193) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:297) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:145) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]

2018-05-01 16:38:31.385 ERROR 18064 --- [restartedMain] o.apache.catalina.core.StandardService   : Failed to start connector [Connector[HTTP/1.1-2222]]

org.apache.catalina.LifecycleException: Failed to start component [Connector[HTTP/1.1-2222]]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:167) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.core.StandardService.addConnector(StandardService.java:225) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.addPreviouslyRemovedConnectors(TomcatEmbeddedServletContainer.java:250) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.start(TomcatEmbeddedServletContainer.java:193) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:297) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:145) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]
Caused by: org.apache.catalina.LifecycleException: service.getName(): "Tomcat";  Protocol handler start failed
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1031) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	... 18 common frames omitted
Caused by: java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method) ~[na:1.8.0_131]
	at sun.nio.ch.Net.bind(Net.java:433) ~[na:1.8.0_131]
	at sun.nio.ch.Net.bind(Net.java:425) ~[na:1.8.0_131]
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223) ~[na:1.8.0_131]
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74) ~[na:1.8.0_131]
	at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:210) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:990) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:635) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1022) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	... 19 common frames omitted

2018-05-01 16:38:31.392  INFO 18064 --- [restartedMain] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2018-05-01 16:38:31.401  INFO 18064 --- [restartedMain] utoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2018-05-01 16:38:31.407 ERROR 18064 --- [restartedMain] o.s.b.d.LoggingFailureAnalysisReporter   : 

***************************
APPLICATION FAILED TO START
***************************

Description:

The Tomcat connector configured to listen on port 2222 failed to start. The port may already be in use or the connector may be misconfigured.

Action:

Verify the connector's configuration, identify and stop any process that's listening on port 2222, or configure this application to listen on another port.

2018-05-01 16:38:31.408  INFO 18064 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b05d6e4: startup date [Tue May 01 16:38:20 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@54b0b8c1
2018-05-01 16:38:31.408  INFO 18064 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Unregistering application qqqqqqq with eureka with status DOWN
2018-05-01 16:38:31.408  WARN 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525181911408, current=DOWN, previous=UP]
2018-05-01 16:38:31.410  INFO 18064 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222: registering service...
2018-05-01 16:38:31.410  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
2018-05-01 16:38:31.410  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Unregistering ...
2018-05-01 16:38:31.415  INFO 18064 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222 - registration status: 204
2018-05-01 16:38:31.416  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222 - deregister  status: 200
2018-05-01 16:38:31.420  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Completed shut down of DiscoveryClient
2018-05-01 16:38:31.422  INFO 18064 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 2147483647
2018-05-01 16:38:31.423  INFO 18064 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 0
2018-05-01 16:38:31.427  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown
2018-05-01 16:38:31.427  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans
2018-05-01 16:38:31.435  INFO 18064 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Stopped Spark@f42a1a3{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2018-05-01 16:38:31.437  INFO 18064 --- [restartedMain] org.apache.spark.ui.SparkUI              : Stopped Spark web UI at http://172.21.241.193:4041
2018-05-01 16:38:31.445  INFO 18064 --- [dispatcher-event-loop-7] o.a.s.MapOutputTrackerMasterEndpoint     : MapOutputTrackerMasterEndpoint stopped!
2018-05-01 16:38:31.452  INFO 18064 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore cleared
2018-05-01 16:38:31.452  INFO 18064 --- [restartedMain] org.apache.spark.storage.BlockManager    : BlockManager stopped
2018-05-01 16:38:31.457  INFO 18064 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : BlockManagerMaster stopped
2018-05-01 16:38:31.460  INFO 18064 --- [dispatcher-event-loop-4] rdinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2018-05-01 16:38:31.463  INFO 18064 --- [restartedMain] org.apache.spark.SparkContext            : Successfully stopped SparkContext
2018-05-01 16:38:31.466  INFO 18064 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:31.475  INFO 18064 --- [pool-7-thread-1] o.apache.spark.util.ShutdownHookManager  : Shutdown hook called
2018-05-01 16:38:31.476  INFO 18064 --- [pool-7-thread-1] o.apache.spark.util.ShutdownHookManager  : Deleting directory C:\Users\memojja\AppData\Local\Temp\spark-f27db239-928a-40c4-a8cc-9072d99b0e7e
2018-05-01 16:38:50.243  INFO 7440 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 16:38:50.254  INFO 7440 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@19cf7a59: startup date [Tue May 01 16:38:50 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@62d09928
2018-05-01 16:38:51.776  INFO 7440 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 16:38:51.800  INFO 7440 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 16:38:51.808  INFO 7440 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 16:38:52.044  INFO 7440 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 16:38:52.075  INFO 7440 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 16:38:52.209  INFO 7440 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e1d47911] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 16:38:52.249  INFO 7440 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$fdee7c0e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 16:38:52.714  INFO 7440 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 16:38:52.723  INFO 7440 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 16:38:52.724  INFO 7440 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 16:38:52.778  INFO 7440 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 16:38:52.778  INFO 7440 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2524 ms
2018-05-01 16:38:53.059  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 16:38:53.061  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 16:38:53.066  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 16:38:53.067  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 16:38:53.067  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 16:38:53.067  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 16:38:53.068  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 16:38:53.068  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 16:38:53.068  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 16:38:53.426  INFO 7440 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:53.998  INFO 7440 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:54.587  INFO 7440 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 16:38:54.588  INFO 7440 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 16:38:54.728  INFO 7440 --- [cluster-ClusterId{value='5ae86deeb11f8e1d10c3be6e', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:61}] to localhost:27017
2018-05-01 16:38:54.732  INFO 7440 --- [cluster-ClusterId{value='5ae86deeb11f8e1d10c3be6e', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=953679}
2018-05-01 16:38:54.734  INFO 7440 --- [cluster-ClusterId{value='5ae86deeb11f8e1d10c3be6e', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 16:38:55.323  INFO 7440 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 16:38:55.502  WARN 7440 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 16:38:55.637  INFO 7440 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 16:38:55.650  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 16:38:55.651  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 16:38:55.651  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 16:38:55.653  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 16:38:55.653  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 16:38:55.994  INFO 7440 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 57024.
2018-05-01 16:38:56.027  INFO 7440 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 16:38:56.042  INFO 7440 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 16:38:56.045  INFO 7440 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 16:38:56.045  INFO 7440 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 16:38:56.052  INFO 7440 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-7ed48ef5-05ab-487c-af86-f377fb3fb66b
2018-05-01 16:38:56.072  INFO 7440 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 16:38:56.122  INFO 7440 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 16:38:56.184  INFO 7440 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8621ms
2018-05-01 16:38:56.232  INFO 7440 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 16:38:56.243  INFO 7440 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8680ms
2018-05-01 16:38:56.253  WARN 7440 --- [restartedMain] org.apache.spark.util.Utils              : Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-05-01 16:38:56.260  INFO 7440 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@4340a009{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2018-05-01 16:38:56.260  INFO 7440 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4041.
2018-05-01 16:38:56.279  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@21d7bcb2{/jobs,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.280  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2f9ecd44{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.280  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5dfe92c1{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.282  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1874ba5c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.283  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@502bb12c{/stages,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.283  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3d26a894{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.284  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2b7fb60d{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.285  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3f066941{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.285  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@64221815{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.285  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7ac268bd{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.286  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@585a1015{/storage,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.286  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@558860c1{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.287  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1361f19d{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.288  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@a1313d9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.288  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@115466cd{/environment,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.288  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4034fabf{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.289  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@537f5349{/executors,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.289  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3beacb88{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.290  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@a0ccfab{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.290  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5a1be74a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.294  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@14c8d493{/static,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.295  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3326ecd9{/,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.296  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@132c0ef5{/api,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.297  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@c32a5d7{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.297  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@389cff32{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.299  INFO 7440 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4041
2018-05-01 16:38:56.398  INFO 7440 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 16:38:56.432  INFO 7440 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57037.
2018-05-01 16:38:56.433  INFO 7440 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:57037
2018-05-01 16:38:56.434  INFO 7440 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 16:38:56.436  INFO 7440 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 57037, None)
2018-05-01 16:38:56.439  INFO 7440 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:57037 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 57037, None)
2018-05-01 16:38:56.444  INFO 7440 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 57037, None)
2018-05-01 16:38:56.445  INFO 7440 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 57037, None)
2018-05-01 16:38:56.455  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3da98e35{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.501  INFO 7440 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 16:38:56.501  INFO 7440 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 16:38:56.506  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@157c9b9d{/SQL,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.507  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@54b54f93{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.509  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2e3957c9{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.510  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@72a99a5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.513  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1e9d5397{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 16:38:57.021  WARN 7440 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 16:38:57.228  INFO 7440 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 16:38:57.865  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 16:38:57.866  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 16:38:57.869  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 16:38:57.871  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 16:38:57.872  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 16:38:57.874  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 16:38:57.874  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 16:38:58.704  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.706  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 16:38:58.706  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 16:38:58.706  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.707  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.707  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:58.708  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.708  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.709  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.710  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:58.711  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.711  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 16:38:58.712  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 16:38:58.712  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.713  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:58.714  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 16:38:58.714  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.715  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 16:38:58.715  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.716  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 16:38:58.716  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 16:38:58.716  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 16:38:58.716  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.717  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 16:38:58.717  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.719  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 16:38:59.135  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@19cf7a59: startup date [Tue May 01 16:38:50 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@62d09928
2018-05-01 16:38:59.194  INFO 7440 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:59.194  INFO 7440 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:59.215  INFO 7440 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 16:38:59.243  INFO 7440 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:59.708  WARN 7440 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 16:38:59.793  WARN 7440 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 16:38:59.793  INFO 7440 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 16:38:59.799  WARN 7440 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 16:38:59.799  INFO 7440 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 16:38:59.886  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 16:38:59.895  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 16:38:59.896  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 16:38:59.899  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 16:38:59.899  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 16:38:59.900  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 16:38:59.904  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 16:38:59.919  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 16:38:59.930  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 16:38:59.944  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=19cf7a59,type=ConfigurationPropertiesRebinder]
2018-05-01 16:38:59.952  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 16:39:00.260  INFO 7440 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 16:39:00.267  INFO 7440 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 16:39:00.358  INFO 7440 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 16:39:00.358  INFO 7440 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 16:39:00.473  INFO 7440 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 16:39:00.473  INFO 7440 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 16:39:00.820  INFO 7440 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:39:00.934  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 16:39:00.934  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 16:39:00.934  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 16:39:00.935  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 16:39:00.935  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 16:39:00.935  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 16:39:00.935  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 16:39:01.097  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 16:39:01.098  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 16:39:01.100  INFO 7440 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 16:39:01.104  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525181941103 with initial instances count: 1
2018-05-01 16:39:01.125  INFO 7440 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service with eureka with status UP
2018-05-01 16:39:01.126  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525181941126, current=UP, previous=STARTING]
2018-05-01 16:39:01.128  INFO 7440 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE/ari:recomendation-service:3333: registering service...
2018-05-01 16:39:01.170  INFO 7440 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE/ari:recomendation-service:3333 - registration status: 204
2018-05-01 16:39:01.182  INFO 7440 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 16:39:01.183  INFO 7440 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 16:39:01.197  INFO 7440 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 16:39:01.211  INFO 7440 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 16:39:01.268  INFO 7440 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 16:39:01.268  INFO 7440 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 16:39:01.273  INFO 7440 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.515 seconds (JVM running for 13.71)
2018-05-01 16:39:01.637  INFO 7440 --- [RMI TCP Connection(12)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:62}] to localhost:27017
2018-05-01 16:44:00.938  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:49:00.940  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:54:00.942  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:59:00.943  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:04:00.944  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:09:00.946  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:13:01.027  INFO 12612 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:13:01.045  INFO 12612 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@31ac79e9: startup date [Tue May 01 17:13:01 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@335bc18b
2018-05-01 17:13:03.544  INFO 12612 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:13:03.572  INFO 12612 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:13:03.583  INFO 12612 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:13:03.910  INFO 12612 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:13:03.954  INFO 12612 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:13:04.138  INFO 12612 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$6662db67] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:13:04.206  INFO 12612 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$827cde64] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:13:04.901  INFO 12612 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:13:04.916  INFO 12612 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:13:04.917  INFO 12612 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:13:05.022  INFO 12612 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:13:05.024  INFO 12612 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3979 ms
2018-05-01 17:13:05.522  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:13:05.524  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:13:05.574  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:13:05.575  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:13:05.575  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:13:05.575  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:13:05.597  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:13:05.598  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:13:05.598  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:13:06.138  INFO 12612 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:13:07.197  INFO 12612 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:13:07.988  INFO 12612 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:13:07.989  INFO 12612 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:13:08.096  INFO 12612 --- [cluster-ClusterId{value='5ae875f3b11f8e31441c7ade', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:68}] to localhost:27017
2018-05-01 17:13:08.100  INFO 12612 --- [cluster-ClusterId{value='5ae875f3b11f8e31441c7ade', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=778667}
2018-05-01 17:13:08.102  INFO 12612 --- [cluster-ClusterId{value='5ae875f3b11f8e31441c7ade', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:13:08.669  INFO 12612 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:13:08.978  WARN 12612 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:13:09.173  INFO 12612 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:13:09.199  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:13:09.203  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:13:09.206  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:13:09.209  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:13:09.211  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:13:09.743  INFO 12612 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 57604.
2018-05-01 17:13:09.756  INFO 12612 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:13:09.780  INFO 12612 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:13:09.784  INFO 12612 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:13:09.784  INFO 12612 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:13:09.792  INFO 12612 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-645967dd-9191-465f-8d56-6102977d9347
2018-05-01 17:13:09.820  INFO 12612 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:13:09.862  INFO 12612 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:13:09.929  INFO 12612 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @13732ms
2018-05-01 17:13:10.025  INFO 12612 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:13:10.041  INFO 12612 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @13843ms
2018-05-01 17:13:10.084  INFO 12612 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@17e5e4a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:13:10.084  INFO 12612 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:13:10.110  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@53bac889{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.111  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4f8a86a0{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.111  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@71c1ae71{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.112  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74937371{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.112  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@48782d79{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.113  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5d99fab8{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.114  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@33f4d927{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.115  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3da7b1b3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.116  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5c5d6fc9{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.116  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@fe8e20c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.117  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5bfe5da5{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.117  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@b9775ce{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.118  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1cdf3c72{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.120  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@573336d6{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.120  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2d708cc9{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.121  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@548142c2{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.122  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7dbf94c8{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.123  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b629e1b{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.123  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3c4e5f60{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.124  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2c8e694b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.129  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b044f29{/static,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.130  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@f567d33{/,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.131  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7f5ae08d{/api,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.131  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@13eb647b{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.132  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@daea1a9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.134  INFO 12612 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:13:10.240  INFO 12612 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:13:10.271  INFO 12612 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57619.
2018-05-01 17:13:10.272  INFO 12612 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:57619
2018-05-01 17:13:10.274  INFO 12612 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:13:10.276  INFO 12612 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 57619, None)
2018-05-01 17:13:10.279  INFO 12612 --- [dispatcher-event-loop-6] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:57619 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 57619, None)
2018-05-01 17:13:10.284  INFO 12612 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 57619, None)
2018-05-01 17:13:10.285  INFO 12612 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 57619, None)
2018-05-01 17:13:10.303  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@201b2252{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.360  INFO 12612 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:13:10.360  INFO 12612 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:13:10.368  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1f88243a{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.368  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4197fe1{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.369  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b8d216b{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.369  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@38183466{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.372  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@281e5c6b{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.975  WARN 12612 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:13:11.288  INFO 12612 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:13:12.236  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:13:12.240  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:13:12.245  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:13:12.246  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:13:12.248  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:13:12.251  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:13:12.251  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:13:13.452  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:13:13.453  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.456  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:13:13.457  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:13:13.458  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.459  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.462  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.462  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.463  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.464  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:13:13.467  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:13:13.468  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.470  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:13:13.473  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:13:13.474  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.476  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:13:13.479  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:13:13.480  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.481  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:13:13.492  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:13:13.500  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:13:13.501  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:13:13.501  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.502  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:13:13.502  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.503  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:14.239  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@31ac79e9: startup date [Tue May 01 17:13:01 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@335bc18b
2018-05-01 17:13:14.343  INFO 12612 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:13:14.344  INFO 12612 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:13:14.368  INFO 12612 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:13:14.407  INFO 12612 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:13:14.955  INFO 12612 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2018-05-01 17:13:15.046  WARN 12612 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:13:15.046  INFO 12612 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:13:15.055  WARN 12612 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:13:15.055  INFO 12612 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:13:15.160  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:13:15.173  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:13:15.175  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:13:15.180  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:13:15.181  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:13:15.181  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:13:15.186  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:13:15.203  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:13:15.218  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:13:15.235  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=31ac79e9,type=ConfigurationPropertiesRebinder]
2018-05-01 17:13:15.244  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:13:15.596  INFO 12612 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:13:15.606  INFO 12612 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:13:15.718  INFO 12612 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:13:15.719  INFO 12612 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:13:15.867  INFO 12612 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:13:15.868  INFO 12612 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:13:16.240  INFO 12612 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:13:16.402  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:13:16.402  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:13:16.402  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:13:16.402  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:13:16.403  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:13:16.403  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:13:16.403  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:13:16.621  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:13:16.625  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:13:16.628  INFO 12612 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:13:16.631  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525183996630 with initial instances count: 3
2018-05-01 17:13:16.654  INFO 12612 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service with eureka with status UP
2018-05-01 17:13:16.655  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525183996655, current=UP, previous=STARTING]
2018-05-01 17:13:16.657  INFO 12612 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE/ari:recomendation-service:3333: registering service...
2018-05-01 17:13:16.720  INFO 12612 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE/ari:recomendation-service:3333 - registration status: 204
2018-05-01 17:13:16.735  INFO 12612 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:13:16.735  INFO 12612 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:13:16.753  INFO 12612 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:13:16.776  INFO 12612 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:13:16.850  INFO 12612 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:13:16.852  INFO 12612 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:13:16.859  INFO 12612 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 18.795 seconds (JVM running for 20.662)
2018-05-01 17:13:17.004  INFO 12612 --- [RMI TCP Connection(16)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:70}] to localhost:27017
2018-05-01 17:13:25.063  INFO 12612 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-01 17:13:25.063  INFO 12612 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-01 17:13:25.094  INFO 12612 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 31 ms
2018-05-01 17:13:56.823  INFO 8764 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:13:56.838  INFO 8764 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@63c0092a: startup date [Tue May 01 17:13:56 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@38ad47a
2018-05-01 17:13:58.774  INFO 8764 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:13:58.802  INFO 8764 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:13:58.812  INFO 8764 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:13:59.110  INFO 8764 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:13:59.144  INFO 8764 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:13:59.299  INFO 8764 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d890893e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:13:59.345  INFO 8764 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$f4aa8c3b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:13:59.903  INFO 8764 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:13:59.912  INFO 8764 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:13:59.913  INFO 8764 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:13:59.999  INFO 8764 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:13:59.999  INFO 8764 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3161 ms
2018-05-01 17:14:00.390  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:14:00.391  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:14:00.396  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:14:00.396  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:14:00.396  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:14:00.396  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:14:00.397  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:14:00.398  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:14:00.398  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:14:00.790  INFO 8764 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:14:01.482  INFO 8764 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:14:02.137  INFO 8764 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:14:02.138  INFO 8764 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:14:02.201  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:73}] to localhost:27017
2018-05-01 17:14:02.206  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=672395}
2018-05-01 17:14:02.208  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:14:02.661  INFO 8764 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:14:02.898  WARN 8764 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:14:03.012  INFO 8764 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:14:03.025  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:14:03.026  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:14:03.026  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:14:03.028  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:14:03.029  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:14:03.370  INFO 8764 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 57743.
2018-05-01 17:14:03.383  INFO 8764 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:14:03.400  INFO 8764 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:14:03.403  INFO 8764 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:14:03.404  INFO 8764 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:14:03.410  INFO 8764 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-5f8cf114-0c47-4095-ba57-d9ab5316b369
2018-05-01 17:14:03.438  INFO 8764 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:14:03.477  INFO 8764 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:14:03.536  INFO 8764 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @9796ms
2018-05-01 17:14:03.587  INFO 8764 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:14:03.600  INFO 8764 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @9860ms
2018-05-01 17:14:03.618  INFO 8764 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@d726fe2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:14:03.619  INFO 8764 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:14:03.641  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2fd3fade{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.642  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2d46da4e{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.643  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@66cbec08{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.644  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@67726af3{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.645  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2fed91fb{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.646  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4878900c{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.647  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@56e96418{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.648  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@66e55da3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.649  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4ada8456{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.649  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74a6eaf9{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.650  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@44a17250{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.650  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2adcfe09{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.651  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@22bba45{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.652  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@57bb9253{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.653  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7eaeb805{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.654  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3fc13601{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.654  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@53f4bc42{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.654  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@49e2b800{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.655  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6d8f261b{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.655  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6142f5de{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.659  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@121df492{/static,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.660  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6a95c00c{/,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.662  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@357f6e60{/api,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.662  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5c1b4f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.663  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@14b54d2{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.664  INFO 8764 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:14:03.748  INFO 8764 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:14:03.776  INFO 8764 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57756.
2018-05-01 17:14:03.777  INFO 8764 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:57756
2018-05-01 17:14:03.778  INFO 8764 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:14:03.780  INFO 8764 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 57756, None)
2018-05-01 17:14:03.783  INFO 8764 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:57756 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 57756, None)
2018-05-01 17:14:03.789  INFO 8764 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 57756, None)
2018-05-01 17:14:03.789  INFO 8764 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 57756, None)
2018-05-01 17:14:03.807  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7d68b8e1{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.857  INFO 8764 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:14:03.858  INFO 8764 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:14:03.863  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@bc3bab8{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.863  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@667cb762{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.864  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@79da3990{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.864  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3e108e56{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.866  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@364afa97{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:14:04.480  WARN 8764 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:14:04.759  INFO 8764 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:14:05.642  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:14:05.645  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:14:05.649  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:14:05.650  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:14:05.651  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:14:05.654  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:14:05.654  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:14:06.631  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:14:06.632  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:14:06.634  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:14:06.634  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:14:06.634  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:14:06.636  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:14:06.638  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.638  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.639  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:14:06.639  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.640  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.641  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.641  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:14:06.642  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:14:06.642  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.643  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.644  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:14:06.645  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:14:06.645  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.645  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:14:06.645  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.646  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:14:06.646  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:14:06.646  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.647  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.647  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:07.098  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@63c0092a: startup date [Tue May 01 17:13:56 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@38ad47a
2018-05-01 17:14:07.179  INFO 8764 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:14:07.179  INFO 8764 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:14:07.221  INFO 8764 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:14:07.257  INFO 8764 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:14:07.745  WARN 8764 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:14:07.866  WARN 8764 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:14:07.867  INFO 8764 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:14:07.880  WARN 8764 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:14:07.880  INFO 8764 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:14:08.001  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:14:08.012  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:14:08.012  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:14:08.016  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:14:08.017  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:14:08.017  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:14:08.023  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:14:08.045  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:14:08.058  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:14:08.072  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=63c0092a,type=ConfigurationPropertiesRebinder]
2018-05-01 17:14:08.077  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:14:08.398  INFO 8764 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:14:08.405  INFO 8764 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:14:08.501  INFO 8764 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:14:08.502  INFO 8764 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:14:08.602  INFO 8764 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:14:08.603  INFO 8764 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:14:08.881  INFO 8764 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:14:08.995  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:14:08.996  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:14:08.996  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:14:08.996  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:14:08.997  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:14:08.997  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:14:08.997  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:14:09.174  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:14:09.176  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:14:09.178  INFO 8764 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:14:09.181  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525184049181 with initial instances count: 3
2018-05-01 17:14:09.201  INFO 8764 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:14:09.204  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525184049203, current=UP, previous=STARTING]
2018-05-01 17:14:09.205  INFO 8764 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:14:09.243  INFO 8764 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:14:09.258  INFO 8764 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:14:09.258  INFO 8764 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:14:09.273  INFO 8764 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:14:09.287  INFO 8764 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:14:09.344  INFO 8764 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:14:09.345  INFO 8764 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:14:09.350  INFO 8764 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 14.386 seconds (JVM running for 15.61)
2018-05-01 17:14:09.639  INFO 8764 --- [RMI TCP Connection(10)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:75}] to localhost:27017
2018-05-01 17:14:12.447  INFO 8764 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-01 17:14:12.448  INFO 8764 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-01 17:14:12.482  INFO 8764 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 33 ms
2018-05-01 17:15:53.236  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Exception in monitor thread while connecting to server localhost:27017

com.mongodb.MongoSocketOpenException: Exception opening socket
	at com.mongodb.connection.SocketStream.open(SocketStream.java:63) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.InternalStreamConnection.open(InternalStreamConnection.java:115) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:127) ~[mongodb-driver-core-3.4.3.jar:na]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_131]
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at com.mongodb.connection.SocketStreamHelper.initialize(SocketStreamHelper.java:57) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.SocketStream.open(SocketStream.java:58) ~[mongodb-driver-core-3.4.3.jar:na]
	... 3 common frames omitted

2018-05-01 17:16:03.239  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:2}] to localhost:27017
2018-05-01 17:16:03.241  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=465778}
2018-05-01 17:19:09.000  INFO 8764 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:24:09.001  INFO 8764 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:25:55.290  INFO 15012 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:25:55.302  INFO 15012 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@63c0092a: startup date [Tue May 01 17:25:55 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@38ad47a
2018-05-01 17:25:56.907  INFO 15012 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:25:56.930  INFO 15012 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:25:56.938  INFO 15012 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:25:57.172  INFO 15012 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:25:57.201  INFO 15012 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:25:57.328  INFO 15012 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d890893e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:25:57.374  INFO 15012 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$f4aa8c3b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:25:57.890  INFO 15012 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:25:57.902  INFO 15012 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:25:57.903  INFO 15012 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:25:57.963  INFO 15012 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:25:57.964  INFO 15012 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2662 ms
2018-05-01 17:25:58.280  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:25:58.282  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:25:58.288  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:25:58.288  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:25:58.288  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:25:58.288  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:25:58.289  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:25:58.290  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:25:58.290  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:25:58.655  INFO 15012 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:25:59.252  INFO 15012 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:25:59.825  INFO 15012 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:25:59.825  INFO 15012 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:25:59.874  INFO 15012 --- [cluster-ClusterId{value='5ae878f7b11f8e3aa467c390', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:6}] to localhost:27017
2018-05-01 17:25:59.877  INFO 15012 --- [cluster-ClusterId{value='5ae878f7b11f8e3aa467c390', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=625778}
2018-05-01 17:25:59.878  INFO 15012 --- [cluster-ClusterId{value='5ae878f7b11f8e3aa467c390', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:26:00.246  INFO 15012 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:26:00.395  WARN 15012 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:26:00.514  INFO 15012 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:26:00.528  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:26:00.529  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:26:00.530  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:26:00.532  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:26:00.532  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:26:00.838  INFO 15012 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 58040.
2018-05-01 17:26:00.851  INFO 15012 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:26:00.867  INFO 15012 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:26:00.869  INFO 15012 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:26:00.870  INFO 15012 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:26:00.876  INFO 15012 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-190dc532-83c2-4e0f-ad47-2a5a388db107
2018-05-01 17:26:00.898  INFO 15012 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:26:00.932  INFO 15012 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:26:00.998  INFO 15012 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8185ms
2018-05-01 17:26:01.052  INFO 15012 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:26:01.065  INFO 15012 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8252ms
2018-05-01 17:26:01.081  INFO 15012 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@7bcca24{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:26:01.082  INFO 15012 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:26:01.102  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1ae7cf7a{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.103  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2032c3cd{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.103  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7bb13f69{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.104  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4ada8456{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.104  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74a6eaf9{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.105  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@44a17250{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.106  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2adcfe09{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.107  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@57bb9253{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.107  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7eaeb805{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.108  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3fc13601{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.108  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@53f4bc42{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.109  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@49e2b800{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.109  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6d8f261b{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.111  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6142f5de{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.112  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@121df492{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.112  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3a231cbc{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.112  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74cf71a3{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.113  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@55f67994{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.113  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@e8f35a1{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.114  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@d4dcc04{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.118  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b396769{/static,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.118  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2b9ecfae{/,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.119  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6de1fe2d{/api,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.119  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@17b822c3{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.119  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@61d345fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.121  INFO 15012 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:26:01.197  INFO 15012 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:26:01.221  INFO 15012 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58053.
2018-05-01 17:26:01.222  INFO 15012 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:58053
2018-05-01 17:26:01.223  INFO 15012 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:26:01.225  INFO 15012 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 58053, None)
2018-05-01 17:26:01.228  INFO 15012 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:58053 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 58053, None)
2018-05-01 17:26:01.231  INFO 15012 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 58053, None)
2018-05-01 17:26:01.232  INFO 15012 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 58053, None)
2018-05-01 17:26:01.245  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@566ff32c{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.312  INFO 15012 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:26:01.312  INFO 15012 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:26:01.316  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@51b313c5{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.317  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@73f54035{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.317  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@760a646e{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.317  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7550714e{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.318  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6d12c6f3{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.803  WARN 15012 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:26:01.997  INFO 15012 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:26:02.589  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:26:02.591  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:26:02.594  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:26:02.595  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:26:02.596  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:26:02.598  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:26:02.598  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:26:03.416  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:26:03.418  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.420  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:26:03.421  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:26:03.421  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.422  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.423  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.424  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.424  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:26:03.425  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.426  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:26:03.426  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:26:03.427  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:26:03.427  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.428  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:26:03.428  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.429  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:26:03.429  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:26:03.430  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.431  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:26:03.431  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:26:03.431  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.431  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.432  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:26:03.432  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.433  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:26:03.856  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@63c0092a: startup date [Tue May 01 17:25:55 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@38ad47a
2018-05-01 17:26:03.927  INFO 15012 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:26:03.927  INFO 15012 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:26:03.964  INFO 15012 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:26:03.994  INFO 15012 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:26:04.437  WARN 15012 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:26:04.512  WARN 15012 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:26:04.512  INFO 15012 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:26:04.518  WARN 15012 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:26:04.518  INFO 15012 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:26:04.606  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:26:04.618  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:26:04.618  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:26:04.622  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:26:04.623  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:26:04.623  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:26:04.627  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:26:04.642  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:26:04.653  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:26:04.669  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=63c0092a,type=ConfigurationPropertiesRebinder]
2018-05-01 17:26:04.676  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:26:05.006  INFO 15012 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:26:05.015  INFO 15012 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:26:05.107  INFO 15012 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:26:05.108  INFO 15012 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:26:05.227  INFO 15012 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:26:05.227  INFO 15012 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:26:05.500  INFO 15012 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:26:05.607  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:26:05.607  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:26:05.607  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:26:05.607  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:26:05.609  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:26:05.609  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:26:05.609  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:26:05.770  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:26:05.773  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:26:05.776  INFO 15012 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:26:05.779  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525184765779 with initial instances count: 6
2018-05-01 17:26:05.799  INFO 15012 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:26:05.800  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525184765800, current=UP, previous=STARTING]
2018-05-01 17:26:05.802  INFO 15012 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:26:05.844  INFO 15012 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:26:05.859  INFO 15012 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:26:05.859  INFO 15012 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:26:05.875  INFO 15012 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:26:05.892  INFO 15012 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:26:05.952  INFO 15012 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:26:05.953  INFO 15012 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:26:05.958  INFO 15012 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.026 seconds (JVM running for 13.145)
2018-05-01 17:26:06.351  INFO 15012 --- [RMI TCP Connection(8)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:7}] to localhost:27017
2018-05-01 17:31:05.611  INFO 15012 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:32:42.459  INFO 6088 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:32:42.492  INFO 6088 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@33caa67f: startup date [Tue May 01 17:32:42 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@7e14480a
2018-05-01 17:32:44.075  INFO 6088 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:32:44.099  INFO 6088 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:32:44.106  INFO 6088 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:32:44.323  INFO 6088 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:32:44.353  INFO 6088 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:32:44.462  INFO 6088 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b3783e11] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:32:44.505  INFO 6088 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$cf92410e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:32:44.953  INFO 6088 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:32:44.963  INFO 6088 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:32:44.964  INFO 6088 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:32:45.018  INFO 6088 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:32:45.018  INFO 6088 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2527 ms
2018-05-01 17:32:45.294  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:32:45.296  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:32:45.301  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:32:45.301  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:32:45.301  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:32:45.301  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:32:45.302  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:32:45.303  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:32:45.303  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:32:45.639  INFO 6088 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:32:46.284  INFO 6088 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:32:46.963  INFO 6088 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:32:46.964  INFO 6088 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:32:47.025  INFO 6088 --- [cluster-ClusterId{value='5ae87a8eb11f8e17c808bb2c', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:10}] to localhost:27017
2018-05-01 17:32:47.028  INFO 6088 --- [cluster-ClusterId{value='5ae87a8eb11f8e17c808bb2c', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=571655}
2018-05-01 17:32:47.030  INFO 6088 --- [cluster-ClusterId{value='5ae87a8eb11f8e17c808bb2c', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:32:47.383  INFO 6088 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:32:47.540  WARN 6088 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:32:47.640  INFO 6088 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:32:47.654  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:32:47.655  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:32:47.656  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:32:47.657  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:32:47.658  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:32:47.957  INFO 6088 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 58220.
2018-05-01 17:32:47.970  INFO 6088 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:32:47.988  INFO 6088 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:32:47.991  INFO 6088 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:32:47.991  INFO 6088 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:32:47.998  INFO 6088 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-2f0f458b-6edf-494e-a9f1-91a65a53d8bf
2018-05-01 17:32:48.022  INFO 6088 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:32:48.053  INFO 6088 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:32:48.109  INFO 6088 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8136ms
2018-05-01 17:32:48.156  INFO 6088 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:32:48.168  INFO 6088 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8195ms
2018-05-01 17:32:48.187  INFO 6088 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@2d702d9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:32:48.188  INFO 6088 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:32:48.205  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@754a0ed{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.205  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4f11dc0e{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.206  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1990727b{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.206  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4dad37d0{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.207  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2656ef73{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.208  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@30239e5e{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.208  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@52e5e4a6{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.210  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@38a0e878{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.210  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@79023539{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.211  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6cccefbe{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.211  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7b653709{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.212  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@22e929ac{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.212  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@50fd9fdb{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.213  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@ec59c1d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.214  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@21747226{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.214  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3525f069{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.215  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@73e511a7{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.215  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b66b1d6{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.216  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5474199f{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.216  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2e35f62b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.220  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6f44301a{/static,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.221  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2b764cc{/,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.222  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1d9d214b{/api,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.222  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@333228c8{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.222  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@58717e98{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.224  INFO 6088 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:32:48.298  INFO 6088 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:32:48.321  INFO 6088 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58233.
2018-05-01 17:32:48.321  INFO 6088 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:58233
2018-05-01 17:32:48.323  INFO 6088 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:32:48.324  INFO 6088 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 58233, None)
2018-05-01 17:32:48.327  INFO 6088 --- [dispatcher-event-loop-1] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:58233 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 58233, None)
2018-05-01 17:32:48.330  INFO 6088 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 58233, None)
2018-05-01 17:32:48.330  INFO 6088 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 58233, None)
2018-05-01 17:32:48.341  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1f3d0894{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.406  INFO 6088 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:32:48.406  INFO 6088 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:32:48.413  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4bc05f1d{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.414  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5467a4c4{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.415  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@533b8586{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.415  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@590658fe{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.416  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5d51a7a4{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.905  WARN 6088 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:32:49.104  INFO 6088 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:32:49.695  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.List<com.jcombat.profile.model.Movie> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:32:49.698  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:32:49.702  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:32:49.703  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:32:49.703  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:32:49.705  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:32:49.706  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:32:50.525  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.526  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.528  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.528  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:32:50.529  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:32:50.529  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.531  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:32:50.531  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:32:50.532  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:32:50.532  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.534  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:32:50.535  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:32:50.536  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:32:50.536  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.536  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.537  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:32:50.538  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:32:50.538  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.539  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:32:50.539  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:32:50.539  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:32:50.540  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.540  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.540  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:32:50.540  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.541  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.964  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@33caa67f: startup date [Tue May 01 17:32:42 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@7e14480a
2018-05-01 17:32:51.033  INFO 6088 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:32:51.033  INFO 6088 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:32:51.055  INFO 6088 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:32:51.098  INFO 6088 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:32:51.542  WARN 6088 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:32:51.617  WARN 6088 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:32:51.617  INFO 6088 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:32:51.622  WARN 6088 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:32:51.622  INFO 6088 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:32:51.703  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:32:51.712  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:32:51.712  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:32:51.715  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:32:51.716  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:32:51.716  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:32:51.719  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:32:51.733  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:32:51.744  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:32:51.758  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=33caa67f,type=ConfigurationPropertiesRebinder]
2018-05-01 17:32:51.765  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:32:52.110  INFO 6088 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:32:52.117  INFO 6088 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:32:52.226  INFO 6088 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:32:52.226  INFO 6088 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:32:52.388  INFO 6088 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:32:52.389  INFO 6088 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:32:52.693  INFO 6088 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:32:52.821  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:32:52.821  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:32:52.821  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:32:52.821  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:32:52.822  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:32:52.822  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:32:52.822  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:32:53.007  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:32:53.009  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:32:53.013  INFO 6088 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:32:53.017  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525185173017 with initial instances count: 6
2018-05-01 17:32:53.043  INFO 6088 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:32:53.045  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525185173045, current=UP, previous=STARTING]
2018-05-01 17:32:53.047  INFO 6088 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:32:53.093  INFO 6088 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:32:53.107  INFO 6088 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:32:53.108  INFO 6088 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:32:53.126  INFO 6088 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:32:53.144  INFO 6088 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:32:53.207  INFO 6088 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:32:53.209  INFO 6088 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:32:53.215  INFO 6088 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.287 seconds (JVM running for 13.242)
2018-05-01 17:32:53.447  INFO 6088 --- [RMI TCP Connection(10)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:11}] to localhost:27017
2018-05-01 17:35:33.537  INFO 17168 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:35:33.548  INFO 17168 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3187c937: startup date [Tue May 01 17:35:33 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@dadaa75
2018-05-01 17:35:34.969  INFO 17168 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:35:34.995  INFO 17168 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:35:35.005  INFO 17168 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:35:35.250  INFO 17168 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:35:35.279  INFO 17168 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:35:35.384  INFO 17168 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$4bb8b089] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:35:35.420  INFO 17168 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$67d2b386] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:35:35.865  INFO 17168 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:35:35.874  INFO 17168 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:35:35.875  INFO 17168 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:35:35.932  INFO 17168 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:35:35.932  INFO 17168 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2384 ms
2018-05-01 17:35:36.227  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:35:36.229  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:35:36.233  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:35:36.233  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:35:36.233  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:35:36.233  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:35:36.234  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:35:36.235  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:35:36.235  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:35:36.553  INFO 17168 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:35:37.126  INFO 17168 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:35:37.612  INFO 17168 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:35:37.613  INFO 17168 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:35:37.661  INFO 17168 --- [cluster-ClusterId{value='5ae87b39b11f8e431050e167', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:14}] to localhost:27017
2018-05-01 17:35:37.664  INFO 17168 --- [cluster-ClusterId{value='5ae87b39b11f8e431050e167', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=614321}
2018-05-01 17:35:37.666  INFO 17168 --- [cluster-ClusterId{value='5ae87b39b11f8e431050e167', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:35:38.023  INFO 17168 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:35:38.188  WARN 17168 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:35:38.284  INFO 17168 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:35:38.295  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:35:38.296  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:35:38.297  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:35:38.298  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:35:38.298  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:35:38.586  INFO 17168 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 58350.
2018-05-01 17:35:38.598  INFO 17168 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:35:38.613  INFO 17168 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:35:38.616  INFO 17168 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:35:38.616  INFO 17168 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:35:38.622  INFO 17168 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-c509552c-c791-43f2-9f74-21dc8e870480
2018-05-01 17:35:38.642  INFO 17168 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:35:38.676  INFO 17168 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:35:38.726  INFO 17168 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @7544ms
2018-05-01 17:35:38.769  INFO 17168 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:35:38.780  INFO 17168 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @7598ms
2018-05-01 17:35:38.797  INFO 17168 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@733bbcb1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:35:38.798  INFO 17168 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:35:38.825  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7f9b16b7{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.825  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@22e929ac{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.826  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@50fd9fdb{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.826  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1dcb3503{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.827  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@17a2a3f4{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.829  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7102a8e3{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.829  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@715ab12c{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.831  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@708311ec{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.831  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1b087a05{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.832  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@720406f{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.833  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5e25f09d{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.833  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1589c6e1{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.834  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@498105cb{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.837  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7c58ed47{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.837  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@80899b9{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.838  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@78bbf7b2{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.838  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4e3ee072{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.839  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3a3c432d{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.840  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3a909cd2{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.841  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@168e626a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.846  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@d7a5470{/static,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.846  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@27b66b5e{/,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.847  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1d17cb79{/api,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.848  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@51dc0f6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.848  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5c21f9cc{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.850  INFO 17168 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:35:38.936  INFO 17168 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:35:38.958  INFO 17168 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58363.
2018-05-01 17:35:38.959  INFO 17168 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:58363
2018-05-01 17:35:38.960  INFO 17168 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:35:38.961  INFO 17168 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 58363, None)
2018-05-01 17:35:38.964  INFO 17168 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:58363 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 58363, None)
2018-05-01 17:35:38.967  INFO 17168 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 58363, None)
2018-05-01 17:35:38.967  INFO 17168 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 58363, None)
2018-05-01 17:35:38.978  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1b40a5ff{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.022  INFO 17168 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:35:39.023  INFO 17168 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:35:39.028  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3c9ff59a{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.029  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@b7b7041{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.029  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@548b8f96{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.030  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3faa751f{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.031  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@62150053{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.556  WARN 17168 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:35:39.740  INFO 17168 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:35:40.327  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.List<com.jcombat.profile.model.Movie> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:35:40.329  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[GET]}" onto public com.jcombat.profile.model.Movie com.jcombat.profile.controller.RecomendationController.asdsa() throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:35:40.330  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:35:40.333  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:35:40.334  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:35:40.334  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:35:40.336  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:35:40.336  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:35:41.112  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:35:41.112  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.113  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.113  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.114  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:35:41.114  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.115  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.115  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:35:41.116  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.117  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:35:41.119  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:35:41.119  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:35:41.119  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.120  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:35:41.120  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:35:41.121  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.121  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.121  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.122  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:35:41.123  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:35:41.123  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:35:41.123  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:35:41.124  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.124  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.124  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:35:41.126  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:35:41.555  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3187c937: startup date [Tue May 01 17:35:33 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@dadaa75
2018-05-01 17:35:41.618  INFO 17168 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:35:41.619  INFO 17168 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:35:41.640  INFO 17168 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:35:41.681  INFO 17168 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:35:42.112  WARN 17168 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:35:42.185  WARN 17168 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:35:42.186  INFO 17168 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:35:42.191  WARN 17168 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:35:42.191  INFO 17168 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:35:42.277  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:35:42.287  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:35:42.287  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:35:42.290  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:35:42.290  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:35:42.292  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:35:42.294  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:35:42.307  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:35:42.317  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:35:42.330  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=3187c937,type=ConfigurationPropertiesRebinder]
2018-05-01 17:35:42.338  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:35:42.671  INFO 17168 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:35:42.678  INFO 17168 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:35:42.776  INFO 17168 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:35:42.776  INFO 17168 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:35:42.875  INFO 17168 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:35:42.876  INFO 17168 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:35:43.165  INFO 17168 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:35:43.275  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:35:43.275  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:35:43.275  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:35:43.276  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:35:43.276  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:35:43.277  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:35:43.277  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:35:43.452  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:35:43.456  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:35:43.458  INFO 17168 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:35:43.461  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525185343461 with initial instances count: 6
2018-05-01 17:35:43.485  INFO 17168 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:35:43.485  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525185343485, current=UP, previous=STARTING]
2018-05-01 17:35:43.487  INFO 17168 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:35:43.529  INFO 17168 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:35:43.543  INFO 17168 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:35:43.544  INFO 17168 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:35:43.560  INFO 17168 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:35:43.574  INFO 17168 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:35:43.629  INFO 17168 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:35:43.630  INFO 17168 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:35:43.634  INFO 17168 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 11.433 seconds (JVM running for 12.452)
2018-05-01 17:35:44.114  INFO 17168 --- [RMI TCP Connection(2)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:15}] to localhost:27017
2018-05-01 17:37:55.062  INFO 17168 --- [http-nio-3333-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-01 17:37:55.062  INFO 17168 --- [http-nio-3333-exec-2] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-01 17:37:55.088  INFO 17168 --- [http-nio-3333-exec-2] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 25 ms
2018-05-01 17:40:43.280  INFO 17168 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:42:02.425  WARN 17168 --- [http-nio-3333-exec-2] o.apache.spark.sql.SparkSession$Builder  : Using an existing SparkSession; some configuration may not take effect.
2018-05-01 17:42:02.541  INFO 17168 --- [http-nio-3333-exec-2] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0 stored as values in memory (estimated size 248.0 B, free 1990.8 MB)
2018-05-01 17:42:02.662  INFO 17168 --- [http-nio-3333-exec-2] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0_piece0 stored as bytes in memory (estimated size 419.0 B, free 1990.8 MB)
2018-05-01 17:42:02.665  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_0_piece0 in memory on 172.21.241.193:58363 (size: 419.0 B, free: 1990.8 MB)
2018-05-01 17:42:02.671  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Created broadcast 0 from broadcast at MongoSpark.scala:536
2018-05-01 17:42:02.879  INFO 17168 --- [http-nio-3333-exec-2] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:42:02.887  INFO 17168 --- [http-nio-3333-exec-2] org.mongodb.driver.cluster               : Cluster description not yet available. Waiting for 30000 ms before timing out
2018-05-01 17:42:02.890  INFO 17168 --- [cluster-ClusterId{value='5ae87cbab11f8e431050e168', description='null'}-127.0.0.1:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:20}] to 127.0.0.1:27017
2018-05-01 17:42:02.892  INFO 17168 --- [cluster-ClusterId{value='5ae87cbab11f8e431050e168', description='null'}-127.0.0.1:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=259950}
2018-05-01 17:42:02.893  INFO 17168 --- [http-nio-3333-exec-2] c.m.spark.connection.MongoClientCache    : Creating MongoClient: [127.0.0.1:27017]
2018-05-01 17:42:02.906  INFO 17168 --- [http-nio-3333-exec-2] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:21}] to 127.0.0.1:27017
2018-05-01 17:42:04.059  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: collect at RecomendationServiceImpl.java:86
2018-05-01 17:42:04.076  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 0 (collect at RecomendationServiceImpl.java:86) with 66 output partitions
2018-05-01 17:42:04.077  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 0 (collect at RecomendationServiceImpl.java:86)
2018-05-01 17:42:04.077  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:42:04.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:42:04.088  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 0 (MapPartitionsRDD[1] at map at RecomendationServiceImpl.java:83), which has no missing parents
2018-05-01 17:42:04.115  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 1990.8 MB)
2018-05-01 17:42:04.118  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1990.8 MB)
2018-05-01 17:42:04.119  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_1_piece0 in memory on 172.21.241.193:58363 (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 17:42:04.121  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:04.133  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 66 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at RecomendationServiceImpl.java:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-05-01 17:42:04.134  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 0.0 with 66 tasks
2018-05-01 17:42:04.184  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 4987 bytes)
2018-05-01 17:42:04.195  INFO 17168 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Running task 0.0 in stage 0.0 (TID 0)
2018-05-01 17:42:04.270  INFO 17168 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 0.0 (TID 0). 708 bytes result sent to driver
2018-05-01 17:42:04.273  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 4999 bytes)
2018-05-01 17:42:04.273  INFO 17168 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Running task 1.0 in stage 0.0 (TID 1)
2018-05-01 17:42:04.280  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 0.0 (TID 0) in 112 ms on localhost (executor driver) (1/66)
2018-05-01 17:42:04.947  INFO 17168 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 0.0 (TID 1). 429884 bytes result sent to driver
2018-05-01 17:42:04.948  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 5005 bytes)
2018-05-01 17:42:04.948  INFO 17168 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Running task 2.0 in stage 0.0 (TID 2)
2018-05-01 17:42:04.966  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 0.0 (TID 1) in 694 ms on localhost (executor driver) (2/66)
2018-05-01 17:42:05.695  INFO 17168 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 0.0 (TID 2). 432580 bytes result sent to driver
2018-05-01 17:42:05.696  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 5004 bytes)
2018-05-01 17:42:05.696  INFO 17168 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Running task 3.0 in stage 0.0 (TID 3)
2018-05-01 17:42:05.712  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 0.0 (TID 2) in 764 ms on localhost (executor driver) (3/66)
2018-05-01 17:42:06.345  INFO 17168 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 0.0 (TID 3). 433940 bytes result sent to driver
2018-05-01 17:42:06.346  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 5003 bytes)
2018-05-01 17:42:06.346  INFO 17168 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Running task 4.0 in stage 0.0 (TID 4)
2018-05-01 17:42:06.370  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 0.0 (TID 3) in 674 ms on localhost (executor driver) (4/66)
2018-05-01 17:42:07.000  INFO 17168 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Finished task 4.0 in stage 0.0 (TID 4). 423957 bytes result sent to driver
2018-05-01 17:42:07.000  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 5003 bytes)
2018-05-01 17:42:07.001  INFO 17168 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Running task 5.0 in stage 0.0 (TID 5)
2018-05-01 17:42:07.019  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 4.0 in stage 0.0 (TID 4) in 673 ms on localhost (executor driver) (5/66)
2018-05-01 17:42:07.722  INFO 17168 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Finished task 5.0 in stage 0.0 (TID 5). 418098 bytes result sent to driver
2018-05-01 17:42:07.723  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 5003 bytes)
2018-05-01 17:42:07.723  INFO 17168 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Running task 6.0 in stage 0.0 (TID 6)
2018-05-01 17:42:07.738  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 5.0 in stage 0.0 (TID 5) in 738 ms on localhost (executor driver) (6/66)
2018-05-01 17:42:08.348  INFO 17168 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Finished task 6.0 in stage 0.0 (TID 6). 416945 bytes result sent to driver
2018-05-01 17:42:08.348  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 5003 bytes)
2018-05-01 17:42:08.349  INFO 17168 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Running task 7.0 in stage 0.0 (TID 7)
2018-05-01 17:42:08.366  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 6.0 in stage 0.0 (TID 6) in 644 ms on localhost (executor driver) (7/66)
2018-05-01 17:42:08.986  INFO 17168 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Finished task 7.0 in stage 0.0 (TID 7). 426842 bytes result sent to driver
2018-05-01 17:42:08.987  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 5003 bytes)
2018-05-01 17:42:08.988  INFO 17168 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Running task 8.0 in stage 0.0 (TID 8)
2018-05-01 17:42:09.003  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 7.0 in stage 0.0 (TID 7) in 655 ms on localhost (executor driver) (8/66)
2018-05-01 17:42:09.573  INFO 17168 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Finished task 8.0 in stage 0.0 (TID 8). 430736 bytes result sent to driver
2018-05-01 17:42:09.574  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 5003 bytes)
2018-05-01 17:42:09.574  INFO 17168 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Running task 9.0 in stage 0.0 (TID 9)
2018-05-01 17:42:09.591  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 8.0 in stage 0.0 (TID 8) in 603 ms on localhost (executor driver) (9/66)
2018-05-01 17:42:10.161  INFO 17168 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Finished task 9.0 in stage 0.0 (TID 9). 432112 bytes result sent to driver
2018-05-01 17:42:10.162  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 5003 bytes)
2018-05-01 17:42:10.162  INFO 17168 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Running task 10.0 in stage 0.0 (TID 10)
2018-05-01 17:42:10.182  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 9.0 in stage 0.0 (TID 9) in 608 ms on localhost (executor driver) (10/66)
2018-05-01 17:42:10.734  INFO 17168 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Finished task 10.0 in stage 0.0 (TID 10). 428533 bytes result sent to driver
2018-05-01 17:42:10.735  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 5003 bytes)
2018-05-01 17:42:10.735  INFO 17168 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Running task 11.0 in stage 0.0 (TID 11)
2018-05-01 17:42:10.750  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 10.0 in stage 0.0 (TID 10) in 588 ms on localhost (executor driver) (11/66)
2018-05-01 17:42:11.355  INFO 17168 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Finished task 11.0 in stage 0.0 (TID 11). 432916 bytes result sent to driver
2018-05-01 17:42:11.357  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 5003 bytes)
2018-05-01 17:42:11.357  INFO 17168 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Running task 12.0 in stage 0.0 (TID 12)
2018-05-01 17:42:11.374  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 11.0 in stage 0.0 (TID 11) in 639 ms on localhost (executor driver) (12/66)
2018-05-01 17:42:11.936  INFO 17168 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Finished task 12.0 in stage 0.0 (TID 12). 431975 bytes result sent to driver
2018-05-01 17:42:11.936  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 5003 bytes)
2018-05-01 17:42:11.937  INFO 17168 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Running task 13.0 in stage 0.0 (TID 13)
2018-05-01 17:42:11.951  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 12.0 in stage 0.0 (TID 12) in 596 ms on localhost (executor driver) (13/66)
2018-05-01 17:42:12.547  INFO 17168 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Finished task 13.0 in stage 0.0 (TID 13). 430518 bytes result sent to driver
2018-05-01 17:42:12.548  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 5003 bytes)
2018-05-01 17:42:12.548  INFO 17168 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Running task 14.0 in stage 0.0 (TID 14)
2018-05-01 17:42:12.569  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 13.0 in stage 0.0 (TID 13) in 633 ms on localhost (executor driver) (14/66)
2018-05-01 17:42:13.126  INFO 17168 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Finished task 14.0 in stage 0.0 (TID 14). 433458 bytes result sent to driver
2018-05-01 17:42:13.127  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 5003 bytes)
2018-05-01 17:42:13.127  INFO 17168 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Running task 15.0 in stage 0.0 (TID 15)
2018-05-01 17:42:13.142  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 14.0 in stage 0.0 (TID 14) in 594 ms on localhost (executor driver) (15/66)
2018-05-01 17:42:13.683  INFO 17168 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Finished task 15.0 in stage 0.0 (TID 15). 433639 bytes result sent to driver
2018-05-01 17:42:13.684  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 5003 bytes)
2018-05-01 17:42:13.684  INFO 17168 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Running task 16.0 in stage 0.0 (TID 16)
2018-05-01 17:42:13.701  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 15.0 in stage 0.0 (TID 15) in 574 ms on localhost (executor driver) (16/66)
2018-05-01 17:42:14.236  INFO 17168 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Finished task 16.0 in stage 0.0 (TID 16). 429584 bytes result sent to driver
2018-05-01 17:42:14.237  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 5002 bytes)
2018-05-01 17:42:14.237  INFO 17168 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Running task 17.0 in stage 0.0 (TID 17)
2018-05-01 17:42:14.255  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 16.0 in stage 0.0 (TID 16) in 571 ms on localhost (executor driver) (17/66)
2018-05-01 17:42:14.805  INFO 17168 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Finished task 17.0 in stage 0.0 (TID 17). 434264 bytes result sent to driver
2018-05-01 17:42:14.806  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 5002 bytes)
2018-05-01 17:42:14.806  INFO 17168 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Running task 18.0 in stage 0.0 (TID 18)
2018-05-01 17:42:14.821  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 17.0 in stage 0.0 (TID 17) in 585 ms on localhost (executor driver) (18/66)
2018-05-01 17:42:15.381  INFO 17168 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Finished task 18.0 in stage 0.0 (TID 18). 431426 bytes result sent to driver
2018-05-01 17:42:15.382  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 5003 bytes)
2018-05-01 17:42:15.382  INFO 17168 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Running task 19.0 in stage 0.0 (TID 19)
2018-05-01 17:42:15.398  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 18.0 in stage 0.0 (TID 18) in 592 ms on localhost (executor driver) (19/66)
2018-05-01 17:42:15.959  INFO 17168 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Finished task 19.0 in stage 0.0 (TID 19). 435226 bytes result sent to driver
2018-05-01 17:42:15.960  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 5003 bytes)
2018-05-01 17:42:15.960  INFO 17168 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Running task 20.0 in stage 0.0 (TID 20)
2018-05-01 17:42:15.975  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 19.0 in stage 0.0 (TID 19) in 593 ms on localhost (executor driver) (20/66)
2018-05-01 17:42:16.500  INFO 17168 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Finished task 20.0 in stage 0.0 (TID 20). 434347 bytes result sent to driver
2018-05-01 17:42:16.500  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 5003 bytes)
2018-05-01 17:42:16.500  INFO 17168 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Running task 21.0 in stage 0.0 (TID 21)
2018-05-01 17:42:16.515  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 20.0 in stage 0.0 (TID 20) in 555 ms on localhost (executor driver) (21/66)
2018-05-01 17:42:17.091  INFO 17168 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Finished task 21.0 in stage 0.0 (TID 21). 428428 bytes result sent to driver
2018-05-01 17:42:17.091  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 22.0 in stage 0.0 (TID 22, localhost, executor driver, partition 22, ANY, 5003 bytes)
2018-05-01 17:42:17.092  INFO 17168 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Running task 22.0 in stage 0.0 (TID 22)
2018-05-01 17:42:17.107  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 21.0 in stage 0.0 (TID 21) in 607 ms on localhost (executor driver) (22/66)
2018-05-01 17:42:17.627  INFO 17168 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Finished task 22.0 in stage 0.0 (TID 22). 434997 bytes result sent to driver
2018-05-01 17:42:17.628  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 23.0 in stage 0.0 (TID 23, localhost, executor driver, partition 23, ANY, 5003 bytes)
2018-05-01 17:42:17.628  INFO 17168 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Running task 23.0 in stage 0.0 (TID 23)
2018-05-01 17:42:17.647  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 22.0 in stage 0.0 (TID 22) in 556 ms on localhost (executor driver) (23/66)
2018-05-01 17:42:18.205  INFO 17168 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Finished task 23.0 in stage 0.0 (TID 23). 430843 bytes result sent to driver
2018-05-01 17:42:18.206  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 24.0 in stage 0.0 (TID 24, localhost, executor driver, partition 24, ANY, 5003 bytes)
2018-05-01 17:42:18.206  INFO 17168 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Running task 24.0 in stage 0.0 (TID 24)
2018-05-01 17:42:18.224  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 23.0 in stage 0.0 (TID 23) in 596 ms on localhost (executor driver) (24/66)
2018-05-01 17:42:18.743  INFO 17168 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Finished task 24.0 in stage 0.0 (TID 24). 429256 bytes result sent to driver
2018-05-01 17:42:18.744  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 25.0 in stage 0.0 (TID 25, localhost, executor driver, partition 25, ANY, 5003 bytes)
2018-05-01 17:42:18.744  INFO 17168 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Running task 25.0 in stage 0.0 (TID 25)
2018-05-01 17:42:18.759  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 24.0 in stage 0.0 (TID 24) in 553 ms on localhost (executor driver) (25/66)
2018-05-01 17:42:19.330  INFO 17168 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Finished task 25.0 in stage 0.0 (TID 25). 432294 bytes result sent to driver
2018-05-01 17:42:19.330  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 26.0 in stage 0.0 (TID 26, localhost, executor driver, partition 26, ANY, 5003 bytes)
2018-05-01 17:42:19.331  INFO 17168 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Running task 26.0 in stage 0.0 (TID 26)
2018-05-01 17:42:19.345  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 25.0 in stage 0.0 (TID 25) in 601 ms on localhost (executor driver) (26/66)
2018-05-01 17:42:19.875  INFO 17168 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Finished task 26.0 in stage 0.0 (TID 26). 433194 bytes result sent to driver
2018-05-01 17:42:19.875  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 27.0 in stage 0.0 (TID 27, localhost, executor driver, partition 27, ANY, 5003 bytes)
2018-05-01 17:42:19.875  INFO 17168 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Running task 27.0 in stage 0.0 (TID 27)
2018-05-01 17:42:19.895  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 26.0 in stage 0.0 (TID 26) in 565 ms on localhost (executor driver) (27/66)
2018-05-01 17:42:20.443  INFO 17168 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Finished task 27.0 in stage 0.0 (TID 27). 433416 bytes result sent to driver
2018-05-01 17:42:20.443  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 28.0 in stage 0.0 (TID 28, localhost, executor driver, partition 28, ANY, 5003 bytes)
2018-05-01 17:42:20.443  INFO 17168 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Running task 28.0 in stage 0.0 (TID 28)
2018-05-01 17:42:20.459  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 27.0 in stage 0.0 (TID 27) in 584 ms on localhost (executor driver) (28/66)
2018-05-01 17:42:20.997  INFO 17168 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Finished task 28.0 in stage 0.0 (TID 28). 431277 bytes result sent to driver
2018-05-01 17:42:20.998  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 29.0 in stage 0.0 (TID 29, localhost, executor driver, partition 29, ANY, 5003 bytes)
2018-05-01 17:42:20.998  INFO 17168 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Running task 29.0 in stage 0.0 (TID 29)
2018-05-01 17:42:21.012  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 28.0 in stage 0.0 (TID 28) in 569 ms on localhost (executor driver) (29/66)
2018-05-01 17:42:21.550  INFO 17168 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Finished task 29.0 in stage 0.0 (TID 29). 432490 bytes result sent to driver
2018-05-01 17:42:21.551  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 30.0 in stage 0.0 (TID 30, localhost, executor driver, partition 30, ANY, 5003 bytes)
2018-05-01 17:42:21.551  INFO 17168 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Running task 30.0 in stage 0.0 (TID 30)
2018-05-01 17:42:21.597  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 29.0 in stage 0.0 (TID 29) in 600 ms on localhost (executor driver) (30/66)
2018-05-01 17:42:22.127  INFO 17168 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Finished task 30.0 in stage 0.0 (TID 30). 431401 bytes result sent to driver
2018-05-01 17:42:22.129  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 31.0 in stage 0.0 (TID 31, localhost, executor driver, partition 31, ANY, 5003 bytes)
2018-05-01 17:42:22.129  INFO 17168 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Running task 31.0 in stage 0.0 (TID 31)
2018-05-01 17:42:22.145  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 30.0 in stage 0.0 (TID 30) in 595 ms on localhost (executor driver) (31/66)
2018-05-01 17:42:22.683  INFO 17168 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Finished task 31.0 in stage 0.0 (TID 31). 434098 bytes result sent to driver
2018-05-01 17:42:22.684  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 32.0 in stage 0.0 (TID 32, localhost, executor driver, partition 32, ANY, 5002 bytes)
2018-05-01 17:42:22.684  INFO 17168 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Running task 32.0 in stage 0.0 (TID 32)
2018-05-01 17:42:22.699  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 31.0 in stage 0.0 (TID 31) in 571 ms on localhost (executor driver) (32/66)
2018-05-01 17:42:23.231  INFO 17168 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Finished task 32.0 in stage 0.0 (TID 32). 432096 bytes result sent to driver
2018-05-01 17:42:23.231  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 33.0 in stage 0.0 (TID 33, localhost, executor driver, partition 33, ANY, 5002 bytes)
2018-05-01 17:42:23.232  INFO 17168 --- [Executor task launch worker for task 33] org.apache.spark.executor.Executor       : Running task 33.0 in stage 0.0 (TID 33)
2018-05-01 17:42:23.247  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 32.0 in stage 0.0 (TID 32) in 563 ms on localhost (executor driver) (33/66)
2018-05-01 17:42:23.778  INFO 17168 --- [Executor task launch worker for task 33] org.apache.spark.executor.Executor       : Finished task 33.0 in stage 0.0 (TID 33). 433257 bytes result sent to driver
2018-05-01 17:42:23.779  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 34.0 in stage 0.0 (TID 34, localhost, executor driver, partition 34, ANY, 5002 bytes)
2018-05-01 17:42:23.779  INFO 17168 --- [Executor task launch worker for task 34] org.apache.spark.executor.Executor       : Running task 34.0 in stage 0.0 (TID 34)
2018-05-01 17:42:23.795  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 33.0 in stage 0.0 (TID 33) in 564 ms on localhost (executor driver) (34/66)
2018-05-01 17:42:24.365  INFO 17168 --- [Executor task launch worker for task 34] org.apache.spark.executor.Executor       : Finished task 34.0 in stage 0.0 (TID 34). 433019 bytes result sent to driver
2018-05-01 17:42:24.365  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 35.0 in stage 0.0 (TID 35, localhost, executor driver, partition 35, ANY, 5002 bytes)
2018-05-01 17:42:24.366  INFO 17168 --- [Executor task launch worker for task 35] org.apache.spark.executor.Executor       : Running task 35.0 in stage 0.0 (TID 35)
2018-05-01 17:42:24.382  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 34.0 in stage 0.0 (TID 34) in 604 ms on localhost (executor driver) (35/66)
2018-05-01 17:42:24.903  INFO 17168 --- [Executor task launch worker for task 35] org.apache.spark.executor.Executor       : Finished task 35.0 in stage 0.0 (TID 35). 431659 bytes result sent to driver
2018-05-01 17:42:24.904  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 36.0 in stage 0.0 (TID 36, localhost, executor driver, partition 36, ANY, 5002 bytes)
2018-05-01 17:42:24.904  INFO 17168 --- [Executor task launch worker for task 36] org.apache.spark.executor.Executor       : Running task 36.0 in stage 0.0 (TID 36)
2018-05-01 17:42:24.919  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 35.0 in stage 0.0 (TID 35) in 554 ms on localhost (executor driver) (36/66)
2018-05-01 17:42:25.455  INFO 17168 --- [Executor task launch worker for task 36] org.apache.spark.executor.Executor       : Finished task 36.0 in stage 0.0 (TID 36). 435545 bytes result sent to driver
2018-05-01 17:42:25.456  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 37.0 in stage 0.0 (TID 37, localhost, executor driver, partition 37, ANY, 5002 bytes)
2018-05-01 17:42:25.456  INFO 17168 --- [Executor task launch worker for task 37] org.apache.spark.executor.Executor       : Running task 37.0 in stage 0.0 (TID 37)
2018-05-01 17:42:25.472  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 36.0 in stage 0.0 (TID 36) in 569 ms on localhost (executor driver) (37/66)
2018-05-01 17:42:25.999  INFO 17168 --- [Executor task launch worker for task 37] org.apache.spark.executor.Executor       : Finished task 37.0 in stage 0.0 (TID 37). 432635 bytes result sent to driver
2018-05-01 17:42:26.000  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 38.0 in stage 0.0 (TID 38, localhost, executor driver, partition 38, ANY, 5003 bytes)
2018-05-01 17:42:26.000  INFO 17168 --- [Executor task launch worker for task 38] org.apache.spark.executor.Executor       : Running task 38.0 in stage 0.0 (TID 38)
2018-05-01 17:42:26.015  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 37.0 in stage 0.0 (TID 37) in 559 ms on localhost (executor driver) (38/66)
2018-05-01 17:42:26.558  INFO 17168 --- [Executor task launch worker for task 38] org.apache.spark.executor.Executor       : Finished task 38.0 in stage 0.0 (TID 38). 433731 bytes result sent to driver
2018-05-01 17:42:26.559  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 39.0 in stage 0.0 (TID 39, localhost, executor driver, partition 39, ANY, 5003 bytes)
2018-05-01 17:42:26.559  INFO 17168 --- [Executor task launch worker for task 39] org.apache.spark.executor.Executor       : Running task 39.0 in stage 0.0 (TID 39)
2018-05-01 17:42:26.574  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 38.0 in stage 0.0 (TID 38) in 574 ms on localhost (executor driver) (39/66)
2018-05-01 17:42:27.155  INFO 17168 --- [Executor task launch worker for task 39] org.apache.spark.executor.Executor       : Finished task 39.0 in stage 0.0 (TID 39). 430075 bytes result sent to driver
2018-05-01 17:42:27.157  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 40.0 in stage 0.0 (TID 40, localhost, executor driver, partition 40, ANY, 5003 bytes)
2018-05-01 17:42:27.157  INFO 17168 --- [Executor task launch worker for task 40] org.apache.spark.executor.Executor       : Running task 40.0 in stage 0.0 (TID 40)
2018-05-01 17:42:27.172  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 39.0 in stage 0.0 (TID 39) in 614 ms on localhost (executor driver) (40/66)
2018-05-01 17:42:27.707  INFO 17168 --- [Executor task launch worker for task 40] org.apache.spark.executor.Executor       : Finished task 40.0 in stage 0.0 (TID 40). 432889 bytes result sent to driver
2018-05-01 17:42:27.707  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 41.0 in stage 0.0 (TID 41, localhost, executor driver, partition 41, ANY, 5003 bytes)
2018-05-01 17:42:27.708  INFO 17168 --- [Executor task launch worker for task 41] org.apache.spark.executor.Executor       : Running task 41.0 in stage 0.0 (TID 41)
2018-05-01 17:42:27.723  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 40.0 in stage 0.0 (TID 40) in 567 ms on localhost (executor driver) (41/66)
2018-05-01 17:42:28.250  INFO 17168 --- [Executor task launch worker for task 41] org.apache.spark.executor.Executor       : Finished task 41.0 in stage 0.0 (TID 41). 431707 bytes result sent to driver
2018-05-01 17:42:28.250  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 42.0 in stage 0.0 (TID 42, localhost, executor driver, partition 42, ANY, 5003 bytes)
2018-05-01 17:42:28.250  INFO 17168 --- [Executor task launch worker for task 42] org.apache.spark.executor.Executor       : Running task 42.0 in stage 0.0 (TID 42)
2018-05-01 17:42:28.266  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 41.0 in stage 0.0 (TID 41) in 559 ms on localhost (executor driver) (42/66)
2018-05-01 17:42:28.805  INFO 17168 --- [Executor task launch worker for task 42] org.apache.spark.executor.Executor       : Finished task 42.0 in stage 0.0 (TID 42). 432035 bytes result sent to driver
2018-05-01 17:42:28.806  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 43.0 in stage 0.0 (TID 43, localhost, executor driver, partition 43, ANY, 5003 bytes)
2018-05-01 17:42:28.806  INFO 17168 --- [Executor task launch worker for task 43] org.apache.spark.executor.Executor       : Running task 43.0 in stage 0.0 (TID 43)
2018-05-01 17:42:28.822  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 42.0 in stage 0.0 (TID 42) in 572 ms on localhost (executor driver) (43/66)
2018-05-01 17:42:29.341  INFO 17168 --- [Executor task launch worker for task 43] org.apache.spark.executor.Executor       : Finished task 43.0 in stage 0.0 (TID 43). 428969 bytes result sent to driver
2018-05-01 17:42:29.341  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 44.0 in stage 0.0 (TID 44, localhost, executor driver, partition 44, ANY, 5003 bytes)
2018-05-01 17:42:29.342  INFO 17168 --- [Executor task launch worker for task 44] org.apache.spark.executor.Executor       : Running task 44.0 in stage 0.0 (TID 44)
2018-05-01 17:42:29.358  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 43.0 in stage 0.0 (TID 43) in 552 ms on localhost (executor driver) (44/66)
2018-05-01 17:42:29.948  INFO 17168 --- [Executor task launch worker for task 44] org.apache.spark.executor.Executor       : Finished task 44.0 in stage 0.0 (TID 44). 432725 bytes result sent to driver
2018-05-01 17:42:29.949  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 45.0 in stage 0.0 (TID 45, localhost, executor driver, partition 45, ANY, 5003 bytes)
2018-05-01 17:42:29.949  INFO 17168 --- [Executor task launch worker for task 45] org.apache.spark.executor.Executor       : Running task 45.0 in stage 0.0 (TID 45)
2018-05-01 17:42:29.967  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 44.0 in stage 0.0 (TID 44) in 626 ms on localhost (executor driver) (45/66)
2018-05-01 17:42:30.484  INFO 17168 --- [Executor task launch worker for task 45] org.apache.spark.executor.Executor       : Finished task 45.0 in stage 0.0 (TID 45). 430122 bytes result sent to driver
2018-05-01 17:42:30.485  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 46.0 in stage 0.0 (TID 46, localhost, executor driver, partition 46, ANY, 5003 bytes)
2018-05-01 17:42:30.485  INFO 17168 --- [Executor task launch worker for task 46] org.apache.spark.executor.Executor       : Running task 46.0 in stage 0.0 (TID 46)
2018-05-01 17:42:30.500  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 45.0 in stage 0.0 (TID 45) in 551 ms on localhost (executor driver) (46/66)
2018-05-01 17:42:31.042  INFO 17168 --- [Executor task launch worker for task 46] org.apache.spark.executor.Executor       : Finished task 46.0 in stage 0.0 (TID 46). 430137 bytes result sent to driver
2018-05-01 17:42:31.043  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 47.0 in stage 0.0 (TID 47, localhost, executor driver, partition 47, ANY, 5003 bytes)
2018-05-01 17:42:31.043  INFO 17168 --- [Executor task launch worker for task 47] org.apache.spark.executor.Executor       : Running task 47.0 in stage 0.0 (TID 47)
2018-05-01 17:42:31.058  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 46.0 in stage 0.0 (TID 46) in 573 ms on localhost (executor driver) (47/66)
2018-05-01 17:42:31.572  INFO 17168 --- [Executor task launch worker for task 47] org.apache.spark.executor.Executor       : Finished task 47.0 in stage 0.0 (TID 47). 433553 bytes result sent to driver
2018-05-01 17:42:31.573  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 48.0 in stage 0.0 (TID 48, localhost, executor driver, partition 48, ANY, 5003 bytes)
2018-05-01 17:42:31.573  INFO 17168 --- [Executor task launch worker for task 48] org.apache.spark.executor.Executor       : Running task 48.0 in stage 0.0 (TID 48)
2018-05-01 17:42:31.588  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 47.0 in stage 0.0 (TID 47) in 545 ms on localhost (executor driver) (48/66)
2018-05-01 17:42:32.141  INFO 17168 --- [Executor task launch worker for task 48] org.apache.spark.executor.Executor       : Finished task 48.0 in stage 0.0 (TID 48). 431478 bytes result sent to driver
2018-05-01 17:42:32.142  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 49.0 in stage 0.0 (TID 49, localhost, executor driver, partition 49, ANY, 5003 bytes)
2018-05-01 17:42:32.142  INFO 17168 --- [Executor task launch worker for task 49] org.apache.spark.executor.Executor       : Running task 49.0 in stage 0.0 (TID 49)
2018-05-01 17:42:32.157  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 48.0 in stage 0.0 (TID 48) in 584 ms on localhost (executor driver) (49/66)
2018-05-01 17:42:32.726  INFO 17168 --- [Executor task launch worker for task 49] org.apache.spark.executor.Executor       : Finished task 49.0 in stage 0.0 (TID 49). 432786 bytes result sent to driver
2018-05-01 17:42:32.727  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 50.0 in stage 0.0 (TID 50, localhost, executor driver, partition 50, ANY, 5003 bytes)
2018-05-01 17:42:32.727  INFO 17168 --- [Executor task launch worker for task 50] org.apache.spark.executor.Executor       : Running task 50.0 in stage 0.0 (TID 50)
2018-05-01 17:42:32.743  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 49.0 in stage 0.0 (TID 49) in 601 ms on localhost (executor driver) (50/66)
2018-05-01 17:42:33.276  INFO 17168 --- [Executor task launch worker for task 50] org.apache.spark.executor.Executor       : Finished task 50.0 in stage 0.0 (TID 50). 430368 bytes result sent to driver
2018-05-01 17:42:33.276  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 51.0 in stage 0.0 (TID 51, localhost, executor driver, partition 51, ANY, 5002 bytes)
2018-05-01 17:42:33.277  INFO 17168 --- [Executor task launch worker for task 51] org.apache.spark.executor.Executor       : Running task 51.0 in stage 0.0 (TID 51)
2018-05-01 17:42:33.292  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 50.0 in stage 0.0 (TID 50) in 565 ms on localhost (executor driver) (51/66)
2018-05-01 17:42:33.846  INFO 17168 --- [Executor task launch worker for task 51] org.apache.spark.executor.Executor       : Finished task 51.0 in stage 0.0 (TID 51). 435039 bytes result sent to driver
2018-05-01 17:42:33.846  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 52.0 in stage 0.0 (TID 52, localhost, executor driver, partition 52, ANY, 5002 bytes)
2018-05-01 17:42:33.846  INFO 17168 --- [Executor task launch worker for task 52] org.apache.spark.executor.Executor       : Running task 52.0 in stage 0.0 (TID 52)
2018-05-01 17:42:33.861  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 51.0 in stage 0.0 (TID 51) in 585 ms on localhost (executor driver) (52/66)
2018-05-01 17:42:34.392  INFO 17168 --- [Executor task launch worker for task 52] org.apache.spark.executor.Executor       : Finished task 52.0 in stage 0.0 (TID 52). 431702 bytes result sent to driver
2018-05-01 17:42:34.392  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 53.0 in stage 0.0 (TID 53, localhost, executor driver, partition 53, ANY, 5002 bytes)
2018-05-01 17:42:34.393  INFO 17168 --- [Executor task launch worker for task 53] org.apache.spark.executor.Executor       : Running task 53.0 in stage 0.0 (TID 53)
2018-05-01 17:42:34.409  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 52.0 in stage 0.0 (TID 52) in 563 ms on localhost (executor driver) (53/66)
2018-05-01 17:42:34.994  INFO 17168 --- [Executor task launch worker for task 53] org.apache.spark.executor.Executor       : Finished task 53.0 in stage 0.0 (TID 53). 431628 bytes result sent to driver
2018-05-01 17:42:34.995  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 54.0 in stage 0.0 (TID 54, localhost, executor driver, partition 54, ANY, 5002 bytes)
2018-05-01 17:42:34.995  INFO 17168 --- [Executor task launch worker for task 54] org.apache.spark.executor.Executor       : Running task 54.0 in stage 0.0 (TID 54)
2018-05-01 17:42:35.011  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 53.0 in stage 0.0 (TID 53) in 619 ms on localhost (executor driver) (54/66)
2018-05-01 17:42:35.541  INFO 17168 --- [Executor task launch worker for task 54] org.apache.spark.executor.Executor       : Finished task 54.0 in stage 0.0 (TID 54). 428857 bytes result sent to driver
2018-05-01 17:42:35.542  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 55.0 in stage 0.0 (TID 55, localhost, executor driver, partition 55, ANY, 5003 bytes)
2018-05-01 17:42:35.542  INFO 17168 --- [Executor task launch worker for task 55] org.apache.spark.executor.Executor       : Running task 55.0 in stage 0.0 (TID 55)
2018-05-01 17:42:35.556  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 54.0 in stage 0.0 (TID 54) in 561 ms on localhost (executor driver) (55/66)
2018-05-01 17:42:36.101  INFO 17168 --- [Executor task launch worker for task 55] org.apache.spark.executor.Executor       : Finished task 55.0 in stage 0.0 (TID 55). 431970 bytes result sent to driver
2018-05-01 17:42:36.102  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 56.0 in stage 0.0 (TID 56, localhost, executor driver, partition 56, ANY, 5003 bytes)
2018-05-01 17:42:36.102  INFO 17168 --- [Executor task launch worker for task 56] org.apache.spark.executor.Executor       : Running task 56.0 in stage 0.0 (TID 56)
2018-05-01 17:42:36.119  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 55.0 in stage 0.0 (TID 55) in 577 ms on localhost (executor driver) (56/66)
2018-05-01 17:42:36.638  INFO 17168 --- [Executor task launch worker for task 56] org.apache.spark.executor.Executor       : Finished task 56.0 in stage 0.0 (TID 56). 431035 bytes result sent to driver
2018-05-01 17:42:36.639  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 57.0 in stage 0.0 (TID 57, localhost, executor driver, partition 57, ANY, 5003 bytes)
2018-05-01 17:42:36.639  INFO 17168 --- [Executor task launch worker for task 57] org.apache.spark.executor.Executor       : Running task 57.0 in stage 0.0 (TID 57)
2018-05-01 17:42:36.654  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 56.0 in stage 0.0 (TID 56) in 552 ms on localhost (executor driver) (57/66)
2018-05-01 17:42:37.199  INFO 17168 --- [Executor task launch worker for task 57] org.apache.spark.executor.Executor       : Finished task 57.0 in stage 0.0 (TID 57). 433983 bytes result sent to driver
2018-05-01 17:42:37.200  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 58.0 in stage 0.0 (TID 58, localhost, executor driver, partition 58, ANY, 5003 bytes)
2018-05-01 17:42:37.200  INFO 17168 --- [Executor task launch worker for task 58] org.apache.spark.executor.Executor       : Running task 58.0 in stage 0.0 (TID 58)
2018-05-01 17:42:37.215  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 57.0 in stage 0.0 (TID 57) in 577 ms on localhost (executor driver) (58/66)
2018-05-01 17:42:37.789  INFO 17168 --- [Executor task launch worker for task 58] org.apache.spark.executor.Executor       : Finished task 58.0 in stage 0.0 (TID 58). 431075 bytes result sent to driver
2018-05-01 17:42:37.790  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 59.0 in stage 0.0 (TID 59, localhost, executor driver, partition 59, ANY, 5003 bytes)
2018-05-01 17:42:37.790  INFO 17168 --- [Executor task launch worker for task 59] org.apache.spark.executor.Executor       : Running task 59.0 in stage 0.0 (TID 59)
2018-05-01 17:42:37.806  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 58.0 in stage 0.0 (TID 58) in 607 ms on localhost (executor driver) (59/66)
2018-05-01 17:42:38.350  INFO 17168 --- [Executor task launch worker for task 59] org.apache.spark.executor.Executor       : Finished task 59.0 in stage 0.0 (TID 59). 433207 bytes result sent to driver
2018-05-01 17:42:38.350  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 60.0 in stage 0.0 (TID 60, localhost, executor driver, partition 60, ANY, 5003 bytes)
2018-05-01 17:42:38.351  INFO 17168 --- [Executor task launch worker for task 60] org.apache.spark.executor.Executor       : Running task 60.0 in stage 0.0 (TID 60)
2018-05-01 17:42:38.367  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 59.0 in stage 0.0 (TID 59) in 577 ms on localhost (executor driver) (60/66)
2018-05-01 17:42:38.886  INFO 17168 --- [Executor task launch worker for task 60] org.apache.spark.executor.Executor       : Finished task 60.0 in stage 0.0 (TID 60). 432171 bytes result sent to driver
2018-05-01 17:42:38.887  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 61.0 in stage 0.0 (TID 61, localhost, executor driver, partition 61, ANY, 5003 bytes)
2018-05-01 17:42:38.887  INFO 17168 --- [Executor task launch worker for task 61] org.apache.spark.executor.Executor       : Running task 61.0 in stage 0.0 (TID 61)
2018-05-01 17:42:38.903  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 60.0 in stage 0.0 (TID 60) in 553 ms on localhost (executor driver) (61/66)
2018-05-01 17:42:39.443  INFO 17168 --- [Executor task launch worker for task 61] org.apache.spark.executor.Executor       : Finished task 61.0 in stage 0.0 (TID 61). 432524 bytes result sent to driver
2018-05-01 17:42:39.443  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 62.0 in stage 0.0 (TID 62, localhost, executor driver, partition 62, ANY, 5003 bytes)
2018-05-01 17:42:39.443  INFO 17168 --- [Executor task launch worker for task 62] org.apache.spark.executor.Executor       : Running task 62.0 in stage 0.0 (TID 62)
2018-05-01 17:42:39.458  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 61.0 in stage 0.0 (TID 61) in 571 ms on localhost (executor driver) (62/66)
2018-05-01 17:42:40.034  INFO 17168 --- [Executor task launch worker for task 62] org.apache.spark.executor.Executor       : Finished task 62.0 in stage 0.0 (TID 62). 431615 bytes result sent to driver
2018-05-01 17:42:40.034  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 63.0 in stage 0.0 (TID 63, localhost, executor driver, partition 63, ANY, 5003 bytes)
2018-05-01 17:42:40.035  INFO 17168 --- [Executor task launch worker for task 63] org.apache.spark.executor.Executor       : Running task 63.0 in stage 0.0 (TID 63)
2018-05-01 17:42:40.052  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 62.0 in stage 0.0 (TID 62) in 609 ms on localhost (executor driver) (63/66)
2018-05-01 17:42:40.598  INFO 17168 --- [Executor task launch worker for task 63] org.apache.spark.executor.Executor       : Finished task 63.0 in stage 0.0 (TID 63). 429910 bytes result sent to driver
2018-05-01 17:42:40.599  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 64.0 in stage 0.0 (TID 64, localhost, executor driver, partition 64, ANY, 5003 bytes)
2018-05-01 17:42:40.599  INFO 17168 --- [Executor task launch worker for task 64] org.apache.spark.executor.Executor       : Running task 64.0 in stage 0.0 (TID 64)
2018-05-01 17:42:40.614  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 63.0 in stage 0.0 (TID 63) in 580 ms on localhost (executor driver) (64/66)
2018-05-01 17:42:41.136  INFO 17168 --- [Executor task launch worker for task 64] org.apache.spark.executor.Executor       : Finished task 64.0 in stage 0.0 (TID 64). 434975 bytes result sent to driver
2018-05-01 17:42:41.137  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 65.0 in stage 0.0 (TID 65, localhost, executor driver, partition 65, ANY, 4992 bytes)
2018-05-01 17:42:41.137  INFO 17168 --- [Executor task launch worker for task 65] org.apache.spark.executor.Executor       : Running task 65.0 in stage 0.0 (TID 65)
2018-05-01 17:42:41.141  INFO 17168 --- [Executor task launch worker for task 65] org.apache.spark.executor.Executor       : Finished task 65.0 in stage 0.0 (TID 65). 777 bytes result sent to driver
2018-05-01 17:42:41.142  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 65.0 in stage 0.0 (TID 65) in 6 ms on localhost (executor driver) (65/66)
2018-05-01 17:42:41.151  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 64.0 in stage 0.0 (TID 64) in 552 ms on localhost (executor driver) (66/66)
2018-05-01 17:42:41.152  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-05-01 17:42:41.153  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 0 (collect at RecomendationServiceImpl.java:86) finished in 36.998 s
2018-05-01 17:42:41.159  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 0 finished: collect at RecomendationServiceImpl.java:86, took 37.099721 s
2018-05-01 17:42:41.344  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:240
2018-05-01 17:42:41.346  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 1 (isEmpty at ALS.scala:240) with 1 output partitions
2018-05-01 17:42:41.346  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1 (isEmpty at ALS.scala:240)
2018-05-01 17:42:41.346  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:42:41.349  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:42:41.349  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1 (UnionRDD[5] at union at RecomendationServiceImpl.java:77), which has no missing parents
2018-05-01 17:42:41.353  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.8 MB)
2018-05-01 17:42:41.355  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.8 MB)
2018-05-01 17:42:41.357  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_2_piece0 in memory on 172.21.241.193:58363 (size: 2.1 KB, free: 1990.8 MB)
2018-05-01 17:42:41.357  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:41.358  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1 (UnionRDD[5] at union at RecomendationServiceImpl.java:77) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:41.358  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1.0 with 1 tasks
2018-05-01 17:42:44.286  WARN 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Stage 1 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:42:44.286  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:42:44.287  INFO 17168 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1.0 (TID 66)
2018-05-01 17:42:45.889  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_1_piece0 on 172.21.241.193:58363 in memory (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 17:42:45.894  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_0_piece0 on 172.21.241.193:58363 in memory (size: 419.0 B, free: 1990.8 MB)
2018-05-01 17:42:46.188  INFO 17168 --- [pool-25-thread-1] c.m.spark.connection.MongoClientCache    : Closing MongoClient: [127.0.0.1:27017]
2018-05-01 17:42:46.190  INFO 17168 --- [pool-25-thread-1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:21}] to 127.0.0.1:27017 because the pool has been closed.
2018-05-01 17:42:47.028  INFO 17168 --- [Executor task launch worker for task 66] o.a.spark.storage.memory.MemoryStore     : Block rdd_3_0 stored as values in memory (estimated size 36.0 MB, free 1954.8 MB)
2018-05-01 17:42:47.029  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_3_0 in memory on 172.21.241.193:58363 (size: 36.0 MB, free: 1954.8 MB)
2018-05-01 17:42:47.037  INFO 17168 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 66:
[rdd_3_0]
2018-05-01 17:42:47.040  INFO 17168 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1.0 (TID 66). 1551 bytes result sent to driver
2018-05-01 17:42:47.042  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1.0 (TID 66) in 5683 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:47.042  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-05-01 17:42:47.043  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1 (isEmpty at ALS.scala:240) finished in 5.684 s
2018-05-01 17:42:47.044  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 1 finished: isEmpty at ALS.scala:240, took 5.700280 s
2018-05-01 17:42:47.059  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:843
2018-05-01 17:42:47.060  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 2 (isEmpty at ALS.scala:843) with 1 output partitions
2018-05-01 17:42:47.060  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 2 (isEmpty at ALS.scala:843)
2018-05-01 17:42:47.061  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:42:47.061  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:42:47.061  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 2 (MapPartitionsRDD[6] at map at ALS.scala:256), which has no missing parents
2018-05-01 17:42:47.063  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1954.8 MB)
2018-05-01 17:42:47.065  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1954.8 MB)
2018-05-01 17:42:47.066  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_3_piece0 in memory on 172.21.241.193:58363 (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 17:42:47.066  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:47.066  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:47.067  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 2.0 with 1 tasks
2018-05-01 17:42:51.196  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_2_piece0 on 172.21.241.193:58363 in memory (size: 2.1 KB, free: 1954.8 MB)
2018-05-01 17:42:51.520  WARN 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 2 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:42:51.520  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 2.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:42:51.520  INFO 17168 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : Running task 0.0 in stage 2.0 (TID 67)
2018-05-01 17:42:52.509  INFO 17168 --- [Executor task launch worker for task 67] org.apache.spark.storage.BlockManager    : Found block rdd_3_0 locally
2018-05-01 17:42:52.512  INFO 17168 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 67:
[rdd_3_0]
2018-05-01 17:42:52.513  INFO 17168 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 2.0 (TID 67). 1089 bytes result sent to driver
2018-05-01 17:42:52.516  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 2.0 (TID 67) in 5447 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:52.516  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-05-01 17:42:52.516  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 2 (isEmpty at ALS.scala:843) finished in 5.448 s
2018-05-01 17:42:52.516  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 2 finished: isEmpty at ALS.scala:843, took 5.456916 s
2018-05-01 17:42:52.591  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:857
2018-05-01 17:42:52.596  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 7 (mapPartitions at ALS.scala:1101)
2018-05-01 17:42:52.596  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 10 (map at ALS.scala:1344)
2018-05-01 17:42:52.597  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 3 (count at ALS.scala:857) with 1 output partitions
2018-05-01 17:42:52.598  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 5 (count at ALS.scala:857)
2018-05-01 17:42:52.598  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 4)
2018-05-01 17:42:52.598  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 4)
2018-05-01 17:42:52.600  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 3 (MapPartitionsRDD[7] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-05-01 17:42:52.604  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 1954.8 MB)
2018-05-01 17:42:52.606  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1954.8 MB)
2018-05-01 17:42:52.607  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_4_piece0 in memory on 172.21.241.193:58363 (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 17:42:52.608  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:52.610  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[7] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:42:52.610  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 3.0 with 2 tasks
2018-05-01 17:42:55.529  WARN 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 3 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:42:55.530  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 3.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427802 bytes)
2018-05-01 17:42:55.530  INFO 17168 --- [Executor task launch worker for task 68] org.apache.spark.executor.Executor       : Running task 0.0 in stage 3.0 (TID 68)
2018-05-01 17:42:56.644  INFO 17168 --- [Executor task launch worker for task 68] org.apache.spark.storage.BlockManager    : Found block rdd_3_0 locally
2018-05-01 17:42:56.981  INFO 17168 --- [Executor task launch worker for task 68] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 3.0 (TID 68). 1070 bytes result sent to driver
2018-05-01 17:42:56.982  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 3.0 (TID 69, localhost, executor driver, partition 1, PROCESS_LOCAL, 5072 bytes)
2018-05-01 17:42:56.983  INFO 17168 --- [Executor task launch worker for task 69] org.apache.spark.executor.Executor       : Running task 1.0 in stage 3.0 (TID 69)
2018-05-01 17:42:56.985  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 3.0 (TID 68) in 4375 ms on localhost (executor driver) (1/2)
2018-05-01 17:42:57.004  INFO 17168 --- [Executor task launch worker for task 69] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 3.0 (TID 69). 812 bytes result sent to driver
2018-05-01 17:42:57.005  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 3.0 (TID 69) in 24 ms on localhost (executor driver) (2/2)
2018-05-01 17:42:57.006  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-05-01 17:42:57.006  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 3 (mapPartitions at ALS.scala:1101) finished in 4.396 s
2018-05-01 17:42:57.006  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:57.007  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:57.009  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 5, ShuffleMapStage 4)
2018-05-01 17:42:57.009  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:57.014  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:42:57.018  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 1954.8 MB)
2018-05-01 17:42:57.020  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1954.8 MB)
2018-05-01 17:42:57.021  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_5_piece0 in memory on 172.21.241.193:58363 (size: 3.7 KB, free: 1954.8 MB)
2018-05-01 17:42:57.022  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:57.022  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:42:57.023  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 4.0 with 2 tasks
2018-05-01 17:42:57.024  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 4.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:42:57.024  INFO 17168 --- [Executor task launch worker for task 70] org.apache.spark.executor.Executor       : Running task 0.0 in stage 4.0 (TID 70)
2018-05-01 17:42:57.036  INFO 17168 --- [Executor task launch worker for task 70] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 2 blocks
2018-05-01 17:42:57.037  INFO 17168 --- [Executor task launch worker for task 70] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 3 ms
2018-05-01 17:42:57.048  INFO 17168 --- [Executor task launch worker for task 70] o.a.spark.storage.memory.MemoryStore     : Block rdd_9_0 stored as values in memory (estimated size 16.0 B, free 1954.8 MB)
2018-05-01 17:42:57.049  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_9_0 in memory on 172.21.241.193:58363 (size: 16.0 B, free: 1954.8 MB)
2018-05-01 17:42:57.056  INFO 17168 --- [Executor task launch worker for task 70] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 4.0 (TID 70). 1852 bytes result sent to driver
2018-05-01 17:42:57.057  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 4.0 (TID 71, localhost, executor driver, partition 1, ANY, 4610 bytes)
2018-05-01 17:42:57.057  INFO 17168 --- [Executor task launch worker for task 71] org.apache.spark.executor.Executor       : Running task 1.0 in stage 4.0 (TID 71)
2018-05-01 17:42:57.057  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 4.0 (TID 70) in 34 ms on localhost (executor driver) (1/2)
2018-05-01 17:42:57.059  INFO 17168 --- [Executor task launch worker for task 71] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 2 non-empty blocks out of 2 blocks
2018-05-01 17:42:57.059  INFO 17168 --- [Executor task launch worker for task 71] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:42:57.205  INFO 17168 --- [Executor task launch worker for task 71] o.a.spark.storage.memory.MemoryStore     : Block rdd_9_1 stored as values in memory (estimated size 12.0 MB, free 1942.8 MB)
2018-05-01 17:42:57.206  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_9_1 in memory on 172.21.241.193:58363 (size: 12.0 MB, free: 1942.8 MB)
2018-05-01 17:42:57.409  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_4_piece0 on 172.21.241.193:58363 in memory (size: 3.2 KB, free: 1942.8 MB)
2018-05-01 17:42:57.588  INFO 17168 --- [Executor task launch worker for task 71] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 4.0 (TID 71). 1938 bytes result sent to driver
2018-05-01 17:42:57.588  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 4.0 (TID 71) in 531 ms on localhost (executor driver) (2/2)
2018-05-01 17:42:57.588  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 4 (map at ALS.scala:1344) finished in 0.565 s
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 5)
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 5 (userOutBlocks MapPartitionsRDD[13] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:42:57.590  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6 stored as values in memory (estimated size 7.7 KB, free 1942.8 MB)
2018-05-01 17:42:57.591  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1942.8 MB)
2018-05-01 17:42:57.592  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_6_piece0 in memory on 172.21.241.193:58363 (size: 3.9 KB, free: 1942.8 MB)
2018-05-01 17:42:57.592  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:57.593  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 5 (userOutBlocks MapPartitionsRDD[13] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:57.593  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 5.0 with 1 tasks
2018-05-01 17:42:57.593  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 5.0 (TID 72, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:42:57.593  INFO 17168 --- [Executor task launch worker for task 72] org.apache.spark.executor.Executor       : Running task 0.0 in stage 5.0 (TID 72)
2018-05-01 17:42:57.595  INFO 17168 --- [Executor task launch worker for task 72] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:42:57.595  INFO 17168 --- [Executor task launch worker for task 72] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:42:58.031  INFO 17168 --- [Executor task launch worker for task 72] o.a.spark.storage.memory.MemoryStore     : Block rdd_12_0 stored as values in memory (estimated size 8.1 MB, free 1934.7 MB)
2018-05-01 17:42:58.032  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_12_0 in memory on 172.21.241.193:58363 (size: 8.1 MB, free: 1934.7 MB)
2018-05-01 17:42:58.041  INFO 17168 --- [Executor task launch worker for task 72] o.a.spark.storage.memory.MemoryStore     : Block rdd_13_0 stored as values in memory (estimated size 27.9 KB, free 1934.7 MB)
2018-05-01 17:42:58.042  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_13_0 in memory on 172.21.241.193:58363 (size: 27.9 KB, free: 1934.7 MB)
2018-05-01 17:42:58.043  INFO 17168 --- [Executor task launch worker for task 72] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 5.0 (TID 72). 1834 bytes result sent to driver
2018-05-01 17:42:58.043  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 5.0 (TID 72) in 450 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:58.043  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-05-01 17:42:58.044  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 5 (count at ALS.scala:857) finished in 0.450 s
2018-05-01 17:42:58.044  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 3 finished: count at ALS.scala:857, took 5.452494 s
2018-05-01 17:42:58.063  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:865
2018-05-01 17:42:58.067  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:42:58.068  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 15 (map at ALS.scala:1344)
2018-05-01 17:42:58.068  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 4 (count at ALS.scala:865) with 1 output partitions
2018-05-01 17:42:58.069  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 8 (count at ALS.scala:865)
2018-05-01 17:42:58.069  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 7)
2018-05-01 17:42:58.070  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 7)
2018-05-01 17:42:58.070  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 7 (MapPartitionsRDD[15] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:42:58.071  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7 stored as values in memory (estimated size 7.3 KB, free 1934.7 MB)
2018-05-01 17:42:58.073  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1934.7 MB)
2018-05-01 17:42:58.074  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_7_piece0 in memory on 172.21.241.193:58363 (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:42:58.074  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:58.075  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[15] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:42:58.075  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 7.0 with 2 tasks
2018-05-01 17:42:58.075  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 7.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:42:58.075  INFO 17168 --- [Executor task launch worker for task 73] org.apache.spark.executor.Executor       : Running task 0.0 in stage 7.0 (TID 73)
2018-05-01 17:42:58.077  INFO 17168 --- [Executor task launch worker for task 73] org.apache.spark.storage.BlockManager    : Found block rdd_9_0 locally
2018-05-01 17:42:58.082  INFO 17168 --- [Executor task launch worker for task 73] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 7.0 (TID 73). 725 bytes result sent to driver
2018-05-01 17:42:58.082  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 7.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:42:58.082  INFO 17168 --- [Executor task launch worker for task 74] org.apache.spark.executor.Executor       : Running task 1.0 in stage 7.0 (TID 74)
2018-05-01 17:42:58.083  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 7.0 (TID 73) in 7 ms on localhost (executor driver) (1/2)
2018-05-01 17:42:58.084  INFO 17168 --- [Executor task launch worker for task 74] org.apache.spark.storage.BlockManager    : Found block rdd_9_1 locally
2018-05-01 17:42:58.343  INFO 17168 --- [Executor task launch worker for task 74] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 7.0 (TID 74). 940 bytes result sent to driver
2018-05-01 17:42:58.343  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 7.0 (TID 74) in 261 ms on localhost (executor driver) (2/2)
2018-05-01 17:42:58.344  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 7 (map at ALS.scala:1344) finished in 0.269 s
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:58.345  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 8 (itemOutBlocks MapPartitionsRDD[18] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:42:58.346  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8 stored as values in memory (estimated size 7.9 KB, free 1934.7 MB)
2018-05-01 17:42:58.348  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1934.7 MB)
2018-05-01 17:42:58.349  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_8_piece0 in memory on 172.21.241.193:58363 (size: 4.0 KB, free: 1934.7 MB)
2018-05-01 17:42:58.349  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:58.351  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 8 (itemOutBlocks MapPartitionsRDD[18] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:58.352  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 8.0 with 1 tasks
2018-05-01 17:42:58.353  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 8.0 (TID 75, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:42:58.353  INFO 17168 --- [Executor task launch worker for task 75] org.apache.spark.executor.Executor       : Running task 0.0 in stage 8.0 (TID 75)
2018-05-01 17:42:58.356  INFO 17168 --- [Executor task launch worker for task 75] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:42:58.356  INFO 17168 --- [Executor task launch worker for task 75] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:42:58.480  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_5_piece0 on 172.21.241.193:58363 in memory (size: 3.7 KB, free: 1934.7 MB)
2018-05-01 17:42:58.481  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_6_piece0 on 172.21.241.193:58363 in memory (size: 3.9 KB, free: 1934.7 MB)
2018-05-01 17:42:58.482  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_7_piece0 on 172.21.241.193:58363 in memory (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:42:59.639  INFO 17168 --- [Executor task launch worker for task 75] o.a.spark.storage.memory.MemoryStore     : Block rdd_17_0 stored as values in memory (estimated size 8.1 MB, free 1926.6 MB)
2018-05-01 17:42:59.640  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_17_0 in memory on 172.21.241.193:58363 (size: 8.1 MB, free: 1926.6 MB)
2018-05-01 17:42:59.645  INFO 17168 --- [Executor task launch worker for task 75] o.a.spark.storage.memory.MemoryStore     : Block rdd_18_0 stored as values in memory (estimated size 54.9 KB, free 1926.5 MB)
2018-05-01 17:42:59.646  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_18_0 in memory on 172.21.241.193:58363 (size: 54.9 KB, free: 1926.6 MB)
2018-05-01 17:42:59.646  INFO 17168 --- [Executor task launch worker for task 75] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 8.0 (TID 75). 1920 bytes result sent to driver
2018-05-01 17:42:59.647  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 8.0 (TID 75) in 1294 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:59.647  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-05-01 17:42:59.648  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 8 (count at ALS.scala:865) finished in 1.295 s
2018-05-01 17:42:59.649  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 4 finished: count at ALS.scala:865, took 1.585610 s
2018-05-01 17:42:59.675  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:42:59.676  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:42:59.677  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:42:59.677  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 5 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:42:59.677  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 11 (aggregate at ALS.scala:1491)
2018-05-01 17:42:59.677  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 10)
2018-05-01 17:42:59.678  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:42:59.678  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 11 (MapPartitionsRDD[21] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:42:59.679  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9 stored as values in memory (estimated size 9.1 KB, free 1926.5 MB)
2018-05-01 17:42:59.680  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.5 MB)
2018-05-01 17:42:59.681  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_9_piece0 in memory on 172.21.241.193:58363 (size: 4.3 KB, free: 1926.5 MB)
2018-05-01 17:42:59.682  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:59.682  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:59.682  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 11.0 with 1 tasks
2018-05-01 17:42:59.682  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 11.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
2018-05-01 17:42:59.684  INFO 17168 --- [Executor task launch worker for task 76] org.apache.spark.executor.Executor       : Running task 0.0 in stage 11.0 (TID 76)
2018-05-01 17:42:59.689  INFO 17168 --- [Executor task launch worker for task 76] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:42:59.692  WARN 17168 --- [Executor task launch worker for task 76] com.github.fommil.netlib.BLAS            : Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-05-01 17:42:59.692  WARN 17168 --- [Executor task launch worker for task 76] com.github.fommil.netlib.BLAS            : Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-05-01 17:42:59.709  INFO 17168 --- [Executor task launch worker for task 76] o.a.spark.storage.memory.MemoryStore     : Block rdd_19_0 stored as values in memory (estimated size 416.2 KB, free 1926.1 MB)
2018-05-01 17:42:59.709  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_19_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1926.1 MB)
2018-05-01 17:42:59.716  INFO 17168 --- [Executor task launch worker for task 76] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 11.0 (TID 76). 2208 bytes result sent to driver
2018-05-01 17:42:59.717  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 11.0 (TID 76) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:59.717  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-05-01 17:42:59.717  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 11 (aggregate at ALS.scala:1491) finished in 0.035 s
2018-05-01 17:42:59.718  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 5 finished: aggregate at ALS.scala:1491, took 0.043108 s
2018-05-01 17:42:59.750  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 20 from persistence list
2018-05-01 17:42:59.755  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 20
2018-05-01 17:42:59.764  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:42:59.766  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 19 (map at ALS.scala:1017)
2018-05-01 17:42:59.766  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 25 (flatMap at ALS.scala:1433)
2018-05-01 17:42:59.766  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:42:59.767  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 6 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:42:59.767  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 17 (aggregate at ALS.scala:1491)
2018-05-01 17:42:59.767  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 16)
2018-05-01 17:42:59.767  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 15)
2018-05-01 17:42:59.768  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[19] at map at ALS.scala:1017), which has no missing parents
2018-05-01 17:42:59.769  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10 stored as values in memory (estimated size 7.7 KB, free 1926.1 MB)
2018-05-01 17:42:59.770  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1926.1 MB)
2018-05-01 17:42:59.771  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_10_piece0 in memory on 172.21.241.193:58363 (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:42:59.771  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:59.772  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[19] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:59.772  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 14.0 with 1 tasks
2018-05-01 17:42:59.773  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 14.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:42:59.773  INFO 17168 --- [Executor task launch worker for task 77] org.apache.spark.executor.Executor       : Running task 0.0 in stage 14.0 (TID 77)
2018-05-01 17:42:59.774  INFO 17168 --- [Executor task launch worker for task 77] org.apache.spark.storage.BlockManager    : Found block rdd_19_0 locally
2018-05-01 17:42:59.800  INFO 17168 --- [Executor task launch worker for task 77] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 14.0 (TID 77). 940 bytes result sent to driver
2018-05-01 17:42:59.801  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 14.0 (TID 77) in 29 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:59.802  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 14 (map at ALS.scala:1017) finished in 0.030 s
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 15, ResultStage 17)
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 15 (MapPartitionsRDD[25] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:42:59.803  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11 stored as values in memory (estimated size 8.8 KB, free 1926.1 MB)
2018-05-01 17:42:59.805  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.1 MB)
2018-05-01 17:42:59.805  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_11_piece0 in memory on 172.21.241.193:58363 (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 17:42:59.805  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:59.806  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[25] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:59.806  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 15.0 with 1 tasks
2018-05-01 17:42:59.808  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 15.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-05-01 17:42:59.808  INFO 17168 --- [Executor task launch worker for task 78] org.apache.spark.executor.Executor       : Running task 0.0 in stage 15.0 (TID 78)
2018-05-01 17:42:59.812  INFO 17168 --- [Executor task launch worker for task 78] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:42:59.812  INFO 17168 --- [Executor task launch worker for task 78] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:42:59.812  INFO 17168 --- [Executor task launch worker for task 78] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:42:59.849  INFO 17168 --- [Executor task launch worker for task 78] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 15.0 (TID 78). 1327 bytes result sent to driver
2018-05-01 17:42:59.849  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 15.0 (TID 78) in 42 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:59.850  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 15 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 17)
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:59.851  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 17 (MapPartitionsRDD[31] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:42:59.854  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12 stored as values in memory (estimated size 12.6 KB, free 1926.1 MB)
2018-05-01 17:42:59.855  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1926.1 MB)
2018-05-01 17:42:59.856  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_12_piece0 in memory on 172.21.241.193:58363 (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 17:42:59.857  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:59.859  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[31] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:59.859  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 17.0 with 1 tasks
2018-05-01 17:42:59.859  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 17.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:42:59.859  INFO 17168 --- [Executor task launch worker for task 79] org.apache.spark.executor.Executor       : Running task 0.0 in stage 17.0 (TID 79)
2018-05-01 17:42:59.863  INFO 17168 --- [Executor task launch worker for task 79] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:42:59.863  INFO 17168 --- [Executor task launch worker for task 79] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:42:59.863  INFO 17168 --- [Executor task launch worker for task 79] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:42:59.879  WARN 17168 --- [Executor task launch worker for task 79] com.github.fommil.netlib.LAPACK          : Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-05-01 17:42:59.879  WARN 17168 --- [Executor task launch worker for task 79] com.github.fommil.netlib.LAPACK          : Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-05-01 17:43:00.222  INFO 17168 --- [Executor task launch worker for task 79] o.a.spark.storage.memory.MemoryStore     : Block rdd_30_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:43:00.223  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_30_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:43:00.226  INFO 17168 --- [Executor task launch worker for task 79] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 17.0 (TID 79). 2595 bytes result sent to driver
2018-05-01 17:43:00.226  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 17.0 (TID 79) in 367 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.226  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.227  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 17 (aggregate at ALS.scala:1491) finished in 0.368 s
2018-05-01 17:43:00.227  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 6 finished: aggregate at ALS.scala:1491, took 0.463461 s
2018-05-01 17:43:00.246  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 19 from persistence list
2018-05-01 17:43:00.247  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 19
2018-05-01 17:43:00.257  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:00.258  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:00.258  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:00.259  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:00.259  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:00.259  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 35 (flatMap at ALS.scala:1433)
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 7 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 24 (aggregate at ALS.scala:1491)
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 19, ShuffleMapStage 23)
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 23)
2018-05-01 17:43:00.261  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 23 (MapPartitionsRDD[35] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:00.262  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13 stored as values in memory (estimated size 11.8 KB, free 1925.7 MB)
2018-05-01 17:43:00.263  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.6 KB, free 1925.7 MB)
2018-05-01 17:43:00.265  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_13_piece0 in memory on 172.21.241.193:58363 (size: 5.6 KB, free: 1925.7 MB)
2018-05-01 17:43:00.266  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.266  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[35] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.266  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 23.0 with 1 tasks
2018-05-01 17:43:00.266  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 23.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:00.267  INFO 17168 --- [Executor task launch worker for task 80] org.apache.spark.executor.Executor       : Running task 0.0 in stage 23.0 (TID 80)
2018-05-01 17:43:00.269  INFO 17168 --- [Executor task launch worker for task 80] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:00.269  INFO 17168 --- [Executor task launch worker for task 80] org.apache.spark.storage.BlockManager    : Found block rdd_30_0 locally
2018-05-01 17:43:00.300  INFO 17168 --- [Executor task launch worker for task 80] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 23.0 (TID 80). 1069 bytes result sent to driver
2018-05-01 17:43:00.301  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 23.0 (TID 80) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.301  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 23 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 24)
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:00.302  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 24 (MapPartitionsRDD[41] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:00.303  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_14 stored as values in memory (estimated size 14.3 KB, free 1925.7 MB)
2018-05-01 17:43:00.305  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1925.6 MB)
2018-05-01 17:43:00.306  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_14_piece0 in memory on 172.21.241.193:58363 (size: 6.6 KB, free: 1925.7 MB)
2018-05-01 17:43:00.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[41] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.306  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 24.0 with 1 tasks
2018-05-01 17:43:00.307  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 24.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:00.307  INFO 17168 --- [Executor task launch worker for task 81] org.apache.spark.executor.Executor       : Running task 0.0 in stage 24.0 (TID 81)
2018-05-01 17:43:00.309  INFO 17168 --- [Executor task launch worker for task 81] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:00.309  INFO 17168 --- [Executor task launch worker for task 81] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:00.309  INFO 17168 --- [Executor task launch worker for task 81] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:00.587  INFO 17168 --- [Executor task launch worker for task 81] o.a.spark.storage.memory.MemoryStore     : Block rdd_40_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:43:00.588  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_40_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:43:00.590  INFO 17168 --- [Executor task launch worker for task 81] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 24.0 (TID 81). 2638 bytes result sent to driver
2018-05-01 17:43:00.591  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 24.0 (TID 81) in 284 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.591  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 24.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.591  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 24 (aggregate at ALS.scala:1491) finished in 0.285 s
2018-05-01 17:43:00.592  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 7 finished: aggregate at ALS.scala:1491, took 0.334248 s
2018-05-01 17:43:00.610  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 30 from persistence list
2018-05-01 17:43:00.610  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 30
2018-05-01 17:43:00.615  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:00.616  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:00.616  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:00.617  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:00.617  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:00.618  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:00.619  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:00.619  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 45 (flatMap at ALS.scala:1433)
2018-05-01 17:43:00.619  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 8 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:00.620  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 32 (aggregate at ALS.scala:1491)
2018-05-01 17:43:00.620  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 31, ShuffleMapStage 28)
2018-05-01 17:43:00.620  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 31)
2018-05-01 17:43:00.621  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 31 (MapPartitionsRDD[45] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:00.623  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_15 stored as values in memory (estimated size 13.4 KB, free 1926.0 MB)
2018-05-01 17:43:00.624  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1926.0 MB)
2018-05-01 17:43:00.624  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_15_piece0 in memory on 172.21.241.193:58363 (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:43:00.624  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.625  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[45] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.625  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 31.0 with 1 tasks
2018-05-01 17:43:00.625  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 31.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:00.625  INFO 17168 --- [Executor task launch worker for task 82] org.apache.spark.executor.Executor       : Running task 0.0 in stage 31.0 (TID 82)
2018-05-01 17:43:00.627  INFO 17168 --- [Executor task launch worker for task 82] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:00.627  INFO 17168 --- [Executor task launch worker for task 82] org.apache.spark.storage.BlockManager    : Found block rdd_40_0 locally
2018-05-01 17:43:00.656  INFO 17168 --- [Executor task launch worker for task 82] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 31.0 (TID 82). 1069 bytes result sent to driver
2018-05-01 17:43:00.657  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 31.0 (TID 82) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.657  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 31.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.657  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 31 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:43:00.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:00.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:00.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 32)
2018-05-01 17:43:00.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:00.659  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 32 (MapPartitionsRDD[51] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:00.660  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_16 stored as values in memory (estimated size 15.8 KB, free 1926.0 MB)
2018-05-01 17:43:00.661  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1926.0 MB)
2018-05-01 17:43:00.661  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_16_piece0 in memory on 172.21.241.193:58363 (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 17:43:00.662  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.662  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[51] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.662  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 32.0 with 1 tasks
2018-05-01 17:43:00.662  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 32.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:00.663  INFO 17168 --- [Executor task launch worker for task 83] org.apache.spark.executor.Executor       : Running task 0.0 in stage 32.0 (TID 83)
2018-05-01 17:43:00.665  INFO 17168 --- [Executor task launch worker for task 83] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:00.666  INFO 17168 --- [Executor task launch worker for task 83] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:00.666  INFO 17168 --- [Executor task launch worker for task 83] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:00.943  INFO 17168 --- [Executor task launch worker for task 83] o.a.spark.storage.memory.MemoryStore     : Block rdd_50_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 17:43:00.944  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_50_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:43:00.947  INFO 17168 --- [Executor task launch worker for task 83] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 32.0 (TID 83). 2595 bytes result sent to driver
2018-05-01 17:43:00.948  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 32.0 (TID 83) in 286 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.948  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 32.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.948  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 32 (aggregate at ALS.scala:1491) finished in 0.286 s
2018-05-01 17:43:00.948  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 8 finished: aggregate at ALS.scala:1491, took 0.332756 s
2018-05-01 17:43:00.969  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 40 from persistence list
2018-05-01 17:43:00.970  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 40
2018-05-01 17:43:00.976  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:00.976  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:00.977  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:00.977  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:00.978  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:00.978  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:00.979  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:00.979  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:00.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 55 (flatMap at ALS.scala:1433)
2018-05-01 17:43:00.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 9 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:00.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 41 (aggregate at ALS.scala:1491)
2018-05-01 17:43:00.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 40)
2018-05-01 17:43:00.981  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 40)
2018-05-01 17:43:00.981  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 40 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:00.983  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_17 stored as values in memory (estimated size 14.9 KB, free 1925.6 MB)
2018-05-01 17:43:00.984  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1925.6 MB)
2018-05-01 17:43:00.985  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_17_piece0 in memory on 172.21.241.193:58363 (size: 7.0 KB, free: 1925.7 MB)
2018-05-01 17:43:00.985  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.986  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.986  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 40.0 with 1 tasks
2018-05-01 17:43:00.987  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 40.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:00.987  INFO 17168 --- [Executor task launch worker for task 84] org.apache.spark.executor.Executor       : Running task 0.0 in stage 40.0 (TID 84)
2018-05-01 17:43:00.989  INFO 17168 --- [Executor task launch worker for task 84] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:00.989  INFO 17168 --- [Executor task launch worker for task 84] org.apache.spark.storage.BlockManager    : Found block rdd_50_0 locally
2018-05-01 17:43:01.026  INFO 17168 --- [Executor task launch worker for task 84] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 40.0 (TID 84). 1069 bytes result sent to driver
2018-05-01 17:43:01.026  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 40.0 (TID 84) in 40 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.026  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 40.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.026  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 40 (flatMap at ALS.scala:1433) finished in 0.040 s
2018-05-01 17:43:01.026  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:01.027  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:01.027  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 41)
2018-05-01 17:43:01.027  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:01.027  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 41 (MapPartitionsRDD[61] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:01.028  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_18 stored as values in memory (estimated size 17.4 KB, free 1925.6 MB)
2018-05-01 17:43:01.030  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_18_piece0 stored as bytes in memory (estimated size 7.9 KB, free 1925.6 MB)
2018-05-01 17:43:01.030  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_18_piece0 in memory on 172.21.241.193:58363 (size: 7.9 KB, free: 1925.7 MB)
2018-05-01 17:43:01.031  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.031  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[61] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.031  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 41.0 with 1 tasks
2018-05-01 17:43:01.032  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 41.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:01.033  INFO 17168 --- [Executor task launch worker for task 85] org.apache.spark.executor.Executor       : Running task 0.0 in stage 41.0 (TID 85)
2018-05-01 17:43:01.035  INFO 17168 --- [Executor task launch worker for task 85] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:01.035  INFO 17168 --- [Executor task launch worker for task 85] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:01.035  INFO 17168 --- [Executor task launch worker for task 85] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:01.299  INFO 17168 --- [Executor task launch worker for task 85] o.a.spark.storage.memory.MemoryStore     : Block rdd_60_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:43:01.301  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_60_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:43:01.305  INFO 17168 --- [Executor task launch worker for task 85] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 41.0 (TID 85). 2595 bytes result sent to driver
2018-05-01 17:43:01.305  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 41.0 (TID 85) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.305  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 41.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 41 (aggregate at ALS.scala:1491) finished in 0.274 s
2018-05-01 17:43:01.306  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 9 finished: aggregate at ALS.scala:1491, took 0.330251 s
2018-05-01 17:43:01.324  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 50 from persistence list
2018-05-01 17:43:01.324  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 50
2018-05-01 17:43:01.330  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:01.330  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:01.331  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:01.331  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:01.331  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:01.332  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:01.332  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:01.332  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 65 (flatMap at ALS.scala:1433)
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 10 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 51 (aggregate at ALS.scala:1491)
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 45, ShuffleMapStage 50)
2018-05-01 17:43:01.334  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 50)
2018-05-01 17:43:01.334  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 50 (MapPartitionsRDD[65] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:01.336  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_19 stored as values in memory (estimated size 16.5 KB, free 1925.9 MB)
2018-05-01 17:43:01.337  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.8 KB, free 1925.9 MB)
2018-05-01 17:43:01.337  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_19_piece0 in memory on 172.21.241.193:58363 (size: 7.8 KB, free: 1926.1 MB)
2018-05-01 17:43:01.338  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.338  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[65] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.338  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 50.0 with 1 tasks
2018-05-01 17:43:01.338  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 50.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:01.339  INFO 17168 --- [Executor task launch worker for task 86] org.apache.spark.executor.Executor       : Running task 0.0 in stage 50.0 (TID 86)
2018-05-01 17:43:01.340  INFO 17168 --- [Executor task launch worker for task 86] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:01.340  INFO 17168 --- [Executor task launch worker for task 86] org.apache.spark.storage.BlockManager    : Found block rdd_60_0 locally
2018-05-01 17:43:01.366  INFO 17168 --- [Executor task launch worker for task 86] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 50.0 (TID 86). 1026 bytes result sent to driver
2018-05-01 17:43:01.366  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 50.0 (TID 86) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.366  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 50.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 50 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 51)
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 51 (MapPartitionsRDD[71] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:01.369  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_20 stored as values in memory (estimated size 18.9 KB, free 1925.9 MB)
2018-05-01 17:43:01.370  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1925.9 MB)
2018-05-01 17:43:01.370  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_20_piece0 in memory on 172.21.241.193:58363 (size: 8.6 KB, free: 1926.1 MB)
2018-05-01 17:43:01.370  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.370  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[71] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.370  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 51.0 with 1 tasks
2018-05-01 17:43:01.371  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 51.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:01.371  INFO 17168 --- [Executor task launch worker for task 87] org.apache.spark.executor.Executor       : Running task 0.0 in stage 51.0 (TID 87)
2018-05-01 17:43:01.373  INFO 17168 --- [Executor task launch worker for task 87] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:01.373  INFO 17168 --- [Executor task launch worker for task 87] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:01.373  INFO 17168 --- [Executor task launch worker for task 87] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:01.654  INFO 17168 --- [Executor task launch worker for task 87] o.a.spark.storage.memory.MemoryStore     : Block rdd_70_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 17:43:01.654  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_70_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:43:01.657  INFO 17168 --- [Executor task launch worker for task 87] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 51.0 (TID 87). 2595 bytes result sent to driver
2018-05-01 17:43:01.658  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 51.0 (TID 87) in 287 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.658  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 51.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 51 (aggregate at ALS.scala:1491) finished in 0.287 s
2018-05-01 17:43:01.659  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 10 finished: aggregate at ALS.scala:1491, took 0.329520 s
2018-05-01 17:43:01.678  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 60 from persistence list
2018-05-01 17:43:01.678  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 60
2018-05-01 17:43:01.684  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:01.685  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:01.685  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:01.686  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:01.686  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:01.686  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:01.687  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:01.687  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:01.687  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:01.687  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 75 (flatMap at ALS.scala:1433)
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 11 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 62 (aggregate at ALS.scala:1491)
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 53, ShuffleMapStage 61)
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 61)
2018-05-01 17:43:01.689  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 61 (MapPartitionsRDD[75] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:01.691  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_21 stored as values in memory (estimated size 18.0 KB, free 1925.5 MB)
2018-05-01 17:43:01.692  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1925.5 MB)
2018-05-01 17:43:01.693  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_21_piece0 in memory on 172.21.241.193:58363 (size: 8.4 KB, free: 1925.7 MB)
2018-05-01 17:43:01.693  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.693  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[75] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.694  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 61.0 with 1 tasks
2018-05-01 17:43:01.694  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 61.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:01.694  INFO 17168 --- [Executor task launch worker for task 88] org.apache.spark.executor.Executor       : Running task 0.0 in stage 61.0 (TID 88)
2018-05-01 17:43:01.696  INFO 17168 --- [Executor task launch worker for task 88] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:01.696  INFO 17168 --- [Executor task launch worker for task 88] org.apache.spark.storage.BlockManager    : Found block rdd_70_0 locally
2018-05-01 17:43:01.732  INFO 17168 --- [Executor task launch worker for task 88] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 61.0 (TID 88). 1069 bytes result sent to driver
2018-05-01 17:43:01.733  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 61.0 (TID 88) in 39 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.733  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 61.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 61 (flatMap at ALS.scala:1433) finished in 0.039 s
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 62)
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:01.734  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 62 (MapPartitionsRDD[81] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:01.735  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_22 stored as values in memory (estimated size 20.5 KB, free 1925.5 MB)
2018-05-01 17:43:01.737  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.2 KB, free 1925.5 MB)
2018-05-01 17:43:01.737  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_22_piece0 in memory on 172.21.241.193:58363 (size: 9.2 KB, free: 1925.7 MB)
2018-05-01 17:43:01.738  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.738  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[81] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.738  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 62.0 with 1 tasks
2018-05-01 17:43:01.738  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 62.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:01.739  INFO 17168 --- [Executor task launch worker for task 89] org.apache.spark.executor.Executor       : Running task 0.0 in stage 62.0 (TID 89)
2018-05-01 17:43:01.741  INFO 17168 --- [Executor task launch worker for task 89] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:01.741  INFO 17168 --- [Executor task launch worker for task 89] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:01.741  INFO 17168 --- [Executor task launch worker for task 89] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:02.008  INFO 17168 --- [Executor task launch worker for task 89] o.a.spark.storage.memory.MemoryStore     : Block rdd_80_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 17:43:02.009  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_80_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:43:02.011  INFO 17168 --- [Executor task launch worker for task 89] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 62.0 (TID 89). 2595 bytes result sent to driver
2018-05-01 17:43:02.011  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 62.0 (TID 89) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.011  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 62.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.012  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 62 (aggregate at ALS.scala:1491) finished in 0.274 s
2018-05-01 17:43:02.012  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 11 finished: aggregate at ALS.scala:1491, took 0.328132 s
2018-05-01 17:43:02.033  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 70 from persistence list
2018-05-01 17:43:02.034  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 70
2018-05-01 17:43:02.040  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:02.041  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:02.041  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:02.042  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:02.042  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:02.043  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:02.044  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:02.044  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:02.045  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:02.045  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:02.045  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:02.045  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 85 (flatMap at ALS.scala:1433)
2018-05-01 17:43:02.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 12 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:02.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 74 (aggregate at ALS.scala:1491)
2018-05-01 17:43:02.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 66, ShuffleMapStage 73)
2018-05-01 17:43:02.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 73)
2018-05-01 17:43:02.047  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 73 (MapPartitionsRDD[85] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:02.048  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_23 stored as values in memory (estimated size 19.6 KB, free 1925.8 MB)
2018-05-01 17:43:02.049  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.1 KB, free 1925.8 MB)
2018-05-01 17:43:02.051  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_23_piece0 in memory on 172.21.241.193:58363 (size: 9.1 KB, free: 1926.0 MB)
2018-05-01 17:43:02.051  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.051  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[85] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.051  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 73.0 with 1 tasks
2018-05-01 17:43:02.052  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 73.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:02.052  INFO 17168 --- [Executor task launch worker for task 90] org.apache.spark.executor.Executor       : Running task 0.0 in stage 73.0 (TID 90)
2018-05-01 17:43:02.054  INFO 17168 --- [Executor task launch worker for task 90] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:02.054  INFO 17168 --- [Executor task launch worker for task 90] org.apache.spark.storage.BlockManager    : Found block rdd_80_0 locally
2018-05-01 17:43:02.080  INFO 17168 --- [Executor task launch worker for task 90] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 73.0 (TID 90). 1069 bytes result sent to driver
2018-05-01 17:43:02.080  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 73.0 (TID 90) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.080  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 73.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 73 (flatMap at ALS.scala:1433) finished in 0.028 s
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 74)
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:02.081  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 74 (MapPartitionsRDD[91] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:02.082  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_24 stored as values in memory (estimated size 22.0 KB, free 1925.8 MB)
2018-05-01 17:43:02.083  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.9 KB, free 1925.8 MB)
2018-05-01 17:43:02.083  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_24_piece0 in memory on 172.21.241.193:58363 (size: 9.9 KB, free: 1926.0 MB)
2018-05-01 17:43:02.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[91] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.085  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 74.0 with 1 tasks
2018-05-01 17:43:02.085  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 74.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:02.085  INFO 17168 --- [Executor task launch worker for task 91] org.apache.spark.executor.Executor       : Running task 0.0 in stage 74.0 (TID 91)
2018-05-01 17:43:02.088  INFO 17168 --- [Executor task launch worker for task 91] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:02.088  INFO 17168 --- [Executor task launch worker for task 91] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:02.088  INFO 17168 --- [Executor task launch worker for task 91] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:02.382  INFO 17168 --- [Executor task launch worker for task 91] o.a.spark.storage.memory.MemoryStore     : Block rdd_90_0 stored as values in memory (estimated size 820.5 KB, free 1925.0 MB)
2018-05-01 17:43:02.382  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_90_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:43:02.386  INFO 17168 --- [Executor task launch worker for task 91] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 74.0 (TID 91). 2595 bytes result sent to driver
2018-05-01 17:43:02.387  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 74.0 (TID 91) in 302 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.387  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 74.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.387  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 74 (aggregate at ALS.scala:1491) finished in 0.302 s
2018-05-01 17:43:02.388  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 12 finished: aggregate at ALS.scala:1491, took 0.347280 s
2018-05-01 17:43:02.404  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 80 from persistence list
2018-05-01 17:43:02.405  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 80
2018-05-01 17:43:02.409  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:02.410  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:02.411  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:02.411  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:02.411  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:02.411  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:02.413  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:02.413  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 95 (flatMap at ALS.scala:1433)
2018-05-01 17:43:02.414  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 13 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:02.414  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 87 (aggregate at ALS.scala:1491)
2018-05-01 17:43:02.414  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 86, ShuffleMapStage 76)
2018-05-01 17:43:02.415  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 86)
2018-05-01 17:43:02.415  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 86 (MapPartitionsRDD[95] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:02.417  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_25 stored as values in memory (estimated size 21.1 KB, free 1925.4 MB)
2018-05-01 17:43:02.419  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1925.4 MB)
2018-05-01 17:43:02.419  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_25_piece0 in memory on 172.21.241.193:58363 (size: 9.7 KB, free: 1925.6 MB)
2018-05-01 17:43:02.419  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.420  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[95] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.420  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 86.0 with 1 tasks
2018-05-01 17:43:02.421  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 86.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:02.421  INFO 17168 --- [Executor task launch worker for task 92] org.apache.spark.executor.Executor       : Running task 0.0 in stage 86.0 (TID 92)
2018-05-01 17:43:02.423  INFO 17168 --- [Executor task launch worker for task 92] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:02.423  INFO 17168 --- [Executor task launch worker for task 92] org.apache.spark.storage.BlockManager    : Found block rdd_90_0 locally
2018-05-01 17:43:02.452  INFO 17168 --- [Executor task launch worker for task 92] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 86.0 (TID 92). 1069 bytes result sent to driver
2018-05-01 17:43:02.453  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 86.0 (TID 92) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.453  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 86.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 86 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 87)
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:02.454  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 87 (MapPartitionsRDD[101] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:02.456  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_26 stored as values in memory (estimated size 23.6 KB, free 1925.3 MB)
2018-05-01 17:43:02.457  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_26_piece0 stored as bytes in memory (estimated size 10.6 KB, free 1925.3 MB)
2018-05-01 17:43:02.457  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_26_piece0 in memory on 172.21.241.193:58363 (size: 10.6 KB, free: 1925.6 MB)
2018-05-01 17:43:02.458  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.458  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[101] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.458  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 87.0 with 1 tasks
2018-05-01 17:43:02.458  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 87.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:02.458  INFO 17168 --- [Executor task launch worker for task 93] org.apache.spark.executor.Executor       : Running task 0.0 in stage 87.0 (TID 93)
2018-05-01 17:43:02.460  INFO 17168 --- [Executor task launch worker for task 93] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:02.460  INFO 17168 --- [Executor task launch worker for task 93] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:02.461  INFO 17168 --- [Executor task launch worker for task 93] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:43:02.730  INFO 17168 --- [Executor task launch worker for task 93] o.a.spark.storage.memory.MemoryStore     : Block rdd_100_0 stored as values in memory (estimated size 416.2 KB, free 1924.9 MB)
2018-05-01 17:43:02.731  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_100_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:43:02.733  INFO 17168 --- [Executor task launch worker for task 93] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 87.0 (TID 93). 2595 bytes result sent to driver
2018-05-01 17:43:02.733  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 87.0 (TID 93) in 275 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.733  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 87.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 87 (aggregate at ALS.scala:1491) finished in 0.275 s
2018-05-01 17:43:02.734  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 13 finished: aggregate at ALS.scala:1491, took 0.324174 s
2018-05-01 17:43:02.752  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 90 from persistence list
2018-05-01 17:43:02.752  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 90
2018-05-01 17:43:02.758  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:02.759  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:02.759  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:02.759  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:02.760  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:02.760  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:02.760  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:02.760  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:02.761  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:02.761  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:02.761  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 105 (flatMap at ALS.scala:1433)
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 14 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 101 (aggregate at ALS.scala:1491)
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 100, ShuffleMapStage 91)
2018-05-01 17:43:02.763  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 100)
2018-05-01 17:43:02.763  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 100 (MapPartitionsRDD[105] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:02.765  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_27 stored as values in memory (estimated size 22.7 KB, free 1925.7 MB)
2018-05-01 17:43:02.769  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_27_piece0 stored as bytes in memory (estimated size 10.5 KB, free 1925.7 MB)
2018-05-01 17:43:02.770  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_27_piece0 in memory on 172.21.241.193:58363 (size: 10.5 KB, free: 1926.0 MB)
2018-05-01 17:43:02.770  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.770  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[105] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.770  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 100.0 with 1 tasks
2018-05-01 17:43:02.771  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 100.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:02.771  INFO 17168 --- [Executor task launch worker for task 94] org.apache.spark.executor.Executor       : Running task 0.0 in stage 100.0 (TID 94)
2018-05-01 17:43:02.773  INFO 17168 --- [Executor task launch worker for task 94] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:02.773  INFO 17168 --- [Executor task launch worker for task 94] org.apache.spark.storage.BlockManager    : Found block rdd_100_0 locally
2018-05-01 17:43:02.818  INFO 17168 --- [Executor task launch worker for task 94] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 100.0 (TID 94). 1069 bytes result sent to driver
2018-05-01 17:43:02.819  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 100.0 (TID 94) in 48 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.819  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 100.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 100 (flatMap at ALS.scala:1433) finished in 0.049 s
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 101)
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 101 (MapPartitionsRDD[111] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:02.822  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_28 stored as values in memory (estimated size 25.1 KB, free 1925.7 MB)
2018-05-01 17:43:02.823  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.2 KB, free 1925.7 MB)
2018-05-01 17:43:02.823  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_28_piece0 in memory on 172.21.241.193:58363 (size: 11.2 KB, free: 1926.0 MB)
2018-05-01 17:43:02.823  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.823  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[111] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.823  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 101.0 with 1 tasks
2018-05-01 17:43:02.824  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 101.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:02.824  INFO 17168 --- [Executor task launch worker for task 95] org.apache.spark.executor.Executor       : Running task 0.0 in stage 101.0 (TID 95)
2018-05-01 17:43:02.826  INFO 17168 --- [Executor task launch worker for task 95] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:02.826  INFO 17168 --- [Executor task launch worker for task 95] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:02.826  INFO 17168 --- [Executor task launch worker for task 95] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:03.112  INFO 17168 --- [Executor task launch worker for task 95] o.a.spark.storage.memory.MemoryStore     : Block rdd_110_0 stored as values in memory (estimated size 820.5 KB, free 1924.9 MB)
2018-05-01 17:43:03.112  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_110_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:43:03.115  INFO 17168 --- [Executor task launch worker for task 95] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 101.0 (TID 95). 2595 bytes result sent to driver
2018-05-01 17:43:03.116  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 101.0 (TID 95) in 292 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.116  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 101.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.116  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 101 (aggregate at ALS.scala:1491) finished in 0.292 s
2018-05-01 17:43:03.117  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 14 finished: aggregate at ALS.scala:1491, took 0.358523 s
2018-05-01 17:43:03.133  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 100 from persistence list
2018-05-01 17:43:03.134  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 100
2018-05-01 17:43:03.139  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:03.140  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:03.140  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:03.141  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:03.141  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:03.141  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:03.141  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 115 (flatMap at ALS.scala:1433)
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 15 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 116 (aggregate at ALS.scala:1491)
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 103, ShuffleMapStage 115)
2018-05-01 17:43:03.144  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 115)
2018-05-01 17:43:03.144  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 115 (MapPartitionsRDD[115] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:03.146  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_29 stored as values in memory (estimated size 24.2 KB, free 1925.2 MB)
2018-05-01 17:43:03.147  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.1 KB, free 1925.2 MB)
2018-05-01 17:43:03.147  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_29_piece0 in memory on 172.21.241.193:58363 (size: 11.1 KB, free: 1925.6 MB)
2018-05-01 17:43:03.147  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.148  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[115] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.148  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 115.0 with 1 tasks
2018-05-01 17:43:03.149  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 115.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:03.149  INFO 17168 --- [Executor task launch worker for task 96] org.apache.spark.executor.Executor       : Running task 0.0 in stage 115.0 (TID 96)
2018-05-01 17:43:03.152  INFO 17168 --- [Executor task launch worker for task 96] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:03.152  INFO 17168 --- [Executor task launch worker for task 96] org.apache.spark.storage.BlockManager    : Found block rdd_110_0 locally
2018-05-01 17:43:03.187  INFO 17168 --- [Executor task launch worker for task 96] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 115.0 (TID 96). 1155 bytes result sent to driver
2018-05-01 17:43:03.187  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 115.0 (TID 96) in 38 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.187  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 115.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 115 (flatMap at ALS.scala:1433) finished in 0.039 s
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 116)
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 116 (MapPartitionsRDD[121] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:03.190  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_30 stored as values in memory (estimated size 26.7 KB, free 1925.2 MB)
2018-05-01 17:43:03.191  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1925.2 MB)
2018-05-01 17:43:03.192  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_30_piece0 in memory on 172.21.241.193:58363 (size: 11.9 KB, free: 1925.6 MB)
2018-05-01 17:43:03.192  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.192  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[121] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.192  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 116.0 with 1 tasks
2018-05-01 17:43:03.193  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 116.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:03.193  INFO 17168 --- [Executor task launch worker for task 97] org.apache.spark.executor.Executor       : Running task 0.0 in stage 116.0 (TID 97)
2018-05-01 17:43:03.196  INFO 17168 --- [Executor task launch worker for task 97] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:03.197  INFO 17168 --- [Executor task launch worker for task 97] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:03.197  INFO 17168 --- [Executor task launch worker for task 97] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:03.470  INFO 17168 --- [Executor task launch worker for task 97] o.a.spark.storage.memory.MemoryStore     : Block rdd_120_0 stored as values in memory (estimated size 416.2 KB, free 1924.8 MB)
2018-05-01 17:43:03.471  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_120_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:43:03.472  INFO 17168 --- [Executor task launch worker for task 97] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 116.0 (TID 97). 2595 bytes result sent to driver
2018-05-01 17:43:03.473  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 116.0 (TID 97) in 280 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.473  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 116.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.473  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 116 (aggregate at ALS.scala:1491) finished in 0.281 s
2018-05-01 17:43:03.474  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 15 finished: aggregate at ALS.scala:1491, took 0.334581 s
2018-05-01 17:43:03.492  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 110 from persistence list
2018-05-01 17:43:03.492  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 110
2018-05-01 17:43:03.497  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:03.498  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:03.500  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:03.500  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:03.500  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:03.501  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:03.502  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:03.502  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:03.502  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 125 (flatMap at ALS.scala:1433)
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 16 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 132 (aggregate at ALS.scala:1491)
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 120, ShuffleMapStage 131)
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 131)
2018-05-01 17:43:03.504  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 131 (MapPartitionsRDD[125] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:03.507  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_31 stored as values in memory (estimated size 25.8 KB, free 1925.6 MB)
2018-05-01 17:43:03.508  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_31_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1925.6 MB)
2018-05-01 17:43:03.509  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_31_piece0 in memory on 172.21.241.193:58363 (size: 11.7 KB, free: 1926.0 MB)
2018-05-01 17:43:03.509  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.509  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[125] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.509  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 131.0 with 1 tasks
2018-05-01 17:43:03.510  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 131.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:03.510  INFO 17168 --- [Executor task launch worker for task 98] org.apache.spark.executor.Executor       : Running task 0.0 in stage 131.0 (TID 98)
2018-05-01 17:43:03.512  INFO 17168 --- [Executor task launch worker for task 98] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:03.512  INFO 17168 --- [Executor task launch worker for task 98] org.apache.spark.storage.BlockManager    : Found block rdd_120_0 locally
2018-05-01 17:43:03.538  INFO 17168 --- [Executor task launch worker for task 98] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 131.0 (TID 98). 1112 bytes result sent to driver
2018-05-01 17:43:03.539  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 131.0 (TID 98) in 29 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.539  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 131.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 131 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 132)
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:03.540  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 132 (MapPartitionsRDD[131] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:03.541  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_32 stored as values in memory (estimated size 28.2 KB, free 1925.5 MB)
2018-05-01 17:43:03.542  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_32_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1925.5 MB)
2018-05-01 17:43:03.543  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_32_piece0 in memory on 172.21.241.193:58363 (size: 12.5 KB, free: 1926.0 MB)
2018-05-01 17:43:03.543  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.543  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[131] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.543  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 132.0 with 1 tasks
2018-05-01 17:43:03.544  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 132.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:03.544  INFO 17168 --- [Executor task launch worker for task 99] org.apache.spark.executor.Executor       : Running task 0.0 in stage 132.0 (TID 99)
2018-05-01 17:43:03.546  INFO 17168 --- [Executor task launch worker for task 99] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:03.546  INFO 17168 --- [Executor task launch worker for task 99] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:03.546  INFO 17168 --- [Executor task launch worker for task 99] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:03.833  INFO 17168 --- [Executor task launch worker for task 99] o.a.spark.storage.memory.MemoryStore     : Block rdd_130_0 stored as values in memory (estimated size 820.5 KB, free 1924.7 MB)
2018-05-01 17:43:03.834  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_130_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:43:03.840  INFO 17168 --- [Executor task launch worker for task 99] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 132.0 (TID 99). 2595 bytes result sent to driver
2018-05-01 17:43:03.840  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 132.0 (TID 99) in 296 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.840  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 132.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.841  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 132 (aggregate at ALS.scala:1491) finished in 0.298 s
2018-05-01 17:43:03.841  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 16 finished: aggregate at ALS.scala:1491, took 0.343726 s
2018-05-01 17:43:03.861  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 120 from persistence list
2018-05-01 17:43:03.862  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 120
2018-05-01 17:43:03.866  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:03.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:03.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:03.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:03.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:03.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:03.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:03.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:03.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 135 (flatMap at ALS.scala:1433)
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 17 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 149 (aggregate at ALS.scala:1491)
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 148, ShuffleMapStage 134)
2018-05-01 17:43:03.871  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 148)
2018-05-01 17:43:03.871  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 148 (MapPartitionsRDD[135] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:03.873  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_33 stored as values in memory (estimated size 27.3 KB, free 1925.1 MB)
2018-05-01 17:43:03.874  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_33_piece0 stored as bytes in memory (estimated size 12.4 KB, free 1925.1 MB)
2018-05-01 17:43:03.874  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_33_piece0 in memory on 172.21.241.193:58363 (size: 12.4 KB, free: 1925.5 MB)
2018-05-01 17:43:03.875  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.875  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[135] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.875  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 148.0 with 1 tasks
2018-05-01 17:43:03.875  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 148.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:03.875  INFO 17168 --- [Executor task launch worker for task 100] org.apache.spark.executor.Executor       : Running task 0.0 in stage 148.0 (TID 100)
2018-05-01 17:43:03.877  INFO 17168 --- [Executor task launch worker for task 100] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:03.877  INFO 17168 --- [Executor task launch worker for task 100] org.apache.spark.storage.BlockManager    : Found block rdd_130_0 locally
2018-05-01 17:43:03.909  INFO 17168 --- [Executor task launch worker for task 100] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 148.0 (TID 100). 1069 bytes result sent to driver
2018-05-01 17:43:03.909  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 148.0 (TID 100) in 34 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.910  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 148.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.910  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 148 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:43:03.910  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:03.911  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:03.911  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 149)
2018-05-01 17:43:03.911  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:03.911  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 149 (MapPartitionsRDD[141] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:03.913  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_34 stored as values in memory (estimated size 29.8 KB, free 1925.0 MB)
2018-05-01 17:43:03.913  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_34_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1925.0 MB)
2018-05-01 17:43:03.914  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_34_piece0 in memory on 172.21.241.193:58363 (size: 13.3 KB, free: 1925.5 MB)
2018-05-01 17:43:03.914  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.914  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[141] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.914  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 149.0 with 1 tasks
2018-05-01 17:43:03.915  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 149.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:03.915  INFO 17168 --- [Executor task launch worker for task 101] org.apache.spark.executor.Executor       : Running task 0.0 in stage 149.0 (TID 101)
2018-05-01 17:43:03.917  INFO 17168 --- [Executor task launch worker for task 101] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:03.917  INFO 17168 --- [Executor task launch worker for task 101] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:03.917  INFO 17168 --- [Executor task launch worker for task 101] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:04.193  INFO 17168 --- [Executor task launch worker for task 101] o.a.spark.storage.memory.MemoryStore     : Block rdd_140_0 stored as values in memory (estimated size 416.2 KB, free 1924.6 MB)
2018-05-01 17:43:04.193  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_140_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 17:43:04.195  INFO 17168 --- [Executor task launch worker for task 101] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 149.0 (TID 101). 2638 bytes result sent to driver
2018-05-01 17:43:04.196  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 149.0 (TID 101) in 281 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.196  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 149.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.196  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 149 (aggregate at ALS.scala:1491) finished in 0.282 s
2018-05-01 17:43:04.197  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 17 finished: aggregate at ALS.scala:1491, took 0.330489 s
2018-05-01 17:43:04.212  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 130 from persistence list
2018-05-01 17:43:04.213  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 130
2018-05-01 17:43:04.218  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:04.218  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:04.219  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:04.219  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:04.219  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:04.220  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:04.220  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:04.220  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:04.220  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:04.221  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:04.221  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:04.221  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:04.221  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 145 (flatMap at ALS.scala:1433)
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 18 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 167 (aggregate at ALS.scala:1491)
2018-05-01 17:43:04.223  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 153, ShuffleMapStage 166)
2018-05-01 17:43:04.223  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 166)
2018-05-01 17:43:04.223  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 166 (MapPartitionsRDD[145] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:04.225  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_35 stored as values in memory (estimated size 28.9 KB, free 1925.4 MB)
2018-05-01 17:43:04.226  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_35_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1925.4 MB)
2018-05-01 17:43:04.226  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_35_piece0 in memory on 172.21.241.193:58363 (size: 13.0 KB, free: 1925.9 MB)
2018-05-01 17:43:04.226  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.227  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[145] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.227  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 166.0 with 1 tasks
2018-05-01 17:43:04.227  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 166.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:04.227  INFO 17168 --- [Executor task launch worker for task 102] org.apache.spark.executor.Executor       : Running task 0.0 in stage 166.0 (TID 102)
2018-05-01 17:43:04.229  INFO 17168 --- [Executor task launch worker for task 102] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:04.229  INFO 17168 --- [Executor task launch worker for task 102] org.apache.spark.storage.BlockManager    : Found block rdd_140_0 locally
2018-05-01 17:43:04.255  INFO 17168 --- [Executor task launch worker for task 102] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 166.0 (TID 102). 1069 bytes result sent to driver
2018-05-01 17:43:04.255  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 166.0 (TID 102) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.256  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 166.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.256  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 166 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:43:04.256  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:04.257  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:04.257  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 167)
2018-05-01 17:43:04.257  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:04.257  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 167 (MapPartitionsRDD[151] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:04.259  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_36 stored as values in memory (estimated size 31.3 KB, free 1925.4 MB)
2018-05-01 17:43:04.260  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_36_piece0 stored as bytes in memory (estimated size 13.8 KB, free 1925.3 MB)
2018-05-01 17:43:04.260  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_36_piece0 in memory on 172.21.241.193:58363 (size: 13.8 KB, free: 1925.9 MB)
2018-05-01 17:43:04.261  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.261  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[151] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.261  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 167.0 with 1 tasks
2018-05-01 17:43:04.261  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 167.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:04.262  INFO 17168 --- [Executor task launch worker for task 103] org.apache.spark.executor.Executor       : Running task 0.0 in stage 167.0 (TID 103)
2018-05-01 17:43:04.264  INFO 17168 --- [Executor task launch worker for task 103] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:04.264  INFO 17168 --- [Executor task launch worker for task 103] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:04.264  INFO 17168 --- [Executor task launch worker for task 103] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:04.540  INFO 17168 --- [Executor task launch worker for task 103] o.a.spark.storage.memory.MemoryStore     : Block rdd_150_0 stored as values in memory (estimated size 820.5 KB, free 1924.5 MB)
2018-05-01 17:43:04.540  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_150_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:43:04.544  INFO 17168 --- [Executor task launch worker for task 103] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 167.0 (TID 103). 2595 bytes result sent to driver
2018-05-01 17:43:04.545  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 167.0 (TID 103) in 284 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.545  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 167.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.545  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 167 (aggregate at ALS.scala:1491) finished in 0.284 s
2018-05-01 17:43:04.545  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 18 finished: aggregate at ALS.scala:1491, took 0.327285 s
2018-05-01 17:43:04.562  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 140 from persistence list
2018-05-01 17:43:04.563  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 140
2018-05-01 17:43:04.567  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:04.568  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:04.568  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:04.569  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:04.569  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:04.569  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:04.569  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 155 (flatMap at ALS.scala:1433)
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 19 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 186 (aggregate at ALS.scala:1491)
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 169, ShuffleMapStage 185)
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 185)
2018-05-01 17:43:04.573  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 185 (MapPartitionsRDD[155] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:04.575  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_37 stored as values in memory (estimated size 30.4 KB, free 1924.9 MB)
2018-05-01 17:43:04.576  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_37_piece0 stored as bytes in memory (estimated size 13.7 KB, free 1924.9 MB)
2018-05-01 17:43:04.576  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_37_piece0 in memory on 172.21.241.193:58363 (size: 13.7 KB, free: 1925.5 MB)
2018-05-01 17:43:04.576  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.577  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 185 (MapPartitionsRDD[155] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.577  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 185.0 with 1 tasks
2018-05-01 17:43:04.577  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 185.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:04.577  INFO 17168 --- [Executor task launch worker for task 104] org.apache.spark.executor.Executor       : Running task 0.0 in stage 185.0 (TID 104)
2018-05-01 17:43:04.579  INFO 17168 --- [Executor task launch worker for task 104] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:04.579  INFO 17168 --- [Executor task launch worker for task 104] org.apache.spark.storage.BlockManager    : Found block rdd_150_0 locally
2018-05-01 17:43:04.610  INFO 17168 --- [Executor task launch worker for task 104] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 185.0 (TID 104). 1069 bytes result sent to driver
2018-05-01 17:43:04.610  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 185.0 (TID 104) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.610  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 185.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.610  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 185 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 17:43:04.610  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:04.610  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:04.611  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 186)
2018-05-01 17:43:04.611  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:04.612  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 186 (MapPartitionsRDD[161] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:04.613  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_38 stored as values in memory (estimated size 32.9 KB, free 1924.9 MB)
2018-05-01 17:43:04.614  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_38_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1924.9 MB)
2018-05-01 17:43:04.615  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_38_piece0 in memory on 172.21.241.193:58363 (size: 14.6 KB, free: 1925.5 MB)
2018-05-01 17:43:04.615  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.615  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[161] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.615  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 186.0 with 1 tasks
2018-05-01 17:43:04.616  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 186.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:04.616  INFO 17168 --- [Executor task launch worker for task 105] org.apache.spark.executor.Executor       : Running task 0.0 in stage 186.0 (TID 105)
2018-05-01 17:43:04.618  INFO 17168 --- [Executor task launch worker for task 105] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:04.618  INFO 17168 --- [Executor task launch worker for task 105] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:04.618  INFO 17168 --- [Executor task launch worker for task 105] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:04.893  INFO 17168 --- [Executor task launch worker for task 105] o.a.spark.storage.memory.MemoryStore     : Block rdd_160_0 stored as values in memory (estimated size 416.2 KB, free 1924.5 MB)
2018-05-01 17:43:04.893  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_160_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 17:43:04.895  INFO 17168 --- [Executor task launch worker for task 105] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 186.0 (TID 105). 2595 bytes result sent to driver
2018-05-01 17:43:04.896  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 186.0 (TID 105) in 280 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.896  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 186.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.896  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 186 (aggregate at ALS.scala:1491) finished in 0.281 s
2018-05-01 17:43:04.897  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 19 finished: aggregate at ALS.scala:1491, took 0.329117 s
2018-05-01 17:43:04.919  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 150 from persistence list
2018-05-01 17:43:04.920  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 150
2018-05-01 17:43:04.925  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:04.925  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:04.925  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:04.928  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:04.928  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:04.928  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:04.928  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 165 (flatMap at ALS.scala:1433)
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 20 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 206 (aggregate at ALS.scala:1491)
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 190, ShuffleMapStage 205)
2018-05-01 17:43:04.930  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 205)
2018-05-01 17:43:04.930  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 205 (MapPartitionsRDD[165] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:04.932  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_39 stored as values in memory (estimated size 32.0 KB, free 1925.2 MB)
2018-05-01 17:43:04.933  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_39_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1925.2 MB)
2018-05-01 17:43:04.933  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_39_piece0 in memory on 172.21.241.193:58363 (size: 14.3 KB, free: 1925.9 MB)
2018-05-01 17:43:04.933  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.934  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 205 (MapPartitionsRDD[165] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.934  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 205.0 with 1 tasks
2018-05-01 17:43:04.934  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 205.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:04.934  INFO 17168 --- [Executor task launch worker for task 106] org.apache.spark.executor.Executor       : Running task 0.0 in stage 205.0 (TID 106)
2018-05-01 17:43:04.937  INFO 17168 --- [Executor task launch worker for task 106] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:04.937  INFO 17168 --- [Executor task launch worker for task 106] org.apache.spark.storage.BlockManager    : Found block rdd_160_0 locally
2018-05-01 17:43:04.979  INFO 17168 --- [Executor task launch worker for task 106] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 205.0 (TID 106). 1069 bytes result sent to driver
2018-05-01 17:43:04.980  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 205.0 (TID 106) in 46 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.980  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 205.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 205 (flatMap at ALS.scala:1433) finished in 0.046 s
2018-05-01 17:43:04.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:04.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:04.981  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 206)
2018-05-01 17:43:04.981  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:04.982  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 206 (MapPartitionsRDD[171] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:04.984  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_40 stored as values in memory (estimated size 34.4 KB, free 1925.2 MB)
2018-05-01 17:43:04.986  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_40_piece0 stored as bytes in memory (estimated size 15.5 KB, free 1925.2 MB)
2018-05-01 17:43:04.986  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_40_piece0 in memory on 172.21.241.193:58363 (size: 15.5 KB, free: 1925.8 MB)
2018-05-01 17:43:04.987  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.987  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 206 (MapPartitionsRDD[171] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.987  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 206.0 with 1 tasks
2018-05-01 17:43:04.988  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 206.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:04.988  INFO 17168 --- [Executor task launch worker for task 107] org.apache.spark.executor.Executor       : Running task 0.0 in stage 206.0 (TID 107)
2018-05-01 17:43:04.990  INFO 17168 --- [Executor task launch worker for task 107] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:04.990  INFO 17168 --- [Executor task launch worker for task 107] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:04.990  INFO 17168 --- [Executor task launch worker for task 107] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:05.273  INFO 17168 --- [Executor task launch worker for task 107] o.a.spark.storage.memory.MemoryStore     : Block rdd_170_0 stored as values in memory (estimated size 820.5 KB, free 1924.4 MB)
2018-05-01 17:43:05.274  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_170_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.0 MB)
2018-05-01 17:43:05.277  INFO 17168 --- [Executor task launch worker for task 107] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 206.0 (TID 107). 2595 bytes result sent to driver
2018-05-01 17:43:05.278  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 206.0 (TID 107) in 290 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:05.278  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 206.0, whose tasks have all completed, from pool 
2018-05-01 17:43:05.278  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 206 (aggregate at ALS.scala:1491) finished in 0.291 s
2018-05-01 17:43:05.279  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 20 finished: aggregate at ALS.scala:1491, took 0.354083 s
2018-05-01 17:43:05.297  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 160 from persistence list
2018-05-01 17:43:05.297  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 160
2018-05-01 17:43:05.302  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:05.303  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:05.303  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:05.303  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:05.303  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:05.305  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:05.305  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:05.305  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:05.305  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:05.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:05.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:05.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:05.307  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:05.307  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 175 (flatMap at ALS.scala:1433)
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 21 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 227 (aggregate at ALS.scala:1491)
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 208, ShuffleMapStage 226)
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 226)
2018-05-01 17:43:05.309  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 226 (MapPartitionsRDD[175] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:05.311  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_41 stored as values in memory (estimated size 33.5 KB, free 1924.7 MB)
2018-05-01 17:43:05.312  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_41_piece0 stored as bytes in memory (estimated size 15.2 KB, free 1924.7 MB)
2018-05-01 17:43:05.312  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_41_piece0 in memory on 172.21.241.193:58363 (size: 15.2 KB, free: 1925.4 MB)
2018-05-01 17:43:05.312  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:05.313  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 226 (MapPartitionsRDD[175] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:05.313  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 226.0 with 1 tasks
2018-05-01 17:43:05.313  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 226.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:05.313  INFO 17168 --- [Executor task launch worker for task 108] org.apache.spark.executor.Executor       : Running task 0.0 in stage 226.0 (TID 108)
2018-05-01 17:43:05.315  INFO 17168 --- [Executor task launch worker for task 108] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:05.315  INFO 17168 --- [Executor task launch worker for task 108] org.apache.spark.storage.BlockManager    : Found block rdd_170_0 locally
2018-05-01 17:43:05.346  INFO 17168 --- [Executor task launch worker for task 108] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 226.0 (TID 108). 1069 bytes result sent to driver
2018-05-01 17:43:05.346  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 226.0 (TID 108) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:05.346  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 226.0, whose tasks have all completed, from pool 
2018-05-01 17:43:05.346  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 226 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 17:43:05.347  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:05.348  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:05.348  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 227)
2018-05-01 17:43:05.348  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:05.348  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 227 (MapPartitionsRDD[181] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:05.350  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_42 stored as values in memory (estimated size 36.0 KB, free 1924.7 MB)
2018-05-01 17:43:05.351  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_42_piece0 stored as bytes in memory (estimated size 16.3 KB, free 1924.7 MB)
2018-05-01 17:43:05.351  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_42_piece0 in memory on 172.21.241.193:58363 (size: 16.3 KB, free: 1925.4 MB)
2018-05-01 17:43:05.352  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:05.352  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[181] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:05.352  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 227.0 with 1 tasks
2018-05-01 17:43:05.353  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 227.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:05.353  INFO 17168 --- [Executor task launch worker for task 109] org.apache.spark.executor.Executor       : Running task 0.0 in stage 227.0 (TID 109)
2018-05-01 17:43:05.356  INFO 17168 --- [Executor task launch worker for task 109] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:05.356  INFO 17168 --- [Executor task launch worker for task 109] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:05.356  INFO 17168 --- [Executor task launch worker for task 109] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:05.632  INFO 17168 --- [Executor task launch worker for task 109] o.a.spark.storage.memory.MemoryStore     : Block rdd_180_0 stored as values in memory (estimated size 416.2 KB, free 1924.3 MB)
2018-05-01 17:43:05.632  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_180_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.0 MB)
2018-05-01 17:43:05.635  INFO 17168 --- [Executor task launch worker for task 109] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 227.0 (TID 109). 2638 bytes result sent to driver
2018-05-01 17:43:05.636  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 227.0 (TID 109) in 283 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:05.636  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 227.0, whose tasks have all completed, from pool 
2018-05-01 17:43:05.636  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 227 (aggregate at ALS.scala:1491) finished in 0.284 s
2018-05-01 17:43:05.637  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 21 finished: aggregate at ALS.scala:1491, took 0.334334 s
2018-05-01 17:43:05.656  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 170 from persistence list
2018-05-01 17:43:05.657  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 170
2018-05-01 17:43:05.662  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:05.662  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:05.662  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:05.663  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:05.663  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:05.663  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:05.663  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:05.664  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:05.664  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:05.664  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:05.664  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 185 (flatMap at ALS.scala:1433)
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 22 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 249 (aggregate at ALS.scala:1491)
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 248, ShuffleMapStage 229)
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 248)
2018-05-01 17:43:05.668  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 248 (MapPartitionsRDD[185] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:05.670  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_43 stored as values in memory (estimated size 35.1 KB, free 1925.0 MB)
2018-05-01 17:43:05.671  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_43_piece0 stored as bytes in memory (estimated size 15.9 KB, free 1925.0 MB)
2018-05-01 17:43:05.671  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_43_piece0 in memory on 172.21.241.193:58363 (size: 15.9 KB, free: 1925.8 MB)
2018-05-01 17:43:05.671  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:05.671  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 248 (MapPartitionsRDD[185] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:05.672  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 248.0 with 1 tasks
2018-05-01 17:43:05.672  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 248.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:05.672  INFO 17168 --- [Executor task launch worker for task 110] org.apache.spark.executor.Executor       : Running task 0.0 in stage 248.0 (TID 110)
2018-05-01 17:43:05.674  INFO 17168 --- [Executor task launch worker for task 110] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:05.674  INFO 17168 --- [Executor task launch worker for task 110] org.apache.spark.storage.BlockManager    : Found block rdd_180_0 locally
2018-05-01 17:43:05.704  INFO 17168 --- [Executor task launch worker for task 110] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 248.0 (TID 110). 1069 bytes result sent to driver
2018-05-01 17:43:05.705  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 248.0 (TID 110) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:05.705  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 248.0, whose tasks have all completed, from pool 
2018-05-01 17:43:05.705  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 248 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 249)
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 249 (MapPartitionsRDD[191] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:05.708  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_44 stored as values in memory (estimated size 37.5 KB, free 1925.0 MB)
2018-05-01 17:43:05.709  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.8 KB, free 1925.0 MB)
2018-05-01 17:43:05.710  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_44_piece0 in memory on 172.21.241.193:58363 (size: 16.8 KB, free: 1925.8 MB)
2018-05-01 17:43:05.710  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:05.710  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 249 (MapPartitionsRDD[191] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:05.710  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 249.0 with 1 tasks
2018-05-01 17:43:05.711  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 249.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:05.711  INFO 17168 --- [Executor task launch worker for task 111] org.apache.spark.executor.Executor       : Running task 0.0 in stage 249.0 (TID 111)
2018-05-01 17:43:05.714  INFO 17168 --- [Executor task launch worker for task 111] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:05.714  INFO 17168 --- [Executor task launch worker for task 111] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:05.714  INFO 17168 --- [Executor task launch worker for task 111] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:06.008  INFO 17168 --- [Executor task launch worker for task 111] o.a.spark.storage.memory.MemoryStore     : Block rdd_190_0 stored as values in memory (estimated size 820.5 KB, free 1924.2 MB)
2018-05-01 17:43:06.009  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_190_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.0 MB)
2018-05-01 17:43:06.012  INFO 17168 --- [Executor task launch worker for task 111] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 249.0 (TID 111). 2638 bytes result sent to driver
2018-05-01 17:43:06.013  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 249.0 (TID 111) in 303 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.013  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 249.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.013  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 249 (aggregate at ALS.scala:1491) finished in 0.303 s
2018-05-01 17:43:06.014  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 22 finished: aggregate at ALS.scala:1491, took 0.351830 s
2018-05-01 17:43:06.031  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 180 from persistence list
2018-05-01 17:43:06.031  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 180
2018-05-01 17:43:06.036  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:06.036  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:06.036  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:06.037  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:06.037  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:06.037  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:06.037  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 195 (flatMap at ALS.scala:1433)
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 23 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 272 (aggregate at ALS.scala:1491)
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 251, ShuffleMapStage 271)
2018-05-01 17:43:06.041  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 271)
2018-05-01 17:43:06.041  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 271 (MapPartitionsRDD[195] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:06.044  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_45 stored as values in memory (estimated size 36.6 KB, free 1924.5 MB)
2018-05-01 17:43:06.045  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_45_piece0 stored as bytes in memory (estimated size 16.5 KB, free 1924.5 MB)
2018-05-01 17:43:06.045  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_45_piece0 in memory on 172.21.241.193:58363 (size: 16.5 KB, free: 1925.4 MB)
2018-05-01 17:43:06.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 271 (MapPartitionsRDD[195] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.046  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 271.0 with 1 tasks
2018-05-01 17:43:06.047  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 271.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:06.047  INFO 17168 --- [Executor task launch worker for task 112] org.apache.spark.executor.Executor       : Running task 0.0 in stage 271.0 (TID 112)
2018-05-01 17:43:06.049  INFO 17168 --- [Executor task launch worker for task 112] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:06.049  INFO 17168 --- [Executor task launch worker for task 112] org.apache.spark.storage.BlockManager    : Found block rdd_190_0 locally
2018-05-01 17:43:06.084  INFO 17168 --- [Executor task launch worker for task 112] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 271.0 (TID 112). 1069 bytes result sent to driver
2018-05-01 17:43:06.084  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 271.0 (TID 112) in 38 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.084  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 271.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 271 (flatMap at ALS.scala:1433) finished in 0.038 s
2018-05-01 17:43:06.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:06.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:06.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 272)
2018-05-01 17:43:06.085  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:06.085  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 272 (MapPartitionsRDD[201] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:06.088  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_46 stored as values in memory (estimated size 39.1 KB, free 1924.5 MB)
2018-05-01 17:43:06.089  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_46_piece0 stored as bytes in memory (estimated size 17.6 KB, free 1924.5 MB)
2018-05-01 17:43:06.089  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_46_piece0 in memory on 172.21.241.193:58363 (size: 17.6 KB, free: 1925.4 MB)
2018-05-01 17:43:06.090  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.090  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[201] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.090  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 272.0 with 1 tasks
2018-05-01 17:43:06.090  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 272.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:06.091  INFO 17168 --- [Executor task launch worker for task 113] org.apache.spark.executor.Executor       : Running task 0.0 in stage 272.0 (TID 113)
2018-05-01 17:43:06.093  INFO 17168 --- [Executor task launch worker for task 113] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:06.093  INFO 17168 --- [Executor task launch worker for task 113] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:06.093  INFO 17168 --- [Executor task launch worker for task 113] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:06.363  INFO 17168 --- [Executor task launch worker for task 113] o.a.spark.storage.memory.MemoryStore     : Block rdd_200_0 stored as values in memory (estimated size 416.2 KB, free 1924.1 MB)
2018-05-01 17:43:06.363  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_200_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1924.9 MB)
2018-05-01 17:43:06.365  INFO 17168 --- [Executor task launch worker for task 113] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 272.0 (TID 113). 2595 bytes result sent to driver
2018-05-01 17:43:06.365  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 272.0 (TID 113) in 275 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.365  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 272.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.366  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 272 (aggregate at ALS.scala:1491) finished in 0.276 s
2018-05-01 17:43:06.366  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 23 finished: aggregate at ALS.scala:1491, took 0.330080 s
2018-05-01 17:43:06.382  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 190 from persistence list
2018-05-01 17:43:06.382  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 190
2018-05-01 17:43:06.387  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:06.388  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:06.388  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:06.389  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:06.389  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:06.389  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:06.389  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 205 (flatMap at ALS.scala:1433)
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 24 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 296 (aggregate at ALS.scala:1491)
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 276, ShuffleMapStage 295)
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 295)
2018-05-01 17:43:06.394  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 295 (MapPartitionsRDD[205] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:06.396  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_47 stored as values in memory (estimated size 38.2 KB, free 1924.8 MB)
2018-05-01 17:43:06.397  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_47_piece0 stored as bytes in memory (estimated size 17.3 KB, free 1924.8 MB)
2018-05-01 17:43:06.397  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_47_piece0 in memory on 172.21.241.193:58363 (size: 17.3 KB, free: 1925.7 MB)
2018-05-01 17:43:06.397  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.398  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 295 (MapPartitionsRDD[205] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.398  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 295.0 with 1 tasks
2018-05-01 17:43:06.399  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 295.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:06.399  INFO 17168 --- [Executor task launch worker for task 114] org.apache.spark.executor.Executor       : Running task 0.0 in stage 295.0 (TID 114)
2018-05-01 17:43:06.402  INFO 17168 --- [Executor task launch worker for task 114] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:06.402  INFO 17168 --- [Executor task launch worker for task 114] org.apache.spark.storage.BlockManager    : Found block rdd_200_0 locally
2018-05-01 17:43:06.434  INFO 17168 --- [Executor task launch worker for task 114] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 295.0 (TID 114). 1112 bytes result sent to driver
2018-05-01 17:43:06.435  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 295.0 (TID 114) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.435  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 295.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 295 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 296)
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:06.436  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 296 (MapPartitionsRDD[211] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:06.438  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_48 stored as values in memory (estimated size 40.6 KB, free 1924.8 MB)
2018-05-01 17:43:06.521  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_48_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1924.7 MB)
2018-05-01 17:43:06.523  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_48_piece0 in memory on 172.21.241.193:58363 (size: 18.2 KB, free: 1925.7 MB)
2018-05-01 17:43:06.527  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.528  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 296 (MapPartitionsRDD[211] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.528  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 296.0 with 1 tasks
2018-05-01 17:43:06.528  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_9_piece0 on 172.21.241.193:58363 in memory (size: 4.3 KB, free: 1925.7 MB)
2018-05-01 17:43:06.528  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 296.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:06.528  INFO 17168 --- [Executor task launch worker for task 115] org.apache.spark.executor.Executor       : Running task 0.0 in stage 296.0 (TID 115)
2018-05-01 17:43:06.529  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_18_piece0 on 172.21.241.193:58363 in memory (size: 7.9 KB, free: 1925.7 MB)
2018-05-01 17:43:06.529  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_26_piece0 on 172.21.241.193:58363 in memory (size: 10.6 KB, free: 1925.7 MB)
2018-05-01 17:43:06.530  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_17_piece0 on 172.21.241.193:58363 in memory (size: 7.0 KB, free: 1925.7 MB)
2018-05-01 17:43:06.531  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_29_piece0 on 172.21.241.193:58363 in memory (size: 11.1 KB, free: 1925.8 MB)
2018-05-01 17:43:06.531  INFO 17168 --- [Executor task launch worker for task 115] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:06.532  INFO 17168 --- [Executor task launch worker for task 115] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:06.532  INFO 17168 --- [Executor task launch worker for task 115] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:06.532  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_36_piece0 on 172.21.241.193:58363 in memory (size: 13.8 KB, free: 1925.8 MB)
2018-05-01 17:43:06.532  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_31_piece0 on 172.21.241.193:58363 in memory (size: 11.7 KB, free: 1925.8 MB)
2018-05-01 17:43:06.533  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_8_piece0 on 172.21.241.193:58363 in memory (size: 4.0 KB, free: 1925.8 MB)
2018-05-01 17:43:06.534  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_41_piece0 on 172.21.241.193:58363 in memory (size: 15.2 KB, free: 1925.8 MB)
2018-05-01 17:43:06.535  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_44_piece0 on 172.21.241.193:58363 in memory (size: 16.8 KB, free: 1925.8 MB)
2018-05-01 17:43:06.536  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_14_piece0 on 172.21.241.193:58363 in memory (size: 6.6 KB, free: 1925.8 MB)
2018-05-01 17:43:06.537  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_30_piece0 on 172.21.241.193:58363 in memory (size: 11.9 KB, free: 1925.8 MB)
2018-05-01 17:43:06.537  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_11_piece0 on 172.21.241.193:58363 in memory (size: 4.3 KB, free: 1925.8 MB)
2018-05-01 17:43:06.538  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_28_piece0 on 172.21.241.193:58363 in memory (size: 11.2 KB, free: 1925.8 MB)
2018-05-01 17:43:06.539  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_38_piece0 on 172.21.241.193:58363 in memory (size: 14.6 KB, free: 1925.9 MB)
2018-05-01 17:43:06.539  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_16_piece0 on 172.21.241.193:58363 in memory (size: 7.3 KB, free: 1925.9 MB)
2018-05-01 17:43:06.540  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_20_piece0 on 172.21.241.193:58363 in memory (size: 8.6 KB, free: 1925.9 MB)
2018-05-01 17:43:06.541  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_35_piece0 on 172.21.241.193:58363 in memory (size: 13.0 KB, free: 1925.9 MB)
2018-05-01 17:43:06.542  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_10_piece0 on 172.21.241.193:58363 in memory (size: 4.0 KB, free: 1925.9 MB)
2018-05-01 17:43:06.542  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_27_piece0 on 172.21.241.193:58363 in memory (size: 10.5 KB, free: 1925.9 MB)
2018-05-01 17:43:06.543  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_21_piece0 on 172.21.241.193:58363 in memory (size: 8.4 KB, free: 1925.9 MB)
2018-05-01 17:43:06.544  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_23_piece0 on 172.21.241.193:58363 in memory (size: 9.1 KB, free: 1925.9 MB)
2018-05-01 17:43:06.544  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_34_piece0 on 172.21.241.193:58363 in memory (size: 13.3 KB, free: 1925.9 MB)
2018-05-01 17:43:06.545  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_24_piece0 on 172.21.241.193:58363 in memory (size: 9.9 KB, free: 1925.9 MB)
2018-05-01 17:43:06.545  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_33_piece0 on 172.21.241.193:58363 in memory (size: 12.4 KB, free: 1926.0 MB)
2018-05-01 17:43:06.546  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_46_piece0 on 172.21.241.193:58363 in memory (size: 17.6 KB, free: 1926.0 MB)
2018-05-01 17:43:06.547  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_12_piece0 on 172.21.241.193:58363 in memory (size: 5.8 KB, free: 1926.0 MB)
2018-05-01 17:43:06.547  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_13_piece0 on 172.21.241.193:58363 in memory (size: 5.6 KB, free: 1926.0 MB)
2018-05-01 17:43:06.548  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_42_piece0 on 172.21.241.193:58363 in memory (size: 16.3 KB, free: 1926.0 MB)
2018-05-01 17:43:06.548  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_25_piece0 on 172.21.241.193:58363 in memory (size: 9.7 KB, free: 1926.0 MB)
2018-05-01 17:43:06.549  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_19_piece0 on 172.21.241.193:58363 in memory (size: 7.8 KB, free: 1926.0 MB)
2018-05-01 17:43:06.549  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_45_piece0 on 172.21.241.193:58363 in memory (size: 16.5 KB, free: 1926.0 MB)
2018-05-01 17:43:06.550  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_43_piece0 on 172.21.241.193:58363 in memory (size: 15.9 KB, free: 1926.0 MB)
2018-05-01 17:43:06.551  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_32_piece0 on 172.21.241.193:58363 in memory (size: 12.5 KB, free: 1926.1 MB)
2018-05-01 17:43:06.551  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_22_piece0 on 172.21.241.193:58363 in memory (size: 9.2 KB, free: 1926.1 MB)
2018-05-01 17:43:06.552  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_37_piece0 on 172.21.241.193:58363 in memory (size: 13.7 KB, free: 1926.1 MB)
2018-05-01 17:43:06.553  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_39_piece0 on 172.21.241.193:58363 in memory (size: 14.3 KB, free: 1926.1 MB)
2018-05-01 17:43:06.554  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_15_piece0 on 172.21.241.193:58363 in memory (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:43:06.554  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_40_piece0 on 172.21.241.193:58363 in memory (size: 15.5 KB, free: 1926.1 MB)
2018-05-01 17:43:06.808  INFO 17168 --- [Executor task launch worker for task 115] o.a.spark.storage.memory.MemoryStore     : Block rdd_210_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 17:43:06.809  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_210_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:43:06.813  INFO 17168 --- [Executor task launch worker for task 115] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 296.0 (TID 115). 2595 bytes result sent to driver
2018-05-01 17:43:06.813  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 296.0 (TID 115) in 285 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.813  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 296.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.814  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 296 (aggregate at ALS.scala:1491) finished in 0.285 s
2018-05-01 17:43:06.814  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 24 finished: aggregate at ALS.scala:1491, took 0.426876 s
2018-05-01 17:43:06.834  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 200 from persistence list
2018-05-01 17:43:06.835  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 200
2018-05-01 17:43:06.864  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:279
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:06.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:43:06.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:43:06.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 22 is 150 bytes
2018-05-01 17:43:06.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 215 (flatMap at ALS.scala:1433)
2018-05-01 17:43:06.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 25 (count at ALS.scala:279) with 1 output partitions
2018-05-01 17:43:06.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 321 (count at ALS.scala:279)
2018-05-01 17:43:06.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 320, ShuffleMapStage 298)
2018-05-01 17:43:06.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 320)
2018-05-01 17:43:06.871  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 320 (MapPartitionsRDD[215] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:06.873  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_49 stored as values in memory (estimated size 39.7 KB, free 1925.6 MB)
2018-05-01 17:43:06.874  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_49_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1925.6 MB)
2018-05-01 17:43:06.874  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_49_piece0 in memory on 172.21.241.193:58363 (size: 18.0 KB, free: 1925.7 MB)
2018-05-01 17:43:06.874  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.874  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 320 (MapPartitionsRDD[215] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.874  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 320.0 with 1 tasks
2018-05-01 17:43:06.875  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 320.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:06.875  INFO 17168 --- [Executor task launch worker for task 116] org.apache.spark.executor.Executor       : Running task 0.0 in stage 320.0 (TID 116)
2018-05-01 17:43:06.877  INFO 17168 --- [Executor task launch worker for task 116] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:06.877  INFO 17168 --- [Executor task launch worker for task 116] org.apache.spark.storage.BlockManager    : Found block rdd_210_0 locally
2018-05-01 17:43:06.906  INFO 17168 --- [Executor task launch worker for task 116] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 320.0 (TID 116). 1069 bytes result sent to driver
2018-05-01 17:43:06.907  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 320.0 (TID 116) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.907  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 320.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 320 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 321)
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:06.908  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 321 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:43:06.910  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_50 stored as values in memory (estimated size 41.6 KB, free 1925.5 MB)
2018-05-01 17:43:06.910  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_50_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1925.5 MB)
2018-05-01 17:43:06.911  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_50_piece0 in memory on 172.21.241.193:58363 (size: 18.7 KB, free: 1925.7 MB)
2018-05-01 17:43:06.912  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.912  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 321 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.912  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 321.0 with 1 tasks
2018-05-01 17:43:06.912  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 321.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:06.913  INFO 17168 --- [Executor task launch worker for task 117] org.apache.spark.executor.Executor       : Running task 0.0 in stage 321.0 (TID 117)
2018-05-01 17:43:06.916  INFO 17168 --- [Executor task launch worker for task 117] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:06.917  INFO 17168 --- [Executor task launch worker for task 117] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:06.917  INFO 17168 --- [Executor task launch worker for task 117] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:06.917  INFO 17168 --- [Executor task launch worker for task 117] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:07.275  INFO 17168 --- [Executor task launch worker for task 117] o.a.spark.storage.memory.MemoryStore     : Block rdd_231_0 stored as values in memory (estimated size 970.8 KB, free 1924.6 MB)
2018-05-01 17:43:07.275  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_231_0 in memory on 172.21.241.193:58363 (size: 970.8 KB, free: 1924.7 MB)
2018-05-01 17:43:07.276  INFO 17168 --- [Executor task launch worker for task 117] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 321.0 (TID 117). 1873 bytes result sent to driver
2018-05-01 17:43:07.276  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 321.0 (TID 117) in 364 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.276  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 321.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.277  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 321 (count at ALS.scala:279) finished in 0.365 s
2018-05-01 17:43:07.277  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 25 finished: count at ALS.scala:279, took 0.413265 s
2018-05-01 17:43:07.280  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:280
2018-05-01 17:43:07.280  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:07.280  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:07.283  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:07.283  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:07.283  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:07.283  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:07.284  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:07.285  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:07.285  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 22 is 150 bytes
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 26 (count at ALS.scala:280) with 1 output partitions
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 345 (count at ALS.scala:280)
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 325, ShuffleMapStage 344)
2018-05-01 17:43:07.287  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.287  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 345 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:43:07.289  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_51 stored as values in memory (estimated size 40.1 KB, free 1924.5 MB)
2018-05-01 17:43:07.290  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1924.5 MB)
2018-05-01 17:43:07.290  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_51_piece0 in memory on 172.21.241.193:58363 (size: 18.0 KB, free: 1924.7 MB)
2018-05-01 17:43:07.290  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.290  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 345 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.291  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 345.0 with 1 tasks
2018-05-01 17:43:07.291  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 345.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.291  INFO 17168 --- [Executor task launch worker for task 118] org.apache.spark.executor.Executor       : Running task 0.0 in stage 345.0 (TID 118)
2018-05-01 17:43:07.294  INFO 17168 --- [Executor task launch worker for task 118] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:07.294  INFO 17168 --- [Executor task launch worker for task 118] org.apache.spark.storage.BlockManager    : Found block rdd_210_0 locally
2018-05-01 17:43:07.375  INFO 17168 --- [Executor task launch worker for task 118] o.a.spark.storage.memory.MemoryStore     : Block rdd_232_0 stored as values in memory (estimated size 1914.2 KB, free 1922.7 MB)
2018-05-01 17:43:07.375  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_232_0 in memory on 172.21.241.193:58363 (size: 1914.2 KB, free: 1922.9 MB)
2018-05-01 17:43:07.376  INFO 17168 --- [Executor task launch worker for task 118] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 345.0 (TID 118). 1658 bytes result sent to driver
2018-05-01 17:43:07.377  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 345.0 (TID 118) in 86 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.377  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 345.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.377  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 345 (count at ALS.scala:280) finished in 0.086 s
2018-05-01 17:43:07.377  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 26 finished: count at ALS.scala:280, took 0.097097 s
2018-05-01 17:43:07.383  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 23 is 150 bytes
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 27 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 370 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 369, ShuffleMapStage 347)
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.387  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 370 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:43:07.389  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_52 stored as values in memory (estimated size 41.8 KB, free 1922.6 MB)
2018-05-01 17:43:07.390  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_52_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1922.6 MB)
2018-05-01 17:43:07.391  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_52_piece0 in memory on 172.21.241.193:58363 (size: 18.8 KB, free: 1922.8 MB)
2018-05-01 17:43:07.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 370 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.392  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 370.0 with 1 tasks
2018-05-01 17:43:07.392  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 370.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.392  INFO 17168 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : Running task 0.0 in stage 370.0 (TID 119)
2018-05-01 17:43:07.395  INFO 17168 --- [Executor task launch worker for task 119] org.apache.spark.storage.BlockManager    : Found block rdd_231_0 locally
2018-05-01 17:43:07.395  INFO 17168 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 119:
[rdd_231_0]
2018-05-01 17:43:07.395  INFO 17168 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 370.0 (TID 119). 909 bytes result sent to driver
2018-05-01 17:43:07.396  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 370.0 (TID 119) in 3 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.396  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 370.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.396  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 370 (first at MatrixFactorizationModel.scala:67) finished in 0.004 s
2018-05-01 17:43:07.396  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 27 finished: first at MatrixFactorizationModel.scala:67, took 0.012869 s
2018-05-01 17:43:07.404  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:43:07.406  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 28 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:43:07.406  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 394 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:43:07.406  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 393)
2018-05-01 17:43:07.406  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.407  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 394 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:43:07.408  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_53 stored as values in memory (estimated size 40.2 KB, free 1922.6 MB)
2018-05-01 17:43:07.409  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_53_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1922.5 MB)
2018-05-01 17:43:07.410  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_53_piece0 in memory on 172.21.241.193:58363 (size: 18.1 KB, free: 1922.8 MB)
2018-05-01 17:43:07.410  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.410  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 394 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.410  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 394.0 with 1 tasks
2018-05-01 17:43:07.411  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 394.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.411  INFO 17168 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : Running task 0.0 in stage 394.0 (TID 120)
2018-05-01 17:43:07.413  INFO 17168 --- [Executor task launch worker for task 120] org.apache.spark.storage.BlockManager    : Found block rdd_232_0 locally
2018-05-01 17:43:07.413  INFO 17168 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 120:
[rdd_232_0]
2018-05-01 17:43:07.413  INFO 17168 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 394.0 (TID 120). 909 bytes result sent to driver
2018-05-01 17:43:07.413  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 394.0 (TID 120) in 3 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.413  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 394.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.414  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 394 (first at MatrixFactorizationModel.scala:67) finished in 0.004 s
2018-05-01 17:43:07.414  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 28 finished: first at MatrixFactorizationModel.scala:67, took 0.010330 s
2018-05-01 17:43:07.423  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: lookup at MatrixFactorizationModel.scala:168
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 29 (lookup at MatrixFactorizationModel.scala:168) with 1 output partitions
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 419 (lookup at MatrixFactorizationModel.scala:168)
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 396, ShuffleMapStage 418)
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 419 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:43:07.428  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_54 stored as values in memory (estimated size 41.9 KB, free 1922.5 MB)
2018-05-01 17:43:07.429  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_54_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1922.5 MB)
2018-05-01 17:43:07.429  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_54_piece0 in memory on 172.21.241.193:58363 (size: 18.8 KB, free: 1922.8 MB)
2018-05-01 17:43:07.430  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.430  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 419 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.430  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 419.0 with 1 tasks
2018-05-01 17:43:07.430  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 419.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.430  INFO 17168 --- [Executor task launch worker for task 121] org.apache.spark.executor.Executor       : Running task 0.0 in stage 419.0 (TID 121)
2018-05-01 17:43:07.433  INFO 17168 --- [Executor task launch worker for task 121] org.apache.spark.storage.BlockManager    : Found block rdd_231_0 locally
2018-05-01 17:43:07.435  INFO 17168 --- [Executor task launch worker for task 121] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 419.0 (TID 121). 985 bytes result sent to driver
2018-05-01 17:43:07.435  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 419.0 (TID 121) in 5 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.435  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 419.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.436  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 419 (lookup at MatrixFactorizationModel.scala:168) finished in 0.005 s
2018-05-01 17:43:07.436  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 29 finished: lookup at MatrixFactorizationModel.scala:168, took 0.012811 s
2018-05-01 17:43:07.453  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: top at MatrixFactorizationModel.scala:259
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 30 (top at MatrixFactorizationModel.scala:259) with 1 output partitions
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 443 (top at MatrixFactorizationModel.scala:259)
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 423, ShuffleMapStage 442)
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 443 (MapPartitionsRDD[234] at top at MatrixFactorizationModel.scala:259), which has no missing parents
2018-05-01 17:43:07.460  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_55 stored as values in memory (estimated size 41.2 KB, free 1922.4 MB)
2018-05-01 17:43:07.462  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_55_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1922.4 MB)
2018-05-01 17:43:07.462  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_55_piece0 in memory on 172.21.241.193:58363 (size: 18.7 KB, free: 1922.8 MB)
2018-05-01 17:43:07.463  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.463  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 443 (MapPartitionsRDD[234] at top at MatrixFactorizationModel.scala:259) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.463  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 443.0 with 1 tasks
2018-05-01 17:43:07.463  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 443.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.463  INFO 17168 --- [Executor task launch worker for task 122] org.apache.spark.executor.Executor       : Running task 0.0 in stage 443.0 (TID 122)
2018-05-01 17:43:07.466  INFO 17168 --- [Executor task launch worker for task 122] org.apache.spark.storage.BlockManager    : Found block rdd_232_0 locally
2018-05-01 17:43:07.478  INFO 17168 --- [Executor task launch worker for task 122] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 443.0 (TID 122). 1652 bytes result sent to driver
2018-05-01 17:43:07.479  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 443.0 (TID 122) in 15 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.479  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 443.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.479  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 443 (top at MatrixFactorizationModel.scala:259) finished in 0.016 s
2018-05-01 17:43:07.479  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 30 finished: top at MatrixFactorizationModel.scala:259, took 0.025885 s
2018-05-01 17:43:07.481  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Recommendations for1
2018-05-01 17:43:07.482  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1214-- Rating : 0.996791517895507
2018-05-01 17:43:07.513  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1200-- Rating : 0.9640660249450387
2018-05-01 17:43:07.516  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 541-- Rating : 0.928069625916408
2018-05-01 17:43:07.518  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 924-- Rating : 0.9245498636950754
2018-05-01 17:43:07.522  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1206-- Rating : 0.9212852243141509
2018-05-01 17:45:43.281  INFO 17168 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:45:57.859  INFO 16044 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:45:57.875  INFO 16044 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7a027ff0: startup date [Tue May 01 17:45:57 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3bc6718a
2018-05-01 17:45:59.419  INFO 16044 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:45:59.442  INFO 16044 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:45:59.450  INFO 16044 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:45:59.717  INFO 16044 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:45:59.761  INFO 16044 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:45:59.877  INFO 16044 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c11eba2b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:45:59.921  INFO 16044 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$dd38bd28] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:46:00.413  INFO 16044 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:46:00.423  INFO 16044 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:46:00.423  INFO 16044 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:46:00.481  INFO 16044 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:46:00.481  INFO 16044 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2607 ms
2018-05-01 17:46:00.781  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:46:00.784  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:46:00.789  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:46:00.789  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:46:00.789  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:46:00.789  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:46:00.790  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:46:00.791  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:46:00.791  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:46:01.259  INFO 16044 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:46:01.957  INFO 16044 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:46:02.500  INFO 16044 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:46:02.501  INFO 16044 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:46:02.550  INFO 16044 --- [cluster-ClusterId{value='5ae87daab11f8e3eac338e32', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:22}] to localhost:27017
2018-05-01 17:46:02.553  INFO 16044 --- [cluster-ClusterId{value='5ae87daab11f8e3eac338e32', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=576791}
2018-05-01 17:46:02.554  INFO 16044 --- [cluster-ClusterId{value='5ae87daab11f8e3eac338e32', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:46:02.923  INFO 16044 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:46:03.077  WARN 16044 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:46:03.179  INFO 16044 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:46:03.190  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:46:03.190  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:46:03.191  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:46:03.192  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:46:03.193  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:46:03.519  INFO 16044 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 58607.
2018-05-01 17:46:03.534  INFO 16044 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:46:03.550  INFO 16044 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:46:03.552  INFO 16044 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:46:03.552  INFO 16044 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:46:03.558  INFO 16044 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-791e8dc9-b201-4054-8118-4169f2f7545e
2018-05-01 17:46:03.581  INFO 16044 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:46:03.618  INFO 16044 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:46:03.669  INFO 16044 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8439ms
2018-05-01 17:46:03.714  INFO 16044 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:46:03.725  INFO 16044 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8496ms
2018-05-01 17:46:03.746  INFO 16044 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@71ae6b79{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:46:03.747  INFO 16044 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:46:03.767  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5859388b{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.768  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1328ce00{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.768  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6281d4b3{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.769  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2a15bc7e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.769  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@c86d4a7{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.771  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@78c0e38f{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.772  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6a2223c1{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.773  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1430f0b7{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.773  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@71d15733{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.773  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3205e013{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.774  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@63a2d760{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.775  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@476e99b0{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.775  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@213ccb49{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.777  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7fcba19e{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.777  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6c155a00{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.778  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5a2a629a{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.778  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1246d77b{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.779  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1c63d566{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.780  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4694f264{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.781  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7362399f{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.786  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@182186e0{/static,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.787  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@37a2b8e1{/,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.788  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@d08c792{/api,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.788  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@144b723b{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.789  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2459beff{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.790  INFO 16044 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:46:03.875  INFO 16044 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:46:03.900  INFO 16044 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58620.
2018-05-01 17:46:03.901  INFO 16044 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:58620
2018-05-01 17:46:03.902  INFO 16044 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:46:03.903  INFO 16044 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 58620, None)
2018-05-01 17:46:03.906  INFO 16044 --- [dispatcher-event-loop-3] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:58620 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 58620, None)
2018-05-01 17:46:03.910  INFO 16044 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 58620, None)
2018-05-01 17:46:03.910  INFO 16044 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 58620, None)
2018-05-01 17:46:03.921  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@235b1574{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.970  INFO 16044 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:46:03.971  INFO 16044 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:46:03.976  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5fa69481{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.977  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5e8813a0{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.978  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4e9a94a4{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.978  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6306825e{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.980  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2a94ad38{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:46:04.507  WARN 16044 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:46:04.718  INFO 16044 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:46:05.352  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:46:05.355  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:46:05.358  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:46:05.359  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:46:05.359  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:46:05.361  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:46:05.361  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:46:06.242  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:46:06.244  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:46:06.245  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.246  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.247  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:46:06.247  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.248  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:46:06.250  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:46:06.250  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:46:06.250  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.252  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:46:06.252  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.253  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:46:06.253  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.253  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.254  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.254  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.255  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:46:06.255  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:46:06.256  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:46:06.256  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.257  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:46:06.257  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.258  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.259  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:46:06.259  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:46:06.709  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7a027ff0: startup date [Tue May 01 17:45:57 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3bc6718a
2018-05-01 17:46:06.787  INFO 16044 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:46:06.787  INFO 16044 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:46:06.808  INFO 16044 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:46:06.838  INFO 16044 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:46:07.347  WARN 16044 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:46:07.436  WARN 16044 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:46:07.436  INFO 16044 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:46:07.442  WARN 16044 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:46:07.442  INFO 16044 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:46:07.539  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:46:07.551  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:46:07.551  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:46:07.555  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:46:07.555  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:46:07.556  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:46:07.560  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:46:07.577  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:46:07.590  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:46:07.605  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=7a027ff0,type=ConfigurationPropertiesRebinder]
2018-05-01 17:46:07.612  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:46:07.977  INFO 16044 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:46:07.987  INFO 16044 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:46:08.096  INFO 16044 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:46:08.096  INFO 16044 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:46:08.216  INFO 16044 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:46:08.216  INFO 16044 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:46:08.532  INFO 16044 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:46:08.652  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:46:08.652  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:46:08.652  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:46:08.652  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:46:08.654  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:46:08.654  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:46:08.654  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:46:08.842  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:46:08.846  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:46:08.848  INFO 16044 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:46:08.852  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525185968852 with initial instances count: 6
2018-05-01 17:46:08.871  INFO 16044 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:46:08.872  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525185968872, current=UP, previous=STARTING]
2018-05-01 17:46:08.874  INFO 16044 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:46:08.917  INFO 16044 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:46:08.931  INFO 16044 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:46:08.931  INFO 16044 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:46:08.949  INFO 16044 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:46:08.963  INFO 16044 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:46:09.025  INFO 16044 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:46:09.027  INFO 16044 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:46:09.031  INFO 16044 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.658 seconds (JVM running for 13.802)
2018-05-01 17:46:09.612  INFO 16044 --- [RMI TCP Connection(11)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:23}] to localhost:27017
2018-05-01 17:47:27.670  INFO 16044 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-01 17:47:27.670  INFO 16044 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-01 17:47:27.700  INFO 16044 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 30 ms
2018-05-01 17:47:27.720  WARN 16044 --- [http-nio-3333-exec-1] o.s.web.servlet.PageNotFound             : Request method 'GET' not supported
2018-05-01 17:47:27.721  WARN 16044 --- [http-nio-3333-exec-1] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved exception caused by Handler execution: org.springframework.web.HttpRequestMethodNotSupportedException: Request method 'GET' not supported
2018-05-01 17:48:03.882  WARN 16044 --- [http-nio-3333-exec-3] o.apache.spark.sql.SparkSession$Builder  : Using an existing SparkSession; some configuration may not take effect.
2018-05-01 17:48:03.965  INFO 16044 --- [http-nio-3333-exec-3] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0 stored as values in memory (estimated size 248.0 B, free 1990.8 MB)
2018-05-01 17:48:04.037  INFO 16044 --- [http-nio-3333-exec-3] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0_piece0 stored as bytes in memory (estimated size 419.0 B, free 1990.8 MB)
2018-05-01 17:48:04.039  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_0_piece0 in memory on 172.21.241.193:58620 (size: 419.0 B, free: 1990.8 MB)
2018-05-01 17:48:04.043  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Created broadcast 0 from broadcast at MongoSpark.scala:536
2018-05-01 17:48:04.252  INFO 16044 --- [http-nio-3333-exec-3] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:48:04.258  INFO 16044 --- [http-nio-3333-exec-3] org.mongodb.driver.cluster               : Cluster description not yet available. Waiting for 30000 ms before timing out
2018-05-01 17:48:04.261  INFO 16044 --- [cluster-ClusterId{value='5ae87e24b11f8e3eac338e33', description='null'}-127.0.0.1:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:28}] to 127.0.0.1:27017
2018-05-01 17:48:04.263  INFO 16044 --- [cluster-ClusterId{value='5ae87e24b11f8e3eac338e33', description='null'}-127.0.0.1:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=934321}
2018-05-01 17:48:04.265  INFO 16044 --- [http-nio-3333-exec-3] c.m.spark.connection.MongoClientCache    : Creating MongoClient: [127.0.0.1:27017]
2018-05-01 17:48:04.276  INFO 16044 --- [http-nio-3333-exec-3] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:29}] to 127.0.0.1:27017
2018-05-01 17:48:05.508  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: collect at RecomendationServiceImpl.java:86
2018-05-01 17:48:05.520  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 0 (collect at RecomendationServiceImpl.java:86) with 66 output partitions
2018-05-01 17:48:05.520  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 0 (collect at RecomendationServiceImpl.java:86)
2018-05-01 17:48:05.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:48:05.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:48:05.529  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 0 (MapPartitionsRDD[1] at map at RecomendationServiceImpl.java:83), which has no missing parents
2018-05-01 17:48:05.549  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 1990.8 MB)
2018-05-01 17:48:05.553  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1990.8 MB)
2018-05-01 17:48:05.553  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_1_piece0 in memory on 172.21.241.193:58620 (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 17:48:05.554  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:48:05.564  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 66 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at RecomendationServiceImpl.java:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-05-01 17:48:05.565  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 0.0 with 66 tasks
2018-05-01 17:48:05.606  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 4987 bytes)
2018-05-01 17:48:05.613  INFO 16044 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Running task 0.0 in stage 0.0 (TID 0)
2018-05-01 17:48:05.672  INFO 16044 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 0.0 (TID 0). 751 bytes result sent to driver
2018-05-01 17:48:05.675  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 4999 bytes)
2018-05-01 17:48:05.675  INFO 16044 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Running task 1.0 in stage 0.0 (TID 1)
2018-05-01 17:48:05.680  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 0.0 (TID 0) in 88 ms on localhost (executor driver) (1/66)
2018-05-01 17:48:06.346  INFO 16044 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 0.0 (TID 1). 429841 bytes result sent to driver
2018-05-01 17:48:06.347  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 5005 bytes)
2018-05-01 17:48:06.347  INFO 16044 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Running task 2.0 in stage 0.0 (TID 2)
2018-05-01 17:48:06.368  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 0.0 (TID 1) in 694 ms on localhost (executor driver) (2/66)
2018-05-01 17:48:06.920  INFO 16044 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 0.0 (TID 2). 432580 bytes result sent to driver
2018-05-01 17:48:06.922  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 5004 bytes)
2018-05-01 17:48:06.922  INFO 16044 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Running task 3.0 in stage 0.0 (TID 3)
2018-05-01 17:48:06.940  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 0.0 (TID 2) in 593 ms on localhost (executor driver) (3/66)
2018-05-01 17:48:07.584  INFO 16044 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 0.0 (TID 3). 433940 bytes result sent to driver
2018-05-01 17:48:07.585  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 5003 bytes)
2018-05-01 17:48:07.585  INFO 16044 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Running task 4.0 in stage 0.0 (TID 4)
2018-05-01 17:48:07.601  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 0.0 (TID 3) in 679 ms on localhost (executor driver) (4/66)
2018-05-01 17:48:08.136  INFO 16044 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Finished task 4.0 in stage 0.0 (TID 4). 423957 bytes result sent to driver
2018-05-01 17:48:08.137  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 5003 bytes)
2018-05-01 17:48:08.137  INFO 16044 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Running task 5.0 in stage 0.0 (TID 5)
2018-05-01 17:48:08.153  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 4.0 in stage 0.0 (TID 4) in 567 ms on localhost (executor driver) (5/66)
2018-05-01 17:48:08.708  INFO 16044 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Finished task 5.0 in stage 0.0 (TID 5). 418098 bytes result sent to driver
2018-05-01 17:48:08.710  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 5003 bytes)
2018-05-01 17:48:08.710  INFO 16044 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Running task 6.0 in stage 0.0 (TID 6)
2018-05-01 17:48:08.735  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 5.0 in stage 0.0 (TID 5) in 598 ms on localhost (executor driver) (6/66)
2018-05-01 17:48:09.336  INFO 16044 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Finished task 6.0 in stage 0.0 (TID 6). 416988 bytes result sent to driver
2018-05-01 17:48:09.337  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 5003 bytes)
2018-05-01 17:48:09.337  INFO 16044 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Running task 7.0 in stage 0.0 (TID 7)
2018-05-01 17:48:09.353  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 6.0 in stage 0.0 (TID 6) in 644 ms on localhost (executor driver) (7/66)
2018-05-01 17:48:09.889  INFO 16044 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Finished task 7.0 in stage 0.0 (TID 7). 426842 bytes result sent to driver
2018-05-01 17:48:09.889  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 5003 bytes)
2018-05-01 17:48:09.889  INFO 16044 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Running task 8.0 in stage 0.0 (TID 8)
2018-05-01 17:48:09.907  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 7.0 in stage 0.0 (TID 7) in 570 ms on localhost (executor driver) (8/66)
2018-05-01 17:48:10.447  INFO 16044 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Finished task 8.0 in stage 0.0 (TID 8). 430736 bytes result sent to driver
2018-05-01 17:48:10.448  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 5003 bytes)
2018-05-01 17:48:10.449  INFO 16044 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Running task 9.0 in stage 0.0 (TID 9)
2018-05-01 17:48:10.464  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 8.0 in stage 0.0 (TID 8) in 575 ms on localhost (executor driver) (9/66)
2018-05-01 17:48:11.021  INFO 16044 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Finished task 9.0 in stage 0.0 (TID 9). 432112 bytes result sent to driver
2018-05-01 17:48:11.022  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 5003 bytes)
2018-05-01 17:48:11.022  INFO 16044 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Running task 10.0 in stage 0.0 (TID 10)
2018-05-01 17:48:11.040  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 9.0 in stage 0.0 (TID 9) in 592 ms on localhost (executor driver) (10/66)
2018-05-01 17:48:11.642  INFO 16044 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Finished task 10.0 in stage 0.0 (TID 10). 428533 bytes result sent to driver
2018-05-01 17:48:11.643  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 5003 bytes)
2018-05-01 17:48:11.643  INFO 16044 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Running task 11.0 in stage 0.0 (TID 11)
2018-05-01 17:48:11.660  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 10.0 in stage 0.0 (TID 10) in 638 ms on localhost (executor driver) (11/66)
2018-05-01 17:48:12.276  INFO 16044 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Finished task 11.0 in stage 0.0 (TID 11). 432916 bytes result sent to driver
2018-05-01 17:48:12.277  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 5003 bytes)
2018-05-01 17:48:12.278  INFO 16044 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Running task 12.0 in stage 0.0 (TID 12)
2018-05-01 17:48:12.296  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 11.0 in stage 0.0 (TID 11) in 653 ms on localhost (executor driver) (12/66)
2018-05-01 17:48:12.849  INFO 16044 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Finished task 12.0 in stage 0.0 (TID 12). 431975 bytes result sent to driver
2018-05-01 17:48:12.850  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 5003 bytes)
2018-05-01 17:48:12.850  INFO 16044 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Running task 13.0 in stage 0.0 (TID 13)
2018-05-01 17:48:12.868  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 12.0 in stage 0.0 (TID 12) in 591 ms on localhost (executor driver) (13/66)
2018-05-01 17:48:13.480  INFO 16044 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Finished task 13.0 in stage 0.0 (TID 13). 430518 bytes result sent to driver
2018-05-01 17:48:13.480  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 5003 bytes)
2018-05-01 17:48:13.481  INFO 16044 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Running task 14.0 in stage 0.0 (TID 14)
2018-05-01 17:48:13.497  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 13.0 in stage 0.0 (TID 13) in 647 ms on localhost (executor driver) (14/66)
2018-05-01 17:48:14.119  INFO 16044 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Finished task 14.0 in stage 0.0 (TID 14). 433458 bytes result sent to driver
2018-05-01 17:48:14.120  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 5003 bytes)
2018-05-01 17:48:14.121  INFO 16044 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Running task 15.0 in stage 0.0 (TID 15)
2018-05-01 17:48:14.140  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 14.0 in stage 0.0 (TID 14) in 660 ms on localhost (executor driver) (15/66)
2018-05-01 17:48:14.705  INFO 16044 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Finished task 15.0 in stage 0.0 (TID 15). 433639 bytes result sent to driver
2018-05-01 17:48:14.706  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 5003 bytes)
2018-05-01 17:48:14.706  INFO 16044 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Running task 16.0 in stage 0.0 (TID 16)
2018-05-01 17:48:14.729  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 15.0 in stage 0.0 (TID 15) in 609 ms on localhost (executor driver) (16/66)
2018-05-01 17:48:15.284  INFO 16044 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Finished task 16.0 in stage 0.0 (TID 16). 429584 bytes result sent to driver
2018-05-01 17:48:15.285  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 5002 bytes)
2018-05-01 17:48:15.285  INFO 16044 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Running task 17.0 in stage 0.0 (TID 17)
2018-05-01 17:48:15.302  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 16.0 in stage 0.0 (TID 16) in 596 ms on localhost (executor driver) (17/66)
2018-05-01 17:48:15.887  INFO 16044 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Finished task 17.0 in stage 0.0 (TID 17). 434264 bytes result sent to driver
2018-05-01 17:48:15.887  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 5002 bytes)
2018-05-01 17:48:15.888  INFO 16044 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Running task 18.0 in stage 0.0 (TID 18)
2018-05-01 17:48:15.903  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 17.0 in stage 0.0 (TID 17) in 618 ms on localhost (executor driver) (18/66)
2018-05-01 17:48:16.437  INFO 16044 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Finished task 18.0 in stage 0.0 (TID 18). 431383 bytes result sent to driver
2018-05-01 17:48:16.438  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 5003 bytes)
2018-05-01 17:48:16.438  INFO 16044 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Running task 19.0 in stage 0.0 (TID 19)
2018-05-01 17:48:16.453  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 18.0 in stage 0.0 (TID 18) in 566 ms on localhost (executor driver) (19/66)
2018-05-01 17:48:17.020  INFO 16044 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Finished task 19.0 in stage 0.0 (TID 19). 435226 bytes result sent to driver
2018-05-01 17:48:17.021  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 5003 bytes)
2018-05-01 17:48:17.021  INFO 16044 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Running task 20.0 in stage 0.0 (TID 20)
2018-05-01 17:48:17.042  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 19.0 in stage 0.0 (TID 19) in 605 ms on localhost (executor driver) (20/66)
2018-05-01 17:48:17.584  INFO 16044 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Finished task 20.0 in stage 0.0 (TID 20). 434347 bytes result sent to driver
2018-05-01 17:48:17.584  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 5003 bytes)
2018-05-01 17:48:17.585  INFO 16044 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Running task 21.0 in stage 0.0 (TID 21)
2018-05-01 17:48:17.602  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 20.0 in stage 0.0 (TID 20) in 581 ms on localhost (executor driver) (21/66)
2018-05-01 17:48:18.231  INFO 16044 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Finished task 21.0 in stage 0.0 (TID 21). 428428 bytes result sent to driver
2018-05-01 17:48:18.231  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 22.0 in stage 0.0 (TID 22, localhost, executor driver, partition 22, ANY, 5003 bytes)
2018-05-01 17:48:18.232  INFO 16044 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Running task 22.0 in stage 0.0 (TID 22)
2018-05-01 17:48:18.249  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 21.0 in stage 0.0 (TID 21) in 664 ms on localhost (executor driver) (22/66)
2018-05-01 17:48:18.811  INFO 16044 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Finished task 22.0 in stage 0.0 (TID 22). 434997 bytes result sent to driver
2018-05-01 17:48:18.811  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 23.0 in stage 0.0 (TID 23, localhost, executor driver, partition 23, ANY, 5003 bytes)
2018-05-01 17:48:18.811  INFO 16044 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Running task 23.0 in stage 0.0 (TID 23)
2018-05-01 17:48:18.829  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 22.0 in stage 0.0 (TID 22) in 598 ms on localhost (executor driver) (23/66)
2018-05-01 17:48:19.381  INFO 16044 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Finished task 23.0 in stage 0.0 (TID 23). 430843 bytes result sent to driver
2018-05-01 17:48:19.381  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 24.0 in stage 0.0 (TID 24, localhost, executor driver, partition 24, ANY, 5003 bytes)
2018-05-01 17:48:19.382  INFO 16044 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Running task 24.0 in stage 0.0 (TID 24)
2018-05-01 17:48:19.397  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 23.0 in stage 0.0 (TID 23) in 586 ms on localhost (executor driver) (24/66)
2018-05-01 17:48:19.987  INFO 16044 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Finished task 24.0 in stage 0.0 (TID 24). 429256 bytes result sent to driver
2018-05-01 17:48:19.988  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 25.0 in stage 0.0 (TID 25, localhost, executor driver, partition 25, ANY, 5003 bytes)
2018-05-01 17:48:19.988  INFO 16044 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Running task 25.0 in stage 0.0 (TID 25)
2018-05-01 17:48:20.006  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 24.0 in stage 0.0 (TID 24) in 625 ms on localhost (executor driver) (25/66)
2018-05-01 17:48:20.630  INFO 16044 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Finished task 25.0 in stage 0.0 (TID 25). 432251 bytes result sent to driver
2018-05-01 17:48:20.631  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 26.0 in stage 0.0 (TID 26, localhost, executor driver, partition 26, ANY, 5003 bytes)
2018-05-01 17:48:20.631  INFO 16044 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Running task 26.0 in stage 0.0 (TID 26)
2018-05-01 17:48:20.649  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 25.0 in stage 0.0 (TID 25) in 662 ms on localhost (executor driver) (26/66)
2018-05-01 17:48:21.205  INFO 16044 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Finished task 26.0 in stage 0.0 (TID 26). 433194 bytes result sent to driver
2018-05-01 17:48:21.206  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 27.0 in stage 0.0 (TID 27, localhost, executor driver, partition 27, ANY, 5003 bytes)
2018-05-01 17:48:21.206  INFO 16044 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Running task 27.0 in stage 0.0 (TID 27)
2018-05-01 17:48:21.221  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 26.0 in stage 0.0 (TID 26) in 590 ms on localhost (executor driver) (27/66)
2018-05-01 17:48:21.759  INFO 16044 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Finished task 27.0 in stage 0.0 (TID 27). 433416 bytes result sent to driver
2018-05-01 17:48:21.759  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 28.0 in stage 0.0 (TID 28, localhost, executor driver, partition 28, ANY, 5003 bytes)
2018-05-01 17:48:21.760  INFO 16044 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Running task 28.0 in stage 0.0 (TID 28)
2018-05-01 17:48:21.776  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 27.0 in stage 0.0 (TID 27) in 571 ms on localhost (executor driver) (28/66)
2018-05-01 17:48:22.376  INFO 16044 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Finished task 28.0 in stage 0.0 (TID 28). 431320 bytes result sent to driver
2018-05-01 17:48:22.377  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 29.0 in stage 0.0 (TID 29, localhost, executor driver, partition 29, ANY, 5003 bytes)
2018-05-01 17:48:22.377  INFO 16044 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Running task 29.0 in stage 0.0 (TID 29)
2018-05-01 17:48:22.396  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 28.0 in stage 0.0 (TID 28) in 637 ms on localhost (executor driver) (29/66)
2018-05-01 17:48:23.032  INFO 16044 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Finished task 29.0 in stage 0.0 (TID 29). 432533 bytes result sent to driver
2018-05-01 17:48:23.033  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 30.0 in stage 0.0 (TID 30, localhost, executor driver, partition 30, ANY, 5003 bytes)
2018-05-01 17:48:23.033  INFO 16044 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Running task 30.0 in stage 0.0 (TID 30)
2018-05-01 17:48:23.049  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 29.0 in stage 0.0 (TID 29) in 672 ms on localhost (executor driver) (30/66)
2018-05-01 17:48:23.680  INFO 16044 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Finished task 30.0 in stage 0.0 (TID 30). 431358 bytes result sent to driver
2018-05-01 17:48:23.681  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 31.0 in stage 0.0 (TID 31, localhost, executor driver, partition 31, ANY, 5003 bytes)
2018-05-01 17:48:23.681  INFO 16044 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Running task 31.0 in stage 0.0 (TID 31)
2018-05-01 17:48:23.697  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 30.0 in stage 0.0 (TID 30) in 665 ms on localhost (executor driver) (31/66)
2018-05-01 17:48:24.311  INFO 16044 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Finished task 31.0 in stage 0.0 (TID 31). 434098 bytes result sent to driver
2018-05-01 17:48:24.312  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 32.0 in stage 0.0 (TID 32, localhost, executor driver, partition 32, ANY, 5002 bytes)
2018-05-01 17:48:24.312  INFO 16044 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Running task 32.0 in stage 0.0 (TID 32)
2018-05-01 17:48:24.335  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 31.0 in stage 0.0 (TID 31) in 654 ms on localhost (executor driver) (32/66)
2018-05-01 17:48:24.915  INFO 16044 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Finished task 32.0 in stage 0.0 (TID 32). 432096 bytes result sent to driver
2018-05-01 17:48:24.915  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 33.0 in stage 0.0 (TID 33, localhost, executor driver, partition 33, ANY, 5002 bytes)
2018-05-01 17:48:24.915  INFO 16044 --- [Executor task launch worker for task 33] org.apache.spark.executor.Executor       : Running task 33.0 in stage 0.0 (TID 33)
2018-05-01 17:48:24.939  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 32.0 in stage 0.0 (TID 32) in 627 ms on localhost (executor driver) (33/66)
2018-05-01 17:48:25.491  INFO 16044 --- [Executor task launch worker for task 33] org.apache.spark.executor.Executor       : Finished task 33.0 in stage 0.0 (TID 33). 433300 bytes result sent to driver
2018-05-01 17:48:25.491  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 34.0 in stage 0.0 (TID 34, localhost, executor driver, partition 34, ANY, 5002 bytes)
2018-05-01 17:48:25.492  INFO 16044 --- [Executor task launch worker for task 34] org.apache.spark.executor.Executor       : Running task 34.0 in stage 0.0 (TID 34)
2018-05-01 17:48:25.510  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 33.0 in stage 0.0 (TID 33) in 595 ms on localhost (executor driver) (34/66)
2018-05-01 17:48:26.097  INFO 16044 --- [Executor task launch worker for task 34] org.apache.spark.executor.Executor       : Finished task 34.0 in stage 0.0 (TID 34). 433019 bytes result sent to driver
2018-05-01 17:48:26.098  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 35.0 in stage 0.0 (TID 35, localhost, executor driver, partition 35, ANY, 5002 bytes)
2018-05-01 17:48:26.098  INFO 16044 --- [Executor task launch worker for task 35] org.apache.spark.executor.Executor       : Running task 35.0 in stage 0.0 (TID 35)
2018-05-01 17:48:26.120  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 34.0 in stage 0.0 (TID 34) in 628 ms on localhost (executor driver) (35/66)
2018-05-01 17:48:26.698  INFO 16044 --- [Executor task launch worker for task 35] org.apache.spark.executor.Executor       : Finished task 35.0 in stage 0.0 (TID 35). 431659 bytes result sent to driver
2018-05-01 17:48:26.699  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 36.0 in stage 0.0 (TID 36, localhost, executor driver, partition 36, ANY, 5002 bytes)
2018-05-01 17:48:26.699  INFO 16044 --- [Executor task launch worker for task 36] org.apache.spark.executor.Executor       : Running task 36.0 in stage 0.0 (TID 36)
2018-05-01 17:48:26.714  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 35.0 in stage 0.0 (TID 35) in 616 ms on localhost (executor driver) (36/66)
2018-05-01 17:48:27.446  INFO 16044 --- [Executor task launch worker for task 36] org.apache.spark.executor.Executor       : Finished task 36.0 in stage 0.0 (TID 36). 435545 bytes result sent to driver
2018-05-01 17:48:27.447  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 37.0 in stage 0.0 (TID 37, localhost, executor driver, partition 37, ANY, 5002 bytes)
2018-05-01 17:48:27.447  INFO 16044 --- [Executor task launch worker for task 37] org.apache.spark.executor.Executor       : Running task 37.0 in stage 0.0 (TID 37)
2018-05-01 17:48:27.465  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 36.0 in stage 0.0 (TID 36) in 766 ms on localhost (executor driver) (37/66)
2018-05-01 17:48:28.021  INFO 16044 --- [Executor task launch worker for task 37] org.apache.spark.executor.Executor       : Finished task 37.0 in stage 0.0 (TID 37). 432678 bytes result sent to driver
2018-05-01 17:48:28.021  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 38.0 in stage 0.0 (TID 38, localhost, executor driver, partition 38, ANY, 5003 bytes)
2018-05-01 17:48:28.022  INFO 16044 --- [Executor task launch worker for task 38] org.apache.spark.executor.Executor       : Running task 38.0 in stage 0.0 (TID 38)
2018-05-01 17:48:28.046  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 37.0 in stage 0.0 (TID 37) in 599 ms on localhost (executor driver) (38/66)
2018-05-01 17:48:28.596  INFO 16044 --- [Executor task launch worker for task 38] org.apache.spark.executor.Executor       : Finished task 38.0 in stage 0.0 (TID 38). 433731 bytes result sent to driver
2018-05-01 17:48:28.596  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 39.0 in stage 0.0 (TID 39, localhost, executor driver, partition 39, ANY, 5003 bytes)
2018-05-01 17:48:28.597  INFO 16044 --- [Executor task launch worker for task 39] org.apache.spark.executor.Executor       : Running task 39.0 in stage 0.0 (TID 39)
2018-05-01 17:48:28.655  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 38.0 in stage 0.0 (TID 38) in 634 ms on localhost (executor driver) (39/66)
2018-05-01 17:48:29.190  INFO 16044 --- [Executor task launch worker for task 39] org.apache.spark.executor.Executor       : Finished task 39.0 in stage 0.0 (TID 39). 430075 bytes result sent to driver
2018-05-01 17:48:29.191  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 40.0 in stage 0.0 (TID 40, localhost, executor driver, partition 40, ANY, 5003 bytes)
2018-05-01 17:48:29.191  INFO 16044 --- [Executor task launch worker for task 40] org.apache.spark.executor.Executor       : Running task 40.0 in stage 0.0 (TID 40)
2018-05-01 17:48:29.208  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 39.0 in stage 0.0 (TID 39) in 611 ms on localhost (executor driver) (40/66)
2018-05-01 17:48:29.775  INFO 16044 --- [Executor task launch worker for task 40] org.apache.spark.executor.Executor       : Finished task 40.0 in stage 0.0 (TID 40). 432889 bytes result sent to driver
2018-05-01 17:48:29.775  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 41.0 in stage 0.0 (TID 41, localhost, executor driver, partition 41, ANY, 5003 bytes)
2018-05-01 17:48:29.775  INFO 16044 --- [Executor task launch worker for task 41] org.apache.spark.executor.Executor       : Running task 41.0 in stage 0.0 (TID 41)
2018-05-01 17:48:29.800  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 40.0 in stage 0.0 (TID 40) in 609 ms on localhost (executor driver) (41/66)
2018-05-01 17:48:30.374  INFO 16044 --- [Executor task launch worker for task 41] org.apache.spark.executor.Executor       : Finished task 41.0 in stage 0.0 (TID 41). 431750 bytes result sent to driver
2018-05-01 17:48:30.374  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 42.0 in stage 0.0 (TID 42, localhost, executor driver, partition 42, ANY, 5003 bytes)
2018-05-01 17:48:30.374  INFO 16044 --- [Executor task launch worker for task 42] org.apache.spark.executor.Executor       : Running task 42.0 in stage 0.0 (TID 42)
2018-05-01 17:48:30.390  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 41.0 in stage 0.0 (TID 41) in 615 ms on localhost (executor driver) (42/66)
2018-05-01 17:48:30.971  INFO 16044 --- [Executor task launch worker for task 42] org.apache.spark.executor.Executor       : Finished task 42.0 in stage 0.0 (TID 42). 432035 bytes result sent to driver
2018-05-01 17:48:30.971  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 43.0 in stage 0.0 (TID 43, localhost, executor driver, partition 43, ANY, 5003 bytes)
2018-05-01 17:48:30.971  INFO 16044 --- [Executor task launch worker for task 43] org.apache.spark.executor.Executor       : Running task 43.0 in stage 0.0 (TID 43)
2018-05-01 17:48:30.990  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 42.0 in stage 0.0 (TID 42) in 616 ms on localhost (executor driver) (43/66)
2018-05-01 17:48:31.613  INFO 16044 --- [Executor task launch worker for task 43] org.apache.spark.executor.Executor       : Finished task 43.0 in stage 0.0 (TID 43). 428969 bytes result sent to driver
2018-05-01 17:48:31.613  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 44.0 in stage 0.0 (TID 44, localhost, executor driver, partition 44, ANY, 5003 bytes)
2018-05-01 17:48:31.613  INFO 16044 --- [Executor task launch worker for task 44] org.apache.spark.executor.Executor       : Running task 44.0 in stage 0.0 (TID 44)
2018-05-01 17:48:31.635  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 43.0 in stage 0.0 (TID 43) in 664 ms on localhost (executor driver) (44/66)
2018-05-01 17:48:32.366  INFO 16044 --- [Executor task launch worker for task 44] org.apache.spark.executor.Executor       : Finished task 44.0 in stage 0.0 (TID 44). 432682 bytes result sent to driver
2018-05-01 17:48:32.367  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 45.0 in stage 0.0 (TID 45, localhost, executor driver, partition 45, ANY, 5003 bytes)
2018-05-01 17:48:32.367  INFO 16044 --- [Executor task launch worker for task 45] org.apache.spark.executor.Executor       : Running task 45.0 in stage 0.0 (TID 45)
2018-05-01 17:48:32.384  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 44.0 in stage 0.0 (TID 44) in 771 ms on localhost (executor driver) (45/66)
2018-05-01 17:48:33.008  INFO 16044 --- [Executor task launch worker for task 45] org.apache.spark.executor.Executor       : Finished task 45.0 in stage 0.0 (TID 45). 430122 bytes result sent to driver
2018-05-01 17:48:33.009  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 46.0 in stage 0.0 (TID 46, localhost, executor driver, partition 46, ANY, 5003 bytes)
2018-05-01 17:48:33.009  INFO 16044 --- [Executor task launch worker for task 46] org.apache.spark.executor.Executor       : Running task 46.0 in stage 0.0 (TID 46)
2018-05-01 17:48:33.032  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 45.0 in stage 0.0 (TID 45) in 665 ms on localhost (executor driver) (46/66)
2018-05-01 17:48:33.549  INFO 16044 --- [Executor task launch worker for task 46] org.apache.spark.executor.Executor       : Finished task 46.0 in stage 0.0 (TID 46). 430180 bytes result sent to driver
2018-05-01 17:48:33.549  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 47.0 in stage 0.0 (TID 47, localhost, executor driver, partition 47, ANY, 5003 bytes)
2018-05-01 17:48:33.549  INFO 16044 --- [Executor task launch worker for task 47] org.apache.spark.executor.Executor       : Running task 47.0 in stage 0.0 (TID 47)
2018-05-01 17:48:33.565  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 46.0 in stage 0.0 (TID 46) in 557 ms on localhost (executor driver) (47/66)
2018-05-01 17:48:34.149  INFO 16044 --- [Executor task launch worker for task 47] org.apache.spark.executor.Executor       : Finished task 47.0 in stage 0.0 (TID 47). 433553 bytes result sent to driver
2018-05-01 17:48:34.149  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 48.0 in stage 0.0 (TID 48, localhost, executor driver, partition 48, ANY, 5003 bytes)
2018-05-01 17:48:34.149  INFO 16044 --- [Executor task launch worker for task 48] org.apache.spark.executor.Executor       : Running task 48.0 in stage 0.0 (TID 48)
2018-05-01 17:48:34.166  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 47.0 in stage 0.0 (TID 47) in 617 ms on localhost (executor driver) (48/66)
2018-05-01 17:48:34.765  INFO 16044 --- [Executor task launch worker for task 48] org.apache.spark.executor.Executor       : Finished task 48.0 in stage 0.0 (TID 48). 431564 bytes result sent to driver
2018-05-01 17:48:34.765  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 49.0 in stage 0.0 (TID 49, localhost, executor driver, partition 49, ANY, 5003 bytes)
2018-05-01 17:48:34.766  INFO 16044 --- [Executor task launch worker for task 49] org.apache.spark.executor.Executor       : Running task 49.0 in stage 0.0 (TID 49)
2018-05-01 17:48:34.783  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 48.0 in stage 0.0 (TID 48) in 634 ms on localhost (executor driver) (49/66)
2018-05-01 17:48:35.327  INFO 16044 --- [Executor task launch worker for task 49] org.apache.spark.executor.Executor       : Finished task 49.0 in stage 0.0 (TID 49). 432743 bytes result sent to driver
2018-05-01 17:48:35.327  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 50.0 in stage 0.0 (TID 50, localhost, executor driver, partition 50, ANY, 5003 bytes)
2018-05-01 17:48:35.328  INFO 16044 --- [Executor task launch worker for task 50] org.apache.spark.executor.Executor       : Running task 50.0 in stage 0.0 (TID 50)
2018-05-01 17:48:35.347  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 49.0 in stage 0.0 (TID 49) in 582 ms on localhost (executor driver) (50/66)
2018-05-01 17:48:35.880  INFO 16044 --- [Executor task launch worker for task 50] org.apache.spark.executor.Executor       : Finished task 50.0 in stage 0.0 (TID 50). 430368 bytes result sent to driver
2018-05-01 17:48:35.881  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 51.0 in stage 0.0 (TID 51, localhost, executor driver, partition 51, ANY, 5002 bytes)
2018-05-01 17:48:35.881  INFO 16044 --- [Executor task launch worker for task 51] org.apache.spark.executor.Executor       : Running task 51.0 in stage 0.0 (TID 51)
2018-05-01 17:48:35.904  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 50.0 in stage 0.0 (TID 50) in 577 ms on localhost (executor driver) (51/66)
2018-05-01 17:48:36.440  INFO 16044 --- [Executor task launch worker for task 51] org.apache.spark.executor.Executor       : Finished task 51.0 in stage 0.0 (TID 51). 435039 bytes result sent to driver
2018-05-01 17:48:36.440  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 52.0 in stage 0.0 (TID 52, localhost, executor driver, partition 52, ANY, 5002 bytes)
2018-05-01 17:48:36.441  INFO 16044 --- [Executor task launch worker for task 52] org.apache.spark.executor.Executor       : Running task 52.0 in stage 0.0 (TID 52)
2018-05-01 17:48:36.457  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 51.0 in stage 0.0 (TID 51) in 576 ms on localhost (executor driver) (52/66)
2018-05-01 17:48:36.987  INFO 16044 --- [Executor task launch worker for task 52] org.apache.spark.executor.Executor       : Finished task 52.0 in stage 0.0 (TID 52). 431702 bytes result sent to driver
2018-05-01 17:48:36.987  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 53.0 in stage 0.0 (TID 53, localhost, executor driver, partition 53, ANY, 5002 bytes)
2018-05-01 17:48:36.987  INFO 16044 --- [Executor task launch worker for task 53] org.apache.spark.executor.Executor       : Running task 53.0 in stage 0.0 (TID 53)
2018-05-01 17:48:37.005  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 52.0 in stage 0.0 (TID 52) in 565 ms on localhost (executor driver) (53/66)
2018-05-01 17:48:37.622  INFO 16044 --- [Executor task launch worker for task 53] org.apache.spark.executor.Executor       : Finished task 53.0 in stage 0.0 (TID 53). 431628 bytes result sent to driver
2018-05-01 17:48:37.623  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 54.0 in stage 0.0 (TID 54, localhost, executor driver, partition 54, ANY, 5002 bytes)
2018-05-01 17:48:37.623  INFO 16044 --- [Executor task launch worker for task 54] org.apache.spark.executor.Executor       : Running task 54.0 in stage 0.0 (TID 54)
2018-05-01 17:48:37.641  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 53.0 in stage 0.0 (TID 53) in 654 ms on localhost (executor driver) (54/66)
2018-05-01 17:48:38.190  INFO 16044 --- [Executor task launch worker for task 54] org.apache.spark.executor.Executor       : Finished task 54.0 in stage 0.0 (TID 54). 428857 bytes result sent to driver
2018-05-01 17:48:38.191  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 55.0 in stage 0.0 (TID 55, localhost, executor driver, partition 55, ANY, 5003 bytes)
2018-05-01 17:48:38.191  INFO 16044 --- [Executor task launch worker for task 55] org.apache.spark.executor.Executor       : Running task 55.0 in stage 0.0 (TID 55)
2018-05-01 17:48:38.209  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 54.0 in stage 0.0 (TID 54) in 586 ms on localhost (executor driver) (55/66)
2018-05-01 17:48:38.735  INFO 16044 --- [Executor task launch worker for task 55] org.apache.spark.executor.Executor       : Finished task 55.0 in stage 0.0 (TID 55). 431970 bytes result sent to driver
2018-05-01 17:48:38.735  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 56.0 in stage 0.0 (TID 56, localhost, executor driver, partition 56, ANY, 5003 bytes)
2018-05-01 17:48:38.736  INFO 16044 --- [Executor task launch worker for task 56] org.apache.spark.executor.Executor       : Running task 56.0 in stage 0.0 (TID 56)
2018-05-01 17:48:38.753  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 55.0 in stage 0.0 (TID 55) in 563 ms on localhost (executor driver) (56/66)
2018-05-01 17:48:39.284  INFO 16044 --- [Executor task launch worker for task 56] org.apache.spark.executor.Executor       : Finished task 56.0 in stage 0.0 (TID 56). 430992 bytes result sent to driver
2018-05-01 17:48:39.285  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 57.0 in stage 0.0 (TID 57, localhost, executor driver, partition 57, ANY, 5003 bytes)
2018-05-01 17:48:39.285  INFO 16044 --- [Executor task launch worker for task 57] org.apache.spark.executor.Executor       : Running task 57.0 in stage 0.0 (TID 57)
2018-05-01 17:48:39.303  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 56.0 in stage 0.0 (TID 56) in 568 ms on localhost (executor driver) (57/66)
2018-05-01 17:48:39.886  INFO 16044 --- [Executor task launch worker for task 57] org.apache.spark.executor.Executor       : Finished task 57.0 in stage 0.0 (TID 57). 434026 bytes result sent to driver
2018-05-01 17:48:39.887  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 58.0 in stage 0.0 (TID 58, localhost, executor driver, partition 58, ANY, 5003 bytes)
2018-05-01 17:48:39.887  INFO 16044 --- [Executor task launch worker for task 58] org.apache.spark.executor.Executor       : Running task 58.0 in stage 0.0 (TID 58)
2018-05-01 17:48:39.910  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 57.0 in stage 0.0 (TID 57) in 626 ms on localhost (executor driver) (58/66)
2018-05-01 17:48:40.443  INFO 16044 --- [Executor task launch worker for task 58] org.apache.spark.executor.Executor       : Finished task 58.0 in stage 0.0 (TID 58). 431032 bytes result sent to driver
2018-05-01 17:48:40.444  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 59.0 in stage 0.0 (TID 59, localhost, executor driver, partition 59, ANY, 5003 bytes)
2018-05-01 17:48:40.445  INFO 16044 --- [Executor task launch worker for task 59] org.apache.spark.executor.Executor       : Running task 59.0 in stage 0.0 (TID 59)
2018-05-01 17:48:40.462  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 58.0 in stage 0.0 (TID 58) in 575 ms on localhost (executor driver) (59/66)
2018-05-01 17:48:41.014  INFO 16044 --- [Executor task launch worker for task 59] org.apache.spark.executor.Executor       : Finished task 59.0 in stage 0.0 (TID 59). 433164 bytes result sent to driver
2018-05-01 17:48:41.014  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 60.0 in stage 0.0 (TID 60, localhost, executor driver, partition 60, ANY, 5003 bytes)
2018-05-01 17:48:41.015  INFO 16044 --- [Executor task launch worker for task 60] org.apache.spark.executor.Executor       : Running task 60.0 in stage 0.0 (TID 60)
2018-05-01 17:48:41.030  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 59.0 in stage 0.0 (TID 59) in 586 ms on localhost (executor driver) (60/66)
2018-05-01 17:48:41.561  INFO 16044 --- [Executor task launch worker for task 60] org.apache.spark.executor.Executor       : Finished task 60.0 in stage 0.0 (TID 60). 432171 bytes result sent to driver
2018-05-01 17:48:41.562  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 61.0 in stage 0.0 (TID 61, localhost, executor driver, partition 61, ANY, 5003 bytes)
2018-05-01 17:48:41.562  INFO 16044 --- [Executor task launch worker for task 61] org.apache.spark.executor.Executor       : Running task 61.0 in stage 0.0 (TID 61)
2018-05-01 17:48:41.583  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 60.0 in stage 0.0 (TID 60) in 569 ms on localhost (executor driver) (61/66)
2018-05-01 17:48:42.103  INFO 16044 --- [Executor task launch worker for task 61] org.apache.spark.executor.Executor       : Finished task 61.0 in stage 0.0 (TID 61). 432524 bytes result sent to driver
2018-05-01 17:48:42.104  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 62.0 in stage 0.0 (TID 62, localhost, executor driver, partition 62, ANY, 5003 bytes)
2018-05-01 17:48:42.104  INFO 16044 --- [Executor task launch worker for task 62] org.apache.spark.executor.Executor       : Running task 62.0 in stage 0.0 (TID 62)
2018-05-01 17:48:42.119  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 61.0 in stage 0.0 (TID 61) in 557 ms on localhost (executor driver) (62/66)
2018-05-01 17:48:42.713  INFO 16044 --- [Executor task launch worker for task 62] org.apache.spark.executor.Executor       : Finished task 62.0 in stage 0.0 (TID 62). 431615 bytes result sent to driver
2018-05-01 17:48:42.714  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 63.0 in stage 0.0 (TID 63, localhost, executor driver, partition 63, ANY, 5003 bytes)
2018-05-01 17:48:42.714  INFO 16044 --- [Executor task launch worker for task 63] org.apache.spark.executor.Executor       : Running task 63.0 in stage 0.0 (TID 63)
2018-05-01 17:48:42.730  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 62.0 in stage 0.0 (TID 62) in 626 ms on localhost (executor driver) (63/66)
2018-05-01 17:48:43.294  INFO 16044 --- [Executor task launch worker for task 63] org.apache.spark.executor.Executor       : Finished task 63.0 in stage 0.0 (TID 63). 429910 bytes result sent to driver
2018-05-01 17:48:43.295  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 64.0 in stage 0.0 (TID 64, localhost, executor driver, partition 64, ANY, 5003 bytes)
2018-05-01 17:48:43.295  INFO 16044 --- [Executor task launch worker for task 64] org.apache.spark.executor.Executor       : Running task 64.0 in stage 0.0 (TID 64)
2018-05-01 17:48:43.311  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 63.0 in stage 0.0 (TID 63) in 598 ms on localhost (executor driver) (64/66)
2018-05-01 17:48:43.840  INFO 16044 --- [Executor task launch worker for task 64] org.apache.spark.executor.Executor       : Finished task 64.0 in stage 0.0 (TID 64). 434975 bytes result sent to driver
2018-05-01 17:48:43.840  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 65.0 in stage 0.0 (TID 65, localhost, executor driver, partition 65, ANY, 4992 bytes)
2018-05-01 17:48:43.841  INFO 16044 --- [Executor task launch worker for task 65] org.apache.spark.executor.Executor       : Running task 65.0 in stage 0.0 (TID 65)
2018-05-01 17:48:43.844  INFO 16044 --- [Executor task launch worker for task 65] org.apache.spark.executor.Executor       : Finished task 65.0 in stage 0.0 (TID 65). 777 bytes result sent to driver
2018-05-01 17:48:43.846  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 65.0 in stage 0.0 (TID 65) in 6 ms on localhost (executor driver) (65/66)
2018-05-01 17:48:43.856  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 64.0 in stage 0.0 (TID 64) in 562 ms on localhost (executor driver) (66/66)
2018-05-01 17:48:43.857  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-05-01 17:48:43.858  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 0 (collect at RecomendationServiceImpl.java:86) finished in 38.276 s
2018-05-01 17:48:43.863  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 0 finished: collect at RecomendationServiceImpl.java:86, took 38.355071 s
2018-05-01 17:48:44.034  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:240
2018-05-01 17:48:44.035  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 1 (isEmpty at ALS.scala:240) with 1 output partitions
2018-05-01 17:48:44.035  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1 (isEmpty at ALS.scala:240)
2018-05-01 17:48:44.035  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:48:44.037  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:48:44.037  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1 (UnionRDD[5] at union at RecomendationServiceImpl.java:77), which has no missing parents
2018-05-01 17:48:44.041  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.8 MB)
2018-05-01 17:48:44.042  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.8 MB)
2018-05-01 17:48:44.044  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_2_piece0 in memory on 172.21.241.193:58620 (size: 2.1 KB, free: 1990.8 MB)
2018-05-01 17:48:44.044  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:48:44.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1 (UnionRDD[5] at union at RecomendationServiceImpl.java:77) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:48:44.045  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1.0 with 1 tasks
2018-05-01 17:48:48.082  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_1_piece0 on 172.21.241.193:58620 in memory (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 17:48:48.085  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_0_piece0 on 172.21.241.193:58620 in memory (size: 419.0 B, free: 1990.8 MB)
2018-05-01 17:48:48.795  WARN 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 1 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:48:48.795  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:48:48.795  INFO 16044 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1.0 (TID 66)
2018-05-01 17:48:48.921  INFO 16044 --- [pool-25-thread-1] c.m.spark.connection.MongoClientCache    : Closing MongoClient: [127.0.0.1:27017]
2018-05-01 17:48:48.923  INFO 16044 --- [pool-25-thread-1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:29}] to 127.0.0.1:27017 because the pool has been closed.
2018-05-01 17:48:50.195  INFO 16044 --- [Executor task launch worker for task 66] o.a.spark.storage.memory.MemoryStore     : Block rdd_3_0 stored as values in memory (estimated size 36.0 MB, free 1954.8 MB)
2018-05-01 17:48:50.196  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_3_0 in memory on 172.21.241.193:58620 (size: 36.0 MB, free: 1954.8 MB)
2018-05-01 17:48:50.205  INFO 16044 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 66:
[rdd_3_0]
2018-05-01 17:48:50.208  INFO 16044 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1.0 (TID 66). 1508 bytes result sent to driver
2018-05-01 17:48:50.210  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1.0 (TID 66) in 6165 ms on localhost (executor driver) (1/1)
2018-05-01 17:48:50.210  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-05-01 17:48:50.211  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1 (isEmpty at ALS.scala:240) finished in 6.165 s
2018-05-01 17:48:50.212  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 1 finished: isEmpty at ALS.scala:240, took 6.177699 s
2018-05-01 17:48:50.227  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:843
2018-05-01 17:48:50.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 2 (isEmpty at ALS.scala:843) with 1 output partitions
2018-05-01 17:48:50.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 2 (isEmpty at ALS.scala:843)
2018-05-01 17:48:50.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:48:50.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:48:50.230  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 2 (MapPartitionsRDD[6] at map at ALS.scala:256), which has no missing parents
2018-05-01 17:48:50.231  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1954.8 MB)
2018-05-01 17:48:50.233  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1954.8 MB)
2018-05-01 17:48:50.233  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_3_piece0 in memory on 172.21.241.193:58620 (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 17:48:50.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:48:50.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:48:50.235  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 2.0 with 1 tasks
2018-05-01 17:48:53.029  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_2_piece0 on 172.21.241.193:58620 in memory (size: 2.1 KB, free: 1954.8 MB)
2018-05-01 17:48:54.790  WARN 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 2 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:48:54.791  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 2.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:48:54.792  INFO 16044 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : Running task 0.0 in stage 2.0 (TID 67)
2018-05-01 17:48:55.956  INFO 16044 --- [Executor task launch worker for task 67] org.apache.spark.storage.BlockManager    : Found block rdd_3_0 locally
2018-05-01 17:48:55.959  INFO 16044 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 67:
[rdd_3_0]
2018-05-01 17:48:55.961  INFO 16044 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 2.0 (TID 67). 1089 bytes result sent to driver
2018-05-01 17:48:55.963  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 2.0 (TID 67) in 5727 ms on localhost (executor driver) (1/1)
2018-05-01 17:48:55.963  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-05-01 17:48:55.963  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 2 (isEmpty at ALS.scala:843) finished in 5.727 s
2018-05-01 17:48:55.964  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 2 finished: isEmpty at ALS.scala:843, took 5.735909 s
2018-05-01 17:48:56.071  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:857
2018-05-01 17:48:56.076  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 7 (mapPartitions at ALS.scala:1101)
2018-05-01 17:48:56.077  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 10 (map at ALS.scala:1344)
2018-05-01 17:48:56.077  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 3 (count at ALS.scala:857) with 1 output partitions
2018-05-01 17:48:56.078  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 5 (count at ALS.scala:857)
2018-05-01 17:48:56.078  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 4)
2018-05-01 17:48:56.079  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 4)
2018-05-01 17:48:56.080  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 3 (MapPartitionsRDD[7] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-05-01 17:48:56.084  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 1954.8 MB)
2018-05-01 17:48:56.086  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1954.8 MB)
2018-05-01 17:48:56.087  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_4_piece0 in memory on 172.21.241.193:58620 (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 17:48:56.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:48:56.090  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[7] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:48:56.090  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 3.0 with 2 tasks
2018-05-01 17:48:59.196  WARN 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Stage 3 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:48:59.196  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 3.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427802 bytes)
2018-05-01 17:48:59.197  INFO 16044 --- [Executor task launch worker for task 68] org.apache.spark.executor.Executor       : Running task 0.0 in stage 3.0 (TID 68)
2018-05-01 17:49:00.411  INFO 16044 --- [Executor task launch worker for task 68] org.apache.spark.storage.BlockManager    : Found block rdd_3_0 locally
2018-05-01 17:49:00.737  INFO 16044 --- [Executor task launch worker for task 68] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 3.0 (TID 68). 1070 bytes result sent to driver
2018-05-01 17:49:00.738  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 3.0 (TID 69, localhost, executor driver, partition 1, PROCESS_LOCAL, 5072 bytes)
2018-05-01 17:49:00.739  INFO 16044 --- [Executor task launch worker for task 69] org.apache.spark.executor.Executor       : Running task 1.0 in stage 3.0 (TID 69)
2018-05-01 17:49:00.740  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 3.0 (TID 68) in 4650 ms on localhost (executor driver) (1/2)
2018-05-01 17:49:00.756  INFO 16044 --- [Executor task launch worker for task 69] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 3.0 (TID 69). 855 bytes result sent to driver
2018-05-01 17:49:00.756  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 3.0 (TID 69) in 18 ms on localhost (executor driver) (2/2)
2018-05-01 17:49:00.757  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-05-01 17:49:00.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 3 (mapPartitions at ALS.scala:1101) finished in 4.667 s
2018-05-01 17:49:00.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:00.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:00.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 5, ShuffleMapStage 4)
2018-05-01 17:49:00.761  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:00.765  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:49:00.768  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 1954.8 MB)
2018-05-01 17:49:00.770  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1954.8 MB)
2018-05-01 17:49:00.771  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_5_piece0 in memory on 172.21.241.193:58620 (size: 3.7 KB, free: 1954.8 MB)
2018-05-01 17:49:00.772  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:00.772  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:49:00.773  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 4.0 with 2 tasks
2018-05-01 17:49:00.774  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 4.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:49:00.774  INFO 16044 --- [Executor task launch worker for task 70] org.apache.spark.executor.Executor       : Running task 0.0 in stage 4.0 (TID 70)
2018-05-01 17:49:00.785  INFO 16044 --- [Executor task launch worker for task 70] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 2 blocks
2018-05-01 17:49:00.787  INFO 16044 --- [Executor task launch worker for task 70] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 4 ms
2018-05-01 17:49:00.798  INFO 16044 --- [Executor task launch worker for task 70] o.a.spark.storage.memory.MemoryStore     : Block rdd_9_0 stored as values in memory (estimated size 16.0 B, free 1954.8 MB)
2018-05-01 17:49:00.798  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_9_0 in memory on 172.21.241.193:58620 (size: 16.0 B, free: 1954.8 MB)
2018-05-01 17:49:00.805  INFO 16044 --- [Executor task launch worker for task 70] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 4.0 (TID 70). 1852 bytes result sent to driver
2018-05-01 17:49:00.805  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 4.0 (TID 71, localhost, executor driver, partition 1, ANY, 4610 bytes)
2018-05-01 17:49:00.805  INFO 16044 --- [Executor task launch worker for task 71] org.apache.spark.executor.Executor       : Running task 1.0 in stage 4.0 (TID 71)
2018-05-01 17:49:00.805  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 4.0 (TID 70) in 31 ms on localhost (executor driver) (1/2)
2018-05-01 17:49:00.807  INFO 16044 --- [Executor task launch worker for task 71] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 2 non-empty blocks out of 2 blocks
2018-05-01 17:49:00.807  INFO 16044 --- [Executor task launch worker for task 71] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:00.962  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_4_piece0 on 172.21.241.193:58620 in memory (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 17:49:01.004  INFO 16044 --- [Executor task launch worker for task 71] o.a.spark.storage.memory.MemoryStore     : Block rdd_9_1 stored as values in memory (estimated size 12.0 MB, free 1942.8 MB)
2018-05-01 17:49:01.005  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_9_1 in memory on 172.21.241.193:58620 (size: 12.0 MB, free: 1942.8 MB)
2018-05-01 17:49:01.324  INFO 16044 --- [Executor task launch worker for task 71] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 4.0 (TID 71). 1981 bytes result sent to driver
2018-05-01 17:49:01.325  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 4.0 (TID 71) in 520 ms on localhost (executor driver) (2/2)
2018-05-01 17:49:01.325  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-05-01 17:49:01.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 4 (map at ALS.scala:1344) finished in 0.552 s
2018-05-01 17:49:01.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:01.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:01.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 5)
2018-05-01 17:49:01.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:01.332  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 5 (userOutBlocks MapPartitionsRDD[13] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:49:01.334  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6 stored as values in memory (estimated size 7.7 KB, free 1942.8 MB)
2018-05-01 17:49:01.336  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1942.8 MB)
2018-05-01 17:49:01.338  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_6_piece0 in memory on 172.21.241.193:58620 (size: 3.9 KB, free: 1942.8 MB)
2018-05-01 17:49:01.338  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:01.339  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 5 (userOutBlocks MapPartitionsRDD[13] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:01.339  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 5.0 with 1 tasks
2018-05-01 17:49:01.339  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 5.0 (TID 72, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:49:01.340  INFO 16044 --- [Executor task launch worker for task 72] org.apache.spark.executor.Executor       : Running task 0.0 in stage 5.0 (TID 72)
2018-05-01 17:49:01.342  INFO 16044 --- [Executor task launch worker for task 72] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:49:01.342  INFO 16044 --- [Executor task launch worker for task 72] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:01.784  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_5_piece0 on 172.21.241.193:58620 in memory (size: 3.7 KB, free: 1942.8 MB)
2018-05-01 17:49:01.844  INFO 16044 --- [Executor task launch worker for task 72] o.a.spark.storage.memory.MemoryStore     : Block rdd_12_0 stored as values in memory (estimated size 8.1 MB, free 1934.7 MB)
2018-05-01 17:49:01.847  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_12_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1934.7 MB)
2018-05-01 17:49:01.854  INFO 16044 --- [Executor task launch worker for task 72] o.a.spark.storage.memory.MemoryStore     : Block rdd_13_0 stored as values in memory (estimated size 27.9 KB, free 1934.7 MB)
2018-05-01 17:49:01.856  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_13_0 in memory on 172.21.241.193:58620 (size: 27.9 KB, free: 1934.7 MB)
2018-05-01 17:49:01.857  INFO 16044 --- [Executor task launch worker for task 72] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 5.0 (TID 72). 1877 bytes result sent to driver
2018-05-01 17:49:01.858  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 5.0 (TID 72) in 519 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:01.858  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-05-01 17:49:01.859  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 5 (count at ALS.scala:857) finished in 0.519 s
2018-05-01 17:49:01.859  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 3 finished: count at ALS.scala:857, took 5.787201 s
2018-05-01 17:49:01.880  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:865
2018-05-01 17:49:01.883  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:01.884  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 15 (map at ALS.scala:1344)
2018-05-01 17:49:01.885  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 4 (count at ALS.scala:865) with 1 output partitions
2018-05-01 17:49:01.885  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 8 (count at ALS.scala:865)
2018-05-01 17:49:01.885  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 7)
2018-05-01 17:49:01.886  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 7)
2018-05-01 17:49:01.887  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 7 (MapPartitionsRDD[15] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:49:01.888  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7 stored as values in memory (estimated size 7.3 KB, free 1934.7 MB)
2018-05-01 17:49:01.890  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1934.7 MB)
2018-05-01 17:49:01.891  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_7_piece0 in memory on 172.21.241.193:58620 (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:49:01.892  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:01.892  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[15] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:49:01.892  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 7.0 with 2 tasks
2018-05-01 17:49:01.892  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 7.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:49:01.892  INFO 16044 --- [Executor task launch worker for task 73] org.apache.spark.executor.Executor       : Running task 0.0 in stage 7.0 (TID 73)
2018-05-01 17:49:01.895  INFO 16044 --- [Executor task launch worker for task 73] org.apache.spark.storage.BlockManager    : Found block rdd_9_0 locally
2018-05-01 17:49:01.900  INFO 16044 --- [Executor task launch worker for task 73] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 7.0 (TID 73). 725 bytes result sent to driver
2018-05-01 17:49:01.901  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 7.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:49:01.901  INFO 16044 --- [Executor task launch worker for task 74] org.apache.spark.executor.Executor       : Running task 1.0 in stage 7.0 (TID 74)
2018-05-01 17:49:01.901  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 7.0 (TID 73) in 9 ms on localhost (executor driver) (1/2)
2018-05-01 17:49:01.902  INFO 16044 --- [Executor task launch worker for task 74] org.apache.spark.storage.BlockManager    : Found block rdd_9_1 locally
2018-05-01 17:49:02.168  INFO 16044 --- [Executor task launch worker for task 74] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 7.0 (TID 74). 983 bytes result sent to driver
2018-05-01 17:49:02.169  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 7.0 (TID 74) in 268 ms on localhost (executor driver) (2/2)
2018-05-01 17:49:02.169  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 7 (map at ALS.scala:1344) finished in 0.277 s
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:02.170  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 8 (itemOutBlocks MapPartitionsRDD[18] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:49:02.171  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8 stored as values in memory (estimated size 7.9 KB, free 1934.7 MB)
2018-05-01 17:49:02.173  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1934.7 MB)
2018-05-01 17:49:02.174  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_8_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1934.7 MB)
2018-05-01 17:49:02.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:02.176  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 8 (itemOutBlocks MapPartitionsRDD[18] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:02.176  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 8.0 with 1 tasks
2018-05-01 17:49:02.176  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 8.0 (TID 75, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:49:02.176  INFO 16044 --- [Executor task launch worker for task 75] org.apache.spark.executor.Executor       : Running task 0.0 in stage 8.0 (TID 75)
2018-05-01 17:49:02.179  INFO 16044 --- [Executor task launch worker for task 75] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:49:02.179  INFO 16044 --- [Executor task launch worker for task 75] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:02.645  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_7_piece0 on 172.21.241.193:58620 in memory (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:49:02.646  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_6_piece0 on 172.21.241.193:58620 in memory (size: 3.9 KB, free: 1934.7 MB)
2018-05-01 17:49:03.431  INFO 16044 --- [Executor task launch worker for task 75] o.a.spark.storage.memory.MemoryStore     : Block rdd_17_0 stored as values in memory (estimated size 8.1 MB, free 1926.6 MB)
2018-05-01 17:49:03.433  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_17_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1926.6 MB)
2018-05-01 17:49:03.439  INFO 16044 --- [Executor task launch worker for task 75] o.a.spark.storage.memory.MemoryStore     : Block rdd_18_0 stored as values in memory (estimated size 54.9 KB, free 1926.5 MB)
2018-05-01 17:49:03.441  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_18_0 in memory on 172.21.241.193:58620 (size: 54.9 KB, free: 1926.6 MB)
2018-05-01 17:49:03.442  INFO 16044 --- [Executor task launch worker for task 75] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 8.0 (TID 75). 1877 bytes result sent to driver
2018-05-01 17:49:03.442  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 8.0 (TID 75) in 1266 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:03.442  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-05-01 17:49:03.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 8 (count at ALS.scala:865) finished in 1.266 s
2018-05-01 17:49:03.445  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 4 finished: count at ALS.scala:865, took 1.564824 s
2018-05-01 17:49:03.480  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:03.481  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:03.481  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:03.481  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 5 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:03.481  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 11 (aggregate at ALS.scala:1491)
2018-05-01 17:49:03.482  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 10)
2018-05-01 17:49:03.482  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:03.482  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 11 (MapPartitionsRDD[21] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:03.483  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9 stored as values in memory (estimated size 9.1 KB, free 1926.5 MB)
2018-05-01 17:49:03.485  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.5 MB)
2018-05-01 17:49:03.486  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_9_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.5 MB)
2018-05-01 17:49:03.486  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:03.487  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:03.487  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 11.0 with 1 tasks
2018-05-01 17:49:03.487  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 11.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
2018-05-01 17:49:03.488  INFO 16044 --- [Executor task launch worker for task 76] org.apache.spark.executor.Executor       : Running task 0.0 in stage 11.0 (TID 76)
2018-05-01 17:49:03.494  INFO 16044 --- [Executor task launch worker for task 76] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:03.498  WARN 16044 --- [Executor task launch worker for task 76] com.github.fommil.netlib.BLAS            : Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-05-01 17:49:03.498  WARN 16044 --- [Executor task launch worker for task 76] com.github.fommil.netlib.BLAS            : Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-05-01 17:49:03.514  INFO 16044 --- [Executor task launch worker for task 76] o.a.spark.storage.memory.MemoryStore     : Block rdd_19_0 stored as values in memory (estimated size 416.2 KB, free 1926.1 MB)
2018-05-01 17:49:03.515  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_19_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1926.1 MB)
2018-05-01 17:49:03.521  INFO 16044 --- [Executor task launch worker for task 76] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 11.0 (TID 76). 2208 bytes result sent to driver
2018-05-01 17:49:03.522  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 11.0 (TID 76) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:03.522  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-05-01 17:49:03.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 11 (aggregate at ALS.scala:1491) finished in 0.035 s
2018-05-01 17:49:03.523  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 5 finished: aggregate at ALS.scala:1491, took 0.042372 s
2018-05-01 17:49:03.557  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 20 from persistence list
2018-05-01 17:49:03.561  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 20
2018-05-01 17:49:03.570  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:03.572  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 19 (map at ALS.scala:1017)
2018-05-01 17:49:03.572  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 25 (flatMap at ALS.scala:1433)
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 6 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 17 (aggregate at ALS.scala:1491)
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 16)
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 15)
2018-05-01 17:49:03.574  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[19] at map at ALS.scala:1017), which has no missing parents
2018-05-01 17:49:03.575  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10 stored as values in memory (estimated size 7.7 KB, free 1926.1 MB)
2018-05-01 17:49:03.576  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1926.1 MB)
2018-05-01 17:49:03.577  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_10_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:49:03.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:03.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[19] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:03.579  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 14.0 with 1 tasks
2018-05-01 17:49:03.580  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 14.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:49:03.580  INFO 16044 --- [Executor task launch worker for task 77] org.apache.spark.executor.Executor       : Running task 0.0 in stage 14.0 (TID 77)
2018-05-01 17:49:03.581  INFO 16044 --- [Executor task launch worker for task 77] org.apache.spark.storage.BlockManager    : Found block rdd_19_0 locally
2018-05-01 17:49:03.607  INFO 16044 --- [Executor task launch worker for task 77] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 14.0 (TID 77). 940 bytes result sent to driver
2018-05-01 17:49:03.608  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 14.0 (TID 77) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:03.608  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 14 (map at ALS.scala:1017) finished in 0.029 s
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 15, ResultStage 17)
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 15 (MapPartitionsRDD[25] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:03.610  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11 stored as values in memory (estimated size 8.8 KB, free 1926.1 MB)
2018-05-01 17:49:03.611  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.1 MB)
2018-05-01 17:49:03.612  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_11_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 17:49:03.612  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:03.613  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[25] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:03.613  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 15.0 with 1 tasks
2018-05-01 17:49:03.615  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 15.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-05-01 17:49:03.615  INFO 16044 --- [Executor task launch worker for task 78] org.apache.spark.executor.Executor       : Running task 0.0 in stage 15.0 (TID 78)
2018-05-01 17:49:03.618  INFO 16044 --- [Executor task launch worker for task 78] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:03.618  INFO 16044 --- [Executor task launch worker for task 78] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:03.618  INFO 16044 --- [Executor task launch worker for task 78] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:03.657  INFO 16044 --- [Executor task launch worker for task 78] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 15.0 (TID 78). 1327 bytes result sent to driver
2018-05-01 17:49:03.657  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 15.0 (TID 78) in 43 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:03.657  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 15 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 17)
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:03.659  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 17 (MapPartitionsRDD[31] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:03.661  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12 stored as values in memory (estimated size 12.6 KB, free 1926.1 MB)
2018-05-01 17:49:03.664  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1926.1 MB)
2018-05-01 17:49:03.665  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_12_piece0 in memory on 172.21.241.193:58620 (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 17:49:03.665  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:03.667  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[31] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:03.667  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 17.0 with 1 tasks
2018-05-01 17:49:03.667  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 17.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:03.667  INFO 16044 --- [Executor task launch worker for task 79] org.apache.spark.executor.Executor       : Running task 0.0 in stage 17.0 (TID 79)
2018-05-01 17:49:03.670  INFO 16044 --- [Executor task launch worker for task 79] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:03.670  INFO 16044 --- [Executor task launch worker for task 79] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:03.670  INFO 16044 --- [Executor task launch worker for task 79] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:03.683  WARN 16044 --- [Executor task launch worker for task 79] com.github.fommil.netlib.LAPACK          : Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-05-01 17:49:03.684  WARN 16044 --- [Executor task launch worker for task 79] com.github.fommil.netlib.LAPACK          : Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-05-01 17:49:04.027  INFO 16044 --- [Executor task launch worker for task 79] o.a.spark.storage.memory.MemoryStore     : Block rdd_30_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:49:04.027  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_30_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:49:04.032  INFO 16044 --- [Executor task launch worker for task 79] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 17.0 (TID 79). 2595 bytes result sent to driver
2018-05-01 17:49:04.033  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 17.0 (TID 79) in 366 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.033  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.033  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 17 (aggregate at ALS.scala:1491) finished in 0.366 s
2018-05-01 17:49:04.033  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 6 finished: aggregate at ALS.scala:1491, took 0.462373 s
2018-05-01 17:49:04.052  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 19 from persistence list
2018-05-01 17:49:04.053  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 19
2018-05-01 17:49:04.062  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:04.063  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:04.063  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:04.063  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 35 (flatMap at ALS.scala:1433)
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 7 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 24 (aggregate at ALS.scala:1491)
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 19, ShuffleMapStage 23)
2018-05-01 17:49:04.065  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 23)
2018-05-01 17:49:04.066  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 23 (MapPartitionsRDD[35] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:04.067  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13 stored as values in memory (estimated size 11.8 KB, free 1925.7 MB)
2018-05-01 17:49:04.069  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.6 KB, free 1925.7 MB)
2018-05-01 17:49:04.071  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_13_piece0 in memory on 172.21.241.193:58620 (size: 5.6 KB, free: 1925.7 MB)
2018-05-01 17:49:04.071  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.071  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[35] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.072  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 23.0 with 1 tasks
2018-05-01 17:49:04.072  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 23.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:04.072  INFO 16044 --- [Executor task launch worker for task 80] org.apache.spark.executor.Executor       : Running task 0.0 in stage 23.0 (TID 80)
2018-05-01 17:49:04.074  INFO 16044 --- [Executor task launch worker for task 80] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:04.074  INFO 16044 --- [Executor task launch worker for task 80] org.apache.spark.storage.BlockManager    : Found block rdd_30_0 locally
2018-05-01 17:49:04.107  INFO 16044 --- [Executor task launch worker for task 80] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 23.0 (TID 80). 1112 bytes result sent to driver
2018-05-01 17:49:04.107  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 23.0 (TID 80) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.107  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 23 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 24)
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 24 (MapPartitionsRDD[41] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:04.110  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_14 stored as values in memory (estimated size 14.3 KB, free 1925.7 MB)
2018-05-01 17:49:04.112  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1925.6 MB)
2018-05-01 17:49:04.112  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_14_piece0 in memory on 172.21.241.193:58620 (size: 6.6 KB, free: 1925.7 MB)
2018-05-01 17:49:04.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.113  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[41] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.113  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 24.0 with 1 tasks
2018-05-01 17:49:04.113  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 24.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:04.113  INFO 16044 --- [Executor task launch worker for task 81] org.apache.spark.executor.Executor       : Running task 0.0 in stage 24.0 (TID 81)
2018-05-01 17:49:04.115  INFO 16044 --- [Executor task launch worker for task 81] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:04.116  INFO 16044 --- [Executor task launch worker for task 81] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:04.116  INFO 16044 --- [Executor task launch worker for task 81] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:04.382  INFO 16044 --- [Executor task launch worker for task 81] o.a.spark.storage.memory.MemoryStore     : Block rdd_40_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:49:04.383  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_40_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:49:04.385  INFO 16044 --- [Executor task launch worker for task 81] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 24.0 (TID 81). 2595 bytes result sent to driver
2018-05-01 17:49:04.386  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 24.0 (TID 81) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.386  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 24.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.386  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 24 (aggregate at ALS.scala:1491) finished in 0.273 s
2018-05-01 17:49:04.387  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 7 finished: aggregate at ALS.scala:1491, took 0.324465 s
2018-05-01 17:49:04.409  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 30 from persistence list
2018-05-01 17:49:04.410  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 30
2018-05-01 17:49:04.464  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_8_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:49:04.465  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_13_piece0 on 172.21.241.193:58620 in memory (size: 5.6 KB, free: 1926.1 MB)
2018-05-01 17:49:04.466  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_12_piece0 on 172.21.241.193:58620 in memory (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 17:49:04.466  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_10_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:49:04.468  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_11_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 17:49:04.468  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_14_piece0 on 172.21.241.193:58620 in memory (size: 6.6 KB, free: 1926.1 MB)
2018-05-01 17:49:04.469  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_9_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1926.2 MB)
2018-05-01 17:49:04.470  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:04.470  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:04.471  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:04.472  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:04.472  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:04.473  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:04.473  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 45 (flatMap at ALS.scala:1433)
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 8 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 32 (aggregate at ALS.scala:1491)
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 31, ShuffleMapStage 28)
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 31)
2018-05-01 17:49:04.475  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 31 (MapPartitionsRDD[45] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:04.477  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_15 stored as values in memory (estimated size 13.4 KB, free 1926.1 MB)
2018-05-01 17:49:04.479  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1926.1 MB)
2018-05-01 17:49:04.479  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_15_piece0 in memory on 172.21.241.193:58620 (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:49:04.480  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.480  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[45] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.480  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 31.0 with 1 tasks
2018-05-01 17:49:04.481  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 31.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:04.482  INFO 16044 --- [Executor task launch worker for task 82] org.apache.spark.executor.Executor       : Running task 0.0 in stage 31.0 (TID 82)
2018-05-01 17:49:04.484  INFO 16044 --- [Executor task launch worker for task 82] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:04.484  INFO 16044 --- [Executor task launch worker for task 82] org.apache.spark.storage.BlockManager    : Found block rdd_40_0 locally
2018-05-01 17:49:04.510  INFO 16044 --- [Executor task launch worker for task 82] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 31.0 (TID 82). 1026 bytes result sent to driver
2018-05-01 17:49:04.511  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 31.0 (TID 82) in 31 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.512  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 31.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 31 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 32)
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:04.513  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 32 (MapPartitionsRDD[51] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:04.515  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_16 stored as values in memory (estimated size 15.8 KB, free 1926.1 MB)
2018-05-01 17:49:04.517  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1926.1 MB)
2018-05-01 17:49:04.517  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_16_piece0 in memory on 172.21.241.193:58620 (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 17:49:04.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[51] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.518  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 32.0 with 1 tasks
2018-05-01 17:49:04.518  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 32.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:04.518  INFO 16044 --- [Executor task launch worker for task 83] org.apache.spark.executor.Executor       : Running task 0.0 in stage 32.0 (TID 83)
2018-05-01 17:49:04.521  INFO 16044 --- [Executor task launch worker for task 83] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:04.521  INFO 16044 --- [Executor task launch worker for task 83] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:04.521  INFO 16044 --- [Executor task launch worker for task 83] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:04.800  INFO 16044 --- [Executor task launch worker for task 83] o.a.spark.storage.memory.MemoryStore     : Block rdd_50_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:49:04.800  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_50_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:49:04.803  INFO 16044 --- [Executor task launch worker for task 83] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 32.0 (TID 83). 2595 bytes result sent to driver
2018-05-01 17:49:04.804  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 32.0 (TID 83) in 286 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.804  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 32.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 32 (aggregate at ALS.scala:1491) finished in 0.286 s
2018-05-01 17:49:04.804  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 8 finished: aggregate at ALS.scala:1491, took 0.334600 s
2018-05-01 17:49:04.825  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 40 from persistence list
2018-05-01 17:49:04.825  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 40
2018-05-01 17:49:04.832  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:04.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:04.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:04.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:04.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:04.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:04.834  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 55 (flatMap at ALS.scala:1433)
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 9 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 41 (aggregate at ALS.scala:1491)
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 40)
2018-05-01 17:49:04.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 40)
2018-05-01 17:49:04.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 40 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:04.838  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_17 stored as values in memory (estimated size 14.9 KB, free 1925.7 MB)
2018-05-01 17:49:04.840  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1925.7 MB)
2018-05-01 17:49:04.840  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_17_piece0 in memory on 172.21.241.193:58620 (size: 7.1 KB, free: 1925.7 MB)
2018-05-01 17:49:04.840  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.841  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.841  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 40.0 with 1 tasks
2018-05-01 17:49:04.842  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 40.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:04.842  INFO 16044 --- [Executor task launch worker for task 84] org.apache.spark.executor.Executor       : Running task 0.0 in stage 40.0 (TID 84)
2018-05-01 17:49:04.843  INFO 16044 --- [Executor task launch worker for task 84] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:04.844  INFO 16044 --- [Executor task launch worker for task 84] org.apache.spark.storage.BlockManager    : Found block rdd_50_0 locally
2018-05-01 17:49:04.877  INFO 16044 --- [Executor task launch worker for task 84] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 40.0 (TID 84). 1069 bytes result sent to driver
2018-05-01 17:49:04.878  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 40.0 (TID 84) in 37 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.878  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 40.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 40 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 41)
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:04.880  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 41 (MapPartitionsRDD[61] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:04.881  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_18 stored as values in memory (estimated size 17.4 KB, free 1925.7 MB)
2018-05-01 17:49:04.883  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 1925.7 MB)
2018-05-01 17:49:04.883  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_18_piece0 in memory on 172.21.241.193:58620 (size: 8.0 KB, free: 1925.7 MB)
2018-05-01 17:49:04.883  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.884  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[61] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.884  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 41.0 with 1 tasks
2018-05-01 17:49:04.885  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 41.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:04.885  INFO 16044 --- [Executor task launch worker for task 85] org.apache.spark.executor.Executor       : Running task 0.0 in stage 41.0 (TID 85)
2018-05-01 17:49:04.887  INFO 16044 --- [Executor task launch worker for task 85] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:04.887  INFO 16044 --- [Executor task launch worker for task 85] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:04.887  INFO 16044 --- [Executor task launch worker for task 85] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:05.160  INFO 16044 --- [Executor task launch worker for task 85] o.a.spark.storage.memory.MemoryStore     : Block rdd_60_0 stored as values in memory (estimated size 416.2 KB, free 1925.3 MB)
2018-05-01 17:49:05.162  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_60_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:49:05.164  INFO 16044 --- [Executor task launch worker for task 85] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 41.0 (TID 85). 2595 bytes result sent to driver
2018-05-01 17:49:05.165  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 41.0 (TID 85) in 281 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:05.165  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 41.0, whose tasks have all completed, from pool 
2018-05-01 17:49:05.166  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 41 (aggregate at ALS.scala:1491) finished in 0.281 s
2018-05-01 17:49:05.166  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 9 finished: aggregate at ALS.scala:1491, took 0.334084 s
2018-05-01 17:49:05.184  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 50 from persistence list
2018-05-01 17:49:05.185  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 50
2018-05-01 17:49:05.190  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:05.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:05.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:05.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:05.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:05.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:05.193  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:05.193  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:05.193  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 65 (flatMap at ALS.scala:1433)
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 10 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 51 (aggregate at ALS.scala:1491)
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 50, ShuffleMapStage 43)
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 50)
2018-05-01 17:49:05.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 50 (MapPartitionsRDD[65] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:05.197  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_19 stored as values in memory (estimated size 16.5 KB, free 1926.0 MB)
2018-05-01 17:49:05.198  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.8 KB, free 1926.0 MB)
2018-05-01 17:49:05.198  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_19_piece0 in memory on 172.21.241.193:58620 (size: 7.8 KB, free: 1926.1 MB)
2018-05-01 17:49:05.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:05.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[65] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:05.199  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 50.0 with 1 tasks
2018-05-01 17:49:05.200  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 50.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:05.200  INFO 16044 --- [Executor task launch worker for task 86] org.apache.spark.executor.Executor       : Running task 0.0 in stage 50.0 (TID 86)
2018-05-01 17:49:05.201  INFO 16044 --- [Executor task launch worker for task 86] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:05.202  INFO 16044 --- [Executor task launch worker for task 86] org.apache.spark.storage.BlockManager    : Found block rdd_60_0 locally
2018-05-01 17:49:05.226  INFO 16044 --- [Executor task launch worker for task 86] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 50.0 (TID 86). 1069 bytes result sent to driver
2018-05-01 17:49:05.226  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 50.0 (TID 86) in 27 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:05.226  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 50.0, whose tasks have all completed, from pool 
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 50 (flatMap at ALS.scala:1433) finished in 0.027 s
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 51)
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:05.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 51 (MapPartitionsRDD[71] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:05.229  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_20 stored as values in memory (estimated size 18.9 KB, free 1926.0 MB)
2018-05-01 17:49:05.230  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1926.0 MB)
2018-05-01 17:49:05.231  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_20_piece0 in memory on 172.21.241.193:58620 (size: 8.6 KB, free: 1926.1 MB)
2018-05-01 17:49:05.231  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:05.232  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[71] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:05.232  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 51.0 with 1 tasks
2018-05-01 17:49:05.232  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 51.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:05.232  INFO 16044 --- [Executor task launch worker for task 87] org.apache.spark.executor.Executor       : Running task 0.0 in stage 51.0 (TID 87)
2018-05-01 17:49:05.234  INFO 16044 --- [Executor task launch worker for task 87] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:05.235  INFO 16044 --- [Executor task launch worker for task 87] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:05.235  INFO 16044 --- [Executor task launch worker for task 87] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:05.524  INFO 16044 --- [Executor task launch worker for task 87] o.a.spark.storage.memory.MemoryStore     : Block rdd_70_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 17:49:05.524  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_70_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:49:05.528  INFO 16044 --- [Executor task launch worker for task 87] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 51.0 (TID 87). 2595 bytes result sent to driver
2018-05-01 17:49:05.528  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 51.0 (TID 87) in 296 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:05.529  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 51.0, whose tasks have all completed, from pool 
2018-05-01 17:49:05.529  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 51 (aggregate at ALS.scala:1491) finished in 0.297 s
2018-05-01 17:49:05.530  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 10 finished: aggregate at ALS.scala:1491, took 0.339306 s
2018-05-01 17:49:05.550  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 60 from persistence list
2018-05-01 17:49:05.550  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 60
2018-05-01 17:49:05.555  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:05.556  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:05.556  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:05.556  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:05.557  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:05.557  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:05.557  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:05.557  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 75 (flatMap at ALS.scala:1433)
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 11 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 62 (aggregate at ALS.scala:1491)
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 53, ShuffleMapStage 61)
2018-05-01 17:49:05.559  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 61)
2018-05-01 17:49:05.559  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 61 (MapPartitionsRDD[75] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:05.561  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_21 stored as values in memory (estimated size 18.0 KB, free 1925.6 MB)
2018-05-01 17:49:05.563  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1925.6 MB)
2018-05-01 17:49:05.564  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_21_piece0 in memory on 172.21.241.193:58620 (size: 8.4 KB, free: 1925.7 MB)
2018-05-01 17:49:05.564  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:05.565  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[75] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:05.565  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 61.0 with 1 tasks
2018-05-01 17:49:05.565  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 61.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:05.565  INFO 16044 --- [Executor task launch worker for task 88] org.apache.spark.executor.Executor       : Running task 0.0 in stage 61.0 (TID 88)
2018-05-01 17:49:05.567  INFO 16044 --- [Executor task launch worker for task 88] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:05.567  INFO 16044 --- [Executor task launch worker for task 88] org.apache.spark.storage.BlockManager    : Found block rdd_70_0 locally
2018-05-01 17:49:05.599  INFO 16044 --- [Executor task launch worker for task 88] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 61.0 (TID 88). 1069 bytes result sent to driver
2018-05-01 17:49:05.599  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 61.0 (TID 88) in 34 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:05.599  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 61.0, whose tasks have all completed, from pool 
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 61 (flatMap at ALS.scala:1433) finished in 0.034 s
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 62)
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:05.600  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 62 (MapPartitionsRDD[81] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:05.601  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_22 stored as values in memory (estimated size 20.5 KB, free 1925.6 MB)
2018-05-01 17:49:05.603  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1925.6 MB)
2018-05-01 17:49:05.603  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_22_piece0 in memory on 172.21.241.193:58620 (size: 9.3 KB, free: 1925.7 MB)
2018-05-01 17:49:05.603  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:05.604  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[81] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:05.604  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 62.0 with 1 tasks
2018-05-01 17:49:05.604  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 62.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:05.604  INFO 16044 --- [Executor task launch worker for task 89] org.apache.spark.executor.Executor       : Running task 0.0 in stage 62.0 (TID 89)
2018-05-01 17:49:05.607  INFO 16044 --- [Executor task launch worker for task 89] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:05.607  INFO 16044 --- [Executor task launch worker for task 89] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:05.607  INFO 16044 --- [Executor task launch worker for task 89] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:05.998  INFO 16044 --- [Executor task launch worker for task 89] o.a.spark.storage.memory.MemoryStore     : Block rdd_80_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:49:06.000  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_80_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:49:06.003  INFO 16044 --- [Executor task launch worker for task 89] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 62.0 (TID 89). 2595 bytes result sent to driver
2018-05-01 17:49:06.003  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 62.0 (TID 89) in 399 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.003  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 62.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.004  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 62 (aggregate at ALS.scala:1491) finished in 0.400 s
2018-05-01 17:49:06.005  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 11 finished: aggregate at ALS.scala:1491, took 0.449342 s
2018-05-01 17:49:06.035  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 70 from persistence list
2018-05-01 17:49:06.035  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 70
2018-05-01 17:49:06.042  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:06.043  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:06.043  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:06.044  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:06.044  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:06.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:06.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:06.046  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:06.046  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:06.046  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 85 (flatMap at ALS.scala:1433)
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 12 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 74 (aggregate at ALS.scala:1491)
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 64, ShuffleMapStage 73)
2018-05-01 17:49:06.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 73)
2018-05-01 17:49:06.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 73 (MapPartitionsRDD[85] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:06.050  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_23 stored as values in memory (estimated size 19.6 KB, free 1925.9 MB)
2018-05-01 17:49:06.051  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.1 KB, free 1925.9 MB)
2018-05-01 17:49:06.053  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_23_piece0 in memory on 172.21.241.193:58620 (size: 9.1 KB, free: 1926.1 MB)
2018-05-01 17:49:06.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[85] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.053  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 73.0 with 1 tasks
2018-05-01 17:49:06.054  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 73.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:06.054  INFO 16044 --- [Executor task launch worker for task 90] org.apache.spark.executor.Executor       : Running task 0.0 in stage 73.0 (TID 90)
2018-05-01 17:49:06.057  INFO 16044 --- [Executor task launch worker for task 90] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:06.057  INFO 16044 --- [Executor task launch worker for task 90] org.apache.spark.storage.BlockManager    : Found block rdd_80_0 locally
2018-05-01 17:49:06.102  INFO 16044 --- [Executor task launch worker for task 90] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 73.0 (TID 90). 1069 bytes result sent to driver
2018-05-01 17:49:06.102  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 73.0 (TID 90) in 48 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.103  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 73.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 73 (flatMap at ALS.scala:1433) finished in 0.049 s
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 74)
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:06.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 74 (MapPartitionsRDD[91] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:06.105  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_24 stored as values in memory (estimated size 22.0 KB, free 1925.9 MB)
2018-05-01 17:49:06.107  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.9 KB, free 1925.9 MB)
2018-05-01 17:49:06.107  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_24_piece0 in memory on 172.21.241.193:58620 (size: 9.9 KB, free: 1926.1 MB)
2018-05-01 17:49:06.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[91] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.108  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 74.0 with 1 tasks
2018-05-01 17:49:06.109  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 74.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:06.109  INFO 16044 --- [Executor task launch worker for task 91] org.apache.spark.executor.Executor       : Running task 0.0 in stage 74.0 (TID 91)
2018-05-01 17:49:06.112  INFO 16044 --- [Executor task launch worker for task 91] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:06.112  INFO 16044 --- [Executor task launch worker for task 91] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:06.112  INFO 16044 --- [Executor task launch worker for task 91] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:06.408  INFO 16044 --- [Executor task launch worker for task 91] o.a.spark.storage.memory.MemoryStore     : Block rdd_90_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 17:49:06.409  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_90_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:49:06.413  INFO 16044 --- [Executor task launch worker for task 91] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 74.0 (TID 91). 2595 bytes result sent to driver
2018-05-01 17:49:06.413  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 74.0 (TID 91) in 305 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.413  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 74.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.414  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 74 (aggregate at ALS.scala:1491) finished in 0.306 s
2018-05-01 17:49:06.414  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 12 finished: aggregate at ALS.scala:1491, took 0.372140 s
2018-05-01 17:49:06.434  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 80 from persistence list
2018-05-01 17:49:06.435  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 80
2018-05-01 17:49:06.440  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:06.441  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:06.441  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:06.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:06.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:06.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:06.444  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:06.444  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:06.445  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:06.445  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 95 (flatMap at ALS.scala:1433)
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 13 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 87 (aggregate at ALS.scala:1491)
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 86, ShuffleMapStage 76)
2018-05-01 17:49:06.447  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 86)
2018-05-01 17:49:06.447  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 86 (MapPartitionsRDD[95] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:06.449  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_25 stored as values in memory (estimated size 21.1 KB, free 1925.5 MB)
2018-05-01 17:49:06.451  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1925.5 MB)
2018-05-01 17:49:06.451  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_25_piece0 in memory on 172.21.241.193:58620 (size: 9.7 KB, free: 1925.7 MB)
2018-05-01 17:49:06.451  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.452  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[95] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.452  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 86.0 with 1 tasks
2018-05-01 17:49:06.452  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 86.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:06.452  INFO 16044 --- [Executor task launch worker for task 92] org.apache.spark.executor.Executor       : Running task 0.0 in stage 86.0 (TID 92)
2018-05-01 17:49:06.454  INFO 16044 --- [Executor task launch worker for task 92] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:06.455  INFO 16044 --- [Executor task launch worker for task 92] org.apache.spark.storage.BlockManager    : Found block rdd_90_0 locally
2018-05-01 17:49:06.495  INFO 16044 --- [Executor task launch worker for task 92] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 86.0 (TID 92). 1069 bytes result sent to driver
2018-05-01 17:49:06.496  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 86.0 (TID 92) in 44 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.496  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 86.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 86 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 17:49:06.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:06.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:06.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 87)
2018-05-01 17:49:06.497  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:06.498  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 87 (MapPartitionsRDD[101] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:06.500  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_26 stored as values in memory (estimated size 23.6 KB, free 1925.4 MB)
2018-05-01 17:49:06.501  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_26_piece0 stored as bytes in memory (estimated size 10.6 KB, free 1925.4 MB)
2018-05-01 17:49:06.501  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_26_piece0 in memory on 172.21.241.193:58620 (size: 10.6 KB, free: 1925.7 MB)
2018-05-01 17:49:06.502  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.502  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[101] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.502  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 87.0 with 1 tasks
2018-05-01 17:49:06.502  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 87.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:06.503  INFO 16044 --- [Executor task launch worker for task 93] org.apache.spark.executor.Executor       : Running task 0.0 in stage 87.0 (TID 93)
2018-05-01 17:49:06.505  INFO 16044 --- [Executor task launch worker for task 93] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:06.505  INFO 16044 --- [Executor task launch worker for task 93] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:06.505  INFO 16044 --- [Executor task launch worker for task 93] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:06.775  INFO 16044 --- [Executor task launch worker for task 93] o.a.spark.storage.memory.MemoryStore     : Block rdd_100_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 17:49:06.775  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_100_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:49:06.777  INFO 16044 --- [Executor task launch worker for task 93] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 87.0 (TID 93). 2595 bytes result sent to driver
2018-05-01 17:49:06.778  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 87.0 (TID 93) in 276 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.778  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 87.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.778  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 87 (aggregate at ALS.scala:1491) finished in 0.276 s
2018-05-01 17:49:06.779  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 13 finished: aggregate at ALS.scala:1491, took 0.339223 s
2018-05-01 17:49:06.795  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 90 from persistence list
2018-05-01 17:49:06.795  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 90
2018-05-01 17:49:06.801  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:06.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:06.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:06.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:06.803  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:06.803  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:06.803  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:06.803  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:06.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:06.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:06.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:06.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:06.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:06.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 105 (flatMap at ALS.scala:1433)
2018-05-01 17:49:06.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 14 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:06.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 101 (aggregate at ALS.scala:1491)
2018-05-01 17:49:06.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 100, ShuffleMapStage 89)
2018-05-01 17:49:06.807  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 100)
2018-05-01 17:49:06.807  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 100 (MapPartitionsRDD[105] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:06.810  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_27 stored as values in memory (estimated size 22.7 KB, free 1925.8 MB)
2018-05-01 17:49:06.812  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_27_piece0 stored as bytes in memory (estimated size 10.4 KB, free 1925.8 MB)
2018-05-01 17:49:06.813  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_27_piece0 in memory on 172.21.241.193:58620 (size: 10.4 KB, free: 1926.0 MB)
2018-05-01 17:49:06.813  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.813  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[105] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.813  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 100.0 with 1 tasks
2018-05-01 17:49:06.814  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 100.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:06.814  INFO 16044 --- [Executor task launch worker for task 94] org.apache.spark.executor.Executor       : Running task 0.0 in stage 100.0 (TID 94)
2018-05-01 17:49:06.816  INFO 16044 --- [Executor task launch worker for task 94] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:06.816  INFO 16044 --- [Executor task launch worker for task 94] org.apache.spark.storage.BlockManager    : Found block rdd_100_0 locally
2018-05-01 17:49:06.860  INFO 16044 --- [Executor task launch worker for task 94] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 100.0 (TID 94). 1069 bytes result sent to driver
2018-05-01 17:49:06.860  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 100.0 (TID 94) in 46 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.860  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 100.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 100 (flatMap at ALS.scala:1433) finished in 0.047 s
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 101)
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 101 (MapPartitionsRDD[111] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:06.863  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_28 stored as values in memory (estimated size 25.1 KB, free 1925.8 MB)
2018-05-01 17:49:06.865  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.2 KB, free 1925.8 MB)
2018-05-01 17:49:06.865  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_28_piece0 in memory on 172.21.241.193:58620 (size: 11.2 KB, free: 1926.0 MB)
2018-05-01 17:49:06.865  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.865  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[111] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.866  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 101.0 with 1 tasks
2018-05-01 17:49:06.866  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 101.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:06.866  INFO 16044 --- [Executor task launch worker for task 95] org.apache.spark.executor.Executor       : Running task 0.0 in stage 101.0 (TID 95)
2018-05-01 17:49:06.868  INFO 16044 --- [Executor task launch worker for task 95] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:06.868  INFO 16044 --- [Executor task launch worker for task 95] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:06.868  INFO 16044 --- [Executor task launch worker for task 95] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:07.171  INFO 16044 --- [Executor task launch worker for task 95] o.a.spark.storage.memory.MemoryStore     : Block rdd_110_0 stored as values in memory (estimated size 820.5 KB, free 1925.0 MB)
2018-05-01 17:49:07.171  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_110_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:49:07.175  INFO 16044 --- [Executor task launch worker for task 95] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 101.0 (TID 95). 2595 bytes result sent to driver
2018-05-01 17:49:07.175  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 101.0 (TID 95) in 309 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.175  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 101.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.176  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 101 (aggregate at ALS.scala:1491) finished in 0.310 s
2018-05-01 17:49:07.176  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 14 finished: aggregate at ALS.scala:1491, took 0.374871 s
2018-05-01 17:49:07.192  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 100 from persistence list
2018-05-01 17:49:07.192  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 100
2018-05-01 17:49:07.198  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:07.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:07.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:07.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:07.201  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:07.201  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:07.201  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:07.201  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 115 (flatMap at ALS.scala:1433)
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 15 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 116 (aggregate at ALS.scala:1491)
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 103, ShuffleMapStage 115)
2018-05-01 17:49:07.203  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 115)
2018-05-01 17:49:07.204  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 115 (MapPartitionsRDD[115] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:07.205  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_29 stored as values in memory (estimated size 24.2 KB, free 1925.3 MB)
2018-05-01 17:49:07.206  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.0 KB, free 1925.3 MB)
2018-05-01 17:49:07.207  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_29_piece0 in memory on 172.21.241.193:58620 (size: 11.0 KB, free: 1925.6 MB)
2018-05-01 17:49:07.207  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[115] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.208  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 115.0 with 1 tasks
2018-05-01 17:49:07.208  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 115.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:07.208  INFO 16044 --- [Executor task launch worker for task 96] org.apache.spark.executor.Executor       : Running task 0.0 in stage 115.0 (TID 96)
2018-05-01 17:49:07.210  INFO 16044 --- [Executor task launch worker for task 96] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:07.210  INFO 16044 --- [Executor task launch worker for task 96] org.apache.spark.storage.BlockManager    : Found block rdd_110_0 locally
2018-05-01 17:49:07.248  INFO 16044 --- [Executor task launch worker for task 96] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 115.0 (TID 96). 1069 bytes result sent to driver
2018-05-01 17:49:07.248  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 115.0 (TID 96) in 40 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.248  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 115.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 115 (flatMap at ALS.scala:1433) finished in 0.040 s
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 116)
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:07.249  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 116 (MapPartitionsRDD[121] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:07.250  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_30 stored as values in memory (estimated size 26.7 KB, free 1925.3 MB)
2018-05-01 17:49:07.251  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1925.3 MB)
2018-05-01 17:49:07.251  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_30_piece0 in memory on 172.21.241.193:58620 (size: 11.9 KB, free: 1925.6 MB)
2018-05-01 17:49:07.252  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.252  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[121] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.252  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 116.0 with 1 tasks
2018-05-01 17:49:07.253  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 116.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:07.253  INFO 16044 --- [Executor task launch worker for task 97] org.apache.spark.executor.Executor       : Running task 0.0 in stage 116.0 (TID 97)
2018-05-01 17:49:07.256  INFO 16044 --- [Executor task launch worker for task 97] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:07.256  INFO 16044 --- [Executor task launch worker for task 97] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:07.257  INFO 16044 --- [Executor task launch worker for task 97] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:49:07.546  INFO 16044 --- [Executor task launch worker for task 97] o.a.spark.storage.memory.MemoryStore     : Block rdd_120_0 stored as values in memory (estimated size 416.2 KB, free 1924.9 MB)
2018-05-01 17:49:07.547  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_120_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:49:07.548  INFO 16044 --- [Executor task launch worker for task 97] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 116.0 (TID 97). 2595 bytes result sent to driver
2018-05-01 17:49:07.549  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 116.0 (TID 97) in 296 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.549  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 116.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.549  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 116 (aggregate at ALS.scala:1491) finished in 0.297 s
2018-05-01 17:49:07.550  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 15 finished: aggregate at ALS.scala:1491, took 0.351506 s
2018-05-01 17:49:07.570  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 110 from persistence list
2018-05-01 17:49:07.570  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 110
2018-05-01 17:49:07.575  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:07.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:07.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:07.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:07.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:07.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 125 (flatMap at ALS.scala:1433)
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 16 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 132 (aggregate at ALS.scala:1491)
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 118, ShuffleMapStage 131)
2018-05-01 17:49:07.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 131)
2018-05-01 17:49:07.582  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 131 (MapPartitionsRDD[125] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:07.584  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_31 stored as values in memory (estimated size 25.8 KB, free 1925.7 MB)
2018-05-01 17:49:07.586  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_31_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1925.7 MB)
2018-05-01 17:49:07.586  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_31_piece0 in memory on 172.21.241.193:58620 (size: 11.7 KB, free: 1926.0 MB)
2018-05-01 17:49:07.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[125] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.588  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 131.0 with 1 tasks
2018-05-01 17:49:07.588  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 131.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:07.588  INFO 16044 --- [Executor task launch worker for task 98] org.apache.spark.executor.Executor       : Running task 0.0 in stage 131.0 (TID 98)
2018-05-01 17:49:07.591  INFO 16044 --- [Executor task launch worker for task 98] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:07.591  INFO 16044 --- [Executor task launch worker for task 98] org.apache.spark.storage.BlockManager    : Found block rdd_120_0 locally
2018-05-01 17:49:07.618  INFO 16044 --- [Executor task launch worker for task 98] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 131.0 (TID 98). 1112 bytes result sent to driver
2018-05-01 17:49:07.619  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 131.0 (TID 98) in 31 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.619  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 131.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 131 (flatMap at ALS.scala:1433) finished in 0.031 s
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 132)
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:07.620  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 132 (MapPartitionsRDD[131] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:07.622  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_32 stored as values in memory (estimated size 28.2 KB, free 1925.6 MB)
2018-05-01 17:49:07.623  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_32_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1925.6 MB)
2018-05-01 17:49:07.623  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_32_piece0 in memory on 172.21.241.193:58620 (size: 12.5 KB, free: 1926.0 MB)
2018-05-01 17:49:07.624  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.624  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[131] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.624  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 132.0 with 1 tasks
2018-05-01 17:49:07.624  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 132.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:07.625  INFO 16044 --- [Executor task launch worker for task 99] org.apache.spark.executor.Executor       : Running task 0.0 in stage 132.0 (TID 99)
2018-05-01 17:49:07.627  INFO 16044 --- [Executor task launch worker for task 99] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:07.627  INFO 16044 --- [Executor task launch worker for task 99] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:07.627  INFO 16044 --- [Executor task launch worker for task 99] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:07.918  INFO 16044 --- [Executor task launch worker for task 99] o.a.spark.storage.memory.MemoryStore     : Block rdd_130_0 stored as values in memory (estimated size 820.5 KB, free 1924.8 MB)
2018-05-01 17:49:07.918  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_130_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:49:07.922  INFO 16044 --- [Executor task launch worker for task 99] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 132.0 (TID 99). 2595 bytes result sent to driver
2018-05-01 17:49:07.922  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 132.0 (TID 99) in 298 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.922  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 132.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.923  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 132 (aggregate at ALS.scala:1491) finished in 0.299 s
2018-05-01 17:49:07.923  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 16 finished: aggregate at ALS.scala:1491, took 0.347837 s
2018-05-01 17:49:07.941  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 120 from persistence list
2018-05-01 17:49:07.941  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 120
2018-05-01 17:49:07.946  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:07.947  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:07.947  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 135 (flatMap at ALS.scala:1433)
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 17 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 149 (aggregate at ALS.scala:1491)
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 148, ShuffleMapStage 134)
2018-05-01 17:49:07.952  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 148)
2018-05-01 17:49:07.952  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 148 (MapPartitionsRDD[135] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:07.954  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_33 stored as values in memory (estimated size 27.3 KB, free 1925.2 MB)
2018-05-01 17:49:07.955  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_33_piece0 stored as bytes in memory (estimated size 12.4 KB, free 1925.2 MB)
2018-05-01 17:49:07.956  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_33_piece0 in memory on 172.21.241.193:58620 (size: 12.4 KB, free: 1925.6 MB)
2018-05-01 17:49:07.956  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.957  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[135] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.957  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 148.0 with 1 tasks
2018-05-01 17:49:07.958  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 148.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:07.958  INFO 16044 --- [Executor task launch worker for task 100] org.apache.spark.executor.Executor       : Running task 0.0 in stage 148.0 (TID 100)
2018-05-01 17:49:07.960  INFO 16044 --- [Executor task launch worker for task 100] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:07.961  INFO 16044 --- [Executor task launch worker for task 100] org.apache.spark.storage.BlockManager    : Found block rdd_130_0 locally
2018-05-01 17:49:08.010  INFO 16044 --- [Executor task launch worker for task 100] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 148.0 (TID 100). 1069 bytes result sent to driver
2018-05-01 17:49:08.010  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 148.0 (TID 100) in 52 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.010  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 148.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 148 (flatMap at ALS.scala:1433) finished in 0.053 s
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 149)
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 149 (MapPartitionsRDD[141] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:08.014  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_34 stored as values in memory (estimated size 29.8 KB, free 1925.2 MB)
2018-05-01 17:49:08.015  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_34_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1925.1 MB)
2018-05-01 17:49:08.016  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_34_piece0 in memory on 172.21.241.193:58620 (size: 13.3 KB, free: 1925.6 MB)
2018-05-01 17:49:08.016  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.016  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[141] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.016  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 149.0 with 1 tasks
2018-05-01 17:49:08.017  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 149.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:08.017  INFO 16044 --- [Executor task launch worker for task 101] org.apache.spark.executor.Executor       : Running task 0.0 in stage 149.0 (TID 101)
2018-05-01 17:49:08.020  INFO 16044 --- [Executor task launch worker for task 101] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:08.020  INFO 16044 --- [Executor task launch worker for task 101] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:08.020  INFO 16044 --- [Executor task launch worker for task 101] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:08.313  INFO 16044 --- [Executor task launch worker for task 101] o.a.spark.storage.memory.MemoryStore     : Block rdd_140_0 stored as values in memory (estimated size 416.2 KB, free 1924.7 MB)
2018-05-01 17:49:08.314  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_140_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:49:08.316  INFO 16044 --- [Executor task launch worker for task 101] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 149.0 (TID 101). 2595 bytes result sent to driver
2018-05-01 17:49:08.316  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 149.0 (TID 101) in 300 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.316  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 149.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.316  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 149 (aggregate at ALS.scala:1491) finished in 0.300 s
2018-05-01 17:49:08.317  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 17 finished: aggregate at ALS.scala:1491, took 0.370103 s
2018-05-01 17:49:08.335  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 130 from persistence list
2018-05-01 17:49:08.335  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 130
2018-05-01 17:49:08.341  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:08.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:08.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:08.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:08.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:08.344  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:08.344  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:08.344  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:08.345  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:08.345  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:08.345  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 145 (flatMap at ALS.scala:1433)
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 18 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 167 (aggregate at ALS.scala:1491)
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 151, ShuffleMapStage 166)
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 166)
2018-05-01 17:49:08.347  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 166 (MapPartitionsRDD[145] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:08.349  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_35 stored as values in memory (estimated size 28.9 KB, free 1925.5 MB)
2018-05-01 17:49:08.349  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_35_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1925.5 MB)
2018-05-01 17:49:08.350  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_35_piece0 in memory on 172.21.241.193:58620 (size: 13.0 KB, free: 1925.9 MB)
2018-05-01 17:49:08.350  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.350  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[145] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.350  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 166.0 with 1 tasks
2018-05-01 17:49:08.351  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 166.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:08.351  INFO 16044 --- [Executor task launch worker for task 102] org.apache.spark.executor.Executor       : Running task 0.0 in stage 166.0 (TID 102)
2018-05-01 17:49:08.354  INFO 16044 --- [Executor task launch worker for task 102] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:08.354  INFO 16044 --- [Executor task launch worker for task 102] org.apache.spark.storage.BlockManager    : Found block rdd_140_0 locally
2018-05-01 17:49:08.383  INFO 16044 --- [Executor task launch worker for task 102] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 166.0 (TID 102). 1069 bytes result sent to driver
2018-05-01 17:49:08.383  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 166.0 (TID 102) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.383  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 166.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 166 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 167)
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:08.384  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 167 (MapPartitionsRDD[151] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:08.386  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_36 stored as values in memory (estimated size 31.3 KB, free 1925.5 MB)
2018-05-01 17:49:08.387  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_36_piece0 stored as bytes in memory (estimated size 13.9 KB, free 1925.4 MB)
2018-05-01 17:49:08.387  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_36_piece0 in memory on 172.21.241.193:58620 (size: 13.9 KB, free: 1925.9 MB)
2018-05-01 17:49:08.388  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.388  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[151] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.388  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 167.0 with 1 tasks
2018-05-01 17:49:08.389  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 167.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:08.389  INFO 16044 --- [Executor task launch worker for task 103] org.apache.spark.executor.Executor       : Running task 0.0 in stage 167.0 (TID 103)
2018-05-01 17:49:08.391  INFO 16044 --- [Executor task launch worker for task 103] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:08.391  INFO 16044 --- [Executor task launch worker for task 103] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:08.391  INFO 16044 --- [Executor task launch worker for task 103] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:08.690  INFO 16044 --- [Executor task launch worker for task 103] o.a.spark.storage.memory.MemoryStore     : Block rdd_150_0 stored as values in memory (estimated size 820.5 KB, free 1924.6 MB)
2018-05-01 17:49:08.691  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_150_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:49:08.696  INFO 16044 --- [Executor task launch worker for task 103] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 167.0 (TID 103). 2595 bytes result sent to driver
2018-05-01 17:49:08.696  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 167.0 (TID 103) in 307 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.696  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 167.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.696  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 167 (aggregate at ALS.scala:1491) finished in 0.307 s
2018-05-01 17:49:08.697  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 18 finished: aggregate at ALS.scala:1491, took 0.355612 s
2018-05-01 17:49:08.718  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 140 from persistence list
2018-05-01 17:49:08.718  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 140
2018-05-01 17:49:08.724  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:08.725  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:08.725  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:08.725  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:08.726  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:08.726  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:08.726  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:08.726  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:08.728  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:08.728  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:08.728  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:08.728  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 155 (flatMap at ALS.scala:1433)
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 19 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 186 (aggregate at ALS.scala:1491)
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 169, ShuffleMapStage 185)
2018-05-01 17:49:08.730  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 185)
2018-05-01 17:49:08.730  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 185 (MapPartitionsRDD[155] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:08.733  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_37 stored as values in memory (estimated size 30.4 KB, free 1925.0 MB)
2018-05-01 17:49:08.734  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_37_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1925.0 MB)
2018-05-01 17:49:08.734  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_37_piece0 in memory on 172.21.241.193:58620 (size: 13.6 KB, free: 1925.5 MB)
2018-05-01 17:49:08.735  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.735  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 185 (MapPartitionsRDD[155] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.735  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 185.0 with 1 tasks
2018-05-01 17:49:08.735  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 185.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:08.735  INFO 16044 --- [Executor task launch worker for task 104] org.apache.spark.executor.Executor       : Running task 0.0 in stage 185.0 (TID 104)
2018-05-01 17:49:08.737  INFO 16044 --- [Executor task launch worker for task 104] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:08.738  INFO 16044 --- [Executor task launch worker for task 104] org.apache.spark.storage.BlockManager    : Found block rdd_150_0 locally
2018-05-01 17:49:08.779  INFO 16044 --- [Executor task launch worker for task 104] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 185.0 (TID 104). 1069 bytes result sent to driver
2018-05-01 17:49:08.779  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 185.0 (TID 104) in 44 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.779  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 185.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 185 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 186)
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 186 (MapPartitionsRDD[161] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:08.783  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_38 stored as values in memory (estimated size 32.9 KB, free 1925.0 MB)
2018-05-01 17:49:08.785  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_38_piece0 stored as bytes in memory (estimated size 14.7 KB, free 1925.0 MB)
2018-05-01 17:49:08.785  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_38_piece0 in memory on 172.21.241.193:58620 (size: 14.7 KB, free: 1925.5 MB)
2018-05-01 17:49:08.785  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.786  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[161] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.786  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 186.0 with 1 tasks
2018-05-01 17:49:08.786  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 186.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:08.786  INFO 16044 --- [Executor task launch worker for task 105] org.apache.spark.executor.Executor       : Running task 0.0 in stage 186.0 (TID 105)
2018-05-01 17:49:08.790  INFO 16044 --- [Executor task launch worker for task 105] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:08.790  INFO 16044 --- [Executor task launch worker for task 105] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:08.790  INFO 16044 --- [Executor task launch worker for task 105] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:09.085  INFO 16044 --- [Executor task launch worker for task 105] o.a.spark.storage.memory.MemoryStore     : Block rdd_160_0 stored as values in memory (estimated size 416.2 KB, free 1924.6 MB)
2018-05-01 17:49:09.085  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_160_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 17:49:09.087  INFO 16044 --- [Executor task launch worker for task 105] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 186.0 (TID 105). 2595 bytes result sent to driver
2018-05-01 17:49:09.088  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 186.0 (TID 105) in 302 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.088  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 186.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 186 (aggregate at ALS.scala:1491) finished in 0.302 s
2018-05-01 17:49:09.088  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 19 finished: aggregate at ALS.scala:1491, took 0.364357 s
2018-05-01 17:49:09.108  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 150 from persistence list
2018-05-01 17:49:09.109  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 150
2018-05-01 17:49:09.114  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:09.114  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:09.115  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:09.115  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:09.115  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:09.118  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:09.118  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:09.118  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 165 (flatMap at ALS.scala:1433)
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 20 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 206 (aggregate at ALS.scala:1491)
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 205, ShuffleMapStage 188)
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 205)
2018-05-01 17:49:09.120  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 205 (MapPartitionsRDD[165] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:09.122  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_39 stored as values in memory (estimated size 32.0 KB, free 1925.3 MB)
2018-05-01 17:49:09.123  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_39_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1925.3 MB)
2018-05-01 17:49:09.123  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_39_piece0 in memory on 172.21.241.193:58620 (size: 14.4 KB, free: 1925.9 MB)
2018-05-01 17:49:09.123  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.123  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 205 (MapPartitionsRDD[165] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.123  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 205.0 with 1 tasks
2018-05-01 17:49:09.124  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 205.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:09.124  INFO 16044 --- [Executor task launch worker for task 106] org.apache.spark.executor.Executor       : Running task 0.0 in stage 205.0 (TID 106)
2018-05-01 17:49:09.127  INFO 16044 --- [Executor task launch worker for task 106] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:09.128  INFO 16044 --- [Executor task launch worker for task 106] org.apache.spark.storage.BlockManager    : Found block rdd_160_0 locally
2018-05-01 17:49:09.158  INFO 16044 --- [Executor task launch worker for task 106] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 205.0 (TID 106). 1069 bytes result sent to driver
2018-05-01 17:49:09.159  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 205.0 (TID 106) in 34 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.159  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 205.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 205 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 206)
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:09.160  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 206 (MapPartitionsRDD[171] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:09.163  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_40 stored as values in memory (estimated size 34.4 KB, free 1925.3 MB)
2018-05-01 17:49:09.164  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_40_piece0 stored as bytes in memory (estimated size 15.5 KB, free 1925.3 MB)
2018-05-01 17:49:09.164  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_40_piece0 in memory on 172.21.241.193:58620 (size: 15.5 KB, free: 1925.9 MB)
2018-05-01 17:49:09.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 206 (MapPartitionsRDD[171] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.165  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 206.0 with 1 tasks
2018-05-01 17:49:09.166  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 206.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:09.166  INFO 16044 --- [Executor task launch worker for task 107] org.apache.spark.executor.Executor       : Running task 0.0 in stage 206.0 (TID 107)
2018-05-01 17:49:09.169  INFO 16044 --- [Executor task launch worker for task 107] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:09.170  INFO 16044 --- [Executor task launch worker for task 107] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:09.170  INFO 16044 --- [Executor task launch worker for task 107] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:49:09.483  INFO 16044 --- [Executor task launch worker for task 107] o.a.spark.storage.memory.MemoryStore     : Block rdd_170_0 stored as values in memory (estimated size 820.5 KB, free 1924.5 MB)
2018-05-01 17:49:09.484  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_170_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:49:09.487  INFO 16044 --- [Executor task launch worker for task 107] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 206.0 (TID 107). 2638 bytes result sent to driver
2018-05-01 17:49:09.487  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 206.0 (TID 107) in 322 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.488  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 206.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.488  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 206 (aggregate at ALS.scala:1491) finished in 0.323 s
2018-05-01 17:49:09.488  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 20 finished: aggregate at ALS.scala:1491, took 0.374356 s
2018-05-01 17:49:09.508  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 160 from persistence list
2018-05-01 17:49:09.509  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 160
2018-05-01 17:49:09.514  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:09.514  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:09.515  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:09.515  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:09.515  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:09.515  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:09.516  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:09.516  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:09.516  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:09.516  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:09.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:09.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:09.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:09.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:09.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:09.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:09.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:09.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 175 (flatMap at ALS.scala:1433)
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 21 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 227 (aggregate at ALS.scala:1491)
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 208, ShuffleMapStage 226)
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 226)
2018-05-01 17:49:09.520  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 226 (MapPartitionsRDD[175] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:09.522  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_41 stored as values in memory (estimated size 33.5 KB, free 1924.8 MB)
2018-05-01 17:49:09.523  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_41_piece0 stored as bytes in memory (estimated size 15.2 KB, free 1924.8 MB)
2018-05-01 17:49:09.523  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_41_piece0 in memory on 172.21.241.193:58620 (size: 15.2 KB, free: 1925.5 MB)
2018-05-01 17:49:09.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 226 (MapPartitionsRDD[175] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.523  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 226.0 with 1 tasks
2018-05-01 17:49:09.524  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 226.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:09.524  INFO 16044 --- [Executor task launch worker for task 108] org.apache.spark.executor.Executor       : Running task 0.0 in stage 226.0 (TID 108)
2018-05-01 17:49:09.528  INFO 16044 --- [Executor task launch worker for task 108] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:09.528  INFO 16044 --- [Executor task launch worker for task 108] org.apache.spark.storage.BlockManager    : Found block rdd_170_0 locally
2018-05-01 17:49:09.565  INFO 16044 --- [Executor task launch worker for task 108] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 226.0 (TID 108). 1155 bytes result sent to driver
2018-05-01 17:49:09.565  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 226.0 (TID 108) in 41 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.565  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 226.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 226 (flatMap at ALS.scala:1433) finished in 0.041 s
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 227)
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 227 (MapPartitionsRDD[181] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:09.569  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_42 stored as values in memory (estimated size 36.0 KB, free 1924.8 MB)
2018-05-01 17:49:09.570  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_42_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1924.8 MB)
2018-05-01 17:49:09.571  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_42_piece0 in memory on 172.21.241.193:58620 (size: 16.4 KB, free: 1925.5 MB)
2018-05-01 17:49:09.571  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.571  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[181] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.571  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 227.0 with 1 tasks
2018-05-01 17:49:09.572  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 227.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:09.572  INFO 16044 --- [Executor task launch worker for task 109] org.apache.spark.executor.Executor       : Running task 0.0 in stage 227.0 (TID 109)
2018-05-01 17:49:09.576  INFO 16044 --- [Executor task launch worker for task 109] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:09.576  INFO 16044 --- [Executor task launch worker for task 109] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:09.576  INFO 16044 --- [Executor task launch worker for task 109] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:09.943  INFO 16044 --- [Executor task launch worker for task 109] o.a.spark.storage.memory.MemoryStore     : Block rdd_180_0 stored as values in memory (estimated size 416.2 KB, free 1924.4 MB)
2018-05-01 17:49:09.943  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_180_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.0 MB)
2018-05-01 17:49:09.947  INFO 16044 --- [Executor task launch worker for task 109] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 227.0 (TID 109). 2638 bytes result sent to driver
2018-05-01 17:49:09.947  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 227.0 (TID 109) in 375 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.947  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 227.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 227 (aggregate at ALS.scala:1491) finished in 0.377 s
2018-05-01 17:49:09.948  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 21 finished: aggregate at ALS.scala:1491, took 0.434254 s
2018-05-01 17:49:09.974  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 170 from persistence list
2018-05-01 17:49:09.974  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 170
2018-05-01 17:49:09.982  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:09.983  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:09.983  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:09.984  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:09.984  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:09.984  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:09.985  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:09.985  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:09.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:09.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:09.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:09.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:09.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:09.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:09.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:09.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:09.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:09.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:09.989  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:09.989  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:09.989  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 185 (flatMap at ALS.scala:1433)
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 22 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 249 (aggregate at ALS.scala:1491)
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 248, ShuffleMapStage 229)
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 248)
2018-05-01 17:49:09.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 248 (MapPartitionsRDD[185] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:09.993  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_43 stored as values in memory (estimated size 35.1 KB, free 1925.1 MB)
2018-05-01 17:49:09.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_43_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1925.1 MB)
2018-05-01 17:49:09.994  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_43_piece0 in memory on 172.21.241.193:58620 (size: 16.0 KB, free: 1925.8 MB)
2018-05-01 17:49:09.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 248 (MapPartitionsRDD[185] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 248.0 with 1 tasks
2018-05-01 17:49:09.996  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 248.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:09.996  INFO 16044 --- [Executor task launch worker for task 110] org.apache.spark.executor.Executor       : Running task 0.0 in stage 248.0 (TID 110)
2018-05-01 17:49:09.999  INFO 16044 --- [Executor task launch worker for task 110] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:09.999  INFO 16044 --- [Executor task launch worker for task 110] org.apache.spark.storage.BlockManager    : Found block rdd_180_0 locally
2018-05-01 17:49:10.031  INFO 16044 --- [Executor task launch worker for task 110] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 248.0 (TID 110). 1069 bytes result sent to driver
2018-05-01 17:49:10.032  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 248.0 (TID 110) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:10.032  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 248.0, whose tasks have all completed, from pool 
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 248 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 249)
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 249 (MapPartitionsRDD[191] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:10.035  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_44 stored as values in memory (estimated size 37.5 KB, free 1925.1 MB)
2018-05-01 17:49:10.037  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.8 KB, free 1925.1 MB)
2018-05-01 17:49:10.037  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_44_piece0 in memory on 172.21.241.193:58620 (size: 16.8 KB, free: 1925.8 MB)
2018-05-01 17:49:10.037  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:10.037  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 249 (MapPartitionsRDD[191] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:10.038  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 249.0 with 1 tasks
2018-05-01 17:49:10.038  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 249.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:10.038  INFO 16044 --- [Executor task launch worker for task 111] org.apache.spark.executor.Executor       : Running task 0.0 in stage 249.0 (TID 111)
2018-05-01 17:49:10.041  INFO 16044 --- [Executor task launch worker for task 111] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:10.041  INFO 16044 --- [Executor task launch worker for task 111] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:10.041  INFO 16044 --- [Executor task launch worker for task 111] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:10.440  INFO 16044 --- [Executor task launch worker for task 111] o.a.spark.storage.memory.MemoryStore     : Block rdd_190_0 stored as values in memory (estimated size 820.5 KB, free 1924.3 MB)
2018-05-01 17:49:10.441  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_190_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.0 MB)
2018-05-01 17:49:10.447  INFO 16044 --- [Executor task launch worker for task 111] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 249.0 (TID 111). 2595 bytes result sent to driver
2018-05-01 17:49:10.447  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 249.0 (TID 111) in 409 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:10.447  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 249.0, whose tasks have all completed, from pool 
2018-05-01 17:49:10.447  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 249 (aggregate at ALS.scala:1491) finished in 0.409 s
2018-05-01 17:49:10.448  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 22 finished: aggregate at ALS.scala:1491, took 0.465869 s
2018-05-01 17:49:10.470  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 180 from persistence list
2018-05-01 17:49:10.470  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 180
2018-05-01 17:49:10.476  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:10.477  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:10.477  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:10.477  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:10.478  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:10.478  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:10.478  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:10.478  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:10.479  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:10.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:10.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:10.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:10.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:10.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:10.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:10.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:10.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:10.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:10.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:10.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:10.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:10.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:49:10.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 195 (flatMap at ALS.scala:1433)
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 23 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 272 (aggregate at ALS.scala:1491)
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 251, ShuffleMapStage 271)
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 271)
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 271 (MapPartitionsRDD[195] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:10.584  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_45 stored as values in memory (estimated size 36.6 KB, free 1924.6 MB)
2018-05-01 17:49:10.586  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_45_piece0 stored as bytes in memory (estimated size 16.5 KB, free 1924.6 MB)
2018-05-01 17:49:10.586  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_45_piece0 in memory on 172.21.241.193:58620 (size: 16.5 KB, free: 1925.4 MB)
2018-05-01 17:49:10.587  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:10.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 271 (MapPartitionsRDD[195] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:10.588  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 271.0 with 1 tasks
2018-05-01 17:49:10.588  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 271.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:10.588  INFO 16044 --- [Executor task launch worker for task 112] org.apache.spark.executor.Executor       : Running task 0.0 in stage 271.0 (TID 112)
2018-05-01 17:49:10.590  INFO 16044 --- [Executor task launch worker for task 112] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:10.590  INFO 16044 --- [Executor task launch worker for task 112] org.apache.spark.storage.BlockManager    : Found block rdd_190_0 locally
2018-05-01 17:49:10.639  INFO 16044 --- [Executor task launch worker for task 112] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 271.0 (TID 112). 1112 bytes result sent to driver
2018-05-01 17:49:10.643  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 271.0 (TID 112) in 55 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:10.644  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 271.0, whose tasks have all completed, from pool 
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 271 (flatMap at ALS.scala:1433) finished in 0.056 s
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 272)
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:10.645  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 272 (MapPartitionsRDD[201] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:10.649  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_46 stored as values in memory (estimated size 39.1 KB, free 1924.6 MB)
2018-05-01 17:49:10.651  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_46_piece0 stored as bytes in memory (estimated size 17.6 KB, free 1924.6 MB)
2018-05-01 17:49:10.652  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_46_piece0 in memory on 172.21.241.193:58620 (size: 17.6 KB, free: 1925.4 MB)
2018-05-01 17:49:10.652  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:10.653  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[201] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:10.653  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 272.0 with 1 tasks
2018-05-01 17:49:10.654  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 272.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:10.655  INFO 16044 --- [Executor task launch worker for task 113] org.apache.spark.executor.Executor       : Running task 0.0 in stage 272.0 (TID 113)
2018-05-01 17:49:10.659  INFO 16044 --- [Executor task launch worker for task 113] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:10.659  INFO 16044 --- [Executor task launch worker for task 113] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:10.659  INFO 16044 --- [Executor task launch worker for task 113] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:11.052  INFO 16044 --- [Executor task launch worker for task 113] o.a.spark.storage.memory.MemoryStore     : Block rdd_200_0 stored as values in memory (estimated size 416.2 KB, free 1924.2 MB)
2018-05-01 17:49:11.053  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_200_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.0 MB)
2018-05-01 17:49:11.055  INFO 16044 --- [Executor task launch worker for task 113] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 272.0 (TID 113). 2595 bytes result sent to driver
2018-05-01 17:49:11.055  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 272.0 (TID 113) in 401 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:11.056  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 272.0, whose tasks have all completed, from pool 
2018-05-01 17:49:11.056  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 272 (aggregate at ALS.scala:1491) finished in 0.402 s
2018-05-01 17:49:11.056  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 23 finished: aggregate at ALS.scala:1491, took 0.580191 s
2018-05-01 17:49:11.079  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 190 from persistence list
2018-05-01 17:49:11.079  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 190
2018-05-01 17:49:11.085  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:11.086  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:11.086  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:11.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:11.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:11.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:11.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:11.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:11.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:11.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:11.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:11.090  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:11.090  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:11.090  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:11.091  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:11.091  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:11.091  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:49:11.091  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 205 (flatMap at ALS.scala:1433)
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 24 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 296 (aggregate at ALS.scala:1491)
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 274, ShuffleMapStage 295)
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 295)
2018-05-01 17:49:11.094  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 295 (MapPartitionsRDD[205] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:11.096  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_47 stored as values in memory (estimated size 38.2 KB, free 1924.9 MB)
2018-05-01 17:49:11.098  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_47_piece0 stored as bytes in memory (estimated size 17.3 KB, free 1924.9 MB)
2018-05-01 17:49:11.098  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_47_piece0 in memory on 172.21.241.193:58620 (size: 17.3 KB, free: 1925.8 MB)
2018-05-01 17:49:11.098  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:11.099  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 295 (MapPartitionsRDD[205] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:11.099  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 295.0 with 1 tasks
2018-05-01 17:49:11.099  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 295.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:11.100  INFO 16044 --- [Executor task launch worker for task 114] org.apache.spark.executor.Executor       : Running task 0.0 in stage 295.0 (TID 114)
2018-05-01 17:49:11.102  INFO 16044 --- [Executor task launch worker for task 114] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:11.103  INFO 16044 --- [Executor task launch worker for task 114] org.apache.spark.storage.BlockManager    : Found block rdd_200_0 locally
2018-05-01 17:49:11.134  INFO 16044 --- [Executor task launch worker for task 114] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 295.0 (TID 114). 1069 bytes result sent to driver
2018-05-01 17:49:11.135  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 295.0 (TID 114) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:11.135  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 295.0, whose tasks have all completed, from pool 
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 295 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 296)
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:11.136  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 296 (MapPartitionsRDD[211] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:11.138  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_48 stored as values in memory (estimated size 40.6 KB, free 1924.9 MB)
2018-05-01 17:49:11.140  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_48_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1924.8 MB)
2018-05-01 17:49:11.140  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_48_piece0 in memory on 172.21.241.193:58620 (size: 18.2 KB, free: 1925.7 MB)
2018-05-01 17:49:11.140  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:11.140  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 296 (MapPartitionsRDD[211] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:11.140  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 296.0 with 1 tasks
2018-05-01 17:49:11.141  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 296.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:11.141  INFO 16044 --- [Executor task launch worker for task 115] org.apache.spark.executor.Executor       : Running task 0.0 in stage 296.0 (TID 115)
2018-05-01 17:49:11.144  INFO 16044 --- [Executor task launch worker for task 115] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:11.144  INFO 16044 --- [Executor task launch worker for task 115] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:11.144  INFO 16044 --- [Executor task launch worker for task 115] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:11.594  INFO 16044 --- [Executor task launch worker for task 115] o.a.spark.storage.memory.MemoryStore     : Block rdd_210_0 stored as values in memory (estimated size 820.5 KB, free 1924.0 MB)
2018-05-01 17:49:11.594  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_210_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1924.9 MB)
2018-05-01 17:49:11.600  INFO 16044 --- [Executor task launch worker for task 115] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 296.0 (TID 115). 2595 bytes result sent to driver
2018-05-01 17:49:11.601  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 296.0 (TID 115) in 459 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:11.601  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 296.0, whose tasks have all completed, from pool 
2018-05-01 17:49:11.601  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 296 (aggregate at ALS.scala:1491) finished in 0.460 s
2018-05-01 17:49:11.602  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 24 finished: aggregate at ALS.scala:1491, took 0.516182 s
2018-05-01 17:49:11.629  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 200 from persistence list
2018-05-01 17:49:11.630  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 200
2018-05-01 17:49:11.673  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:279
2018-05-01 17:49:11.674  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:11.674  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:11.675  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:11.675  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:11.675  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:11.676  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:11.676  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:11.676  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:11.677  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:11.677  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:11.677  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:11.678  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:11.678  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:11.679  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:11.679  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:11.680  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:11.681  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:11.682  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:11.682  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:11.682  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:11.682  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:49:11.683  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:49:11.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 22 is 150 bytes
2018-05-01 17:49:11.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 215 (flatMap at ALS.scala:1433)
2018-05-01 17:49:11.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 25 (count at ALS.scala:279) with 1 output partitions
2018-05-01 17:49:11.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 321 (count at ALS.scala:279)
2018-05-01 17:49:11.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 320, ShuffleMapStage 298)
2018-05-01 17:49:11.686  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 320)
2018-05-01 17:49:11.686  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 320 (MapPartitionsRDD[215] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:11.690  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_49 stored as values in memory (estimated size 39.7 KB, free 1924.4 MB)
2018-05-01 17:49:11.692  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_49_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1924.4 MB)
2018-05-01 17:49:11.692  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_49_piece0 in memory on 172.21.241.193:58620 (size: 18.0 KB, free: 1925.3 MB)
2018-05-01 17:49:11.692  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:11.693  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 320 (MapPartitionsRDD[215] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:11.693  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 320.0 with 1 tasks
2018-05-01 17:49:11.693  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 320.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:11.693  INFO 16044 --- [Executor task launch worker for task 116] org.apache.spark.executor.Executor       : Running task 0.0 in stage 320.0 (TID 116)
2018-05-01 17:49:11.698  INFO 16044 --- [Executor task launch worker for task 116] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:11.699  INFO 16044 --- [Executor task launch worker for task 116] org.apache.spark.storage.BlockManager    : Found block rdd_210_0 locally
2018-05-01 17:49:11.739  INFO 16044 --- [Executor task launch worker for task 116] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 320.0 (TID 116). 1112 bytes result sent to driver
2018-05-01 17:49:11.739  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 320.0 (TID 116) in 46 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:11.740  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 320.0, whose tasks have all completed, from pool 
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 320 (flatMap at ALS.scala:1433) finished in 0.047 s
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 321)
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 321 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:49:11.743  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_50 stored as values in memory (estimated size 41.6 KB, free 1924.4 MB)
2018-05-01 17:49:11.745  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_50_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1924.3 MB)
2018-05-01 17:49:11.745  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_50_piece0 in memory on 172.21.241.193:58620 (size: 18.7 KB, free: 1925.3 MB)
2018-05-01 17:49:11.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:11.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 321 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:11.746  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 321.0 with 1 tasks
2018-05-01 17:49:11.747  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 321.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:11.747  INFO 16044 --- [Executor task launch worker for task 117] org.apache.spark.executor.Executor       : Running task 0.0 in stage 321.0 (TID 117)
2018-05-01 17:49:11.751  INFO 16044 --- [Executor task launch worker for task 117] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:11.751  INFO 16044 --- [Executor task launch worker for task 117] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:11.751  INFO 16044 --- [Executor task launch worker for task 117] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:11.751  INFO 16044 --- [Executor task launch worker for task 117] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:12.282  INFO 16044 --- [Executor task launch worker for task 117] o.a.spark.storage.memory.MemoryStore     : Block rdd_231_0 stored as values in memory (estimated size 970.8 KB, free 1923.4 MB)
2018-05-01 17:49:12.283  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_231_0 in memory on 172.21.241.193:58620 (size: 970.8 KB, free: 1924.4 MB)
2018-05-01 17:49:12.284  INFO 16044 --- [Executor task launch worker for task 117] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 321.0 (TID 117). 1873 bytes result sent to driver
2018-05-01 17:49:12.285  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 321.0 (TID 117) in 539 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:12.285  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 321.0, whose tasks have all completed, from pool 
2018-05-01 17:49:12.285  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 321 (count at ALS.scala:279) finished in 0.539 s
2018-05-01 17:49:12.286  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 25 finished: count at ALS.scala:279, took 0.612536 s
2018-05-01 17:49:12.289  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:280
2018-05-01 17:49:12.290  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:12.290  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:12.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:12.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:12.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:12.292  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:12.292  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:12.292  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:12.292  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:12.293  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:12.293  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:12.293  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:12.293  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:12.294  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:12.294  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:12.295  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:12.295  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:12.295  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:12.295  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:12.297  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:12.298  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:49:12.298  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 22 is 150 bytes
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 26 (count at ALS.scala:280) with 1 output partitions
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 345 (count at ALS.scala:280)
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 344, ShuffleMapStage 323)
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 345 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:49:12.303  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_51 stored as values in memory (estimated size 40.1 KB, free 1923.3 MB)
2018-05-01 17:49:12.304  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1923.3 MB)
2018-05-01 17:49:12.305  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_51_piece0 in memory on 172.21.241.193:58620 (size: 18.1 KB, free: 1924.3 MB)
2018-05-01 17:49:12.305  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:12.305  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 345 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:12.305  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 345.0 with 1 tasks
2018-05-01 17:49:12.306  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 345.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:12.306  INFO 16044 --- [Executor task launch worker for task 118] org.apache.spark.executor.Executor       : Running task 0.0 in stage 345.0 (TID 118)
2018-05-01 17:49:12.310  INFO 16044 --- [Executor task launch worker for task 118] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:12.310  INFO 16044 --- [Executor task launch worker for task 118] org.apache.spark.storage.BlockManager    : Found block rdd_210_0 locally
2018-05-01 17:49:12.606  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_34_piece0 on 172.21.241.193:58620 in memory (size: 13.3 KB, free: 1924.4 MB)
2018-05-01 17:49:12.633  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_40_piece0 on 172.21.241.193:58620 in memory (size: 15.5 KB, free: 1924.4 MB)
2018-05-01 17:49:12.635  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_42_piece0 on 172.21.241.193:58620 in memory (size: 16.4 KB, free: 1924.4 MB)
2018-05-01 17:49:12.651  INFO 16044 --- [Executor task launch worker for task 118] o.a.spark.storage.memory.MemoryStore     : Block rdd_232_0 stored as values in memory (estimated size 1914.2 KB, free 1921.6 MB)
2018-05-01 17:49:12.670  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_232_0 in memory on 172.21.241.193:58620 (size: 1914.2 KB, free: 1922.5 MB)
2018-05-01 17:49:12.684  INFO 16044 --- [Executor task launch worker for task 118] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 345.0 (TID 118). 1701 bytes result sent to driver
2018-05-01 17:49:12.684  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_24_piece0 on 172.21.241.193:58620 in memory (size: 9.9 KB, free: 1922.5 MB)
2018-05-01 17:49:12.684  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 345.0 (TID 118) in 378 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:12.685  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 345.0, whose tasks have all completed, from pool 
2018-05-01 17:49:12.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 345 (count at ALS.scala:280) finished in 0.379 s
2018-05-01 17:49:12.686  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_35_piece0 on 172.21.241.193:58620 in memory (size: 13.0 KB, free: 1922.5 MB)
2018-05-01 17:49:12.686  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 26 finished: count at ALS.scala:280, took 0.395846 s
2018-05-01 17:49:12.716  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_39_piece0 on 172.21.241.193:58620 in memory (size: 14.4 KB, free: 1922.6 MB)
2018-05-01 17:49:12.732  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_27_piece0 on 172.21.241.193:58620 in memory (size: 10.4 KB, free: 1922.6 MB)
2018-05-01 17:49:12.738  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:49:12.799  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_16_piece0 on 172.21.241.193:58620 in memory (size: 7.3 KB, free: 1922.6 MB)
2018-05-01 17:49:12.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 23 is 150 bytes
2018-05-01 17:49:12.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 27 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:49:12.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 370 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:49:12.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 369, ShuffleMapStage 347)
2018-05-01 17:49:12.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:12.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 370 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:49:12.816  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_29_piece0 on 172.21.241.193:58620 in memory (size: 11.0 KB, free: 1922.6 MB)
2018-05-01 17:49:12.830  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_52 stored as values in memory (estimated size 41.8 KB, free 1921.8 MB)
2018-05-01 17:49:12.831  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_52_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1921.8 MB)
2018-05-01 17:49:12.832  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_52_piece0 in memory on 172.21.241.193:58620 (size: 18.8 KB, free: 1922.6 MB)
2018-05-01 17:49:12.832  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_20_piece0 on 172.21.241.193:58620 in memory (size: 8.6 KB, free: 1922.6 MB)
2018-05-01 17:49:12.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:12.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 370 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:12.833  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 370.0 with 1 tasks
2018-05-01 17:49:12.834  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 370.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:12.834  INFO 16044 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : Running task 0.0 in stage 370.0 (TID 119)
2018-05-01 17:49:12.839  INFO 16044 --- [Executor task launch worker for task 119] org.apache.spark.storage.BlockManager    : Found block rdd_231_0 locally
2018-05-01 17:49:12.840  INFO 16044 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 119:
[rdd_231_0]
2018-05-01 17:49:12.841  INFO 16044 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 370.0 (TID 119). 995 bytes result sent to driver
2018-05-01 17:49:12.841  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 370.0 (TID 119) in 7 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:12.841  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 370.0, whose tasks have all completed, from pool 
2018-05-01 17:49:12.841  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 370 (first at MatrixFactorizationModel.scala:67) finished in 0.008 s
2018-05-01 17:49:12.841  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_41_piece0 on 172.21.241.193:58620 in memory (size: 15.2 KB, free: 1922.6 MB)
2018-05-01 17:49:12.842  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 27 finished: first at MatrixFactorizationModel.scala:67, took 0.104570 s
2018-05-01 17:49:12.863  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_37_piece0 on 172.21.241.193:58620 in memory (size: 13.6 KB, free: 1922.6 MB)
2018-05-01 17:49:12.872  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_44_piece0 on 172.21.241.193:58620 in memory (size: 16.8 KB, free: 1922.6 MB)
2018-05-01 17:49:12.874  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_26_piece0 on 172.21.241.193:58620 in memory (size: 10.6 KB, free: 1922.6 MB)
2018-05-01 17:49:12.875  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_47_piece0 on 172.21.241.193:58620 in memory (size: 17.3 KB, free: 1922.6 MB)
2018-05-01 17:49:12.883  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:49:12.888  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_36_piece0 on 172.21.241.193:58620 in memory (size: 13.9 KB, free: 1922.7 MB)
2018-05-01 17:49:12.889  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_28_piece0 on 172.21.241.193:58620 in memory (size: 11.2 KB, free: 1922.7 MB)
2018-05-01 17:49:12.891  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 28 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:49:12.897  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 394 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:49:12.897  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 393, ShuffleMapStage 372)
2018-05-01 17:49:12.897  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:12.898  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 394 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:49:12.939  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_53 stored as values in memory (estimated size 40.2 KB, free 1922.1 MB)
2018-05-01 17:49:12.949  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_53_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1922.0 MB)
2018-05-01 17:49:12.950  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_49_piece0 on 172.21.241.193:58620 in memory (size: 18.0 KB, free: 1922.7 MB)
2018-05-01 17:49:12.951  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_53_piece0 in memory on 172.21.241.193:58620 (size: 18.2 KB, free: 1922.7 MB)
2018-05-01 17:49:12.952  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:12.952  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 394 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:12.952  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 394.0 with 1 tasks
2018-05-01 17:49:12.975  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 394.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:12.977  INFO 16044 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : Running task 0.0 in stage 394.0 (TID 120)
2018-05-01 17:49:12.983  INFO 16044 --- [Executor task launch worker for task 120] org.apache.spark.storage.BlockManager    : Found block rdd_232_0 locally
2018-05-01 17:49:12.983  INFO 16044 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 120:
[rdd_232_0]
2018-05-01 17:49:12.984  INFO 16044 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 394.0 (TID 120). 995 bytes result sent to driver
2018-05-01 17:49:12.985  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 394.0 (TID 120) in 10 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:12.985  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 394.0, whose tasks have all completed, from pool 
2018-05-01 17:49:12.985  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_43_piece0 on 172.21.241.193:58620 in memory (size: 16.0 KB, free: 1922.7 MB)
2018-05-01 17:49:12.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 394 (first at MatrixFactorizationModel.scala:67) finished in 0.034 s
2018-05-01 17:49:12.988  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 28 finished: first at MatrixFactorizationModel.scala:67, took 0.102663 s
2018-05-01 17:49:12.988  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_38_piece0 on 172.21.241.193:58620 in memory (size: 14.7 KB, free: 1922.7 MB)
2018-05-01 17:49:12.990  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_45_piece0 on 172.21.241.193:58620 in memory (size: 16.5 KB, free: 1922.7 MB)
2018-05-01 17:49:12.991  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_33_piece0 on 172.21.241.193:58620 in memory (size: 12.4 KB, free: 1922.7 MB)
2018-05-01 17:49:12.992  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_22_piece0 on 172.21.241.193:58620 in memory (size: 9.3 KB, free: 1922.7 MB)
2018-05-01 17:49:12.993  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_30_piece0 on 172.21.241.193:58620 in memory (size: 11.9 KB, free: 1922.8 MB)
2018-05-01 17:49:12.994  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_19_piece0 on 172.21.241.193:58620 in memory (size: 7.8 KB, free: 1922.8 MB)
2018-05-01 17:49:12.997  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_32_piece0 on 172.21.241.193:58620 in memory (size: 12.5 KB, free: 1922.8 MB)
2018-05-01 17:49:12.998  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_31_piece0 on 172.21.241.193:58620 in memory (size: 11.7 KB, free: 1922.8 MB)
2018-05-01 17:49:13.000  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_50_piece0 on 172.21.241.193:58620 in memory (size: 18.7 KB, free: 1922.8 MB)
2018-05-01 17:49:13.003  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: lookup at MatrixFactorizationModel.scala:168
2018-05-01 17:49:13.004  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_21_piece0 on 172.21.241.193:58620 in memory (size: 8.4 KB, free: 1922.8 MB)
2018-05-01 17:49:13.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 29 (lookup at MatrixFactorizationModel.scala:168) with 1 output partitions
2018-05-01 17:49:13.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 419 (lookup at MatrixFactorizationModel.scala:168)
2018-05-01 17:49:13.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 396, ShuffleMapStage 418)
2018-05-01 17:49:13.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:13.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 419 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:49:13.050  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_54 stored as values in memory (estimated size 41.9 KB, free 1922.5 MB)
2018-05-01 17:49:13.051  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_54_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1922.5 MB)
2018-05-01 17:49:13.052  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_54_piece0 in memory on 172.21.241.193:58620 (size: 18.8 KB, free: 1922.8 MB)
2018-05-01 17:49:13.053  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_23_piece0 on 172.21.241.193:58620 in memory (size: 9.1 KB, free: 1922.8 MB)
2018-05-01 17:49:13.056  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:13.056  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 419 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:13.057  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 419.0 with 1 tasks
2018-05-01 17:49:13.058  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 419.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:13.058  INFO 16044 --- [Executor task launch worker for task 121] org.apache.spark.executor.Executor       : Running task 0.0 in stage 419.0 (TID 121)
2018-05-01 17:49:13.062  INFO 16044 --- [Executor task launch worker for task 121] org.apache.spark.storage.BlockManager    : Found block rdd_231_0 locally
2018-05-01 17:49:13.063  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_17_piece0 on 172.21.241.193:58620 in memory (size: 7.1 KB, free: 1922.8 MB)
2018-05-01 17:49:13.067  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_48_piece0 on 172.21.241.193:58620 in memory (size: 18.2 KB, free: 1922.8 MB)
2018-05-01 17:49:13.068  INFO 16044 --- [Executor task launch worker for task 121] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 419.0 (TID 121). 942 bytes result sent to driver
2018-05-01 17:49:13.073  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 419.0 (TID 121) in 15 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:13.073  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 419.0, whose tasks have all completed, from pool 
2018-05-01 17:49:13.074  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 419 (lookup at MatrixFactorizationModel.scala:168) finished in 0.017 s
2018-05-01 17:49:13.075  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_15_piece0 on 172.21.241.193:58620 in memory (size: 6.4 KB, free: 1922.8 MB)
2018-05-01 17:49:13.075  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 29 finished: lookup at MatrixFactorizationModel.scala:168, took 0.071229 s
2018-05-01 17:49:13.084  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_46_piece0 on 172.21.241.193:58620 in memory (size: 17.6 KB, free: 1922.8 MB)
2018-05-01 17:49:13.087  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_18_piece0 on 172.21.241.193:58620 in memory (size: 8.0 KB, free: 1922.9 MB)
2018-05-01 17:49:13.097  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_25_piece0 on 172.21.241.193:58620 in memory (size: 9.7 KB, free: 1922.9 MB)
2018-05-01 17:49:13.105  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: top at MatrixFactorizationModel.scala:259
2018-05-01 17:49:13.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 30 (top at MatrixFactorizationModel.scala:259) with 1 output partitions
2018-05-01 17:49:13.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 443 (top at MatrixFactorizationModel.scala:259)
2018-05-01 17:49:13.120  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 442, ShuffleMapStage 421)
2018-05-01 17:49:13.121  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:13.121  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 443 (MapPartitionsRDD[234] at top at MatrixFactorizationModel.scala:259), which has no missing parents
2018-05-01 17:49:13.133  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_55 stored as values in memory (estimated size 41.2 KB, free 1922.7 MB)
2018-05-01 17:49:13.135  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_55_piece0 stored as bytes in memory (estimated size 18.6 KB, free 1922.6 MB)
2018-05-01 17:49:13.135  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_55_piece0 in memory on 172.21.241.193:58620 (size: 18.6 KB, free: 1922.8 MB)
2018-05-01 17:49:13.136  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:13.137  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 443 (MapPartitionsRDD[234] at top at MatrixFactorizationModel.scala:259) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:13.137  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 443.0 with 1 tasks
2018-05-01 17:49:13.137  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 443.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:13.138  INFO 16044 --- [Executor task launch worker for task 122] org.apache.spark.executor.Executor       : Running task 0.0 in stage 443.0 (TID 122)
2018-05-01 17:49:13.142  INFO 16044 --- [Executor task launch worker for task 122] org.apache.spark.storage.BlockManager    : Found block rdd_232_0 locally
2018-05-01 17:49:13.179  INFO 16044 --- [Executor task launch worker for task 122] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 443.0 (TID 122). 1652 bytes result sent to driver
2018-05-01 17:49:13.180  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 443.0 (TID 122) in 43 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:13.180  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 443.0, whose tasks have all completed, from pool 
2018-05-01 17:49:13.181  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 443 (top at MatrixFactorizationModel.scala:259) finished in 0.044 s
2018-05-01 17:49:13.182  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 30 finished: top at MatrixFactorizationModel.scala:259, took 0.076463 s
2018-05-01 17:49:13.185  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Recommendations for1
2018-05-01 17:49:13.186  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1214-- Rating : 1.021264172885406
2018-05-01 17:49:13.248  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1200-- Rating : 0.9745515887700025
2018-05-01 17:49:13.253  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 541-- Rating : 0.9676810147435526
2018-05-01 17:49:13.257  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1196-- Rating : 0.9453526818611724
2018-05-01 17:49:13.261  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 924-- Rating : 0.9439457908550074
2018-05-01 17:49:31.329  WARN 16044 --- [http-nio-3333-exec-4] o.apache.spark.sql.SparkSession$Builder  : Using an existing SparkSession; some configuration may not take effect.
2018-05-01 17:49:31.330  INFO 16044 --- [http-nio-3333-exec-4] o.a.spark.storage.memory.MemoryStore     : Block broadcast_56 stored as values in memory (estimated size 248.0 B, free 1922.6 MB)
2018-05-01 17:49:31.331  INFO 16044 --- [http-nio-3333-exec-4] o.a.spark.storage.memory.MemoryStore     : Block broadcast_56_piece0 stored as bytes in memory (estimated size 419.0 B, free 1922.6 MB)
2018-05-01 17:49:31.331  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_56_piece0 in memory on 172.21.241.193:58620 (size: 419.0 B, free: 1922.8 MB)
2018-05-01 17:49:31.332  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Created broadcast 56 from broadcast at MongoSpark.scala:536
2018-05-01 17:49:31.333  INFO 16044 --- [http-nio-3333-exec-4] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:49:31.335  INFO 16044 --- [http-nio-3333-exec-4] org.mongodb.driver.cluster               : Cluster description not yet available. Waiting for 30000 ms before timing out
2018-05-01 17:49:31.338  INFO 16044 --- [cluster-ClusterId{value='5ae87e7bb11f8e3eac338e34', description='null'}-127.0.0.1:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:5, serverValue:32}] to 127.0.0.1:27017
2018-05-01 17:49:31.339  INFO 16044 --- [cluster-ClusterId{value='5ae87e7bb11f8e3eac338e34', description='null'}-127.0.0.1:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=305382}
2018-05-01 17:49:31.340  INFO 16044 --- [http-nio-3333-exec-4] c.m.spark.connection.MongoClientCache    : Creating MongoClient: [127.0.0.1:27017]
2018-05-01 17:49:31.343  INFO 16044 --- [http-nio-3333-exec-4] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:6, serverValue:33}] to 127.0.0.1:27017
2018-05-01 17:49:32.424  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: collect at RecomendationServiceImpl.java:86
2018-05-01 17:49:32.424  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 31 (collect at RecomendationServiceImpl.java:86) with 66 output partitions
2018-05-01 17:49:32.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 444 (collect at RecomendationServiceImpl.java:86)
2018-05-01 17:49:32.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:49:32.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:32.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 444 (MapPartitionsRDD[236] at map at RecomendationServiceImpl.java:83), which has no missing parents
2018-05-01 17:49:32.427  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_57 stored as values in memory (estimated size 7.0 KB, free 1922.6 MB)
2018-05-01 17:49:32.428  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_57_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1922.6 MB)
2018-05-01 17:49:32.428  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_57_piece0 in memory on 172.21.241.193:58620 (size: 3.6 KB, free: 1922.8 MB)
2018-05-01 17:49:32.429  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:32.429  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 66 missing tasks from ResultStage 444 (MapPartitionsRDD[236] at map at RecomendationServiceImpl.java:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-05-01 17:49:32.429  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 444.0 with 66 tasks
2018-05-01 17:49:32.430  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 444.0 (TID 123, localhost, executor driver, partition 0, ANY, 4987 bytes)
2018-05-01 17:49:32.430  INFO 16044 --- [Executor task launch worker for task 123] org.apache.spark.executor.Executor       : Running task 0.0 in stage 444.0 (TID 123)
2018-05-01 17:49:32.433  INFO 16044 --- [Executor task launch worker for task 123] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 444.0 (TID 123). 622 bytes result sent to driver
2018-05-01 17:49:32.434  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 444.0 (TID 124, localhost, executor driver, partition 1, ANY, 4999 bytes)
2018-05-01 17:49:32.434  INFO 16044 --- [Executor task launch worker for task 124] org.apache.spark.executor.Executor       : Running task 1.0 in stage 444.0 (TID 124)
2018-05-01 17:49:32.434  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 444.0 (TID 123) in 4 ms on localhost (executor driver) (1/66)
2018-05-01 17:49:33.053  INFO 16044 --- [Executor task launch worker for task 124] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 444.0 (TID 124). 429841 bytes result sent to driver
2018-05-01 17:49:33.054  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 444.0 (TID 125, localhost, executor driver, partition 2, ANY, 5005 bytes)
2018-05-01 17:49:33.054  INFO 16044 --- [Executor task launch worker for task 125] org.apache.spark.executor.Executor       : Running task 2.0 in stage 444.0 (TID 125)
2018-05-01 17:49:33.082  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 444.0 (TID 124) in 648 ms on localhost (executor driver) (2/66)
2018-05-01 17:49:33.511  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 232
2018-05-01 17:49:33.512  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 232
2018-05-01 17:49:33.514  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 13
2018-05-01 17:49:33.515  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 140
2018-05-01 17:49:33.515  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 140
2018-05-01 17:49:33.516  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 14
2018-05-01 17:49:33.516  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 190
2018-05-01 17:49:33.516  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 190
2018-05-01 17:49:33.518  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 110
2018-05-01 17:49:33.518  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 110
2018-05-01 17:49:33.519  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 15
2018-05-01 17:49:33.519  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_53_piece0 on 172.21.241.193:58620 in memory (size: 18.2 KB, free: 1924.7 MB)
2018-05-01 17:49:33.520  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 225
2018-05-01 17:49:33.520  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 225
2018-05-01 17:49:33.520  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 180
2018-05-01 17:49:33.520  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 180
2018-05-01 17:49:33.520  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 150
2018-05-01 17:49:33.520  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 150
2018-05-01 17:49:33.521  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_51_piece0 on 172.21.241.193:58620 in memory (size: 18.1 KB, free: 1924.7 MB)
2018-05-01 17:49:33.521  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 120
2018-05-01 17:49:33.522  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 120
2018-05-01 17:49:33.522  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 20
2018-05-01 17:49:33.522  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 22
2018-05-01 17:49:33.522  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 130
2018-05-01 17:49:33.523  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 130
2018-05-01 17:49:33.523  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 200
2018-05-01 17:49:33.523  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 200
2018-05-01 17:49:33.524  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_55_piece0 on 172.21.241.193:58620 in memory (size: 18.6 KB, free: 1924.8 MB)
2018-05-01 17:49:33.525  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_54_piece0 on 172.21.241.193:58620 in memory (size: 18.8 KB, free: 1924.8 MB)
2018-05-01 17:49:33.525  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 23
2018-05-01 17:49:33.525  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 170
2018-05-01 17:49:33.526  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 170
2018-05-01 17:49:33.526  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 17
2018-05-01 17:49:33.527  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_52_piece0 on 172.21.241.193:58620 in memory (size: 18.8 KB, free: 1924.8 MB)
2018-05-01 17:49:33.527  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 19
2018-05-01 17:49:33.527  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 210
2018-05-01 17:49:33.528  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 210
2018-05-01 17:49:33.528  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 231
2018-05-01 17:49:33.528  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 231
2018-05-01 17:49:33.528  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 16
2018-05-01 17:49:33.530  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 21
2018-05-01 17:49:33.530  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 18
2018-05-01 17:49:33.530  INFO 16044 --- [block-manager-slave-async-thread-pool-6] org.apache.spark.storage.BlockManager    : Removing RDD 230
2018-05-01 17:49:33.530  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 230
2018-05-01 17:49:33.530  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 160
2018-05-01 17:49:33.530  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 160
2018-05-01 17:49:33.690  INFO 16044 --- [Executor task launch worker for task 125] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 444.0 (TID 125). 432623 bytes result sent to driver
2018-05-01 17:49:33.690  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 444.0 (TID 126, localhost, executor driver, partition 3, ANY, 5004 bytes)
2018-05-01 17:49:33.690  INFO 16044 --- [Executor task launch worker for task 126] org.apache.spark.executor.Executor       : Running task 3.0 in stage 444.0 (TID 126)
2018-05-01 17:49:33.718  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 444.0 (TID 125) in 665 ms on localhost (executor driver) (3/66)
2018-05-01 17:49:34.395  INFO 16044 --- [Executor task launch worker for task 126] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 444.0 (TID 126). 433897 bytes result sent to driver
2018-05-01 17:49:34.395  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 4.0 in stage 444.0 (TID 127, localhost, executor driver, partition 4, ANY, 5003 bytes)
2018-05-01 17:49:34.395  INFO 16044 --- [Executor task launch worker for task 127] org.apache.spark.executor.Executor       : Running task 4.0 in stage 444.0 (TID 127)
2018-05-01 17:49:34.410  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 444.0 (TID 126) in 720 ms on localhost (executor driver) (4/66)
2018-05-01 17:49:35.018  INFO 16044 --- [Executor task launch worker for task 127] org.apache.spark.executor.Executor       : Finished task 4.0 in stage 444.0 (TID 127). 424000 bytes result sent to driver
2018-05-01 17:49:35.018  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 5.0 in stage 444.0 (TID 128, localhost, executor driver, partition 5, ANY, 5003 bytes)
2018-05-01 17:49:35.019  INFO 16044 --- [Executor task launch worker for task 128] org.apache.spark.executor.Executor       : Running task 5.0 in stage 444.0 (TID 128)
2018-05-01 17:49:35.034  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 4.0 in stage 444.0 (TID 127) in 639 ms on localhost (executor driver) (5/66)
2018-05-01 17:49:35.574  INFO 16044 --- [Executor task launch worker for task 128] org.apache.spark.executor.Executor       : Finished task 5.0 in stage 444.0 (TID 128). 418098 bytes result sent to driver
2018-05-01 17:49:35.574  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 6.0 in stage 444.0 (TID 129, localhost, executor driver, partition 6, ANY, 5003 bytes)
2018-05-01 17:49:35.575  INFO 16044 --- [Executor task launch worker for task 129] org.apache.spark.executor.Executor       : Running task 6.0 in stage 444.0 (TID 129)
2018-05-01 17:49:35.591  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 5.0 in stage 444.0 (TID 128) in 573 ms on localhost (executor driver) (6/66)
2018-05-01 17:49:36.163  INFO 16044 --- [Executor task launch worker for task 129] org.apache.spark.executor.Executor       : Finished task 6.0 in stage 444.0 (TID 129). 416945 bytes result sent to driver
2018-05-01 17:49:36.164  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 7.0 in stage 444.0 (TID 130, localhost, executor driver, partition 7, ANY, 5003 bytes)
2018-05-01 17:49:36.165  INFO 16044 --- [Executor task launch worker for task 130] org.apache.spark.executor.Executor       : Running task 7.0 in stage 444.0 (TID 130)
2018-05-01 17:49:36.181  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 6.0 in stage 444.0 (TID 129) in 607 ms on localhost (executor driver) (7/66)
2018-05-01 17:49:36.710  INFO 16044 --- [Executor task launch worker for task 130] org.apache.spark.executor.Executor       : Finished task 7.0 in stage 444.0 (TID 130). 426885 bytes result sent to driver
2018-05-01 17:49:36.710  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 8.0 in stage 444.0 (TID 131, localhost, executor driver, partition 8, ANY, 5003 bytes)
2018-05-01 17:49:36.710  INFO 16044 --- [Executor task launch worker for task 131] org.apache.spark.executor.Executor       : Running task 8.0 in stage 444.0 (TID 131)
2018-05-01 17:49:36.725  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 7.0 in stage 444.0 (TID 130) in 561 ms on localhost (executor driver) (8/66)
2018-05-01 17:49:37.240  INFO 16044 --- [Executor task launch worker for task 131] org.apache.spark.executor.Executor       : Finished task 8.0 in stage 444.0 (TID 131). 430736 bytes result sent to driver
2018-05-01 17:49:37.241  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 9.0 in stage 444.0 (TID 132, localhost, executor driver, partition 9, ANY, 5003 bytes)
2018-05-01 17:49:37.242  INFO 16044 --- [Executor task launch worker for task 132] org.apache.spark.executor.Executor       : Running task 9.0 in stage 444.0 (TID 132)
2018-05-01 17:49:37.257  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 8.0 in stage 444.0 (TID 131) in 547 ms on localhost (executor driver) (9/66)
2018-05-01 17:49:37.846  INFO 16044 --- [Executor task launch worker for task 132] org.apache.spark.executor.Executor       : Finished task 9.0 in stage 444.0 (TID 132). 432112 bytes result sent to driver
2018-05-01 17:49:37.846  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 10.0 in stage 444.0 (TID 133, localhost, executor driver, partition 10, ANY, 5003 bytes)
2018-05-01 17:49:37.847  INFO 16044 --- [Executor task launch worker for task 133] org.apache.spark.executor.Executor       : Running task 10.0 in stage 444.0 (TID 133)
2018-05-01 17:49:37.862  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 9.0 in stage 444.0 (TID 132) in 621 ms on localhost (executor driver) (10/66)
2018-05-01 17:49:38.373  INFO 16044 --- [Executor task launch worker for task 133] org.apache.spark.executor.Executor       : Finished task 10.0 in stage 444.0 (TID 133). 428533 bytes result sent to driver
2018-05-01 17:49:38.373  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 11.0 in stage 444.0 (TID 134, localhost, executor driver, partition 11, ANY, 5003 bytes)
2018-05-01 17:49:38.374  INFO 16044 --- [Executor task launch worker for task 134] org.apache.spark.executor.Executor       : Running task 11.0 in stage 444.0 (TID 134)
2018-05-01 17:49:38.392  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 10.0 in stage 444.0 (TID 133) in 546 ms on localhost (executor driver) (11/66)
2018-05-01 17:49:38.978  INFO 16044 --- [Executor task launch worker for task 134] org.apache.spark.executor.Executor       : Finished task 11.0 in stage 444.0 (TID 134). 432959 bytes result sent to driver
2018-05-01 17:49:38.979  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 12.0 in stage 444.0 (TID 135, localhost, executor driver, partition 12, ANY, 5003 bytes)
2018-05-01 17:49:38.980  INFO 16044 --- [Executor task launch worker for task 135] org.apache.spark.executor.Executor       : Running task 12.0 in stage 444.0 (TID 135)
2018-05-01 17:49:38.995  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 11.0 in stage 444.0 (TID 134) in 622 ms on localhost (executor driver) (12/66)
2018-05-01 17:49:39.551  INFO 16044 --- [Executor task launch worker for task 135] org.apache.spark.executor.Executor       : Finished task 12.0 in stage 444.0 (TID 135). 431932 bytes result sent to driver
2018-05-01 17:49:39.552  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 13.0 in stage 444.0 (TID 136, localhost, executor driver, partition 13, ANY, 5003 bytes)
2018-05-01 17:49:39.553  INFO 16044 --- [Executor task launch worker for task 136] org.apache.spark.executor.Executor       : Running task 13.0 in stage 444.0 (TID 136)
2018-05-01 17:49:39.568  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 12.0 in stage 444.0 (TID 135) in 589 ms on localhost (executor driver) (13/66)
2018-05-01 17:49:40.159  INFO 16044 --- [Executor task launch worker for task 136] org.apache.spark.executor.Executor       : Finished task 13.0 in stage 444.0 (TID 136). 430475 bytes result sent to driver
2018-05-01 17:49:40.160  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 14.0 in stage 444.0 (TID 137, localhost, executor driver, partition 14, ANY, 5003 bytes)
2018-05-01 17:49:40.161  INFO 16044 --- [Executor task launch worker for task 137] org.apache.spark.executor.Executor       : Running task 14.0 in stage 444.0 (TID 137)
2018-05-01 17:49:40.176  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 13.0 in stage 444.0 (TID 136) in 624 ms on localhost (executor driver) (14/66)
2018-05-01 17:49:40.709  INFO 16044 --- [Executor task launch worker for task 137] org.apache.spark.executor.Executor       : Finished task 14.0 in stage 444.0 (TID 137). 433458 bytes result sent to driver
2018-05-01 17:49:40.710  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 15.0 in stage 444.0 (TID 138, localhost, executor driver, partition 15, ANY, 5003 bytes)
2018-05-01 17:49:40.711  INFO 16044 --- [Executor task launch worker for task 138] org.apache.spark.executor.Executor       : Running task 15.0 in stage 444.0 (TID 138)
2018-05-01 17:49:40.729  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 14.0 in stage 444.0 (TID 137) in 569 ms on localhost (executor driver) (15/66)
2018-05-01 17:49:41.242  INFO 16044 --- [Executor task launch worker for task 138] org.apache.spark.executor.Executor       : Finished task 15.0 in stage 444.0 (TID 138). 433596 bytes result sent to driver
2018-05-01 17:49:41.242  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 16.0 in stage 444.0 (TID 139, localhost, executor driver, partition 16, ANY, 5003 bytes)
2018-05-01 17:49:41.243  INFO 16044 --- [Executor task launch worker for task 139] org.apache.spark.executor.Executor       : Running task 16.0 in stage 444.0 (TID 139)
2018-05-01 17:49:41.258  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 15.0 in stage 444.0 (TID 138) in 548 ms on localhost (executor driver) (16/66)
2018-05-01 17:49:41.854  INFO 16044 --- [Executor task launch worker for task 139] org.apache.spark.executor.Executor       : Finished task 16.0 in stage 444.0 (TID 139). 429627 bytes result sent to driver
2018-05-01 17:49:41.855  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 17.0 in stage 444.0 (TID 140, localhost, executor driver, partition 17, ANY, 5002 bytes)
2018-05-01 17:49:41.856  INFO 16044 --- [Executor task launch worker for task 140] org.apache.spark.executor.Executor       : Running task 17.0 in stage 444.0 (TID 140)
2018-05-01 17:49:41.870  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 16.0 in stage 444.0 (TID 139) in 628 ms on localhost (executor driver) (17/66)
2018-05-01 17:49:42.380  INFO 16044 --- [Executor task launch worker for task 140] org.apache.spark.executor.Executor       : Finished task 17.0 in stage 444.0 (TID 140). 434178 bytes result sent to driver
2018-05-01 17:49:42.381  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 18.0 in stage 444.0 (TID 141, localhost, executor driver, partition 18, ANY, 5002 bytes)
2018-05-01 17:49:42.382  INFO 16044 --- [Executor task launch worker for task 141] org.apache.spark.executor.Executor       : Running task 18.0 in stage 444.0 (TID 141)
2018-05-01 17:49:42.398  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 17.0 in stage 444.0 (TID 140) in 544 ms on localhost (executor driver) (18/66)
2018-05-01 17:49:43.006  INFO 16044 --- [Executor task launch worker for task 141] org.apache.spark.executor.Executor       : Finished task 18.0 in stage 444.0 (TID 141). 431426 bytes result sent to driver
2018-05-01 17:49:43.007  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 19.0 in stage 444.0 (TID 142, localhost, executor driver, partition 19, ANY, 5003 bytes)
2018-05-01 17:49:43.008  INFO 16044 --- [Executor task launch worker for task 142] org.apache.spark.executor.Executor       : Running task 19.0 in stage 444.0 (TID 142)
2018-05-01 17:49:43.023  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 18.0 in stage 444.0 (TID 141) in 642 ms on localhost (executor driver) (19/66)
2018-05-01 17:49:43.540  INFO 16044 --- [Executor task launch worker for task 142] org.apache.spark.executor.Executor       : Finished task 19.0 in stage 444.0 (TID 142). 435226 bytes result sent to driver
2018-05-01 17:49:43.541  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 20.0 in stage 444.0 (TID 143, localhost, executor driver, partition 20, ANY, 5003 bytes)
2018-05-01 17:49:43.542  INFO 16044 --- [Executor task launch worker for task 143] org.apache.spark.executor.Executor       : Running task 20.0 in stage 444.0 (TID 143)
2018-05-01 17:49:43.557  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 19.0 in stage 444.0 (TID 142) in 550 ms on localhost (executor driver) (20/66)
2018-05-01 17:49:44.073  INFO 16044 --- [Executor task launch worker for task 143] org.apache.spark.executor.Executor       : Finished task 20.0 in stage 444.0 (TID 143). 434347 bytes result sent to driver
2018-05-01 17:49:44.073  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 21.0 in stage 444.0 (TID 144, localhost, executor driver, partition 21, ANY, 5003 bytes)
2018-05-01 17:49:44.075  INFO 16044 --- [Executor task launch worker for task 144] org.apache.spark.executor.Executor       : Running task 21.0 in stage 444.0 (TID 144)
2018-05-01 17:49:44.089  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 20.0 in stage 444.0 (TID 143) in 548 ms on localhost (executor driver) (21/66)
2018-05-01 17:49:44.931  INFO 16044 --- [block-manager-slave-async-thread-pool-6] org.apache.spark.storage.BlockManager    : Removing RDD 80
2018-05-01 17:49:44.933  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 80
2018-05-01 17:49:44.934  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 13
2018-05-01 17:49:44.934  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 13
2018-05-01 17:49:44.935  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 1
2018-05-01 17:49:44.935  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 70
2018-05-01 17:49:44.936  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 70
2018-05-01 17:49:44.936  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 5
2018-05-01 17:49:44.937  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 2
2018-05-01 17:49:44.937  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 90
2018-05-01 17:49:44.937  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 90
2018-05-01 17:49:44.937  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 6
2018-05-01 17:49:44.937  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 3
2018-05-01 17:49:44.937  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 18
2018-05-01 17:49:44.940  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 18
2018-05-01 17:49:44.940  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 8
2018-05-01 17:49:44.940  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 30
2018-05-01 17:49:44.941  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 30
2018-05-01 17:49:44.941  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 50
2018-05-01 17:49:44.941  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 50
2018-05-01 17:49:44.942  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 40
2018-05-01 17:49:44.942  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 40
2018-05-01 17:49:44.942  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 4
2018-05-01 17:49:44.942  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 12
2018-05-01 17:49:44.942  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 0
2018-05-01 17:49:44.942  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 3
2018-05-01 17:49:44.943  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 3
2018-05-01 17:49:44.943  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 19
2018-05-01 17:49:44.943  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 19
2018-05-01 17:49:44.943  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 12
2018-05-01 17:49:44.945  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 12
2018-05-01 17:49:44.946  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 100
2018-05-01 17:49:44.946  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 100
2018-05-01 17:49:44.946  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 9
2018-05-01 17:49:44.946  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 9
2018-05-01 17:49:44.946  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 11
2018-05-01 17:49:44.947  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 7
2018-05-01 17:49:44.947  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 17
2018-05-01 17:49:44.947  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 17
2018-05-01 17:49:44.947  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_3_piece0 on 172.21.241.193:58620 in memory (size: 2.2 KB, free: 1990.8 MB)
2018-05-01 17:49:44.948  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 9
2018-05-01 17:49:44.948  INFO 16044 --- [block-manager-slave-async-thread-pool-8] org.apache.spark.storage.BlockManager    : Removing RDD 60
2018-05-01 17:49:44.948  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 60
2018-05-01 17:49:44.948  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 10
2018-05-01 17:49:45.141  INFO 16044 --- [Executor task launch worker for task 144] org.apache.spark.executor.Executor       : Finished task 21.0 in stage 444.0 (TID 144). 428428 bytes result sent to driver
2018-05-01 17:49:45.141  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 22.0 in stage 444.0 (TID 145, localhost, executor driver, partition 22, ANY, 5003 bytes)
2018-05-01 17:49:45.142  INFO 16044 --- [Executor task launch worker for task 145] org.apache.spark.executor.Executor       : Running task 22.0 in stage 444.0 (TID 145)
2018-05-01 17:49:45.165  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 21.0 in stage 444.0 (TID 144) in 1092 ms on localhost (executor driver) (22/66)
2018-05-01 17:49:45.690  INFO 16044 --- [Executor task launch worker for task 145] org.apache.spark.executor.Executor       : Finished task 22.0 in stage 444.0 (TID 145). 434997 bytes result sent to driver
2018-05-01 17:49:45.690  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 23.0 in stage 444.0 (TID 146, localhost, executor driver, partition 23, ANY, 5003 bytes)
2018-05-01 17:49:45.690  INFO 16044 --- [Executor task launch worker for task 146] org.apache.spark.executor.Executor       : Running task 23.0 in stage 444.0 (TID 146)
2018-05-01 17:49:45.705  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 22.0 in stage 444.0 (TID 145) in 564 ms on localhost (executor driver) (23/66)
2018-05-01 17:49:46.244  INFO 16044 --- [Executor task launch worker for task 146] org.apache.spark.executor.Executor       : Finished task 23.0 in stage 444.0 (TID 146). 430843 bytes result sent to driver
2018-05-01 17:49:46.245  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 24.0 in stage 444.0 (TID 147, localhost, executor driver, partition 24, ANY, 5003 bytes)
2018-05-01 17:49:46.246  INFO 16044 --- [Executor task launch worker for task 147] org.apache.spark.executor.Executor       : Running task 24.0 in stage 444.0 (TID 147)
2018-05-01 17:49:46.261  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 23.0 in stage 444.0 (TID 146) in 571 ms on localhost (executor driver) (24/66)
2018-05-01 17:49:46.792  INFO 16044 --- [Executor task launch worker for task 147] org.apache.spark.executor.Executor       : Finished task 24.0 in stage 444.0 (TID 147). 429256 bytes result sent to driver
2018-05-01 17:49:46.793  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 25.0 in stage 444.0 (TID 148, localhost, executor driver, partition 25, ANY, 5003 bytes)
2018-05-01 17:49:46.793  INFO 16044 --- [Executor task launch worker for task 148] org.apache.spark.executor.Executor       : Running task 25.0 in stage 444.0 (TID 148)
2018-05-01 17:49:46.809  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 24.0 in stage 444.0 (TID 147) in 564 ms on localhost (executor driver) (25/66)
2018-05-01 17:49:47.338  INFO 16044 --- [Executor task launch worker for task 148] org.apache.spark.executor.Executor       : Finished task 25.0 in stage 444.0 (TID 148). 432165 bytes result sent to driver
2018-05-01 17:49:47.339  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 26.0 in stage 444.0 (TID 149, localhost, executor driver, partition 26, ANY, 5003 bytes)
2018-05-01 17:49:47.341  INFO 16044 --- [Executor task launch worker for task 149] org.apache.spark.executor.Executor       : Running task 26.0 in stage 444.0 (TID 149)
2018-05-01 17:49:47.356  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 25.0 in stage 444.0 (TID 148) in 563 ms on localhost (executor driver) (26/66)
2018-05-01 17:49:47.877  INFO 16044 --- [Executor task launch worker for task 149] org.apache.spark.executor.Executor       : Finished task 26.0 in stage 444.0 (TID 149). 433237 bytes result sent to driver
2018-05-01 17:49:47.877  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 27.0 in stage 444.0 (TID 150, localhost, executor driver, partition 27, ANY, 5003 bytes)
2018-05-01 17:49:47.877  INFO 16044 --- [Executor task launch worker for task 150] org.apache.spark.executor.Executor       : Running task 27.0 in stage 444.0 (TID 150)
2018-05-01 17:49:47.892  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 26.0 in stage 444.0 (TID 149) in 553 ms on localhost (executor driver) (27/66)
2018-05-01 17:49:48.421  INFO 16044 --- [Executor task launch worker for task 150] org.apache.spark.executor.Executor       : Finished task 27.0 in stage 444.0 (TID 150). 433416 bytes result sent to driver
2018-05-01 17:49:48.422  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 28.0 in stage 444.0 (TID 151, localhost, executor driver, partition 28, ANY, 5003 bytes)
2018-05-01 17:49:48.424  INFO 16044 --- [Executor task launch worker for task 151] org.apache.spark.executor.Executor       : Running task 28.0 in stage 444.0 (TID 151)
2018-05-01 17:49:48.438  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 27.0 in stage 444.0 (TID 150) in 561 ms on localhost (executor driver) (28/66)
2018-05-01 17:49:48.949  INFO 16044 --- [Executor task launch worker for task 151] org.apache.spark.executor.Executor       : Finished task 28.0 in stage 444.0 (TID 151). 431277 bytes result sent to driver
2018-05-01 17:49:48.950  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 29.0 in stage 444.0 (TID 152, localhost, executor driver, partition 29, ANY, 5003 bytes)
2018-05-01 17:49:48.951  INFO 16044 --- [Executor task launch worker for task 152] org.apache.spark.executor.Executor       : Running task 29.0 in stage 444.0 (TID 152)
2018-05-01 17:49:48.966  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 28.0 in stage 444.0 (TID 151) in 544 ms on localhost (executor driver) (29/66)
2018-05-01 17:49:49.500  INFO 16044 --- [Executor task launch worker for task 152] org.apache.spark.executor.Executor       : Finished task 29.0 in stage 444.0 (TID 152). 432490 bytes result sent to driver
2018-05-01 17:49:49.501  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 30.0 in stage 444.0 (TID 153, localhost, executor driver, partition 30, ANY, 5003 bytes)
2018-05-01 17:49:49.502  INFO 16044 --- [Executor task launch worker for task 153] org.apache.spark.executor.Executor       : Running task 30.0 in stage 444.0 (TID 153)
2018-05-01 17:49:49.518  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 29.0 in stage 444.0 (TID 152) in 568 ms on localhost (executor driver) (30/66)
2018-05-01 17:49:50.032  INFO 16044 --- [Executor task launch worker for task 153] org.apache.spark.executor.Executor       : Finished task 30.0 in stage 444.0 (TID 153). 431358 bytes result sent to driver
2018-05-01 17:49:50.033  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 31.0 in stage 444.0 (TID 154, localhost, executor driver, partition 31, ANY, 5003 bytes)
2018-05-01 17:49:50.034  INFO 16044 --- [Executor task launch worker for task 154] org.apache.spark.executor.Executor       : Running task 31.0 in stage 444.0 (TID 154)
2018-05-01 17:49:50.051  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 30.0 in stage 444.0 (TID 153) in 550 ms on localhost (executor driver) (31/66)
2018-05-01 17:49:50.588  INFO 16044 --- [Executor task launch worker for task 154] org.apache.spark.executor.Executor       : Finished task 31.0 in stage 444.0 (TID 154). 434141 bytes result sent to driver
2018-05-01 17:49:50.589  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 32.0 in stage 444.0 (TID 155, localhost, executor driver, partition 32, ANY, 5002 bytes)
2018-05-01 17:49:50.590  INFO 16044 --- [Executor task launch worker for task 155] org.apache.spark.executor.Executor       : Running task 32.0 in stage 444.0 (TID 155)
2018-05-01 17:49:50.606  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 31.0 in stage 444.0 (TID 154) in 574 ms on localhost (executor driver) (32/66)
2018-05-01 17:49:51.127  INFO 16044 --- [Executor task launch worker for task 155] org.apache.spark.executor.Executor       : Finished task 32.0 in stage 444.0 (TID 155). 432053 bytes result sent to driver
2018-05-01 17:49:51.127  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 33.0 in stage 444.0 (TID 156, localhost, executor driver, partition 33, ANY, 5002 bytes)
2018-05-01 17:49:51.128  INFO 16044 --- [Executor task launch worker for task 156] org.apache.spark.executor.Executor       : Running task 33.0 in stage 444.0 (TID 156)
2018-05-01 17:49:51.144  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 32.0 in stage 444.0 (TID 155) in 556 ms on localhost (executor driver) (33/66)
2018-05-01 17:49:51.671  INFO 16044 --- [Executor task launch worker for task 156] org.apache.spark.executor.Executor       : Finished task 33.0 in stage 444.0 (TID 156). 433257 bytes result sent to driver
2018-05-01 17:49:51.672  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 34.0 in stage 444.0 (TID 157, localhost, executor driver, partition 34, ANY, 5002 bytes)
2018-05-01 17:49:51.673  INFO 16044 --- [Executor task launch worker for task 157] org.apache.spark.executor.Executor       : Running task 34.0 in stage 444.0 (TID 157)
2018-05-01 17:49:51.688  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 33.0 in stage 444.0 (TID 156) in 561 ms on localhost (executor driver) (34/66)
2018-05-01 17:49:52.233  INFO 16044 --- [Executor task launch worker for task 157] org.apache.spark.executor.Executor       : Finished task 34.0 in stage 444.0 (TID 157). 433019 bytes result sent to driver
2018-05-01 17:49:52.233  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 35.0 in stage 444.0 (TID 158, localhost, executor driver, partition 35, ANY, 5002 bytes)
2018-05-01 17:49:52.235  INFO 16044 --- [Executor task launch worker for task 158] org.apache.spark.executor.Executor       : Running task 35.0 in stage 444.0 (TID 158)
2018-05-01 17:49:52.252  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 34.0 in stage 444.0 (TID 157) in 580 ms on localhost (executor driver) (35/66)
2018-05-01 17:49:52.784  INFO 16044 --- [Executor task launch worker for task 158] org.apache.spark.executor.Executor       : Finished task 35.0 in stage 444.0 (TID 158). 431659 bytes result sent to driver
2018-05-01 17:49:52.785  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 36.0 in stage 444.0 (TID 159, localhost, executor driver, partition 36, ANY, 5002 bytes)
2018-05-01 17:49:52.786  INFO 16044 --- [Executor task launch worker for task 159] org.apache.spark.executor.Executor       : Running task 36.0 in stage 444.0 (TID 159)
2018-05-01 17:49:52.801  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 35.0 in stage 444.0 (TID 158) in 568 ms on localhost (executor driver) (36/66)
2018-05-01 17:49:53.342  INFO 16044 --- [Executor task launch worker for task 159] org.apache.spark.executor.Executor       : Finished task 36.0 in stage 444.0 (TID 159). 435588 bytes result sent to driver
2018-05-01 17:49:53.342  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 37.0 in stage 444.0 (TID 160, localhost, executor driver, partition 37, ANY, 5002 bytes)
2018-05-01 17:49:53.344  INFO 16044 --- [Executor task launch worker for task 160] org.apache.spark.executor.Executor       : Running task 37.0 in stage 444.0 (TID 160)
2018-05-01 17:49:53.361  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 36.0 in stage 444.0 (TID 159) in 576 ms on localhost (executor driver) (37/66)
2018-05-01 17:49:53.883  INFO 16044 --- [Executor task launch worker for task 160] org.apache.spark.executor.Executor       : Finished task 37.0 in stage 444.0 (TID 160). 432592 bytes result sent to driver
2018-05-01 17:49:53.884  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 38.0 in stage 444.0 (TID 161, localhost, executor driver, partition 38, ANY, 5003 bytes)
2018-05-01 17:49:53.885  INFO 16044 --- [Executor task launch worker for task 161] org.apache.spark.executor.Executor       : Running task 38.0 in stage 444.0 (TID 161)
2018-05-01 17:49:53.900  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 37.0 in stage 444.0 (TID 160) in 558 ms on localhost (executor driver) (38/66)
2018-05-01 17:49:54.437  INFO 16044 --- [Executor task launch worker for task 161] org.apache.spark.executor.Executor       : Finished task 38.0 in stage 444.0 (TID 161). 433688 bytes result sent to driver
2018-05-01 17:49:54.437  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 39.0 in stage 444.0 (TID 162, localhost, executor driver, partition 39, ANY, 5003 bytes)
2018-05-01 17:49:54.438  INFO 16044 --- [Executor task launch worker for task 162] org.apache.spark.executor.Executor       : Running task 39.0 in stage 444.0 (TID 162)
2018-05-01 17:49:54.453  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 38.0 in stage 444.0 (TID 161) in 569 ms on localhost (executor driver) (39/66)
2018-05-01 17:49:55.001  INFO 16044 --- [Executor task launch worker for task 162] org.apache.spark.executor.Executor       : Finished task 39.0 in stage 444.0 (TID 162). 430032 bytes result sent to driver
2018-05-01 17:49:55.001  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 40.0 in stage 444.0 (TID 163, localhost, executor driver, partition 40, ANY, 5003 bytes)
2018-05-01 17:49:55.002  INFO 16044 --- [Executor task launch worker for task 163] org.apache.spark.executor.Executor       : Running task 40.0 in stage 444.0 (TID 163)
2018-05-01 17:49:55.018  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 39.0 in stage 444.0 (TID 162) in 581 ms on localhost (executor driver) (40/66)
2018-05-01 17:49:55.538  INFO 16044 --- [Executor task launch worker for task 163] org.apache.spark.executor.Executor       : Finished task 40.0 in stage 444.0 (TID 163). 432889 bytes result sent to driver
2018-05-01 17:49:55.539  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 41.0 in stage 444.0 (TID 164, localhost, executor driver, partition 41, ANY, 5003 bytes)
2018-05-01 17:49:55.540  INFO 16044 --- [Executor task launch worker for task 164] org.apache.spark.executor.Executor       : Running task 41.0 in stage 444.0 (TID 164)
2018-05-01 17:49:55.555  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 40.0 in stage 444.0 (TID 163) in 554 ms on localhost (executor driver) (41/66)
2018-05-01 17:49:56.081  INFO 16044 --- [Executor task launch worker for task 164] org.apache.spark.executor.Executor       : Finished task 41.0 in stage 444.0 (TID 164). 431664 bytes result sent to driver
2018-05-01 17:49:56.082  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 42.0 in stage 444.0 (TID 165, localhost, executor driver, partition 42, ANY, 5003 bytes)
2018-05-01 17:49:56.083  INFO 16044 --- [Executor task launch worker for task 165] org.apache.spark.executor.Executor       : Running task 42.0 in stage 444.0 (TID 165)
2018-05-01 17:49:56.127  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 41.0 in stage 444.0 (TID 164) in 588 ms on localhost (executor driver) (42/66)
2018-05-01 17:49:56.630  INFO 16044 --- [Executor task launch worker for task 165] org.apache.spark.executor.Executor       : Finished task 42.0 in stage 444.0 (TID 165). 432078 bytes result sent to driver
2018-05-01 17:49:56.631  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 43.0 in stage 444.0 (TID 166, localhost, executor driver, partition 43, ANY, 5003 bytes)
2018-05-01 17:49:56.632  INFO 16044 --- [Executor task launch worker for task 166] org.apache.spark.executor.Executor       : Running task 43.0 in stage 444.0 (TID 166)
2018-05-01 17:49:56.648  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 42.0 in stage 444.0 (TID 165) in 566 ms on localhost (executor driver) (43/66)
2018-05-01 17:49:57.167  INFO 16044 --- [Executor task launch worker for task 166] org.apache.spark.executor.Executor       : Finished task 43.0 in stage 444.0 (TID 166). 428926 bytes result sent to driver
2018-05-01 17:49:57.167  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 44.0 in stage 444.0 (TID 167, localhost, executor driver, partition 44, ANY, 5003 bytes)
2018-05-01 17:49:57.168  INFO 16044 --- [Executor task launch worker for task 167] org.apache.spark.executor.Executor       : Running task 44.0 in stage 444.0 (TID 167)
2018-05-01 17:49:57.183  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 43.0 in stage 444.0 (TID 166) in 553 ms on localhost (executor driver) (44/66)
2018-05-01 17:49:57.738  INFO 16044 --- [Executor task launch worker for task 167] org.apache.spark.executor.Executor       : Finished task 44.0 in stage 444.0 (TID 167). 432725 bytes result sent to driver
2018-05-01 17:49:57.738  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 45.0 in stage 444.0 (TID 168, localhost, executor driver, partition 45, ANY, 5003 bytes)
2018-05-01 17:49:57.741  INFO 16044 --- [Executor task launch worker for task 168] org.apache.spark.executor.Executor       : Running task 45.0 in stage 444.0 (TID 168)
2018-05-01 17:49:57.760  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 44.0 in stage 444.0 (TID 167) in 593 ms on localhost (executor driver) (45/66)
2018-05-01 17:49:58.276  INFO 16044 --- [Executor task launch worker for task 168] org.apache.spark.executor.Executor       : Finished task 45.0 in stage 444.0 (TID 168). 430122 bytes result sent to driver
2018-05-01 17:49:58.277  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 46.0 in stage 444.0 (TID 169, localhost, executor driver, partition 46, ANY, 5003 bytes)
2018-05-01 17:49:58.278  INFO 16044 --- [Executor task launch worker for task 169] org.apache.spark.executor.Executor       : Running task 46.0 in stage 444.0 (TID 169)
2018-05-01 17:49:58.300  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 45.0 in stage 444.0 (TID 168) in 562 ms on localhost (executor driver) (46/66)
2018-05-01 17:49:58.802  INFO 16044 --- [Executor task launch worker for task 169] org.apache.spark.executor.Executor       : Finished task 46.0 in stage 444.0 (TID 169). 430137 bytes result sent to driver
2018-05-01 17:49:58.802  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 47.0 in stage 444.0 (TID 170, localhost, executor driver, partition 47, ANY, 5003 bytes)
2018-05-01 17:49:58.803  INFO 16044 --- [Executor task launch worker for task 170] org.apache.spark.executor.Executor       : Running task 47.0 in stage 444.0 (TID 170)
2018-05-01 17:49:58.820  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 46.0 in stage 444.0 (TID 169) in 543 ms on localhost (executor driver) (47/66)
2018-05-01 17:49:59.386  INFO 16044 --- [Executor task launch worker for task 170] org.apache.spark.executor.Executor       : Finished task 47.0 in stage 444.0 (TID 170). 433596 bytes result sent to driver
2018-05-01 17:49:59.387  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 48.0 in stage 444.0 (TID 171, localhost, executor driver, partition 48, ANY, 5003 bytes)
2018-05-01 17:49:59.388  INFO 16044 --- [Executor task launch worker for task 171] org.apache.spark.executor.Executor       : Running task 48.0 in stage 444.0 (TID 171)
2018-05-01 17:49:59.403  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 47.0 in stage 444.0 (TID 170) in 600 ms on localhost (executor driver) (48/66)
2018-05-01 17:49:59.915  INFO 16044 --- [Executor task launch worker for task 171] org.apache.spark.executor.Executor       : Finished task 48.0 in stage 444.0 (TID 171). 431478 bytes result sent to driver
2018-05-01 17:49:59.915  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 49.0 in stage 444.0 (TID 172, localhost, executor driver, partition 49, ANY, 5003 bytes)
2018-05-01 17:49:59.916  INFO 16044 --- [Executor task launch worker for task 172] org.apache.spark.executor.Executor       : Running task 49.0 in stage 444.0 (TID 172)
2018-05-01 17:49:59.931  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 48.0 in stage 444.0 (TID 171) in 545 ms on localhost (executor driver) (49/66)
2018-05-01 17:50:00.449  INFO 16044 --- [Executor task launch worker for task 172] org.apache.spark.executor.Executor       : Finished task 49.0 in stage 444.0 (TID 172). 432786 bytes result sent to driver
2018-05-01 17:50:00.449  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 50.0 in stage 444.0 (TID 173, localhost, executor driver, partition 50, ANY, 5003 bytes)
2018-05-01 17:50:00.451  INFO 16044 --- [Executor task launch worker for task 173] org.apache.spark.executor.Executor       : Running task 50.0 in stage 444.0 (TID 173)
2018-05-01 17:50:00.465  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 49.0 in stage 444.0 (TID 172) in 550 ms on localhost (executor driver) (50/66)
2018-05-01 17:50:01.028  INFO 16044 --- [Executor task launch worker for task 173] org.apache.spark.executor.Executor       : Finished task 50.0 in stage 444.0 (TID 173). 430368 bytes result sent to driver
2018-05-01 17:50:01.029  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 51.0 in stage 444.0 (TID 174, localhost, executor driver, partition 51, ANY, 5002 bytes)
2018-05-01 17:50:01.030  INFO 16044 --- [Executor task launch worker for task 174] org.apache.spark.executor.Executor       : Running task 51.0 in stage 444.0 (TID 174)
2018-05-01 17:50:01.046  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 50.0 in stage 444.0 (TID 173) in 597 ms on localhost (executor driver) (51/66)
2018-05-01 17:50:01.563  INFO 16044 --- [Executor task launch worker for task 174] org.apache.spark.executor.Executor       : Finished task 51.0 in stage 444.0 (TID 174). 435039 bytes result sent to driver
2018-05-01 17:50:01.563  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 52.0 in stage 444.0 (TID 175, localhost, executor driver, partition 52, ANY, 5002 bytes)
2018-05-01 17:50:01.565  INFO 16044 --- [Executor task launch worker for task 175] org.apache.spark.executor.Executor       : Running task 52.0 in stage 444.0 (TID 175)
2018-05-01 17:50:01.581  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 51.0 in stage 444.0 (TID 174) in 552 ms on localhost (executor driver) (52/66)
2018-05-01 17:50:02.095  INFO 16044 --- [Executor task launch worker for task 175] org.apache.spark.executor.Executor       : Finished task 52.0 in stage 444.0 (TID 175). 431702 bytes result sent to driver
2018-05-01 17:50:02.136  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 53.0 in stage 444.0 (TID 176, localhost, executor driver, partition 53, ANY, 5002 bytes)
2018-05-01 17:50:02.137  INFO 16044 --- [Executor task launch worker for task 176] org.apache.spark.executor.Executor       : Running task 53.0 in stage 444.0 (TID 176)
2018-05-01 17:50:02.152  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 52.0 in stage 444.0 (TID 175) in 589 ms on localhost (executor driver) (53/66)
2018-05-01 17:50:02.660  INFO 16044 --- [Executor task launch worker for task 176] org.apache.spark.executor.Executor       : Finished task 53.0 in stage 444.0 (TID 176). 431585 bytes result sent to driver
2018-05-01 17:50:02.661  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 54.0 in stage 444.0 (TID 177, localhost, executor driver, partition 54, ANY, 5002 bytes)
2018-05-01 17:50:02.662  INFO 16044 --- [Executor task launch worker for task 177] org.apache.spark.executor.Executor       : Running task 54.0 in stage 444.0 (TID 177)
2018-05-01 17:50:02.677  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 53.0 in stage 444.0 (TID 176) in 541 ms on localhost (executor driver) (54/66)
2018-05-01 17:50:03.191  INFO 16044 --- [Executor task launch worker for task 177] org.apache.spark.executor.Executor       : Finished task 54.0 in stage 444.0 (TID 177). 428814 bytes result sent to driver
2018-05-01 17:50:03.191  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 55.0 in stage 444.0 (TID 178, localhost, executor driver, partition 55, ANY, 5003 bytes)
2018-05-01 17:50:03.192  INFO 16044 --- [Executor task launch worker for task 178] org.apache.spark.executor.Executor       : Running task 55.0 in stage 444.0 (TID 178)
2018-05-01 17:50:03.207  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 54.0 in stage 444.0 (TID 177) in 546 ms on localhost (executor driver) (55/66)
2018-05-01 17:50:03.758  INFO 16044 --- [Executor task launch worker for task 178] org.apache.spark.executor.Executor       : Finished task 55.0 in stage 444.0 (TID 178). 431970 bytes result sent to driver
2018-05-01 17:50:03.758  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 56.0 in stage 444.0 (TID 179, localhost, executor driver, partition 56, ANY, 5003 bytes)
2018-05-01 17:50:03.759  INFO 16044 --- [Executor task launch worker for task 179] org.apache.spark.executor.Executor       : Running task 56.0 in stage 444.0 (TID 179)
2018-05-01 17:50:03.776  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 55.0 in stage 444.0 (TID 178) in 585 ms on localhost (executor driver) (56/66)
2018-05-01 17:50:04.290  INFO 16044 --- [Executor task launch worker for task 179] org.apache.spark.executor.Executor       : Finished task 56.0 in stage 444.0 (TID 179). 431035 bytes result sent to driver
2018-05-01 17:50:04.290  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 57.0 in stage 444.0 (TID 180, localhost, executor driver, partition 57, ANY, 5003 bytes)
2018-05-01 17:50:04.291  INFO 16044 --- [Executor task launch worker for task 180] org.apache.spark.executor.Executor       : Running task 57.0 in stage 444.0 (TID 180)
2018-05-01 17:50:04.307  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 56.0 in stage 444.0 (TID 179) in 549 ms on localhost (executor driver) (57/66)
2018-05-01 17:50:04.817  INFO 16044 --- [Executor task launch worker for task 180] org.apache.spark.executor.Executor       : Finished task 57.0 in stage 444.0 (TID 180). 434026 bytes result sent to driver
2018-05-01 17:50:04.817  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 58.0 in stage 444.0 (TID 181, localhost, executor driver, partition 58, ANY, 5003 bytes)
2018-05-01 17:50:04.818  INFO 16044 --- [Executor task launch worker for task 181] org.apache.spark.executor.Executor       : Running task 58.0 in stage 444.0 (TID 181)
2018-05-01 17:50:04.833  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 57.0 in stage 444.0 (TID 180) in 543 ms on localhost (executor driver) (58/66)
2018-05-01 17:50:05.395  INFO 16044 --- [Executor task launch worker for task 181] org.apache.spark.executor.Executor       : Finished task 58.0 in stage 444.0 (TID 181). 431075 bytes result sent to driver
2018-05-01 17:50:05.396  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 59.0 in stage 444.0 (TID 182, localhost, executor driver, partition 59, ANY, 5003 bytes)
2018-05-01 17:50:05.397  INFO 16044 --- [Executor task launch worker for task 182] org.apache.spark.executor.Executor       : Running task 59.0 in stage 444.0 (TID 182)
2018-05-01 17:50:05.415  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 58.0 in stage 444.0 (TID 181) in 598 ms on localhost (executor driver) (59/66)
2018-05-01 17:50:05.930  INFO 16044 --- [Executor task launch worker for task 182] org.apache.spark.executor.Executor       : Finished task 59.0 in stage 444.0 (TID 182). 433121 bytes result sent to driver
2018-05-01 17:50:05.931  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 60.0 in stage 444.0 (TID 183, localhost, executor driver, partition 60, ANY, 5003 bytes)
2018-05-01 17:50:05.932  INFO 16044 --- [Executor task launch worker for task 183] org.apache.spark.executor.Executor       : Running task 60.0 in stage 444.0 (TID 183)
2018-05-01 17:50:05.951  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 59.0 in stage 444.0 (TID 182) in 555 ms on localhost (executor driver) (60/66)
2018-05-01 17:50:06.466  INFO 16044 --- [Executor task launch worker for task 183] org.apache.spark.executor.Executor       : Finished task 60.0 in stage 444.0 (TID 183). 432214 bytes result sent to driver
2018-05-01 17:50:06.467  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 61.0 in stage 444.0 (TID 184, localhost, executor driver, partition 61, ANY, 5003 bytes)
2018-05-01 17:50:06.468  INFO 16044 --- [Executor task launch worker for task 184] org.apache.spark.executor.Executor       : Running task 61.0 in stage 444.0 (TID 184)
2018-05-01 17:50:06.484  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 60.0 in stage 444.0 (TID 183) in 554 ms on localhost (executor driver) (61/66)
2018-05-01 17:50:06.996  INFO 16044 --- [Executor task launch worker for task 184] org.apache.spark.executor.Executor       : Finished task 61.0 in stage 444.0 (TID 184). 432524 bytes result sent to driver
2018-05-01 17:50:06.997  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 62.0 in stage 444.0 (TID 185, localhost, executor driver, partition 62, ANY, 5003 bytes)
2018-05-01 17:50:06.998  INFO 16044 --- [Executor task launch worker for task 185] org.apache.spark.executor.Executor       : Running task 62.0 in stage 444.0 (TID 185)
2018-05-01 17:50:07.014  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 61.0 in stage 444.0 (TID 184) in 547 ms on localhost (executor driver) (62/66)
2018-05-01 17:50:07.602  INFO 16044 --- [Executor task launch worker for task 185] org.apache.spark.executor.Executor       : Finished task 62.0 in stage 444.0 (TID 185). 431615 bytes result sent to driver
2018-05-01 17:50:07.602  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 63.0 in stage 444.0 (TID 186, localhost, executor driver, partition 63, ANY, 5003 bytes)
2018-05-01 17:50:07.603  INFO 16044 --- [Executor task launch worker for task 186] org.apache.spark.executor.Executor       : Running task 63.0 in stage 444.0 (TID 186)
2018-05-01 17:50:07.619  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 62.0 in stage 444.0 (TID 185) in 622 ms on localhost (executor driver) (63/66)
2018-05-01 17:50:08.131  INFO 16044 --- [Executor task launch worker for task 186] org.apache.spark.executor.Executor       : Finished task 63.0 in stage 444.0 (TID 186). 429910 bytes result sent to driver
2018-05-01 17:50:08.132  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 64.0 in stage 444.0 (TID 187, localhost, executor driver, partition 64, ANY, 5003 bytes)
2018-05-01 17:50:08.133  INFO 16044 --- [Executor task launch worker for task 187] org.apache.spark.executor.Executor       : Running task 64.0 in stage 444.0 (TID 187)
2018-05-01 17:50:08.149  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 63.0 in stage 444.0 (TID 186) in 547 ms on localhost (executor driver) (64/66)
2018-05-01 17:50:08.671  INFO 16044 --- [Executor task launch worker for task 187] org.apache.spark.executor.Executor       : Finished task 64.0 in stage 444.0 (TID 187). 434975 bytes result sent to driver
2018-05-01 17:50:08.671  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 65.0 in stage 444.0 (TID 188, localhost, executor driver, partition 65, ANY, 4992 bytes)
2018-05-01 17:50:08.672  INFO 16044 --- [Executor task launch worker for task 188] org.apache.spark.executor.Executor       : Running task 65.0 in stage 444.0 (TID 188)
2018-05-01 17:50:08.675  INFO 16044 --- [Executor task launch worker for task 188] org.apache.spark.executor.Executor       : Finished task 65.0 in stage 444.0 (TID 188). 777 bytes result sent to driver
2018-05-01 17:50:08.675  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 65.0 in stage 444.0 (TID 188) in 4 ms on localhost (executor driver) (65/66)
2018-05-01 17:50:08.689  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 64.0 in stage 444.0 (TID 187) in 557 ms on localhost (executor driver) (66/66)
2018-05-01 17:50:08.690  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 444.0, whose tasks have all completed, from pool 
2018-05-01 17:50:08.691  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 444 (collect at RecomendationServiceImpl.java:86) finished in 36.261 s
2018-05-01 17:50:08.691  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 31 finished: collect at RecomendationServiceImpl.java:86, took 36.266965 s
2018-05-01 17:50:08.844  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:240
2018-05-01 17:50:08.844  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 32 (isEmpty at ALS.scala:240) with 1 output partitions
2018-05-01 17:50:08.844  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 445 (isEmpty at ALS.scala:240)
2018-05-01 17:50:08.844  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:50:08.844  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:08.846  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 445 (UnionRDD[240] at union at RecomendationServiceImpl.java:77), which has no missing parents
2018-05-01 17:50:08.847  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_58 stored as values in memory (estimated size 3.3 KB, free 1990.8 MB)
2018-05-01 17:50:08.848  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.8 MB)
2018-05-01 17:50:08.848  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_58_piece0 in memory on 172.21.241.193:58620 (size: 2.1 KB, free: 1990.8 MB)
2018-05-01 17:50:08.848  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:08.849  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 445 (UnionRDD[240] at union at RecomendationServiceImpl.java:77) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:08.849  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 445.0 with 1 tasks
2018-05-01 17:50:11.840  WARN 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Stage 445 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:50:11.841  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 445.0 (TID 189, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:50:11.841  INFO 16044 --- [Executor task launch worker for task 189] org.apache.spark.executor.Executor       : Running task 0.0 in stage 445.0 (TID 189)
2018-05-01 17:50:13.316  INFO 16044 --- [Executor task launch worker for task 189] o.a.spark.storage.memory.MemoryStore     : Block rdd_238_0 stored as values in memory (estimated size 36.0 MB, free 1954.8 MB)
2018-05-01 17:50:13.317  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_238_0 in memory on 172.21.241.193:58620 (size: 36.0 MB, free: 1954.8 MB)
2018-05-01 17:50:13.318  INFO 16044 --- [Executor task launch worker for task 189] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 189:
[rdd_238_0]
2018-05-01 17:50:13.318  INFO 16044 --- [Executor task launch worker for task 189] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 445.0 (TID 189). 1551 bytes result sent to driver
2018-05-01 17:50:13.319  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 445.0 (TID 189) in 4470 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:13.319  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 445.0, whose tasks have all completed, from pool 
2018-05-01 17:50:13.319  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 445 (isEmpty at ALS.scala:240) finished in 4.470 s
2018-05-01 17:50:13.320  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 32 finished: isEmpty at ALS.scala:240, took 4.476114 s
2018-05-01 17:50:13.324  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:843
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 33 (isEmpty at ALS.scala:843) with 1 output partitions
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 446 (isEmpty at ALS.scala:843)
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 446 (MapPartitionsRDD[241] at map at ALS.scala:256), which has no missing parents
2018-05-01 17:50:13.327  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_59 stored as values in memory (estimated size 3.6 KB, free 1954.8 MB)
2018-05-01 17:50:13.328  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1954.8 MB)
2018-05-01 17:50:13.328  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_59_piece0 in memory on 172.21.241.193:58620 (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 17:50:13.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:13.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 446 (MapPartitionsRDD[241] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:13.328  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 446.0 with 1 tasks
2018-05-01 17:50:13.721  INFO 16044 --- [pool-25-thread-1] c.m.spark.connection.MongoClientCache    : Closing MongoClient: [127.0.0.1:27017]
2018-05-01 17:50:13.721  INFO 16044 --- [pool-25-thread-1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:6, serverValue:33}] to 127.0.0.1:27017 because the pool has been closed.
2018-05-01 17:50:16.251  WARN 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Stage 446 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:50:16.252  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 446.0 (TID 190, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:50:16.252  INFO 16044 --- [Executor task launch worker for task 190] org.apache.spark.executor.Executor       : Running task 0.0 in stage 446.0 (TID 190)
2018-05-01 17:50:16.584  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_58_piece0 on 172.21.241.193:58620 in memory (size: 2.1 KB, free: 1954.8 MB)
2018-05-01 17:50:17.347  INFO 16044 --- [Executor task launch worker for task 190] org.apache.spark.storage.BlockManager    : Found block rdd_238_0 locally
2018-05-01 17:50:17.347  INFO 16044 --- [Executor task launch worker for task 190] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 190:
[rdd_238_0]
2018-05-01 17:50:17.347  INFO 16044 --- [Executor task launch worker for task 190] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 446.0 (TID 190). 1003 bytes result sent to driver
2018-05-01 17:50:17.348  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 446.0 (TID 190) in 4020 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:17.349  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 446.0, whose tasks have all completed, from pool 
2018-05-01 17:50:17.349  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 446 (isEmpty at ALS.scala:843) finished in 4.021 s
2018-05-01 17:50:17.349  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 33 finished: isEmpty at ALS.scala:843, took 4.024945 s
2018-05-01 17:50:17.370  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:857
2018-05-01 17:50:17.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 242 (mapPartitions at ALS.scala:1101)
2018-05-01 17:50:17.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 245 (map at ALS.scala:1344)
2018-05-01 17:50:17.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 34 (count at ALS.scala:857) with 1 output partitions
2018-05-01 17:50:17.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 449 (count at ALS.scala:857)
2018-05-01 17:50:17.372  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 448)
2018-05-01 17:50:17.372  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 448)
2018-05-01 17:50:17.373  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 447 (MapPartitionsRDD[242] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-05-01 17:50:17.373  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_60 stored as values in memory (estimated size 5.8 KB, free 1954.8 MB)
2018-05-01 17:50:17.374  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1954.8 MB)
2018-05-01 17:50:17.375  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_60_piece0 in memory on 172.21.241.193:58620 (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 17:50:17.375  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:17.375  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 447 (MapPartitionsRDD[242] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:50:17.376  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 447.0 with 2 tasks
2018-05-01 17:50:19.427  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_59_piece0 on 172.21.241.193:58620 in memory (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 17:50:20.289  WARN 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Stage 447 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:50:20.290  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 447.0 (TID 191, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427802 bytes)
2018-05-01 17:50:20.291  INFO 16044 --- [Executor task launch worker for task 191] org.apache.spark.executor.Executor       : Running task 0.0 in stage 447.0 (TID 191)
2018-05-01 17:50:21.278  INFO 16044 --- [Executor task launch worker for task 191] org.apache.spark.storage.BlockManager    : Found block rdd_238_0 locally
2018-05-01 17:50:21.692  INFO 16044 --- [Executor task launch worker for task 191] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 447.0 (TID 191). 1027 bytes result sent to driver
2018-05-01 17:50:21.693  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 447.0 (TID 192, localhost, executor driver, partition 1, PROCESS_LOCAL, 5072 bytes)
2018-05-01 17:50:21.694  INFO 16044 --- [Executor task launch worker for task 192] org.apache.spark.executor.Executor       : Running task 1.0 in stage 447.0 (TID 192)
2018-05-01 17:50:21.694  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 447.0 (TID 191) in 4318 ms on localhost (executor driver) (1/2)
2018-05-01 17:50:21.709  INFO 16044 --- [Executor task launch worker for task 192] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 447.0 (TID 192). 812 bytes result sent to driver
2018-05-01 17:50:21.710  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 447.0 (TID 192) in 16 ms on localhost (executor driver) (2/2)
2018-05-01 17:50:21.710  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 447.0, whose tasks have all completed, from pool 
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 447 (mapPartitions at ALS.scala:1101) finished in 4.335 s
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 448, ResultStage 449)
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:21.712  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 448 (MapPartitionsRDD[245] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:50:21.713  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_61 stored as values in memory (estimated size 7.1 KB, free 1954.8 MB)
2018-05-01 17:50:21.713  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1954.8 MB)
2018-05-01 17:50:21.713  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_61_piece0 in memory on 172.21.241.193:58620 (size: 3.7 KB, free: 1954.8 MB)
2018-05-01 17:50:21.714  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:21.714  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 448 (MapPartitionsRDD[245] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:50:21.714  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 448.0 with 2 tasks
2018-05-01 17:50:21.715  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 448.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:50:21.715  INFO 16044 --- [Executor task launch worker for task 193] org.apache.spark.executor.Executor       : Running task 0.0 in stage 448.0 (TID 193)
2018-05-01 17:50:21.717  INFO 16044 --- [Executor task launch worker for task 193] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 2 blocks
2018-05-01 17:50:21.717  INFO 16044 --- [Executor task launch worker for task 193] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:21.717  INFO 16044 --- [Executor task launch worker for task 193] o.a.spark.storage.memory.MemoryStore     : Block rdd_244_0 stored as values in memory (estimated size 16.0 B, free 1954.8 MB)
2018-05-01 17:50:21.718  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_244_0 in memory on 172.21.241.193:58620 (size: 16.0 B, free: 1954.8 MB)
2018-05-01 17:50:21.723  INFO 16044 --- [Executor task launch worker for task 193] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 448.0 (TID 193). 1766 bytes result sent to driver
2018-05-01 17:50:21.724  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 448.0 (TID 194, localhost, executor driver, partition 1, ANY, 4610 bytes)
2018-05-01 17:50:21.724  INFO 16044 --- [Executor task launch worker for task 194] org.apache.spark.executor.Executor       : Running task 1.0 in stage 448.0 (TID 194)
2018-05-01 17:50:21.724  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 448.0 (TID 193) in 10 ms on localhost (executor driver) (1/2)
2018-05-01 17:50:21.725  INFO 16044 --- [Executor task launch worker for task 194] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 2 non-empty blocks out of 2 blocks
2018-05-01 17:50:21.725  INFO 16044 --- [Executor task launch worker for task 194] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:21.859  INFO 16044 --- [Executor task launch worker for task 194] o.a.spark.storage.memory.MemoryStore     : Block rdd_244_1 stored as values in memory (estimated size 12.0 MB, free 1942.8 MB)
2018-05-01 17:50:21.859  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_244_1 in memory on 172.21.241.193:58620 (size: 12.0 MB, free: 1942.8 MB)
2018-05-01 17:50:22.125  INFO 16044 --- [Executor task launch worker for task 194] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 448.0 (TID 194). 1938 bytes result sent to driver
2018-05-01 17:50:22.125  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 448.0 (TID 194) in 401 ms on localhost (executor driver) (2/2)
2018-05-01 17:50:22.125  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 448.0, whose tasks have all completed, from pool 
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 448 (map at ALS.scala:1344) finished in 0.411 s
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 449)
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:22.126  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 449 (userOutBlocks MapPartitionsRDD[248] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:50:22.127  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_62 stored as values in memory (estimated size 7.7 KB, free 1942.8 MB)
2018-05-01 17:50:22.128  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1942.8 MB)
2018-05-01 17:50:22.128  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_62_piece0 in memory on 172.21.241.193:58620 (size: 3.9 KB, free: 1942.8 MB)
2018-05-01 17:50:22.129  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:22.129  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 449 (userOutBlocks MapPartitionsRDD[248] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:22.129  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 449.0 with 1 tasks
2018-05-01 17:50:22.129  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 449.0 (TID 195, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:50:22.129  INFO 16044 --- [Executor task launch worker for task 195] org.apache.spark.executor.Executor       : Running task 0.0 in stage 449.0 (TID 195)
2018-05-01 17:50:22.131  INFO 16044 --- [Executor task launch worker for task 195] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:50:22.131  INFO 16044 --- [Executor task launch worker for task 195] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:22.451  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_61_piece0 on 172.21.241.193:58620 in memory (size: 3.7 KB, free: 1942.8 MB)
2018-05-01 17:50:22.452  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_60_piece0 on 172.21.241.193:58620 in memory (size: 3.2 KB, free: 1942.8 MB)
2018-05-01 17:50:22.620  INFO 16044 --- [Executor task launch worker for task 195] o.a.spark.storage.memory.MemoryStore     : Block rdd_247_0 stored as values in memory (estimated size 8.1 MB, free 1934.7 MB)
2018-05-01 17:50:22.620  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_247_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1934.7 MB)
2018-05-01 17:50:22.624  INFO 16044 --- [Executor task launch worker for task 195] o.a.spark.storage.memory.MemoryStore     : Block rdd_248_0 stored as values in memory (estimated size 27.9 KB, free 1934.7 MB)
2018-05-01 17:50:22.624  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_248_0 in memory on 172.21.241.193:58620 (size: 27.9 KB, free: 1934.7 MB)
2018-05-01 17:50:22.624  INFO 16044 --- [Executor task launch worker for task 195] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 449.0 (TID 195). 1877 bytes result sent to driver
2018-05-01 17:50:22.625  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 449.0 (TID 195) in 496 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:22.625  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 449.0, whose tasks have all completed, from pool 
2018-05-01 17:50:22.625  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 449 (count at ALS.scala:857) finished in 0.496 s
2018-05-01 17:50:22.625  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 34 finished: count at ALS.scala:857, took 5.254274 s
2018-05-01 17:50:22.639  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:865
2018-05-01 17:50:22.639  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:22.639  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 250 (map at ALS.scala:1344)
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 35 (count at ALS.scala:865) with 1 output partitions
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 452 (count at ALS.scala:865)
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 451)
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 451)
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 451 (MapPartitionsRDD[250] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:50:22.641  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_63 stored as values in memory (estimated size 7.3 KB, free 1934.7 MB)
2018-05-01 17:50:22.642  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1934.7 MB)
2018-05-01 17:50:22.642  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_63_piece0 in memory on 172.21.241.193:58620 (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:50:22.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:22.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 451 (MapPartitionsRDD[250] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:50:22.643  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 451.0 with 2 tasks
2018-05-01 17:50:22.644  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 451.0 (TID 196, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:50:22.644  INFO 16044 --- [Executor task launch worker for task 196] org.apache.spark.executor.Executor       : Running task 0.0 in stage 451.0 (TID 196)
2018-05-01 17:50:22.645  INFO 16044 --- [Executor task launch worker for task 196] org.apache.spark.storage.BlockManager    : Found block rdd_244_0 locally
2018-05-01 17:50:22.651  INFO 16044 --- [Executor task launch worker for task 196] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 451.0 (TID 196). 725 bytes result sent to driver
2018-05-01 17:50:22.651  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 451.0 (TID 197, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:50:22.651  INFO 16044 --- [Executor task launch worker for task 197] org.apache.spark.executor.Executor       : Running task 1.0 in stage 451.0 (TID 197)
2018-05-01 17:50:22.651  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 451.0 (TID 196) in 7 ms on localhost (executor driver) (1/2)
2018-05-01 17:50:22.652  INFO 16044 --- [Executor task launch worker for task 197] org.apache.spark.storage.BlockManager    : Found block rdd_244_1 locally
2018-05-01 17:50:22.924  INFO 16044 --- [Executor task launch worker for task 197] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 451.0 (TID 197). 897 bytes result sent to driver
2018-05-01 17:50:22.925  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 451.0 (TID 197) in 273 ms on localhost (executor driver) (2/2)
2018-05-01 17:50:22.925  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 451.0, whose tasks have all completed, from pool 
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 451 (map at ALS.scala:1344) finished in 0.281 s
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 452)
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:22.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 452 (itemOutBlocks MapPartitionsRDD[253] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:50:22.926  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_64 stored as values in memory (estimated size 7.9 KB, free 1934.7 MB)
2018-05-01 17:50:22.927  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1934.7 MB)
2018-05-01 17:50:22.928  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_64_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1934.7 MB)
2018-05-01 17:50:22.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:22.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 452 (itemOutBlocks MapPartitionsRDD[253] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:22.928  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 452.0 with 1 tasks
2018-05-01 17:50:22.929  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 452.0 (TID 198, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:50:22.929  INFO 16044 --- [Executor task launch worker for task 198] org.apache.spark.executor.Executor       : Running task 0.0 in stage 452.0 (TID 198)
2018-05-01 17:50:22.931  INFO 16044 --- [Executor task launch worker for task 198] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:50:22.931  INFO 16044 --- [Executor task launch worker for task 198] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:23.564  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_63_piece0 on 172.21.241.193:58620 in memory (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:50:23.566  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_62_piece0 on 172.21.241.193:58620 in memory (size: 3.9 KB, free: 1934.7 MB)
2018-05-01 17:50:24.122  INFO 16044 --- [Executor task launch worker for task 198] o.a.spark.storage.memory.MemoryStore     : Block rdd_252_0 stored as values in memory (estimated size 8.1 MB, free 1926.6 MB)
2018-05-01 17:50:24.122  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_252_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1926.6 MB)
2018-05-01 17:50:24.126  INFO 16044 --- [Executor task launch worker for task 198] o.a.spark.storage.memory.MemoryStore     : Block rdd_253_0 stored as values in memory (estimated size 54.9 KB, free 1926.5 MB)
2018-05-01 17:50:24.126  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_253_0 in memory on 172.21.241.193:58620 (size: 54.9 KB, free: 1926.6 MB)
2018-05-01 17:50:24.126  INFO 16044 --- [Executor task launch worker for task 198] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 452.0 (TID 198). 1877 bytes result sent to driver
2018-05-01 17:50:24.127  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 452.0 (TID 198) in 1199 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.127  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 452.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.127  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 452 (count at ALS.scala:865) finished in 1.199 s
2018-05-01 17:50:24.127  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 35 finished: count at ALS.scala:865, took 1.488659 s
2018-05-01 17:50:24.138  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 36 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 455 (aggregate at ALS.scala:1491)
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 454)
2018-05-01 17:50:24.139  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:24.140  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 455 (MapPartitionsRDD[256] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:24.141  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_65 stored as values in memory (estimated size 9.1 KB, free 1926.5 MB)
2018-05-01 17:50:24.141  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.5 MB)
2018-05-01 17:50:24.142  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_65_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.5 MB)
2018-05-01 17:50:24.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 455 (MapPartitionsRDD[256] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.142  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 455.0 with 1 tasks
2018-05-01 17:50:24.143  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 455.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
2018-05-01 17:50:24.143  INFO 16044 --- [Executor task launch worker for task 199] org.apache.spark.executor.Executor       : Running task 0.0 in stage 455.0 (TID 199)
2018-05-01 17:50:24.144  INFO 16044 --- [Executor task launch worker for task 199] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:24.151  INFO 16044 --- [Executor task launch worker for task 199] o.a.spark.storage.memory.MemoryStore     : Block rdd_254_0 stored as values in memory (estimated size 416.2 KB, free 1926.1 MB)
2018-05-01 17:50:24.151  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_254_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1926.1 MB)
2018-05-01 17:50:24.153  INFO 16044 --- [Executor task launch worker for task 199] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 455.0 (TID 199). 2165 bytes result sent to driver
2018-05-01 17:50:24.154  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 455.0 (TID 199) in 11 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.154  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 455.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.154  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 455 (aggregate at ALS.scala:1491) finished in 0.011 s
2018-05-01 17:50:24.155  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 36 finished: aggregate at ALS.scala:1491, took 0.017356 s
2018-05-01 17:50:24.169  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 255 from persistence list
2018-05-01 17:50:24.169  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 255
2018-05-01 17:50:24.173  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 254 (map at ALS.scala:1017)
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 260 (flatMap at ALS.scala:1433)
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 37 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 461 (aggregate at ALS.scala:1491)
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 460, ShuffleMapStage 457)
2018-05-01 17:50:24.175  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 460)
2018-05-01 17:50:24.175  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 459 (userFactors-1 MapPartitionsRDD[254] at map at ALS.scala:1017), which has no missing parents
2018-05-01 17:50:24.176  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_66 stored as values in memory (estimated size 7.7 KB, free 1926.1 MB)
2018-05-01 17:50:24.176  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_66_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1926.1 MB)
2018-05-01 17:50:24.177  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_66_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:50:24.177  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.177  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 459 (userFactors-1 MapPartitionsRDD[254] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.177  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 459.0 with 1 tasks
2018-05-01 17:50:24.178  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 459.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:50:24.178  INFO 16044 --- [Executor task launch worker for task 200] org.apache.spark.executor.Executor       : Running task 0.0 in stage 459.0 (TID 200)
2018-05-01 17:50:24.179  INFO 16044 --- [Executor task launch worker for task 200] org.apache.spark.storage.BlockManager    : Found block rdd_254_0 locally
2018-05-01 17:50:24.222  INFO 16044 --- [Executor task launch worker for task 200] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 459.0 (TID 200). 940 bytes result sent to driver
2018-05-01 17:50:24.223  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 459.0 (TID 200) in 46 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.223  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 459.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 459 (map at ALS.scala:1017) finished in 0.046 s
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 460, ResultStage 461)
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 460 (MapPartitionsRDD[260] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:24.224  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_67 stored as values in memory (estimated size 8.8 KB, free 1926.1 MB)
2018-05-01 17:50:24.225  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.1 MB)
2018-05-01 17:50:24.227  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_67_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 17:50:24.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 67 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 460 (MapPartitionsRDD[260] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.227  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 460.0 with 1 tasks
2018-05-01 17:50:24.228  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 460.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-05-01 17:50:24.228  INFO 16044 --- [Executor task launch worker for task 201] org.apache.spark.executor.Executor       : Running task 0.0 in stage 460.0 (TID 201)
2018-05-01 17:50:24.229  INFO 16044 --- [Executor task launch worker for task 201] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:24.230  INFO 16044 --- [Executor task launch worker for task 201] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:24.230  INFO 16044 --- [Executor task launch worker for task 201] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:24.287  INFO 16044 --- [Executor task launch worker for task 201] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 460.0 (TID 201). 1327 bytes result sent to driver
2018-05-01 17:50:24.288  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 460.0 (TID 201) in 61 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.288  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 460.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 460 (flatMap at ALS.scala:1433) finished in 0.061 s
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 461)
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:24.289  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 461 (MapPartitionsRDD[266] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:24.289  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_68 stored as values in memory (estimated size 12.6 KB, free 1926.1 MB)
2018-05-01 17:50:24.290  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1926.1 MB)
2018-05-01 17:50:24.290  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_68_piece0 in memory on 172.21.241.193:58620 (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 17:50:24.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 68 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 461 (MapPartitionsRDD[266] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.291  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 461.0 with 1 tasks
2018-05-01 17:50:24.291  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 461.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:24.291  INFO 16044 --- [Executor task launch worker for task 202] org.apache.spark.executor.Executor       : Running task 0.0 in stage 461.0 (TID 202)
2018-05-01 17:50:24.293  INFO 16044 --- [Executor task launch worker for task 202] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:24.293  INFO 16044 --- [Executor task launch worker for task 202] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:24.293  INFO 16044 --- [Executor task launch worker for task 202] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:24.614  INFO 16044 --- [Executor task launch worker for task 202] o.a.spark.storage.memory.MemoryStore     : Block rdd_265_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:50:24.614  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_265_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:24.617  INFO 16044 --- [Executor task launch worker for task 202] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 461.0 (TID 202). 2595 bytes result sent to driver
2018-05-01 17:50:24.618  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 461.0 (TID 202) in 327 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.618  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 461.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.618  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 461 (aggregate at ALS.scala:1491) finished in 0.327 s
2018-05-01 17:50:24.618  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 37 finished: aggregate at ALS.scala:1491, took 0.444691 s
2018-05-01 17:50:24.635  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 254 from persistence list
2018-05-01 17:50:24.636  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 254
2018-05-01 17:50:24.641  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 270 (flatMap at ALS.scala:1433)
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 38 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:24.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 468 (aggregate at ALS.scala:1491)
2018-05-01 17:50:24.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 463, ShuffleMapStage 467)
2018-05-01 17:50:24.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 467)
2018-05-01 17:50:24.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 467 (MapPartitionsRDD[270] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:24.644  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_69 stored as values in memory (estimated size 11.8 KB, free 1925.7 MB)
2018-05-01 17:50:24.645  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.7 KB, free 1925.7 MB)
2018-05-01 17:50:24.646  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_69_piece0 in memory on 172.21.241.193:58620 (size: 5.7 KB, free: 1925.7 MB)
2018-05-01 17:50:24.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 69 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 467 (MapPartitionsRDD[270] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.646  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 467.0 with 1 tasks
2018-05-01 17:50:24.647  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 467.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:24.647  INFO 16044 --- [Executor task launch worker for task 203] org.apache.spark.executor.Executor       : Running task 0.0 in stage 467.0 (TID 203)
2018-05-01 17:50:24.649  INFO 16044 --- [Executor task launch worker for task 203] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:24.649  INFO 16044 --- [Executor task launch worker for task 203] org.apache.spark.storage.BlockManager    : Found block rdd_265_0 locally
2018-05-01 17:50:24.683  INFO 16044 --- [Executor task launch worker for task 203] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 467.0 (TID 203). 1069 bytes result sent to driver
2018-05-01 17:50:24.683  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 467.0 (TID 203) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.683  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 467.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.683  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 467 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 17:50:24.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:24.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:24.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 468)
2018-05-01 17:50:24.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:24.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 468 (MapPartitionsRDD[276] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:24.686  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_70 stored as values in memory (estimated size 14.3 KB, free 1925.6 MB)
2018-05-01 17:50:24.687  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1925.6 MB)
2018-05-01 17:50:24.688  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_70_piece0 in memory on 172.21.241.193:58620 (size: 6.6 KB, free: 1925.7 MB)
2018-05-01 17:50:24.688  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 70 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.688  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 468 (MapPartitionsRDD[276] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.688  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 468.0 with 1 tasks
2018-05-01 17:50:24.689  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 468.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:24.689  INFO 16044 --- [Executor task launch worker for task 204] org.apache.spark.executor.Executor       : Running task 0.0 in stage 468.0 (TID 204)
2018-05-01 17:50:24.691  INFO 16044 --- [Executor task launch worker for task 204] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:24.691  INFO 16044 --- [Executor task launch worker for task 204] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:24.691  INFO 16044 --- [Executor task launch worker for task 204] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:24.953  INFO 16044 --- [Executor task launch worker for task 204] o.a.spark.storage.memory.MemoryStore     : Block rdd_275_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:50:24.953  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_275_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:50:24.955  INFO 16044 --- [Executor task launch worker for task 204] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 468.0 (TID 204). 2595 bytes result sent to driver
2018-05-01 17:50:24.956  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 468.0 (TID 204) in 267 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.956  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 468.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.956  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 468 (aggregate at ALS.scala:1491) finished in 0.268 s
2018-05-01 17:50:24.956  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 38 finished: aggregate at ALS.scala:1491, took 0.315188 s
2018-05-01 17:50:24.973  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 265 from persistence list
2018-05-01 17:50:24.974  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 265
2018-05-01 17:50:24.979  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:24.979  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:24.979  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 280 (flatMap at ALS.scala:1433)
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 39 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 476 (aggregate at ALS.scala:1491)
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 473, ShuffleMapStage 475)
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 475)
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 475 (MapPartitionsRDD[280] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:24.983  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_71 stored as values in memory (estimated size 13.4 KB, free 1926.0 MB)
2018-05-01 17:50:24.984  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_71_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1926.0 MB)
2018-05-01 17:50:24.984  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_71_piece0 in memory on 172.21.241.193:58620 (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:50:24.984  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 71 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.985  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 475 (MapPartitionsRDD[280] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.985  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 475.0 with 1 tasks
2018-05-01 17:50:24.985  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 475.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:24.985  INFO 16044 --- [Executor task launch worker for task 205] org.apache.spark.executor.Executor       : Running task 0.0 in stage 475.0 (TID 205)
2018-05-01 17:50:24.987  INFO 16044 --- [Executor task launch worker for task 205] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:24.987  INFO 16044 --- [Executor task launch worker for task 205] org.apache.spark.storage.BlockManager    : Found block rdd_275_0 locally
2018-05-01 17:50:25.029  INFO 16044 --- [Executor task launch worker for task 205] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 475.0 (TID 205). 1069 bytes result sent to driver
2018-05-01 17:50:25.029  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 475.0 (TID 205) in 44 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.029  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 475.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 475 (flatMap at ALS.scala:1433) finished in 0.045 s
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 476)
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 476 (MapPartitionsRDD[286] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:25.031  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_72 stored as values in memory (estimated size 15.8 KB, free 1926.0 MB)
2018-05-01 17:50:25.033  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_72_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1926.0 MB)
2018-05-01 17:50:25.033  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_72_piece0 in memory on 172.21.241.193:58620 (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 17:50:25.033  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 72 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.033  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 476 (MapPartitionsRDD[286] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.033  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 476.0 with 1 tasks
2018-05-01 17:50:25.034  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 476.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:25.035  INFO 16044 --- [Executor task launch worker for task 206] org.apache.spark.executor.Executor       : Running task 0.0 in stage 476.0 (TID 206)
2018-05-01 17:50:25.037  INFO 16044 --- [Executor task launch worker for task 206] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:25.037  INFO 16044 --- [Executor task launch worker for task 206] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:25.037  INFO 16044 --- [Executor task launch worker for task 206] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:25.391  INFO 16044 --- [Executor task launch worker for task 206] o.a.spark.storage.memory.MemoryStore     : Block rdd_285_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 17:50:25.391  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_285_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:25.394  INFO 16044 --- [Executor task launch worker for task 206] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 476.0 (TID 206). 2595 bytes result sent to driver
2018-05-01 17:50:25.395  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 476.0 (TID 206) in 361 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.395  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 476.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.395  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 476 (aggregate at ALS.scala:1491) finished in 0.361 s
2018-05-01 17:50:25.396  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 39 finished: aggregate at ALS.scala:1491, took 0.416853 s
2018-05-01 17:50:25.418  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 275 from persistence list
2018-05-01 17:50:25.419  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 275
2018-05-01 17:50:25.423  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:25.424  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:25.424  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 290 (flatMap at ALS.scala:1433)
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 40 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 485 (aggregate at ALS.scala:1491)
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 484, ShuffleMapStage 478)
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 484)
2018-05-01 17:50:25.427  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 484 (MapPartitionsRDD[290] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:25.428  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_73 stored as values in memory (estimated size 14.9 KB, free 1925.6 MB)
2018-05-01 17:50:25.429  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_73_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1925.6 MB)
2018-05-01 17:50:25.429  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_73_piece0 in memory on 172.21.241.193:58620 (size: 7.1 KB, free: 1925.7 MB)
2018-05-01 17:50:25.429  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 73 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.429  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 484 (MapPartitionsRDD[290] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.429  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 484.0 with 1 tasks
2018-05-01 17:50:25.430  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 484.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:25.430  INFO 16044 --- [Executor task launch worker for task 207] org.apache.spark.executor.Executor       : Running task 0.0 in stage 484.0 (TID 207)
2018-05-01 17:50:25.431  INFO 16044 --- [Executor task launch worker for task 207] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:25.432  INFO 16044 --- [Executor task launch worker for task 207] org.apache.spark.storage.BlockManager    : Found block rdd_285_0 locally
2018-05-01 17:50:25.475  INFO 16044 --- [Executor task launch worker for task 207] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 484.0 (TID 207). 1069 bytes result sent to driver
2018-05-01 17:50:25.475  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 484.0 (TID 207) in 45 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.475  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 484.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.475  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 484 (flatMap at ALS.scala:1433) finished in 0.045 s
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 485)
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 485 (MapPartitionsRDD[296] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:25.478  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_74 stored as values in memory (estimated size 17.4 KB, free 1925.6 MB)
2018-05-01 17:50:25.479  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_74_piece0 stored as bytes in memory (estimated size 7.9 KB, free 1925.6 MB)
2018-05-01 17:50:25.479  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_74_piece0 in memory on 172.21.241.193:58620 (size: 7.9 KB, free: 1925.7 MB)
2018-05-01 17:50:25.479  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 74 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.480  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 485 (MapPartitionsRDD[296] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.480  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 485.0 with 1 tasks
2018-05-01 17:50:25.481  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 485.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:25.481  INFO 16044 --- [Executor task launch worker for task 208] org.apache.spark.executor.Executor       : Running task 0.0 in stage 485.0 (TID 208)
2018-05-01 17:50:25.484  INFO 16044 --- [Executor task launch worker for task 208] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:25.484  INFO 16044 --- [Executor task launch worker for task 208] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:25.484  INFO 16044 --- [Executor task launch worker for task 208] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:25.807  INFO 16044 --- [Executor task launch worker for task 208] o.a.spark.storage.memory.MemoryStore     : Block rdd_295_0 stored as values in memory (estimated size 416.2 KB, free 1925.1 MB)
2018-05-01 17:50:25.807  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_295_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:50:25.809  INFO 16044 --- [Executor task launch worker for task 208] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 485.0 (TID 208). 2595 bytes result sent to driver
2018-05-01 17:50:25.810  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 485.0 (TID 208) in 329 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.810  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 485.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.810  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 485 (aggregate at ALS.scala:1491) finished in 0.329 s
2018-05-01 17:50:25.810  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 40 finished: aggregate at ALS.scala:1491, took 0.386827 s
2018-05-01 17:50:25.828  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 285 from persistence list
2018-05-01 17:50:25.828  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 285
2018-05-01 17:50:25.832  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:25.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:25.834  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:25.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:25.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:25.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 300 (flatMap at ALS.scala:1433)
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 41 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 495 (aggregate at ALS.scala:1491)
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 494, ShuffleMapStage 487)
2018-05-01 17:50:25.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 494)
2018-05-01 17:50:25.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 494 (MapPartitionsRDD[300] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:25.838  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_75 stored as values in memory (estimated size 16.5 KB, free 1925.9 MB)
2018-05-01 17:50:25.839  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_75_piece0 stored as bytes in memory (estimated size 7.8 KB, free 1925.9 MB)
2018-05-01 17:50:25.839  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_75_piece0 in memory on 172.21.241.193:58620 (size: 7.8 KB, free: 1926.1 MB)
2018-05-01 17:50:25.840  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 75 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.840  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 494 (MapPartitionsRDD[300] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.840  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 494.0 with 1 tasks
2018-05-01 17:50:25.840  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 494.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:25.840  INFO 16044 --- [Executor task launch worker for task 209] org.apache.spark.executor.Executor       : Running task 0.0 in stage 494.0 (TID 209)
2018-05-01 17:50:25.842  INFO 16044 --- [Executor task launch worker for task 209] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:25.842  INFO 16044 --- [Executor task launch worker for task 209] org.apache.spark.storage.BlockManager    : Found block rdd_295_0 locally
2018-05-01 17:50:25.867  INFO 16044 --- [Executor task launch worker for task 209] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 494.0 (TID 209). 1069 bytes result sent to driver
2018-05-01 17:50:25.868  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 494.0 (TID 209) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.868  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 494.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 494 (flatMap at ALS.scala:1433) finished in 0.028 s
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 495)
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:25.869  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 495 (MapPartitionsRDD[306] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:25.870  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_76 stored as values in memory (estimated size 18.9 KB, free 1925.9 MB)
2018-05-01 17:50:25.871  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_76_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1925.9 MB)
2018-05-01 17:50:25.871  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_76_piece0 in memory on 172.21.241.193:58620 (size: 8.6 KB, free: 1926.1 MB)
2018-05-01 17:50:25.871  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 76 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.871  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 495 (MapPartitionsRDD[306] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.871  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 495.0 with 1 tasks
2018-05-01 17:50:25.872  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 495.0 (TID 210, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:25.872  INFO 16044 --- [Executor task launch worker for task 210] org.apache.spark.executor.Executor       : Running task 0.0 in stage 495.0 (TID 210)
2018-05-01 17:50:25.873  INFO 16044 --- [Executor task launch worker for task 210] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:25.874  INFO 16044 --- [Executor task launch worker for task 210] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:25.874  INFO 16044 --- [Executor task launch worker for task 210] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:26.164  INFO 16044 --- [Executor task launch worker for task 210] o.a.spark.storage.memory.MemoryStore     : Block rdd_305_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 17:50:26.165  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_305_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:26.168  INFO 16044 --- [Executor task launch worker for task 210] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 495.0 (TID 210). 2595 bytes result sent to driver
2018-05-01 17:50:26.168  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 495.0 (TID 210) in 297 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.168  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 495.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 495 (aggregate at ALS.scala:1491) finished in 0.298 s
2018-05-01 17:50:26.169  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 41 finished: aggregate at ALS.scala:1491, took 0.336959 s
2018-05-01 17:50:26.184  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 295 from persistence list
2018-05-01 17:50:26.184  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 295
2018-05-01 17:50:26.188  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:26.188  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:26.188  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:26.188  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:26.189  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:26.189  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:26.189  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:26.190  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 310 (flatMap at ALS.scala:1433)
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 42 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 506 (aggregate at ALS.scala:1491)
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 497, ShuffleMapStage 505)
2018-05-01 17:50:26.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 505)
2018-05-01 17:50:26.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 505 (MapPartitionsRDD[310] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:26.193  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_77 stored as values in memory (estimated size 18.0 KB, free 1925.5 MB)
2018-05-01 17:50:26.194  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_77_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1925.5 MB)
2018-05-01 17:50:26.194  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_77_piece0 in memory on 172.21.241.193:58620 (size: 8.4 KB, free: 1925.7 MB)
2018-05-01 17:50:26.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 77 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 505 (MapPartitionsRDD[310] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.194  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 505.0 with 1 tasks
2018-05-01 17:50:26.195  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 505.0 (TID 211, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:26.195  INFO 16044 --- [Executor task launch worker for task 211] org.apache.spark.executor.Executor       : Running task 0.0 in stage 505.0 (TID 211)
2018-05-01 17:50:26.197  INFO 16044 --- [Executor task launch worker for task 211] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:26.197  INFO 16044 --- [Executor task launch worker for task 211] org.apache.spark.storage.BlockManager    : Found block rdd_305_0 locally
2018-05-01 17:50:26.226  INFO 16044 --- [Executor task launch worker for task 211] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 505.0 (TID 211). 1069 bytes result sent to driver
2018-05-01 17:50:26.226  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 505.0 (TID 211) in 31 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.226  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 505.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 505 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 506)
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 506 (MapPartitionsRDD[316] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:26.228  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_78 stored as values in memory (estimated size 20.5 KB, free 1925.5 MB)
2018-05-01 17:50:26.229  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_78_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1925.4 MB)
2018-05-01 17:50:26.229  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_78_piece0 in memory on 172.21.241.193:58620 (size: 9.3 KB, free: 1925.7 MB)
2018-05-01 17:50:26.230  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 78 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.230  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 506 (MapPartitionsRDD[316] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.230  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 506.0 with 1 tasks
2018-05-01 17:50:26.230  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 506.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:26.230  INFO 16044 --- [Executor task launch worker for task 212] org.apache.spark.executor.Executor       : Running task 0.0 in stage 506.0 (TID 212)
2018-05-01 17:50:26.232  INFO 16044 --- [Executor task launch worker for task 212] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:26.233  INFO 16044 --- [Executor task launch worker for task 212] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:26.233  INFO 16044 --- [Executor task launch worker for task 212] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:26.493  INFO 16044 --- [Executor task launch worker for task 212] o.a.spark.storage.memory.MemoryStore     : Block rdd_315_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 17:50:26.494  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_315_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:50:26.496  INFO 16044 --- [Executor task launch worker for task 212] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 506.0 (TID 212). 2595 bytes result sent to driver
2018-05-01 17:50:26.496  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 506.0 (TID 212) in 266 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.496  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 506.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.497  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 506 (aggregate at ALS.scala:1491) finished in 0.266 s
2018-05-01 17:50:26.497  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 42 finished: aggregate at ALS.scala:1491, took 0.308628 s
2018-05-01 17:50:26.513  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 305 from persistence list
2018-05-01 17:50:26.514  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 305
2018-05-01 17:50:26.520  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:26.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:26.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:26.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:26.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 320 (flatMap at ALS.scala:1433)
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 43 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 518 (aggregate at ALS.scala:1491)
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 517, ShuffleMapStage 508)
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 517)
2018-05-01 17:50:26.524  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 517 (MapPartitionsRDD[320] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:26.526  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_79 stored as values in memory (estimated size 19.6 KB, free 1925.8 MB)
2018-05-01 17:50:26.527  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_79_piece0 stored as bytes in memory (estimated size 9.1 KB, free 1925.8 MB)
2018-05-01 17:50:26.528  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_79_piece0 in memory on 172.21.241.193:58620 (size: 9.1 KB, free: 1926.0 MB)
2018-05-01 17:50:26.528  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 79 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.528  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 517 (MapPartitionsRDD[320] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.528  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 517.0 with 1 tasks
2018-05-01 17:50:26.529  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 517.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:26.529  INFO 16044 --- [Executor task launch worker for task 213] org.apache.spark.executor.Executor       : Running task 0.0 in stage 517.0 (TID 213)
2018-05-01 17:50:26.530  INFO 16044 --- [Executor task launch worker for task 213] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:26.531  INFO 16044 --- [Executor task launch worker for task 213] org.apache.spark.storage.BlockManager    : Found block rdd_315_0 locally
2018-05-01 17:50:26.582  INFO 16044 --- [Executor task launch worker for task 213] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 517.0 (TID 213). 1069 bytes result sent to driver
2018-05-01 17:50:26.583  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 517.0 (TID 213) in 54 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.583  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 517.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 517 (flatMap at ALS.scala:1433) finished in 0.055 s
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 518)
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 518 (MapPartitionsRDD[326] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:26.584  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_80 stored as values in memory (estimated size 22.0 KB, free 1925.8 MB)
2018-05-01 17:50:26.585  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_80_piece0 stored as bytes in memory (estimated size 9.8 KB, free 1925.8 MB)
2018-05-01 17:50:26.586  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_80_piece0 in memory on 172.21.241.193:58620 (size: 9.8 KB, free: 1926.0 MB)
2018-05-01 17:50:26.586  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 80 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.586  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 518 (MapPartitionsRDD[326] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.586  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 518.0 with 1 tasks
2018-05-01 17:50:26.586  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 518.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:26.587  INFO 16044 --- [Executor task launch worker for task 214] org.apache.spark.executor.Executor       : Running task 0.0 in stage 518.0 (TID 214)
2018-05-01 17:50:26.588  INFO 16044 --- [Executor task launch worker for task 214] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:26.588  INFO 16044 --- [Executor task launch worker for task 214] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:26.588  INFO 16044 --- [Executor task launch worker for task 214] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:26.898  INFO 16044 --- [Executor task launch worker for task 214] o.a.spark.storage.memory.MemoryStore     : Block rdd_325_0 stored as values in memory (estimated size 820.5 KB, free 1925.0 MB)
2018-05-01 17:50:26.898  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_325_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:50:26.902  INFO 16044 --- [Executor task launch worker for task 214] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 518.0 (TID 214). 2595 bytes result sent to driver
2018-05-01 17:50:26.903  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 518.0 (TID 214) in 317 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.903  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 518.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.903  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 518 (aggregate at ALS.scala:1491) finished in 0.317 s
2018-05-01 17:50:26.904  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 43 finished: aggregate at ALS.scala:1491, took 0.383244 s
2018-05-01 17:50:26.919  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 315 from persistence list
2018-05-01 17:50:26.920  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 315
2018-05-01 17:50:26.925  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:26.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:26.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 330 (flatMap at ALS.scala:1433)
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 44 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 531 (aggregate at ALS.scala:1491)
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 520, ShuffleMapStage 530)
2018-05-01 17:50:26.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 530)
2018-05-01 17:50:26.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 530 (MapPartitionsRDD[330] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:26.930  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_81 stored as values in memory (estimated size 21.1 KB, free 1925.4 MB)
2018-05-01 17:50:26.931  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_81_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1925.4 MB)
2018-05-01 17:50:26.931  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_81_piece0 in memory on 172.21.241.193:58620 (size: 9.7 KB, free: 1925.6 MB)
2018-05-01 17:50:26.931  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 81 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.932  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 530 (MapPartitionsRDD[330] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.932  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 530.0 with 1 tasks
2018-05-01 17:50:26.932  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 530.0 (TID 215, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:26.934  INFO 16044 --- [Executor task launch worker for task 215] org.apache.spark.executor.Executor       : Running task 0.0 in stage 530.0 (TID 215)
2018-05-01 17:50:26.936  INFO 16044 --- [Executor task launch worker for task 215] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:26.936  INFO 16044 --- [Executor task launch worker for task 215] org.apache.spark.storage.BlockManager    : Found block rdd_325_0 locally
2018-05-01 17:50:26.972  INFO 16044 --- [Executor task launch worker for task 215] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 530.0 (TID 215). 1069 bytes result sent to driver
2018-05-01 17:50:26.972  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 530.0 (TID 215) in 40 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.972  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 530.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 530 (flatMap at ALS.scala:1433) finished in 0.040 s
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 531)
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 531 (MapPartitionsRDD[336] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:26.975  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_82 stored as values in memory (estimated size 23.6 KB, free 1925.3 MB)
2018-05-01 17:50:26.976  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_82_piece0 stored as bytes in memory (estimated size 10.6 KB, free 1925.3 MB)
2018-05-01 17:50:26.976  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_82_piece0 in memory on 172.21.241.193:58620 (size: 10.6 KB, free: 1925.6 MB)
2018-05-01 17:50:26.977  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 82 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.977  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 531 (MapPartitionsRDD[336] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.977  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 531.0 with 1 tasks
2018-05-01 17:50:26.977  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 531.0 (TID 216, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:26.978  INFO 16044 --- [Executor task launch worker for task 216] org.apache.spark.executor.Executor       : Running task 0.0 in stage 531.0 (TID 216)
2018-05-01 17:50:26.981  INFO 16044 --- [Executor task launch worker for task 216] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:26.981  INFO 16044 --- [Executor task launch worker for task 216] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:26.981  INFO 16044 --- [Executor task launch worker for task 216] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:27.307  INFO 16044 --- [Executor task launch worker for task 216] o.a.spark.storage.memory.MemoryStore     : Block rdd_335_0 stored as values in memory (estimated size 416.2 KB, free 1924.9 MB)
2018-05-01 17:50:27.308  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_335_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:50:27.311  INFO 16044 --- [Executor task launch worker for task 216] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 531.0 (TID 216). 2638 bytes result sent to driver
2018-05-01 17:50:27.312  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 531.0 (TID 216) in 335 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:27.312  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 531.0, whose tasks have all completed, from pool 
2018-05-01 17:50:27.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 531 (aggregate at ALS.scala:1491) finished in 0.335 s
2018-05-01 17:50:27.313  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 44 finished: aggregate at ALS.scala:1491, took 0.388174 s
2018-05-01 17:50:27.335  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 325 from persistence list
2018-05-01 17:50:27.336  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 325
2018-05-01 17:50:27.340  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:27.340  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 340 (flatMap at ALS.scala:1433)
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 45 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 545 (aggregate at ALS.scala:1491)
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 544, ShuffleMapStage 536)
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 544)
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 544 (MapPartitionsRDD[340] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:27.345  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_83 stored as values in memory (estimated size 22.7 KB, free 1925.7 MB)
2018-05-01 17:50:27.346  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_83_piece0 stored as bytes in memory (estimated size 10.4 KB, free 1925.7 MB)
2018-05-01 17:50:27.346  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_83_piece0 in memory on 172.21.241.193:58620 (size: 10.4 KB, free: 1926.0 MB)
2018-05-01 17:50:27.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 83 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:27.347  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 544 (MapPartitionsRDD[340] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:27.347  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 544.0 with 1 tasks
2018-05-01 17:50:27.347  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 544.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:27.347  INFO 16044 --- [Executor task launch worker for task 217] org.apache.spark.executor.Executor       : Running task 0.0 in stage 544.0 (TID 217)
2018-05-01 17:50:27.350  INFO 16044 --- [Executor task launch worker for task 217] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:27.350  INFO 16044 --- [Executor task launch worker for task 217] org.apache.spark.storage.BlockManager    : Found block rdd_335_0 locally
2018-05-01 17:50:27.392  INFO 16044 --- [Executor task launch worker for task 217] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 544.0 (TID 217). 1069 bytes result sent to driver
2018-05-01 17:50:27.392  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 544.0 (TID 217) in 45 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:27.392  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 544.0, whose tasks have all completed, from pool 
2018-05-01 17:50:27.392  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 544 (flatMap at ALS.scala:1433) finished in 0.045 s
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 545)
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 545 (MapPartitionsRDD[346] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:27.395  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_84 stored as values in memory (estimated size 25.1 KB, free 1925.7 MB)
2018-05-01 17:50:27.397  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_84_piece0 stored as bytes in memory (estimated size 11.1 KB, free 1925.7 MB)
2018-05-01 17:50:27.397  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_84_piece0 in memory on 172.21.241.193:58620 (size: 11.1 KB, free: 1926.0 MB)
2018-05-01 17:50:27.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 84 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:27.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 545 (MapPartitionsRDD[346] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:27.398  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 545.0 with 1 tasks
2018-05-01 17:50:27.398  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 545.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:27.398  INFO 16044 --- [Executor task launch worker for task 218] org.apache.spark.executor.Executor       : Running task 0.0 in stage 545.0 (TID 218)
2018-05-01 17:50:27.402  INFO 16044 --- [Executor task launch worker for task 218] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:27.402  INFO 16044 --- [Executor task launch worker for task 218] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:27.402  INFO 16044 --- [Executor task launch worker for task 218] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:27.767  INFO 16044 --- [Executor task launch worker for task 218] o.a.spark.storage.memory.MemoryStore     : Block rdd_345_0 stored as values in memory (estimated size 820.5 KB, free 1924.9 MB)
2018-05-01 17:50:27.767  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_345_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:50:27.772  INFO 16044 --- [Executor task launch worker for task 218] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 545.0 (TID 218). 2638 bytes result sent to driver
2018-05-01 17:50:27.772  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 545.0 (TID 218) in 374 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:27.772  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 545.0, whose tasks have all completed, from pool 
2018-05-01 17:50:27.773  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 545 (aggregate at ALS.scala:1491) finished in 0.375 s
2018-05-01 17:50:27.774  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 45 finished: aggregate at ALS.scala:1491, took 0.433616 s
2018-05-01 17:50:27.806  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 335 from persistence list
2018-05-01 17:50:27.807  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 335
2018-05-01 17:50:27.813  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:27.814  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:27.814  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:27.814  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:27.814  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:27.816  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:27.816  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:27.817  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 350 (flatMap at ALS.scala:1433)
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 46 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 560 (aggregate at ALS.scala:1491)
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 547, ShuffleMapStage 559)
2018-05-01 17:50:27.819  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 559)
2018-05-01 17:50:27.819  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 559 (MapPartitionsRDD[350] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:27.820  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_85 stored as values in memory (estimated size 24.2 KB, free 1925.2 MB)
2018-05-01 17:50:27.821  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_85_piece0 stored as bytes in memory (estimated size 11.0 KB, free 1925.2 MB)
2018-05-01 17:50:27.821  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_85_piece0 in memory on 172.21.241.193:58620 (size: 11.0 KB, free: 1925.6 MB)
2018-05-01 17:50:27.822  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 85 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:27.822  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 559 (MapPartitionsRDD[350] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:27.822  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 559.0 with 1 tasks
2018-05-01 17:50:27.822  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 559.0 (TID 219, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:27.823  INFO 16044 --- [Executor task launch worker for task 219] org.apache.spark.executor.Executor       : Running task 0.0 in stage 559.0 (TID 219)
2018-05-01 17:50:27.824  INFO 16044 --- [Executor task launch worker for task 219] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:27.824  INFO 16044 --- [Executor task launch worker for task 219] org.apache.spark.storage.BlockManager    : Found block rdd_345_0 locally
2018-05-01 17:50:27.857  INFO 16044 --- [Executor task launch worker for task 219] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 559.0 (TID 219). 1069 bytes result sent to driver
2018-05-01 17:50:27.857  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 559.0 (TID 219) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:27.857  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 559.0, whose tasks have all completed, from pool 
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 559 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 560)
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:27.858  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 560 (MapPartitionsRDD[356] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:27.860  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_86 stored as values in memory (estimated size 26.7 KB, free 1925.2 MB)
2018-05-01 17:50:27.860  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_86_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1925.2 MB)
2018-05-01 17:50:27.861  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_86_piece0 in memory on 172.21.241.193:58620 (size: 11.9 KB, free: 1925.6 MB)
2018-05-01 17:50:27.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 86 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:27.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 560 (MapPartitionsRDD[356] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:27.861  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 560.0 with 1 tasks
2018-05-01 17:50:27.862  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 560.0 (TID 220, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:27.862  INFO 16044 --- [Executor task launch worker for task 220] org.apache.spark.executor.Executor       : Running task 0.0 in stage 560.0 (TID 220)
2018-05-01 17:50:27.863  INFO 16044 --- [Executor task launch worker for task 220] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:27.864  INFO 16044 --- [Executor task launch worker for task 220] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:27.864  INFO 16044 --- [Executor task launch worker for task 220] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:28.137  INFO 16044 --- [Executor task launch worker for task 220] o.a.spark.storage.memory.MemoryStore     : Block rdd_355_0 stored as values in memory (estimated size 416.2 KB, free 1924.8 MB)
2018-05-01 17:50:28.137  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_355_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:50:28.139  INFO 16044 --- [Executor task launch worker for task 220] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 560.0 (TID 220). 2595 bytes result sent to driver
2018-05-01 17:50:28.139  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 560.0 (TID 220) in 278 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.139  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 560.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.140  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 560 (aggregate at ALS.scala:1491) finished in 0.279 s
2018-05-01 17:50:28.140  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 46 finished: aggregate at ALS.scala:1491, took 0.326748 s
2018-05-01 17:50:28.155  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 345 from persistence list
2018-05-01 17:50:28.155  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 345
2018-05-01 17:50:28.160  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:28.160  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:28.160  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:28.161  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:28.161  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:28.163  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:28.163  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:28.163  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 360 (flatMap at ALS.scala:1433)
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 47 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 576 (aggregate at ALS.scala:1491)
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 575, ShuffleMapStage 565)
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 575)
2018-05-01 17:50:28.166  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 575 (MapPartitionsRDD[360] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:28.168  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_87 stored as values in memory (estimated size 25.8 KB, free 1925.6 MB)
2018-05-01 17:50:28.169  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_87_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1925.5 MB)
2018-05-01 17:50:28.169  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_87_piece0 in memory on 172.21.241.193:58620 (size: 11.7 KB, free: 1926.0 MB)
2018-05-01 17:50:28.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 87 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.170  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 575 (MapPartitionsRDD[360] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.170  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 575.0 with 1 tasks
2018-05-01 17:50:28.170  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 575.0 (TID 221, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:28.170  INFO 16044 --- [Executor task launch worker for task 221] org.apache.spark.executor.Executor       : Running task 0.0 in stage 575.0 (TID 221)
2018-05-01 17:50:28.172  INFO 16044 --- [Executor task launch worker for task 221] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:28.172  INFO 16044 --- [Executor task launch worker for task 221] org.apache.spark.storage.BlockManager    : Found block rdd_355_0 locally
2018-05-01 17:50:28.207  INFO 16044 --- [Executor task launch worker for task 221] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 575.0 (TID 221). 1026 bytes result sent to driver
2018-05-01 17:50:28.207  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 575.0 (TID 221) in 37 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.207  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 575.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 575 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 576)
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 576 (MapPartitionsRDD[366] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:28.210  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_88 stored as values in memory (estimated size 28.2 KB, free 1925.5 MB)
2018-05-01 17:50:28.210  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_88_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1925.5 MB)
2018-05-01 17:50:28.211  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_88_piece0 in memory on 172.21.241.193:58620 (size: 12.5 KB, free: 1925.9 MB)
2018-05-01 17:50:28.212  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 88 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.212  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 576 (MapPartitionsRDD[366] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.212  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 576.0 with 1 tasks
2018-05-01 17:50:28.212  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 576.0 (TID 222, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:28.213  INFO 16044 --- [Executor task launch worker for task 222] org.apache.spark.executor.Executor       : Running task 0.0 in stage 576.0 (TID 222)
2018-05-01 17:50:28.214  INFO 16044 --- [Executor task launch worker for task 222] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:28.214  INFO 16044 --- [Executor task launch worker for task 222] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:28.215  INFO 16044 --- [Executor task launch worker for task 222] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:50:28.515  INFO 16044 --- [Executor task launch worker for task 222] o.a.spark.storage.memory.MemoryStore     : Block rdd_365_0 stored as values in memory (estimated size 820.5 KB, free 1924.7 MB)
2018-05-01 17:50:28.516  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_365_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:50:28.519  INFO 16044 --- [Executor task launch worker for task 222] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 576.0 (TID 222). 2638 bytes result sent to driver
2018-05-01 17:50:28.520  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 576.0 (TID 222) in 308 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.520  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 576.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.520  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 576 (aggregate at ALS.scala:1491) finished in 0.308 s
2018-05-01 17:50:28.520  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 47 finished: aggregate at ALS.scala:1491, took 0.360531 s
2018-05-01 17:50:28.539  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 355 from persistence list
2018-05-01 17:50:28.539  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 355
2018-05-01 17:50:28.543  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:28.543  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 370 (flatMap at ALS.scala:1433)
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 48 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 593 (aggregate at ALS.scala:1491)
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 592, ShuffleMapStage 578)
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 592)
2018-05-01 17:50:28.547  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 592 (MapPartitionsRDD[370] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:28.548  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_89 stored as values in memory (estimated size 27.3 KB, free 1925.1 MB)
2018-05-01 17:50:28.549  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_89_piece0 stored as bytes in memory (estimated size 12.4 KB, free 1925.1 MB)
2018-05-01 17:50:28.549  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_89_piece0 in memory on 172.21.241.193:58620 (size: 12.4 KB, free: 1925.5 MB)
2018-05-01 17:50:28.550  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 89 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.550  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 592 (MapPartitionsRDD[370] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.550  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 592.0 with 1 tasks
2018-05-01 17:50:28.551  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 592.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:28.551  INFO 16044 --- [Executor task launch worker for task 223] org.apache.spark.executor.Executor       : Running task 0.0 in stage 592.0 (TID 223)
2018-05-01 17:50:28.553  INFO 16044 --- [Executor task launch worker for task 223] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:28.553  INFO 16044 --- [Executor task launch worker for task 223] org.apache.spark.storage.BlockManager    : Found block rdd_365_0 locally
2018-05-01 17:50:28.588  INFO 16044 --- [Executor task launch worker for task 223] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 592.0 (TID 223). 1069 bytes result sent to driver
2018-05-01 17:50:28.588  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 592.0 (TID 223) in 38 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.588  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 592.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 592 (flatMap at ALS.scala:1433) finished in 0.038 s
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 593)
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:28.589  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 593 (MapPartitionsRDD[376] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:28.590  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_90 stored as values in memory (estimated size 29.8 KB, free 1925.0 MB)
2018-05-01 17:50:28.591  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_90_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1925.0 MB)
2018-05-01 17:50:28.591  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_90_piece0 in memory on 172.21.241.193:58620 (size: 13.2 KB, free: 1925.5 MB)
2018-05-01 17:50:28.591  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 90 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.591  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 593 (MapPartitionsRDD[376] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.591  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 593.0 with 1 tasks
2018-05-01 17:50:28.593  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 593.0 (TID 224, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:28.593  INFO 16044 --- [Executor task launch worker for task 224] org.apache.spark.executor.Executor       : Running task 0.0 in stage 593.0 (TID 224)
2018-05-01 17:50:28.595  INFO 16044 --- [Executor task launch worker for task 224] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:28.595  INFO 16044 --- [Executor task launch worker for task 224] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:28.595  INFO 16044 --- [Executor task launch worker for task 224] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:28.898  INFO 16044 --- [Executor task launch worker for task 224] o.a.spark.storage.memory.MemoryStore     : Block rdd_375_0 stored as values in memory (estimated size 416.2 KB, free 1924.6 MB)
2018-05-01 17:50:28.898  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_375_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 17:50:28.900  INFO 16044 --- [Executor task launch worker for task 224] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 593.0 (TID 224). 2595 bytes result sent to driver
2018-05-01 17:50:28.901  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 593.0 (TID 224) in 308 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.901  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 593.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.902  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 593 (aggregate at ALS.scala:1491) finished in 0.308 s
2018-05-01 17:50:28.902  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 48 finished: aggregate at ALS.scala:1491, took 0.358890 s
2018-05-01 17:50:28.923  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 365 from persistence list
2018-05-01 17:50:28.923  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 365
2018-05-01 17:50:28.985  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_79_piece0 on 172.21.241.193:58620 in memory (size: 9.1 KB, free: 1925.9 MB)
2018-05-01 17:50:28.985  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:28.985  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_64_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1925.9 MB)
2018-05-01 17:50:28.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:28.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:28.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:28.986  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_75_piece0 on 172.21.241.193:58620 in memory (size: 7.8 KB, free: 1925.9 MB)
2018-05-01 17:50:28.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:28.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:28.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:28.987  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_89_piece0 on 172.21.241.193:58620 in memory (size: 12.4 KB, free: 1926.0 MB)
2018-05-01 17:50:28.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:28.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:28.988  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_84_piece0 on 172.21.241.193:58620 in memory (size: 11.1 KB, free: 1926.0 MB)
2018-05-01 17:50:28.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:28.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:28.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:28.988  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_70_piece0 on 172.21.241.193:58620 in memory (size: 6.6 KB, free: 1926.0 MB)
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_88_piece0 on 172.21.241.193:58620 in memory (size: 12.5 KB, free: 1926.0 MB)
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_67_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1926.0 MB)
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 380 (flatMap at ALS.scala:1433)
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 49 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 611 (aggregate at ALS.scala:1491)
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 610, ShuffleMapStage 598)
2018-05-01 17:50:28.992  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_76_piece0 on 172.21.241.193:58620 in memory (size: 8.6 KB, free: 1926.0 MB)
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 610)
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 610 (MapPartitionsRDD[380] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:28.992  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_83_piece0 on 172.21.241.193:58620 in memory (size: 10.4 KB, free: 1926.0 MB)
2018-05-01 17:50:28.993  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_78_piece0 on 172.21.241.193:58620 in memory (size: 9.3 KB, free: 1926.0 MB)
2018-05-01 17:50:28.993  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_77_piece0 on 172.21.241.193:58620 in memory (size: 8.4 KB, free: 1926.0 MB)
2018-05-01 17:50:28.994  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_68_piece0 on 172.21.241.193:58620 in memory (size: 5.8 KB, free: 1926.0 MB)
2018-05-01 17:50:28.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_91 stored as values in memory (estimated size 28.9 KB, free 1925.7 MB)
2018-05-01 17:50:28.995  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_85_piece0 on 172.21.241.193:58620 in memory (size: 11.0 KB, free: 1926.0 MB)
2018-05-01 17:50:28.995  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_91_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1925.8 MB)
2018-05-01 17:50:28.995  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_82_piece0 on 172.21.241.193:58620 in memory (size: 10.6 KB, free: 1926.1 MB)
2018-05-01 17:50:28.996  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_91_piece0 in memory on 172.21.241.193:58620 (size: 13.0 KB, free: 1926.0 MB)
2018-05-01 17:50:28.996  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 91 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.996  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_65_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1926.0 MB)
2018-05-01 17:50:28.996  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 610 (MapPartitionsRDD[380] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.996  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 610.0 with 1 tasks
2018-05-01 17:50:28.996  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_86_piece0 on 172.21.241.193:58620 in memory (size: 11.9 KB, free: 1926.1 MB)
2018-05-01 17:50:28.997  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 610.0 (TID 225, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:28.997  INFO 16044 --- [Executor task launch worker for task 225] org.apache.spark.executor.Executor       : Running task 0.0 in stage 610.0 (TID 225)
2018-05-01 17:50:28.997  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_74_piece0 on 172.21.241.193:58620 in memory (size: 7.9 KB, free: 1926.1 MB)
2018-05-01 17:50:28.998  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_80_piece0 on 172.21.241.193:58620 in memory (size: 9.8 KB, free: 1926.1 MB)
2018-05-01 17:50:28.999  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_73_piece0 on 172.21.241.193:58620 in memory (size: 7.1 KB, free: 1926.1 MB)
2018-05-01 17:50:28.999  INFO 16044 --- [Executor task launch worker for task 225] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:28.999  INFO 16044 --- [Executor task launch worker for task 225] org.apache.spark.storage.BlockManager    : Found block rdd_375_0 locally
2018-05-01 17:50:29.000  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_66_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:50:29.001  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_72_piece0 on 172.21.241.193:58620 in memory (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 17:50:29.002  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_81_piece0 on 172.21.241.193:58620 in memory (size: 9.7 KB, free: 1926.1 MB)
2018-05-01 17:50:29.002  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_90_piece0 on 172.21.241.193:58620 in memory (size: 13.2 KB, free: 1926.1 MB)
2018-05-01 17:50:29.002  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_87_piece0 on 172.21.241.193:58620 in memory (size: 11.7 KB, free: 1926.1 MB)
2018-05-01 17:50:29.003  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_71_piece0 on 172.21.241.193:58620 in memory (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:50:29.003  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_69_piece0 on 172.21.241.193:58620 in memory (size: 5.7 KB, free: 1926.1 MB)
2018-05-01 17:50:29.025  INFO 16044 --- [Executor task launch worker for task 225] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 610.0 (TID 225). 1069 bytes result sent to driver
2018-05-01 17:50:29.025  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 610.0 (TID 225) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.025  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 610.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 610 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 611)
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 611 (MapPartitionsRDD[386] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:29.027  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_92 stored as values in memory (estimated size 31.3 KB, free 1926.1 MB)
2018-05-01 17:50:29.028  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_92_piece0 stored as bytes in memory (estimated size 13.9 KB, free 1926.1 MB)
2018-05-01 17:50:29.028  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_92_piece0 in memory on 172.21.241.193:58620 (size: 13.9 KB, free: 1926.1 MB)
2018-05-01 17:50:29.029  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 92 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.029  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 611 (MapPartitionsRDD[386] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.029  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 611.0 with 1 tasks
2018-05-01 17:50:29.029  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 611.0 (TID 226, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:29.029  INFO 16044 --- [Executor task launch worker for task 226] org.apache.spark.executor.Executor       : Running task 0.0 in stage 611.0 (TID 226)
2018-05-01 17:50:29.032  INFO 16044 --- [Executor task launch worker for task 226] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:29.032  INFO 16044 --- [Executor task launch worker for task 226] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:29.032  INFO 16044 --- [Executor task launch worker for task 226] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:29.301  INFO 16044 --- [Executor task launch worker for task 226] o.a.spark.storage.memory.MemoryStore     : Block rdd_385_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:50:29.301  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_385_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:29.305  INFO 16044 --- [Executor task launch worker for task 226] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 611.0 (TID 226). 2595 bytes result sent to driver
2018-05-01 17:50:29.305  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 611.0 (TID 226) in 276 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.305  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 611.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.306  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 611 (aggregate at ALS.scala:1491) finished in 0.276 s
2018-05-01 17:50:29.306  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 49 finished: aggregate at ALS.scala:1491, took 0.320448 s
2018-05-01 17:50:29.320  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 375 from persistence list
2018-05-01 17:50:29.321  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 375
2018-05-01 17:50:29.325  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:29.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:29.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 390 (flatMap at ALS.scala:1433)
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 50 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 630 (aggregate at ALS.scala:1491)
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 629, ShuffleMapStage 613)
2018-05-01 17:50:29.329  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 629)
2018-05-01 17:50:29.329  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 629 (MapPartitionsRDD[390] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:29.330  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_93 stored as values in memory (estimated size 30.4 KB, free 1925.6 MB)
2018-05-01 17:50:29.332  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_93_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1925.6 MB)
2018-05-01 17:50:29.332  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_93_piece0 in memory on 172.21.241.193:58620 (size: 13.6 KB, free: 1925.7 MB)
2018-05-01 17:50:29.333  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 93 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.333  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 629 (MapPartitionsRDD[390] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.333  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 629.0 with 1 tasks
2018-05-01 17:50:29.333  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 629.0 (TID 227, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:29.333  INFO 16044 --- [Executor task launch worker for task 227] org.apache.spark.executor.Executor       : Running task 0.0 in stage 629.0 (TID 227)
2018-05-01 17:50:29.336  INFO 16044 --- [Executor task launch worker for task 227] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:29.336  INFO 16044 --- [Executor task launch worker for task 227] org.apache.spark.storage.BlockManager    : Found block rdd_385_0 locally
2018-05-01 17:50:29.365  INFO 16044 --- [Executor task launch worker for task 227] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 629.0 (TID 227). 1069 bytes result sent to driver
2018-05-01 17:50:29.365  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 629.0 (TID 227) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.365  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 629.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.365  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 629 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 630)
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 630 (MapPartitionsRDD[396] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:29.368  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_94 stored as values in memory (estimated size 32.9 KB, free 1925.6 MB)
2018-05-01 17:50:29.369  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_94_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1925.6 MB)
2018-05-01 17:50:29.369  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_94_piece0 in memory on 172.21.241.193:58620 (size: 14.6 KB, free: 1925.7 MB)
2018-05-01 17:50:29.369  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 94 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.370  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 630 (MapPartitionsRDD[396] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.370  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 630.0 with 1 tasks
2018-05-01 17:50:29.370  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 630.0 (TID 228, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:29.370  INFO 16044 --- [Executor task launch worker for task 228] org.apache.spark.executor.Executor       : Running task 0.0 in stage 630.0 (TID 228)
2018-05-01 17:50:29.372  INFO 16044 --- [Executor task launch worker for task 228] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:29.372  INFO 16044 --- [Executor task launch worker for task 228] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:29.372  INFO 16044 --- [Executor task launch worker for task 228] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:29.636  INFO 16044 --- [Executor task launch worker for task 228] o.a.spark.storage.memory.MemoryStore     : Block rdd_395_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:50:29.636  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_395_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:50:29.638  INFO 16044 --- [Executor task launch worker for task 228] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 630.0 (TID 228). 2595 bytes result sent to driver
2018-05-01 17:50:29.639  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 630.0 (TID 228) in 269 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.639  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 630.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.639  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 630 (aggregate at ALS.scala:1491) finished in 0.269 s
2018-05-01 17:50:29.639  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 50 finished: aggregate at ALS.scala:1491, took 0.314395 s
2018-05-01 17:50:29.656  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 385 from persistence list
2018-05-01 17:50:29.656  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 385
2018-05-01 17:50:29.660  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 400 (flatMap at ALS.scala:1433)
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 51 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 650 (aggregate at ALS.scala:1491)
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 649, ShuffleMapStage 635)
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 649)
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 649 (MapPartitionsRDD[400] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:29.667  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_95 stored as values in memory (estimated size 32.0 KB, free 1925.9 MB)
2018-05-01 17:50:29.669  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_95_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1925.9 MB)
2018-05-01 17:50:29.670  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_95_piece0 in memory on 172.21.241.193:58620 (size: 14.4 KB, free: 1926.1 MB)
2018-05-01 17:50:29.670  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 95 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.670  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 649 (MapPartitionsRDD[400] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.670  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 649.0 with 1 tasks
2018-05-01 17:50:29.671  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 649.0 (TID 229, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:29.671  INFO 16044 --- [Executor task launch worker for task 229] org.apache.spark.executor.Executor       : Running task 0.0 in stage 649.0 (TID 229)
2018-05-01 17:50:29.673  INFO 16044 --- [Executor task launch worker for task 229] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:29.673  INFO 16044 --- [Executor task launch worker for task 229] org.apache.spark.storage.BlockManager    : Found block rdd_395_0 locally
2018-05-01 17:50:29.699  INFO 16044 --- [Executor task launch worker for task 229] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 649.0 (TID 229). 1069 bytes result sent to driver
2018-05-01 17:50:29.700  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 649.0 (TID 229) in 30 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.700  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 649.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 649 (flatMap at ALS.scala:1433) finished in 0.030 s
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 650)
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:29.701  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 650 (MapPartitionsRDD[406] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:29.703  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_96 stored as values in memory (estimated size 34.4 KB, free 1925.9 MB)
2018-05-01 17:50:29.705  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_96_piece0 stored as bytes in memory (estimated size 15.5 KB, free 1925.9 MB)
2018-05-01 17:50:29.705  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_96_piece0 in memory on 172.21.241.193:58620 (size: 15.5 KB, free: 1926.1 MB)
2018-05-01 17:50:29.705  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 96 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.706  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 650 (MapPartitionsRDD[406] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.706  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 650.0 with 1 tasks
2018-05-01 17:50:29.706  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 650.0 (TID 230, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:29.706  INFO 16044 --- [Executor task launch worker for task 230] org.apache.spark.executor.Executor       : Running task 0.0 in stage 650.0 (TID 230)
2018-05-01 17:50:29.709  INFO 16044 --- [Executor task launch worker for task 230] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:29.709  INFO 16044 --- [Executor task launch worker for task 230] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:29.709  INFO 16044 --- [Executor task launch worker for task 230] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:30.010  INFO 16044 --- [Executor task launch worker for task 230] o.a.spark.storage.memory.MemoryStore     : Block rdd_405_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 17:50:30.010  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_405_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:30.014  INFO 16044 --- [Executor task launch worker for task 230] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 650.0 (TID 230). 2595 bytes result sent to driver
2018-05-01 17:50:30.015  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 650.0 (TID 230) in 309 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.015  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 650.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.015  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 650 (aggregate at ALS.scala:1491) finished in 0.309 s
2018-05-01 17:50:30.016  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 51 finished: aggregate at ALS.scala:1491, took 0.355234 s
2018-05-01 17:50:30.040  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 395 from persistence list
2018-05-01 17:50:30.040  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 395
2018-05-01 17:50:30.047  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:30.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:30.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:30.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:30.049  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:30.049  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:30.049  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:30.049  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:30.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:30.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:30.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:30.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:30.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:30.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 410 (flatMap at ALS.scala:1433)
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 52 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 671 (aggregate at ALS.scala:1491)
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 670, ShuffleMapStage 652)
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 670)
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 670 (MapPartitionsRDD[410] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:30.057  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_97 stored as values in memory (estimated size 33.5 KB, free 1925.4 MB)
2018-05-01 17:50:30.058  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_97_piece0 stored as bytes in memory (estimated size 15.3 KB, free 1925.4 MB)
2018-05-01 17:50:30.058  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_97_piece0 in memory on 172.21.241.193:58620 (size: 15.3 KB, free: 1925.7 MB)
2018-05-01 17:50:30.059  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 97 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.059  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 670 (MapPartitionsRDD[410] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.059  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 670.0 with 1 tasks
2018-05-01 17:50:30.059  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 670.0 (TID 231, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:30.060  INFO 16044 --- [Executor task launch worker for task 231] org.apache.spark.executor.Executor       : Running task 0.0 in stage 670.0 (TID 231)
2018-05-01 17:50:30.062  INFO 16044 --- [Executor task launch worker for task 231] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:30.063  INFO 16044 --- [Executor task launch worker for task 231] org.apache.spark.storage.BlockManager    : Found block rdd_405_0 locally
2018-05-01 17:50:30.109  INFO 16044 --- [Executor task launch worker for task 231] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 670.0 (TID 231). 1069 bytes result sent to driver
2018-05-01 17:50:30.109  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 670.0 (TID 231) in 50 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.109  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 670.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.109  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 670 (flatMap at ALS.scala:1433) finished in 0.050 s
2018-05-01 17:50:30.109  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:30.110  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:30.110  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 671)
2018-05-01 17:50:30.110  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:30.110  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 671 (MapPartitionsRDD[416] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:30.112  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_98 stored as values in memory (estimated size 36.0 KB, free 1925.4 MB)
2018-05-01 17:50:30.113  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_98_piece0 stored as bytes in memory (estimated size 16.3 KB, free 1925.4 MB)
2018-05-01 17:50:30.113  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_98_piece0 in memory on 172.21.241.193:58620 (size: 16.3 KB, free: 1925.6 MB)
2018-05-01 17:50:30.113  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 98 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.113  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 671 (MapPartitionsRDD[416] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.113  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 671.0 with 1 tasks
2018-05-01 17:50:30.114  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 671.0 (TID 232, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:30.114  INFO 16044 --- [Executor task launch worker for task 232] org.apache.spark.executor.Executor       : Running task 0.0 in stage 671.0 (TID 232)
2018-05-01 17:50:30.117  INFO 16044 --- [Executor task launch worker for task 232] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:30.117  INFO 16044 --- [Executor task launch worker for task 232] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:30.117  INFO 16044 --- [Executor task launch worker for task 232] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:30.377  INFO 16044 --- [Executor task launch worker for task 232] o.a.spark.storage.memory.MemoryStore     : Block rdd_415_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 17:50:30.377  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_415_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:50:30.379  INFO 16044 --- [Executor task launch worker for task 232] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 671.0 (TID 232). 2595 bytes result sent to driver
2018-05-01 17:50:30.379  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 671.0 (TID 232) in 265 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.379  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 671.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.379  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 671 (aggregate at ALS.scala:1491) finished in 0.266 s
2018-05-01 17:50:30.380  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 52 finished: aggregate at ALS.scala:1491, took 0.332560 s
2018-05-01 17:50:30.394  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 405 from persistence list
2018-05-01 17:50:30.394  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 405
2018-05-01 17:50:30.398  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:30.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:30.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:30.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:30.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:30.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:30.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:30.404  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 420 (flatMap at ALS.scala:1433)
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 53 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 693 (aggregate at ALS.scala:1491)
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 673, ShuffleMapStage 692)
2018-05-01 17:50:30.407  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 692)
2018-05-01 17:50:30.407  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 692 (MapPartitionsRDD[420] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:30.409  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_99 stored as values in memory (estimated size 35.1 KB, free 1925.7 MB)
2018-05-01 17:50:30.409  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_99_piece0 stored as bytes in memory (estimated size 15.9 KB, free 1925.7 MB)
2018-05-01 17:50:30.410  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_99_piece0 in memory on 172.21.241.193:58620 (size: 15.9 KB, free: 1926.0 MB)
2018-05-01 17:50:30.410  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 99 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.410  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 692 (MapPartitionsRDD[420] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.410  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 692.0 with 1 tasks
2018-05-01 17:50:30.411  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 692.0 (TID 233, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:30.411  INFO 16044 --- [Executor task launch worker for task 233] org.apache.spark.executor.Executor       : Running task 0.0 in stage 692.0 (TID 233)
2018-05-01 17:50:30.413  INFO 16044 --- [Executor task launch worker for task 233] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:30.413  INFO 16044 --- [Executor task launch worker for task 233] org.apache.spark.storage.BlockManager    : Found block rdd_415_0 locally
2018-05-01 17:50:30.438  INFO 16044 --- [Executor task launch worker for task 233] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 692.0 (TID 233). 1112 bytes result sent to driver
2018-05-01 17:50:30.438  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 692.0 (TID 233) in 27 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.438  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 692.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 692 (flatMap at ALS.scala:1433) finished in 0.028 s
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 693)
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:30.439  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 693 (MapPartitionsRDD[426] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:30.440  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_100 stored as values in memory (estimated size 37.5 KB, free 1925.7 MB)
2018-05-01 17:50:30.441  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_100_piece0 stored as bytes in memory (estimated size 16.9 KB, free 1925.7 MB)
2018-05-01 17:50:30.442  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_100_piece0 in memory on 172.21.241.193:58620 (size: 16.9 KB, free: 1926.0 MB)
2018-05-01 17:50:30.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 100 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 693 (MapPartitionsRDD[426] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.442  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 693.0 with 1 tasks
2018-05-01 17:50:30.443  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 693.0 (TID 234, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:30.443  INFO 16044 --- [Executor task launch worker for task 234] org.apache.spark.executor.Executor       : Running task 0.0 in stage 693.0 (TID 234)
2018-05-01 17:50:30.445  INFO 16044 --- [Executor task launch worker for task 234] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:30.445  INFO 16044 --- [Executor task launch worker for task 234] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:30.445  INFO 16044 --- [Executor task launch worker for task 234] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:30.714  INFO 16044 --- [Executor task launch worker for task 234] o.a.spark.storage.memory.MemoryStore     : Block rdd_425_0 stored as values in memory (estimated size 820.5 KB, free 1924.9 MB)
2018-05-01 17:50:30.714  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_425_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:50:30.718  INFO 16044 --- [Executor task launch worker for task 234] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 693.0 (TID 234). 2595 bytes result sent to driver
2018-05-01 17:50:30.719  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 693.0 (TID 234) in 277 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.719  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 693.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.719  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 693 (aggregate at ALS.scala:1491) finished in 0.277 s
2018-05-01 17:50:30.719  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 53 finished: aggregate at ALS.scala:1491, took 0.320889 s
2018-05-01 17:50:30.736  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 415 from persistence list
2018-05-01 17:50:30.736  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 415
2018-05-01 17:50:30.741  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:30.741  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:30.744  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:30.745  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:30.747  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 44 is 150 bytes
2018-05-01 17:50:30.747  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 430 (flatMap at ALS.scala:1433)
2018-05-01 17:50:30.748  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 54 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:30.748  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 716 (aggregate at ALS.scala:1491)
2018-05-01 17:50:30.748  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 695, ShuffleMapStage 715)
2018-05-01 17:50:30.749  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 715)
2018-05-01 17:50:30.749  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 715 (MapPartitionsRDD[430] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:30.752  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_101 stored as values in memory (estimated size 36.6 KB, free 1925.2 MB)
2018-05-01 17:50:30.753  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_101_piece0 stored as bytes in memory (estimated size 16.6 KB, free 1925.2 MB)
2018-05-01 17:50:30.753  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_101_piece0 in memory on 172.21.241.193:58620 (size: 16.6 KB, free: 1925.6 MB)
2018-05-01 17:50:30.753  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 101 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.753  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 715 (MapPartitionsRDD[430] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.753  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 715.0 with 1 tasks
2018-05-01 17:50:30.754  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 715.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:30.754  INFO 16044 --- [Executor task launch worker for task 235] org.apache.spark.executor.Executor       : Running task 0.0 in stage 715.0 (TID 235)
2018-05-01 17:50:30.756  INFO 16044 --- [Executor task launch worker for task 235] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:30.756  INFO 16044 --- [Executor task launch worker for task 235] org.apache.spark.storage.BlockManager    : Found block rdd_425_0 locally
2018-05-01 17:50:30.789  INFO 16044 --- [Executor task launch worker for task 235] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 715.0 (TID 235). 1069 bytes result sent to driver
2018-05-01 17:50:30.790  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 715.0 (TID 235) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.790  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 715.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 715 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 716)
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:30.791  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 716 (MapPartitionsRDD[436] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:30.792  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_102 stored as values in memory (estimated size 39.1 KB, free 1925.2 MB)
2018-05-01 17:50:30.793  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_102_piece0 stored as bytes in memory (estimated size 17.6 KB, free 1925.2 MB)
2018-05-01 17:50:30.793  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_102_piece0 in memory on 172.21.241.193:58620 (size: 17.6 KB, free: 1925.6 MB)
2018-05-01 17:50:30.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 102 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 716 (MapPartitionsRDD[436] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.794  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 716.0 with 1 tasks
2018-05-01 17:50:30.794  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 716.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:30.794  INFO 16044 --- [Executor task launch worker for task 236] org.apache.spark.executor.Executor       : Running task 0.0 in stage 716.0 (TID 236)
2018-05-01 17:50:30.797  INFO 16044 --- [Executor task launch worker for task 236] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:30.797  INFO 16044 --- [Executor task launch worker for task 236] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:30.797  INFO 16044 --- [Executor task launch worker for task 236] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:31.070  INFO 16044 --- [Executor task launch worker for task 236] o.a.spark.storage.memory.MemoryStore     : Block rdd_435_0 stored as values in memory (estimated size 416.2 KB, free 1924.8 MB)
2018-05-01 17:50:31.070  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_435_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:50:31.072  INFO 16044 --- [Executor task launch worker for task 236] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 716.0 (TID 236). 2595 bytes result sent to driver
2018-05-01 17:50:31.072  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 716.0 (TID 236) in 278 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.072  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 716.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.073  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 716 (aggregate at ALS.scala:1491) finished in 0.278 s
2018-05-01 17:50:31.073  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 54 finished: aggregate at ALS.scala:1491, took 0.331969 s
2018-05-01 17:50:31.097  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 425 from persistence list
2018-05-01 17:50:31.097  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 425
2018-05-01 17:50:31.103  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:31.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:31.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:31.106  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:31.106  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:31.106  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 44 is 150 bytes
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 45 is 150 bytes
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 440 (flatMap at ALS.scala:1433)
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 55 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 740 (aggregate at ALS.scala:1491)
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 739, ShuffleMapStage 718)
2018-05-01 17:50:31.109  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 739)
2018-05-01 17:50:31.109  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 739 (MapPartitionsRDD[440] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:31.111  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_103 stored as values in memory (estimated size 38.2 KB, free 1925.5 MB)
2018-05-01 17:50:31.112  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_103_piece0 stored as bytes in memory (estimated size 17.2 KB, free 1925.5 MB)
2018-05-01 17:50:31.112  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_103_piece0 in memory on 172.21.241.193:58620 (size: 17.2 KB, free: 1926.0 MB)
2018-05-01 17:50:31.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 103 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 739 (MapPartitionsRDD[440] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.112  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 739.0 with 1 tasks
2018-05-01 17:50:31.113  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 739.0 (TID 237, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:31.113  INFO 16044 --- [Executor task launch worker for task 237] org.apache.spark.executor.Executor       : Running task 0.0 in stage 739.0 (TID 237)
2018-05-01 17:50:31.115  INFO 16044 --- [Executor task launch worker for task 237] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:31.115  INFO 16044 --- [Executor task launch worker for task 237] org.apache.spark.storage.BlockManager    : Found block rdd_435_0 locally
2018-05-01 17:50:31.141  INFO 16044 --- [Executor task launch worker for task 237] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 739.0 (TID 237). 1069 bytes result sent to driver
2018-05-01 17:50:31.142  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 739.0 (TID 237) in 29 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.142  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 739.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 739 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 740)
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 740 (MapPartitionsRDD[446] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:31.144  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_104 stored as values in memory (estimated size 40.6 KB, free 1925.5 MB)
2018-05-01 17:50:31.145  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_104_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1925.5 MB)
2018-05-01 17:50:31.145  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_104_piece0 in memory on 172.21.241.193:58620 (size: 18.2 KB, free: 1925.9 MB)
2018-05-01 17:50:31.145  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 104 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.146  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 740 (MapPartitionsRDD[446] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.146  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 740.0 with 1 tasks
2018-05-01 17:50:31.146  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 740.0 (TID 238, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:31.146  INFO 16044 --- [Executor task launch worker for task 238] org.apache.spark.executor.Executor       : Running task 0.0 in stage 740.0 (TID 238)
2018-05-01 17:50:31.148  INFO 16044 --- [Executor task launch worker for task 238] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:31.149  INFO 16044 --- [Executor task launch worker for task 238] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:31.149  INFO 16044 --- [Executor task launch worker for task 238] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:31.415  INFO 16044 --- [Executor task launch worker for task 238] o.a.spark.storage.memory.MemoryStore     : Block rdd_445_0 stored as values in memory (estimated size 820.5 KB, free 1924.7 MB)
2018-05-01 17:50:31.415  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_445_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:50:31.419  INFO 16044 --- [Executor task launch worker for task 238] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 740.0 (TID 238). 2595 bytes result sent to driver
2018-05-01 17:50:31.419  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 740.0 (TID 238) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.419  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 740.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.420  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 740 (aggregate at ALS.scala:1491) finished in 0.274 s
2018-05-01 17:50:31.420  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 55 finished: aggregate at ALS.scala:1491, took 0.316564 s
2018-05-01 17:50:31.437  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 435 from persistence list
2018-05-01 17:50:31.437  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 435
2018-05-01 17:50:31.453  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:279
2018-05-01 17:50:31.453  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 44 is 150 bytes
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 45 is 150 bytes
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 46 is 150 bytes
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 450 (flatMap at ALS.scala:1433)
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 56 (count at ALS.scala:279) with 1 output partitions
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 765 (count at ALS.scala:279)
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 742, ShuffleMapStage 764)
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 764)
2018-05-01 17:50:31.459  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 764 (MapPartitionsRDD[450] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:31.461  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_105 stored as values in memory (estimated size 39.7 KB, free 1925.0 MB)
2018-05-01 17:50:31.461  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_105_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1925.0 MB)
2018-05-01 17:50:31.462  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_105_piece0 in memory on 172.21.241.193:58620 (size: 18.0 KB, free: 1925.5 MB)
2018-05-01 17:50:31.462  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 105 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.462  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 764 (MapPartitionsRDD[450] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.462  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 764.0 with 1 tasks
2018-05-01 17:50:31.463  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 764.0 (TID 239, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:31.463  INFO 16044 --- [Executor task launch worker for task 239] org.apache.spark.executor.Executor       : Running task 0.0 in stage 764.0 (TID 239)
2018-05-01 17:50:31.465  INFO 16044 --- [Executor task launch worker for task 239] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:31.465  INFO 16044 --- [Executor task launch worker for task 239] org.apache.spark.storage.BlockManager    : Found block rdd_445_0 locally
2018-05-01 17:50:31.495  INFO 16044 --- [Executor task launch worker for task 239] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 764.0 (TID 239). 1112 bytes result sent to driver
2018-05-01 17:50:31.495  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 764.0 (TID 239) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.496  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 764.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 764 (flatMap at ALS.scala:1433) finished in 0.034 s
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 765)
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 765 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:50:31.498  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_106 stored as values in memory (estimated size 41.6 KB, free 1925.0 MB)
2018-05-01 17:50:31.499  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_106_piece0 stored as bytes in memory (estimated size 18.6 KB, free 1924.9 MB)
2018-05-01 17:50:31.499  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_106_piece0 in memory on 172.21.241.193:58620 (size: 18.6 KB, free: 1925.5 MB)
2018-05-01 17:50:31.500  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 106 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.500  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 765 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.500  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 765.0 with 1 tasks
2018-05-01 17:50:31.500  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 765.0 (TID 240, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.500  INFO 16044 --- [Executor task launch worker for task 240] org.apache.spark.executor.Executor       : Running task 0.0 in stage 765.0 (TID 240)
2018-05-01 17:50:31.503  INFO 16044 --- [Executor task launch worker for task 240] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:31.503  INFO 16044 --- [Executor task launch worker for task 240] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:31.504  INFO 16044 --- [Executor task launch worker for task 240] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:31.504  INFO 16044 --- [Executor task launch worker for task 240] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:50:31.827  INFO 16044 --- [Executor task launch worker for task 240] o.a.spark.storage.memory.MemoryStore     : Block rdd_466_0 stored as values in memory (estimated size 970.8 KB, free 1924.0 MB)
2018-05-01 17:50:31.828  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_466_0 in memory on 172.21.241.193:58620 (size: 970.8 KB, free: 1924.6 MB)
2018-05-01 17:50:31.829  INFO 16044 --- [Executor task launch worker for task 240] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 765.0 (TID 240). 1873 bytes result sent to driver
2018-05-01 17:50:31.829  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 765.0 (TID 240) in 329 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.829  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 765.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.829  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 765 (count at ALS.scala:279) finished in 0.329 s
2018-05-01 17:50:31.829  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 56 finished: count at ALS.scala:279, took 0.376742 s
2018-05-01 17:50:31.831  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:280
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:31.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:31.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:31.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 44 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 45 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 46 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 57 (count at ALS.scala:280) with 1 output partitions
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 789 (count at ALS.scala:280)
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 767, ShuffleMapStage 788)
2018-05-01 17:50:31.838  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:31.838  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 789 (products MapPartitionsRDD[467] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:50:31.840  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_107 stored as values in memory (estimated size 40.1 KB, free 1924.0 MB)
2018-05-01 17:50:31.841  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_107_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1923.9 MB)
2018-05-01 17:50:31.841  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_107_piece0 in memory on 172.21.241.193:58620 (size: 18.0 KB, free: 1924.5 MB)
2018-05-01 17:50:31.841  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 107 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.841  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 789 (products MapPartitionsRDD[467] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.841  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 789.0 with 1 tasks
2018-05-01 17:50:31.842  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 789.0 (TID 241, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.842  INFO 16044 --- [Executor task launch worker for task 241] org.apache.spark.executor.Executor       : Running task 0.0 in stage 789.0 (TID 241)
2018-05-01 17:50:31.844  INFO 16044 --- [Executor task launch worker for task 241] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:31.844  INFO 16044 --- [Executor task launch worker for task 241] org.apache.spark.storage.BlockManager    : Found block rdd_445_0 locally
2018-05-01 17:50:31.940  INFO 16044 --- [Executor task launch worker for task 241] o.a.spark.storage.memory.MemoryStore     : Block rdd_467_0 stored as values in memory (estimated size 1914.2 KB, free 1922.1 MB)
2018-05-01 17:50:31.941  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_467_0 in memory on 172.21.241.193:58620 (size: 1914.2 KB, free: 1922.7 MB)
2018-05-01 17:50:31.942  INFO 16044 --- [Executor task launch worker for task 241] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 789.0 (TID 241). 1615 bytes result sent to driver
2018-05-01 17:50:31.942  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 789.0 (TID 241) in 100 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.942  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 789.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.943  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 789 (count at ALS.scala:280) finished in 0.101 s
2018-05-01 17:50:31.943  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 57 finished: count at ALS.scala:280, took 0.111142 s
2018-05-01 17:50:31.949  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 47 is 150 bytes
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 58 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 814 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 791, ShuffleMapStage 813)
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 814 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:50:31.953  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_108 stored as values in memory (estimated size 41.8 KB, free 1922.0 MB)
2018-05-01 17:50:31.954  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_108_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1922.0 MB)
2018-05-01 17:50:31.954  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_108_piece0 in memory on 172.21.241.193:58620 (size: 18.7 KB, free: 1922.7 MB)
2018-05-01 17:50:31.955  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 108 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.955  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 814 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.955  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 814.0 with 1 tasks
2018-05-01 17:50:31.955  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 814.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.956  INFO 16044 --- [Executor task launch worker for task 242] org.apache.spark.executor.Executor       : Running task 0.0 in stage 814.0 (TID 242)
2018-05-01 17:50:31.959  INFO 16044 --- [Executor task launch worker for task 242] org.apache.spark.storage.BlockManager    : Found block rdd_466_0 locally
2018-05-01 17:50:31.959  INFO 16044 --- [Executor task launch worker for task 242] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 242:
[rdd_466_0]
2018-05-01 17:50:31.959  INFO 16044 --- [Executor task launch worker for task 242] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 814.0 (TID 242). 909 bytes result sent to driver
2018-05-01 17:50:31.960  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 814.0 (TID 242) in 5 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.960  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 814.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.960  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 814 (first at MatrixFactorizationModel.scala:67) finished in 0.005 s
2018-05-01 17:50:31.960  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 58 finished: first at MatrixFactorizationModel.scala:67, took 0.011147 s
2018-05-01 17:50:31.970  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 59 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 838 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 837, ShuffleMapStage 816)
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 838 (products MapPartitionsRDD[467] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:50:31.975  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_109 stored as values in memory (estimated size 40.2 KB, free 1922.0 MB)
2018-05-01 17:50:31.976  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_109_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1922.0 MB)
2018-05-01 17:50:31.977  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_109_piece0 in memory on 172.21.241.193:58620 (size: 18.1 KB, free: 1922.6 MB)
2018-05-01 17:50:31.977  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 109 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.978  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 838 (products MapPartitionsRDD[467] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.978  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 838.0 with 1 tasks
2018-05-01 17:50:31.978  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 838.0 (TID 243, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.978  INFO 16044 --- [Executor task launch worker for task 243] org.apache.spark.executor.Executor       : Running task 0.0 in stage 838.0 (TID 243)
2018-05-01 17:50:31.982  INFO 16044 --- [Executor task launch worker for task 243] org.apache.spark.storage.BlockManager    : Found block rdd_467_0 locally
2018-05-01 17:50:31.982  INFO 16044 --- [Executor task launch worker for task 243] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 243:
[rdd_467_0]
2018-05-01 17:50:31.982  INFO 16044 --- [Executor task launch worker for task 243] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 838.0 (TID 243). 952 bytes result sent to driver
2018-05-01 17:50:31.983  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 838.0 (TID 243) in 5 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.983  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 838.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.983  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 838 (first at MatrixFactorizationModel.scala:67) finished in 0.005 s
2018-05-01 17:50:31.984  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 59 finished: first at MatrixFactorizationModel.scala:67, took 0.013525 s
2018-05-01 17:50:31.988  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: lookup at MatrixFactorizationModel.scala:168
2018-05-01 17:50:31.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 60 (lookup at MatrixFactorizationModel.scala:168) with 1 output partitions
2018-05-01 17:50:31.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 863 (lookup at MatrixFactorizationModel.scala:168)
2018-05-01 17:50:31.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 840, ShuffleMapStage 862)
2018-05-01 17:50:31.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:31.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 863 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:50:31.993  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_110 stored as values in memory (estimated size 41.9 KB, free 1921.9 MB)
2018-05-01 17:50:31.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_110_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1921.9 MB)
2018-05-01 17:50:31.995  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_110_piece0 in memory on 172.21.241.193:58620 (size: 18.8 KB, free: 1922.6 MB)
2018-05-01 17:50:31.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 110 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 863 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.995  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 863.0 with 1 tasks
2018-05-01 17:50:31.995  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 863.0 (TID 244, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.996  INFO 16044 --- [Executor task launch worker for task 244] org.apache.spark.executor.Executor       : Running task 0.0 in stage 863.0 (TID 244)
2018-05-01 17:50:32.000  INFO 16044 --- [Executor task launch worker for task 244] org.apache.spark.storage.BlockManager    : Found block rdd_466_0 locally
2018-05-01 17:50:32.002  INFO 16044 --- [Executor task launch worker for task 244] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 863.0 (TID 244). 942 bytes result sent to driver
2018-05-01 17:50:32.002  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 863.0 (TID 244) in 7 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:32.002  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 863.0, whose tasks have all completed, from pool 
2018-05-01 17:50:32.003  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 863 (lookup at MatrixFactorizationModel.scala:168) finished in 0.008 s
2018-05-01 17:50:32.003  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 60 finished: lookup at MatrixFactorizationModel.scala:168, took 0.015101 s
2018-05-01 17:50:32.010  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: top at MatrixFactorizationModel.scala:259
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 61 (top at MatrixFactorizationModel.scala:259) with 1 output partitions
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 887 (top at MatrixFactorizationModel.scala:259)
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 865, ShuffleMapStage 886)
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 887 (MapPartitionsRDD[469] at top at MatrixFactorizationModel.scala:259), which has no missing parents
2018-05-01 17:50:32.014  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_111 stored as values in memory (estimated size 41.2 KB, free 1921.9 MB)
2018-05-01 17:50:32.015  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_111_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1921.8 MB)
2018-05-01 17:50:32.015  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_111_piece0 in memory on 172.21.241.193:58620 (size: 18.7 KB, free: 1922.6 MB)
2018-05-01 17:50:32.016  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 111 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:32.016  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 887 (MapPartitionsRDD[469] at top at MatrixFactorizationModel.scala:259) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:32.016  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 887.0 with 1 tasks
2018-05-01 17:50:32.016  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 887.0 (TID 245, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:32.016  INFO 16044 --- [Executor task launch worker for task 245] org.apache.spark.executor.Executor       : Running task 0.0 in stage 887.0 (TID 245)
2018-05-01 17:50:32.018  INFO 16044 --- [Executor task launch worker for task 245] org.apache.spark.storage.BlockManager    : Found block rdd_467_0 locally
2018-05-01 17:50:32.022  INFO 16044 --- [Executor task launch worker for task 245] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 887.0 (TID 245). 1566 bytes result sent to driver
2018-05-01 17:50:32.022  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 887.0 (TID 245) in 6 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:32.022  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 887.0, whose tasks have all completed, from pool 
2018-05-01 17:50:32.022  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 887 (top at MatrixFactorizationModel.scala:259) finished in 0.006 s
2018-05-01 17:50:32.023  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 61 finished: top at MatrixFactorizationModel.scala:259, took 0.012563 s
2018-05-01 17:50:32.023  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Recommendations for1
2018-05-01 17:50:32.023  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1214-- Rating : 0.9971559840534798
2018-05-01 17:50:32.026  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1200-- Rating : 0.9553528808073415
2018-05-01 17:50:32.028  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 541-- Rating : 0.9435799010918857
2018-05-01 17:50:32.031  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1196-- Rating : 0.9396974110427829
2018-05-01 17:50:32.033  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 2571-- Rating : 0.9150071477153301
2018-05-01 17:51:08.656  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:56:08.657  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:01:08.658  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:06:08.661  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:10:06.909  WARN 16044 --- [http-nio-3333-exec-5] o.apache.spark.sql.SparkSession$Builder  : Using an existing SparkSession; some configuration may not take effect.
2018-05-01 18:10:06.910  INFO 16044 --- [http-nio-3333-exec-5] o.a.spark.storage.memory.MemoryStore     : Block broadcast_112 stored as values in memory (estimated size 248.0 B, free 1921.8 MB)
2018-05-01 18:10:06.913  INFO 16044 --- [http-nio-3333-exec-5] o.a.spark.storage.memory.MemoryStore     : Block broadcast_112_piece0 stored as bytes in memory (estimated size 419.0 B, free 1921.8 MB)
2018-05-01 18:10:06.914  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_112_piece0 in memory on 172.21.241.193:58620 (size: 419.0 B, free: 1922.6 MB)
2018-05-01 18:10:06.915  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Created broadcast 112 from broadcast at MongoSpark.scala:536
2018-05-01 18:10:06.919  INFO 16044 --- [http-nio-3333-exec-5] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 18:10:06.920  INFO 16044 --- [http-nio-3333-exec-5] org.mongodb.driver.cluster               : Cluster description not yet available. Waiting for 30000 ms before timing out
2018-05-01 18:10:06.929  INFO 16044 --- [cluster-ClusterId{value='5ae8834eb11f8e3eac338e35', description='null'}-127.0.0.1:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:7, serverValue:36}] to 127.0.0.1:27017
2018-05-01 18:10:06.929  INFO 16044 --- [cluster-ClusterId{value='5ae8834eb11f8e3eac338e35', description='null'}-127.0.0.1:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=100346}
2018-05-01 18:10:06.930  INFO 16044 --- [http-nio-3333-exec-5] c.m.spark.connection.MongoClientCache    : Creating MongoClient: [127.0.0.1:27017]
2018-05-01 18:10:06.932  INFO 16044 --- [http-nio-3333-exec-5] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:8, serverValue:37}] to 127.0.0.1:27017
2018-05-01 18:10:07.989  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: collect at RecomendationServiceImpl.java:86
2018-05-01 18:10:07.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 62 (collect at RecomendationServiceImpl.java:86) with 66 output partitions
2018-05-01 18:10:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 888 (collect at RecomendationServiceImpl.java:86)
2018-05-01 18:10:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 18:10:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:10:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 888 (MapPartitionsRDD[471] at map at RecomendationServiceImpl.java:83), which has no missing parents
2018-05-01 18:10:07.993  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_113 stored as values in memory (estimated size 7.0 KB, free 1921.8 MB)
2018-05-01 18:10:07.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1921.8 MB)
2018-05-01 18:10:07.994  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_113_piece0 in memory on 172.21.241.193:58620 (size: 3.6 KB, free: 1922.6 MB)
2018-05-01 18:10:07.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 113 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:10:07.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 66 missing tasks from ResultStage 888 (MapPartitionsRDD[471] at map at RecomendationServiceImpl.java:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-05-01 18:10:07.995  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 888.0 with 66 tasks
2018-05-01 18:10:07.996  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 888.0 (TID 246, localhost, executor driver, partition 0, ANY, 4987 bytes)
2018-05-01 18:10:07.996  INFO 16044 --- [Executor task launch worker for task 246] org.apache.spark.executor.Executor       : Running task 0.0 in stage 888.0 (TID 246)
2018-05-01 18:10:07.999  INFO 16044 --- [Executor task launch worker for task 246] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 888.0 (TID 246). 622 bytes result sent to driver
2018-05-01 18:10:07.999  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 888.0 (TID 247, localhost, executor driver, partition 1, ANY, 4999 bytes)
2018-05-01 18:10:07.999  INFO 16044 --- [Executor task launch worker for task 247] org.apache.spark.executor.Executor       : Running task 1.0 in stage 888.0 (TID 247)
2018-05-01 18:10:07.999  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 888.0 (TID 246) in 4 ms on localhost (executor driver) (1/66)
2018-05-01 18:10:08.640  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 254
2018-05-01 18:10:08.641  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 254
2018-05-01 18:10:08.641  INFO 16044 --- [block-manager-slave-async-thread-pool-11] org.apache.spark.storage.BlockManager    : Removing RDD 435
2018-05-01 18:10:08.642  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 435
2018-05-01 18:10:08.643  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 45
2018-05-01 18:10:08.643  INFO 16044 --- [block-manager-slave-async-thread-pool-10] org.apache.spark.storage.BlockManager    : Removing RDD 335
2018-05-01 18:10:08.644  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 335
2018-05-01 18:10:08.644  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 30
2018-05-01 18:10:08.644  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 38
2018-05-01 18:10:08.644  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 42
2018-05-01 18:10:08.645  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 295
2018-05-01 18:10:08.646  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 295
2018-05-01 18:10:08.646  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_92_piece0 on 172.21.241.193:58620 in memory (size: 13.9 KB, free: 1922.6 MB)
2018-05-01 18:10:08.647  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 36
2018-05-01 18:10:08.647  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_95_piece0 on 172.21.241.193:58620 in memory (size: 14.4 KB, free: 1922.6 MB)
2018-05-01 18:10:08.647  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 24
2018-05-01 18:10:08.648  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_98_piece0 on 172.21.241.193:58620 in memory (size: 16.3 KB, free: 1922.6 MB)
2018-05-01 18:10:08.649  INFO 16044 --- [block-manager-slave-async-thread-pool-16] org.apache.spark.storage.BlockManager    : Removing RDD 460
2018-05-01 18:10:08.649  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 460
2018-05-01 18:10:08.649  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 41
2018-05-01 18:10:08.651  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_105_piece0 on 172.21.241.193:58620 in memory (size: 18.0 KB, free: 1922.7 MB)
2018-05-01 18:10:08.651  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_94_piece0 on 172.21.241.193:58620 in memory (size: 14.6 KB, free: 1922.7 MB)
2018-05-01 18:10:08.652  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 37
2018-05-01 18:10:08.652  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_99_piece0 on 172.21.241.193:58620 in memory (size: 15.9 KB, free: 1922.7 MB)
2018-05-01 18:10:08.653  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_106_piece0 on 172.21.241.193:58620 in memory (size: 18.6 KB, free: 1922.7 MB)
2018-05-01 18:10:08.653  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 325
2018-05-01 18:10:08.653  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 325
2018-05-01 18:10:08.653  INFO 16044 --- [block-manager-slave-async-thread-pool-15] org.apache.spark.storage.BlockManager    : Removing RDD 395
2018-05-01 18:10:08.654  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 395
2018-05-01 18:10:08.654  INFO 16044 --- [block-manager-slave-async-thread-pool-14] org.apache.spark.storage.BlockManager    : Removing RDD 253
2018-05-01 18:10:08.654  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 253
2018-05-01 18:10:08.654  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_104_piece0 on 172.21.241.193:58620 in memory (size: 18.2 KB, free: 1922.8 MB)
2018-05-01 18:10:08.655  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 43
2018-05-01 18:10:08.656  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_108_piece0 on 172.21.241.193:58620 in memory (size: 18.7 KB, free: 1922.8 MB)
2018-05-01 18:10:08.656  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 305
2018-05-01 18:10:08.656  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 305
2018-05-01 18:10:08.658  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 39
2018-05-01 18:10:08.658  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 40
2018-05-01 18:10:08.658  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 26
2018-05-01 18:10:08.658  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 44
2018-05-01 18:10:08.658  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 47
2018-05-01 18:10:08.658  INFO 16044 --- [block-manager-slave-async-thread-pool-15] org.apache.spark.storage.BlockManager    : Removing RDD 355
2018-05-01 18:10:08.659  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 355
2018-05-01 18:10:08.659  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 25
2018-05-01 18:10:08.659  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 29
2018-05-01 18:10:08.659  INFO 16044 --- [block-manager-slave-async-thread-pool-15] org.apache.spark.storage.BlockManager    : Removing RDD 465
2018-05-01 18:10:08.660  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 465
2018-05-01 18:10:08.660  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_111_piece0 on 172.21.241.193:58620 in memory (size: 18.7 KB, free: 1922.8 MB)
2018-05-01 18:10:08.661  INFO 16044 --- [block-manager-slave-async-thread-pool-17] org.apache.spark.storage.BlockManager    : Removing RDD 252
2018-05-01 18:10:08.661  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 252
2018-05-01 18:10:08.661  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 35
2018-05-01 18:10:08.662  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_110_piece0 on 172.21.241.193:58620 in memory (size: 18.8 KB, free: 1930.9 MB)
2018-05-01 18:10:08.662  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_91_piece0 on 172.21.241.193:58620 in memory (size: 13.0 KB, free: 1930.9 MB)
2018-05-01 18:10:08.663  INFO 16044 --- [block-manager-slave-async-thread-pool-15] org.apache.spark.storage.BlockManager    : Removing RDD 265
2018-05-01 18:10:08.663  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 265
2018-05-01 18:10:08.663  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 34
2018-05-01 18:10:08.663  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_93_piece0 on 172.21.241.193:58620 in memory (size: 13.6 KB, free: 1931.0 MB)
2018-05-01 18:10:08.664  INFO 16044 --- [block-manager-slave-async-thread-pool-15] org.apache.spark.storage.BlockManager    : Removing RDD 365
2018-05-01 18:10:08.664  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 365
2018-05-01 18:10:08.665  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_100_piece0 on 172.21.241.193:58620 in memory (size: 16.9 KB, free: 1931.0 MB)
2018-05-01 18:10:08.665  INFO 16044 --- [block-manager-slave-async-thread-pool-15] org.apache.spark.storage.BlockManager    : Removing RDD 385
2018-05-01 18:10:08.665  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 385
2018-05-01 18:10:08.666  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 285
2018-05-01 18:10:08.666  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 285
2018-05-01 18:10:08.666  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 315
2018-05-01 18:10:08.667  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 315
2018-05-01 18:10:08.667  INFO 16044 --- [block-manager-slave-async-thread-pool-17] org.apache.spark.storage.BlockManager    : Removing RDD 466
2018-05-01 18:10:08.667  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 466
2018-05-01 18:10:08.668  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_96_piece0 on 172.21.241.193:58620 in memory (size: 15.5 KB, free: 1931.9 MB)
2018-05-01 18:10:08.668  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 32
2018-05-01 18:10:08.668  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 31
2018-05-01 18:10:08.668  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 405
2018-05-01 18:10:08.668  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 405
2018-05-01 18:10:08.669  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_101_piece0 on 172.21.241.193:58620 in memory (size: 16.6 KB, free: 1932.0 MB)
2018-05-01 18:10:08.669  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 46
2018-05-01 18:10:08.669  INFO 16044 --- [block-manager-slave-async-thread-pool-18] org.apache.spark.storage.BlockManager    : Removing RDD 238
2018-05-01 18:10:08.670  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 238
2018-05-01 18:10:08.670  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 415
2018-05-01 18:10:08.670  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 415
2018-05-01 18:10:08.670  INFO 16044 --- [block-manager-slave-async-thread-pool-18] org.apache.spark.storage.BlockManager    : Removing RDD 467
2018-05-01 18:10:08.670  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 467
2018-05-01 18:10:08.671  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 345
2018-05-01 18:10:08.671  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 345
2018-05-01 18:10:08.671  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_103_piece0 on 172.21.241.193:58620 in memory (size: 17.2 KB, free: 1969.8 MB)
2018-05-01 18:10:08.672  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_107_piece0 on 172.21.241.193:58620 in memory (size: 18.0 KB, free: 1969.9 MB)
2018-05-01 18:10:08.674  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_109_piece0 on 172.21.241.193:58620 in memory (size: 18.1 KB, free: 1969.9 MB)
2018-05-01 18:10:08.674  INFO 16044 --- [block-manager-slave-async-thread-pool-12] org.apache.spark.storage.BlockManager    : Removing RDD 425
2018-05-01 18:10:08.675  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 425
2018-05-01 18:10:08.675  INFO 16044 --- [block-manager-slave-async-thread-pool-17] org.apache.spark.storage.BlockManager    : Removing RDD 244
2018-05-01 18:10:08.675  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 244
2018-05-01 18:10:08.675  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 33
2018-05-01 18:10:08.676  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 247
2018-05-01 18:10:08.676  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 247
2018-05-01 18:10:08.676  INFO 16044 --- [block-manager-slave-async-thread-pool-12] org.apache.spark.storage.BlockManager    : Removing RDD 375
2018-05-01 18:10:08.676  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 375
2018-05-01 18:10:08.676  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_102_piece0 on 172.21.241.193:58620 in memory (size: 17.6 KB, free: 1989.9 MB)
2018-05-01 18:10:08.677  INFO 16044 --- [block-manager-slave-async-thread-pool-12] org.apache.spark.storage.BlockManager    : Removing RDD 275
2018-05-01 18:10:08.677  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 275
2018-05-01 18:10:08.677  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 445
2018-05-01 18:10:08.677  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 445
2018-05-01 18:10:08.678  INFO 16044 --- [block-manager-slave-async-thread-pool-17] org.apache.spark.storage.BlockManager    : Removing RDD 248
2018-05-01 18:10:08.679  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 248
2018-05-01 18:10:08.679  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 28
2018-05-01 18:10:08.679  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 27
2018-05-01 18:10:08.679  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_97_piece0 on 172.21.241.193:58620 in memory (size: 15.3 KB, free: 1990.8 MB)
2018-05-01 18:10:08.715  INFO 16044 --- [Executor task launch worker for task 247] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 888.0 (TID 247). 429884 bytes result sent to driver
2018-05-01 18:10:08.715  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 888.0 (TID 248, localhost, executor driver, partition 2, ANY, 5005 bytes)
2018-05-01 18:10:08.715  INFO 16044 --- [Executor task launch worker for task 248] org.apache.spark.executor.Executor       : Running task 2.0 in stage 888.0 (TID 248)
2018-05-01 18:10:08.740  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 888.0 (TID 247) in 741 ms on localhost (executor driver) (2/66)
2018-05-01 18:10:09.307  INFO 16044 --- [Executor task launch worker for task 248] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 888.0 (TID 248). 432580 bytes result sent to driver
2018-05-01 18:10:09.307  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 888.0 (TID 249, localhost, executor driver, partition 3, ANY, 5004 bytes)
2018-05-01 18:10:09.307  INFO 16044 --- [Executor task launch worker for task 249] org.apache.spark.executor.Executor       : Running task 3.0 in stage 888.0 (TID 249)
2018-05-01 18:10:09.324  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 888.0 (TID 248) in 609 ms on localhost (executor driver) (3/66)
2018-05-01 18:10:09.904  INFO 16044 --- [Executor task launch worker for task 249] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 888.0 (TID 249). 433940 bytes result sent to driver
2018-05-01 18:10:09.905  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 4.0 in stage 888.0 (TID 250, localhost, executor driver, partition 4, ANY, 5003 bytes)
2018-05-01 18:10:09.905  INFO 16044 --- [Executor task launch worker for task 250] org.apache.spark.executor.Executor       : Running task 4.0 in stage 888.0 (TID 250)
2018-05-01 18:10:09.931  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 888.0 (TID 249) in 624 ms on localhost (executor driver) (4/66)
2018-05-01 18:10:10.563  INFO 16044 --- [Executor task launch worker for task 250] org.apache.spark.executor.Executor       : Finished task 4.0 in stage 888.0 (TID 250). 423957 bytes result sent to driver
2018-05-01 18:10:10.564  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 5.0 in stage 888.0 (TID 251, localhost, executor driver, partition 5, ANY, 5003 bytes)
2018-05-01 18:10:10.564  INFO 16044 --- [Executor task launch worker for task 251] org.apache.spark.executor.Executor       : Running task 5.0 in stage 888.0 (TID 251)
2018-05-01 18:10:10.580  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 4.0 in stage 888.0 (TID 250) in 675 ms on localhost (executor driver) (5/66)
2018-05-01 18:10:11.199  INFO 16044 --- [Executor task launch worker for task 251] org.apache.spark.executor.Executor       : Finished task 5.0 in stage 888.0 (TID 251). 418055 bytes result sent to driver
2018-05-01 18:10:11.199  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 6.0 in stage 888.0 (TID 252, localhost, executor driver, partition 6, ANY, 5003 bytes)
2018-05-01 18:10:11.199  INFO 16044 --- [Executor task launch worker for task 252] org.apache.spark.executor.Executor       : Running task 6.0 in stage 888.0 (TID 252)
2018-05-01 18:10:11.214  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 5.0 in stage 888.0 (TID 251) in 650 ms on localhost (executor driver) (6/66)
2018-05-01 18:10:11.777  INFO 16044 --- [Executor task launch worker for task 252] org.apache.spark.executor.Executor       : Finished task 6.0 in stage 888.0 (TID 252). 416902 bytes result sent to driver
2018-05-01 18:10:11.778  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 7.0 in stage 888.0 (TID 253, localhost, executor driver, partition 7, ANY, 5003 bytes)
2018-05-01 18:10:11.778  INFO 16044 --- [Executor task launch worker for task 253] org.apache.spark.executor.Executor       : Running task 7.0 in stage 888.0 (TID 253)
2018-05-01 18:10:11.794  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 6.0 in stage 888.0 (TID 252) in 595 ms on localhost (executor driver) (7/66)
2018-05-01 18:10:12.371  INFO 16044 --- [Executor task launch worker for task 253] org.apache.spark.executor.Executor       : Finished task 7.0 in stage 888.0 (TID 253). 426842 bytes result sent to driver
2018-05-01 18:10:12.372  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 8.0 in stage 888.0 (TID 254, localhost, executor driver, partition 8, ANY, 5003 bytes)
2018-05-01 18:10:12.372  INFO 16044 --- [Executor task launch worker for task 254] org.apache.spark.executor.Executor       : Running task 8.0 in stage 888.0 (TID 254)
2018-05-01 18:10:12.388  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 7.0 in stage 888.0 (TID 253) in 611 ms on localhost (executor driver) (8/66)
2018-05-01 18:10:12.969  INFO 16044 --- [Executor task launch worker for task 254] org.apache.spark.executor.Executor       : Finished task 8.0 in stage 888.0 (TID 254). 430736 bytes result sent to driver
2018-05-01 18:10:12.970  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 9.0 in stage 888.0 (TID 255, localhost, executor driver, partition 9, ANY, 5003 bytes)
2018-05-01 18:10:12.970  INFO 16044 --- [Executor task launch worker for task 255] org.apache.spark.executor.Executor       : Running task 9.0 in stage 888.0 (TID 255)
2018-05-01 18:10:12.985  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 8.0 in stage 888.0 (TID 254) in 614 ms on localhost (executor driver) (9/66)
2018-05-01 18:10:13.519  INFO 16044 --- [Executor task launch worker for task 255] org.apache.spark.executor.Executor       : Finished task 9.0 in stage 888.0 (TID 255). 432069 bytes result sent to driver
2018-05-01 18:10:13.520  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 10.0 in stage 888.0 (TID 256, localhost, executor driver, partition 10, ANY, 5003 bytes)
2018-05-01 18:10:13.521  INFO 16044 --- [Executor task launch worker for task 256] org.apache.spark.executor.Executor       : Running task 10.0 in stage 888.0 (TID 256)
2018-05-01 18:10:13.539  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 9.0 in stage 888.0 (TID 255) in 569 ms on localhost (executor driver) (10/66)
2018-05-01 18:10:14.114  INFO 16044 --- [Executor task launch worker for task 256] org.apache.spark.executor.Executor       : Finished task 10.0 in stage 888.0 (TID 256). 428576 bytes result sent to driver
2018-05-01 18:10:14.115  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 11.0 in stage 888.0 (TID 257, localhost, executor driver, partition 11, ANY, 5003 bytes)
2018-05-01 18:10:14.115  INFO 16044 --- [Executor task launch worker for task 257] org.apache.spark.executor.Executor       : Running task 11.0 in stage 888.0 (TID 257)
2018-05-01 18:10:14.143  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 10.0 in stage 888.0 (TID 256) in 623 ms on localhost (executor driver) (11/66)
2018-05-01 18:10:14.678  INFO 16044 --- [Executor task launch worker for task 257] org.apache.spark.executor.Executor       : Finished task 11.0 in stage 888.0 (TID 257). 432916 bytes result sent to driver
2018-05-01 18:10:14.678  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 12.0 in stage 888.0 (TID 258, localhost, executor driver, partition 12, ANY, 5003 bytes)
2018-05-01 18:10:14.679  INFO 16044 --- [Executor task launch worker for task 258] org.apache.spark.executor.Executor       : Running task 12.0 in stage 888.0 (TID 258)
2018-05-01 18:10:14.695  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 11.0 in stage 888.0 (TID 257) in 580 ms on localhost (executor driver) (12/66)
2018-05-01 18:10:15.295  INFO 16044 --- [Executor task launch worker for task 258] org.apache.spark.executor.Executor       : Finished task 12.0 in stage 888.0 (TID 258). 431975 bytes result sent to driver
2018-05-01 18:10:15.296  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 13.0 in stage 888.0 (TID 259, localhost, executor driver, partition 13, ANY, 5003 bytes)
2018-05-01 18:10:15.296  INFO 16044 --- [Executor task launch worker for task 259] org.apache.spark.executor.Executor       : Running task 13.0 in stage 888.0 (TID 259)
2018-05-01 18:10:15.312  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 12.0 in stage 888.0 (TID 258) in 634 ms on localhost (executor driver) (13/66)
2018-05-01 18:10:15.880  INFO 16044 --- [Executor task launch worker for task 259] org.apache.spark.executor.Executor       : Finished task 13.0 in stage 888.0 (TID 259). 430518 bytes result sent to driver
2018-05-01 18:10:15.880  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 14.0 in stage 888.0 (TID 260, localhost, executor driver, partition 14, ANY, 5003 bytes)
2018-05-01 18:10:15.880  INFO 16044 --- [Executor task launch worker for task 260] org.apache.spark.executor.Executor       : Running task 14.0 in stage 888.0 (TID 260)
2018-05-01 18:10:15.902  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 13.0 in stage 888.0 (TID 259) in 607 ms on localhost (executor driver) (14/66)
2018-05-01 18:10:16.563  INFO 16044 --- [Executor task launch worker for task 260] org.apache.spark.executor.Executor       : Finished task 14.0 in stage 888.0 (TID 260). 433458 bytes result sent to driver
2018-05-01 18:10:16.564  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 15.0 in stage 888.0 (TID 261, localhost, executor driver, partition 15, ANY, 5003 bytes)
2018-05-01 18:10:16.564  INFO 16044 --- [Executor task launch worker for task 261] org.apache.spark.executor.Executor       : Running task 15.0 in stage 888.0 (TID 261)
2018-05-01 18:10:16.589  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 14.0 in stage 888.0 (TID 260) in 709 ms on localhost (executor driver) (15/66)
2018-05-01 18:10:17.165  INFO 16044 --- [Executor task launch worker for task 261] org.apache.spark.executor.Executor       : Finished task 15.0 in stage 888.0 (TID 261). 433639 bytes result sent to driver
2018-05-01 18:10:17.166  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 16.0 in stage 888.0 (TID 262, localhost, executor driver, partition 16, ANY, 5003 bytes)
2018-05-01 18:10:17.166  INFO 16044 --- [Executor task launch worker for task 262] org.apache.spark.executor.Executor       : Running task 16.0 in stage 888.0 (TID 262)
2018-05-01 18:10:17.190  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 15.0 in stage 888.0 (TID 261) in 627 ms on localhost (executor driver) (16/66)
2018-05-01 18:10:17.809  INFO 16044 --- [Executor task launch worker for task 262] org.apache.spark.executor.Executor       : Finished task 16.0 in stage 888.0 (TID 262). 429670 bytes result sent to driver
2018-05-01 18:10:17.809  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 17.0 in stage 888.0 (TID 263, localhost, executor driver, partition 17, ANY, 5002 bytes)
2018-05-01 18:10:17.810  INFO 16044 --- [Executor task launch worker for task 263] org.apache.spark.executor.Executor       : Running task 17.0 in stage 888.0 (TID 263)
2018-05-01 18:10:17.825  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 16.0 in stage 888.0 (TID 262) in 660 ms on localhost (executor driver) (17/66)
2018-05-01 18:10:18.410  INFO 16044 --- [Executor task launch worker for task 263] org.apache.spark.executor.Executor       : Finished task 17.0 in stage 888.0 (TID 263). 434221 bytes result sent to driver
2018-05-01 18:10:18.411  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 18.0 in stage 888.0 (TID 264, localhost, executor driver, partition 18, ANY, 5002 bytes)
2018-05-01 18:10:18.411  INFO 16044 --- [Executor task launch worker for task 264] org.apache.spark.executor.Executor       : Running task 18.0 in stage 888.0 (TID 264)
2018-05-01 18:10:18.427  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 17.0 in stage 888.0 (TID 263) in 618 ms on localhost (executor driver) (18/66)
2018-05-01 18:10:19.002  INFO 16044 --- [Executor task launch worker for task 264] org.apache.spark.executor.Executor       : Finished task 18.0 in stage 888.0 (TID 264). 431383 bytes result sent to driver
2018-05-01 18:10:19.002  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 19.0 in stage 888.0 (TID 265, localhost, executor driver, partition 19, ANY, 5003 bytes)
2018-05-01 18:10:19.002  INFO 16044 --- [Executor task launch worker for task 265] org.apache.spark.executor.Executor       : Running task 19.0 in stage 888.0 (TID 265)
2018-05-01 18:10:19.019  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 18.0 in stage 888.0 (TID 264) in 609 ms on localhost (executor driver) (19/66)
2018-05-01 18:10:19.688  INFO 16044 --- [Executor task launch worker for task 265] org.apache.spark.executor.Executor       : Finished task 19.0 in stage 888.0 (TID 265). 435269 bytes result sent to driver
2018-05-01 18:10:19.689  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 20.0 in stage 888.0 (TID 266, localhost, executor driver, partition 20, ANY, 5003 bytes)
2018-05-01 18:10:19.689  INFO 16044 --- [Executor task launch worker for task 266] org.apache.spark.executor.Executor       : Running task 20.0 in stage 888.0 (TID 266)
2018-05-01 18:10:19.706  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 19.0 in stage 888.0 (TID 265) in 704 ms on localhost (executor driver) (20/66)
2018-05-01 18:10:20.261  INFO 16044 --- [Executor task launch worker for task 266] org.apache.spark.executor.Executor       : Finished task 20.0 in stage 888.0 (TID 266). 434347 bytes result sent to driver
2018-05-01 18:10:20.261  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 21.0 in stage 888.0 (TID 267, localhost, executor driver, partition 21, ANY, 5003 bytes)
2018-05-01 18:10:20.261  INFO 16044 --- [Executor task launch worker for task 267] org.apache.spark.executor.Executor       : Running task 21.0 in stage 888.0 (TID 267)
2018-05-01 18:10:20.278  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 20.0 in stage 888.0 (TID 266) in 590 ms on localhost (executor driver) (21/66)
2018-05-01 18:10:20.838  INFO 16044 --- [Executor task launch worker for task 267] org.apache.spark.executor.Executor       : Finished task 21.0 in stage 888.0 (TID 267). 428385 bytes result sent to driver
2018-05-01 18:10:20.839  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 22.0 in stage 888.0 (TID 268, localhost, executor driver, partition 22, ANY, 5003 bytes)
2018-05-01 18:10:20.839  INFO 16044 --- [Executor task launch worker for task 268] org.apache.spark.executor.Executor       : Running task 22.0 in stage 888.0 (TID 268)
2018-05-01 18:10:20.855  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 21.0 in stage 888.0 (TID 267) in 594 ms on localhost (executor driver) (22/66)
2018-05-01 18:10:21.470  INFO 16044 --- [Executor task launch worker for task 268] org.apache.spark.executor.Executor       : Finished task 22.0 in stage 888.0 (TID 268). 435040 bytes result sent to driver
2018-05-01 18:10:21.471  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 23.0 in stage 888.0 (TID 269, localhost, executor driver, partition 23, ANY, 5003 bytes)
2018-05-01 18:10:21.471  INFO 16044 --- [Executor task launch worker for task 269] org.apache.spark.executor.Executor       : Running task 23.0 in stage 888.0 (TID 269)
2018-05-01 18:10:21.488  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 22.0 in stage 888.0 (TID 268) in 650 ms on localhost (executor driver) (23/66)
2018-05-01 18:10:22.051  INFO 16044 --- [Executor task launch worker for task 269] org.apache.spark.executor.Executor       : Finished task 23.0 in stage 888.0 (TID 269). 430843 bytes result sent to driver
2018-05-01 18:10:22.052  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 24.0 in stage 888.0 (TID 270, localhost, executor driver, partition 24, ANY, 5003 bytes)
2018-05-01 18:10:22.052  INFO 16044 --- [Executor task launch worker for task 270] org.apache.spark.executor.Executor       : Running task 24.0 in stage 888.0 (TID 270)
2018-05-01 18:10:22.068  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 23.0 in stage 888.0 (TID 269) in 597 ms on localhost (executor driver) (24/66)
2018-05-01 18:10:22.626  INFO 16044 --- [Executor task launch worker for task 270] org.apache.spark.executor.Executor       : Finished task 24.0 in stage 888.0 (TID 270). 429256 bytes result sent to driver
2018-05-01 18:10:22.627  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 25.0 in stage 888.0 (TID 271, localhost, executor driver, partition 25, ANY, 5003 bytes)
2018-05-01 18:10:22.627  INFO 16044 --- [Executor task launch worker for task 271] org.apache.spark.executor.Executor       : Running task 25.0 in stage 888.0 (TID 271)
2018-05-01 18:10:22.643  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 24.0 in stage 888.0 (TID 270) in 591 ms on localhost (executor driver) (25/66)
2018-05-01 18:10:23.236  INFO 16044 --- [Executor task launch worker for task 271] org.apache.spark.executor.Executor       : Finished task 25.0 in stage 888.0 (TID 271). 432251 bytes result sent to driver
2018-05-01 18:10:23.237  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 26.0 in stage 888.0 (TID 272, localhost, executor driver, partition 26, ANY, 5003 bytes)
2018-05-01 18:10:23.237  INFO 16044 --- [Executor task launch worker for task 272] org.apache.spark.executor.Executor       : Running task 26.0 in stage 888.0 (TID 272)
2018-05-01 18:10:23.253  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 25.0 in stage 888.0 (TID 271) in 625 ms on localhost (executor driver) (26/66)
2018-05-01 18:10:23.839  INFO 16044 --- [Executor task launch worker for task 272] org.apache.spark.executor.Executor       : Finished task 26.0 in stage 888.0 (TID 272). 433194 bytes result sent to driver
2018-05-01 18:10:23.840  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 27.0 in stage 888.0 (TID 273, localhost, executor driver, partition 27, ANY, 5003 bytes)
2018-05-01 18:10:23.840  INFO 16044 --- [Executor task launch worker for task 273] org.apache.spark.executor.Executor       : Running task 27.0 in stage 888.0 (TID 273)
2018-05-01 18:10:23.856  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 26.0 in stage 888.0 (TID 272) in 619 ms on localhost (executor driver) (27/66)
2018-05-01 18:10:24.397  INFO 16044 --- [Executor task launch worker for task 273] org.apache.spark.executor.Executor       : Finished task 27.0 in stage 888.0 (TID 273). 433416 bytes result sent to driver
2018-05-01 18:10:24.398  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 28.0 in stage 888.0 (TID 274, localhost, executor driver, partition 28, ANY, 5003 bytes)
2018-05-01 18:10:24.398  INFO 16044 --- [Executor task launch worker for task 274] org.apache.spark.executor.Executor       : Running task 28.0 in stage 888.0 (TID 274)
2018-05-01 18:10:24.415  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 27.0 in stage 888.0 (TID 273) in 575 ms on localhost (executor driver) (28/66)
2018-05-01 18:10:24.999  INFO 16044 --- [Executor task launch worker for task 274] org.apache.spark.executor.Executor       : Finished task 28.0 in stage 888.0 (TID 274). 431320 bytes result sent to driver
2018-05-01 18:10:25.000  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 29.0 in stage 888.0 (TID 275, localhost, executor driver, partition 29, ANY, 5003 bytes)
2018-05-01 18:10:25.000  INFO 16044 --- [Executor task launch worker for task 275] org.apache.spark.executor.Executor       : Running task 29.0 in stage 888.0 (TID 275)
2018-05-01 18:10:25.016  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 28.0 in stage 888.0 (TID 274) in 618 ms on localhost (executor driver) (29/66)
2018-05-01 18:10:25.565  INFO 16044 --- [Executor task launch worker for task 275] org.apache.spark.executor.Executor       : Finished task 29.0 in stage 888.0 (TID 275). 432490 bytes result sent to driver
2018-05-01 18:10:25.565  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 30.0 in stage 888.0 (TID 276, localhost, executor driver, partition 30, ANY, 5003 bytes)
2018-05-01 18:10:25.566  INFO 16044 --- [Executor task launch worker for task 276] org.apache.spark.executor.Executor       : Running task 30.0 in stage 888.0 (TID 276)
2018-05-01 18:10:25.582  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 29.0 in stage 888.0 (TID 275) in 582 ms on localhost (executor driver) (30/66)
2018-05-01 18:10:26.159  INFO 16044 --- [Executor task launch worker for task 276] org.apache.spark.executor.Executor       : Finished task 30.0 in stage 888.0 (TID 276). 431358 bytes result sent to driver
2018-05-01 18:10:26.159  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 31.0 in stage 888.0 (TID 277, localhost, executor driver, partition 31, ANY, 5003 bytes)
2018-05-01 18:10:26.159  INFO 16044 --- [Executor task launch worker for task 277] org.apache.spark.executor.Executor       : Running task 31.0 in stage 888.0 (TID 277)
2018-05-01 18:10:26.175  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 30.0 in stage 888.0 (TID 276) in 609 ms on localhost (executor driver) (31/66)
2018-05-01 18:10:26.724  INFO 16044 --- [Executor task launch worker for task 277] org.apache.spark.executor.Executor       : Finished task 31.0 in stage 888.0 (TID 277). 434098 bytes result sent to driver
2018-05-01 18:10:26.724  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 32.0 in stage 888.0 (TID 278, localhost, executor driver, partition 32, ANY, 5002 bytes)
2018-05-01 18:10:26.724  INFO 16044 --- [Executor task launch worker for task 278] org.apache.spark.executor.Executor       : Running task 32.0 in stage 888.0 (TID 278)
2018-05-01 18:10:26.742  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 31.0 in stage 888.0 (TID 277) in 583 ms on localhost (executor driver) (32/66)
2018-05-01 18:10:27.326  INFO 16044 --- [Executor task launch worker for task 278] org.apache.spark.executor.Executor       : Finished task 32.0 in stage 888.0 (TID 278). 432139 bytes result sent to driver
2018-05-01 18:10:27.326  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 33.0 in stage 888.0 (TID 279, localhost, executor driver, partition 33, ANY, 5002 bytes)
2018-05-01 18:10:27.326  INFO 16044 --- [Executor task launch worker for task 279] org.apache.spark.executor.Executor       : Running task 33.0 in stage 888.0 (TID 279)
2018-05-01 18:10:27.342  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 32.0 in stage 888.0 (TID 278) in 618 ms on localhost (executor driver) (33/66)
2018-05-01 18:10:28.009  INFO 16044 --- [Executor task launch worker for task 279] org.apache.spark.executor.Executor       : Finished task 33.0 in stage 888.0 (TID 279). 433257 bytes result sent to driver
2018-05-01 18:10:28.009  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 34.0 in stage 888.0 (TID 280, localhost, executor driver, partition 34, ANY, 5002 bytes)
2018-05-01 18:10:28.009  INFO 16044 --- [Executor task launch worker for task 280] org.apache.spark.executor.Executor       : Running task 34.0 in stage 888.0 (TID 280)
2018-05-01 18:10:28.027  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 33.0 in stage 888.0 (TID 279) in 701 ms on localhost (executor driver) (34/66)
2018-05-01 18:10:28.713  INFO 16044 --- [Executor task launch worker for task 280] org.apache.spark.executor.Executor       : Finished task 34.0 in stage 888.0 (TID 280). 433019 bytes result sent to driver
2018-05-01 18:10:28.713  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 35.0 in stage 888.0 (TID 281, localhost, executor driver, partition 35, ANY, 5002 bytes)
2018-05-01 18:10:28.713  INFO 16044 --- [Executor task launch worker for task 281] org.apache.spark.executor.Executor       : Running task 35.0 in stage 888.0 (TID 281)
2018-05-01 18:10:28.732  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 34.0 in stage 888.0 (TID 280) in 723 ms on localhost (executor driver) (35/66)
2018-05-01 18:10:29.459  INFO 16044 --- [Executor task launch worker for task 281] org.apache.spark.executor.Executor       : Finished task 35.0 in stage 888.0 (TID 281). 431702 bytes result sent to driver
2018-05-01 18:10:29.461  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 36.0 in stage 888.0 (TID 282, localhost, executor driver, partition 36, ANY, 5002 bytes)
2018-05-01 18:10:29.462  INFO 16044 --- [Executor task launch worker for task 282] org.apache.spark.executor.Executor       : Running task 36.0 in stage 888.0 (TID 282)
2018-05-01 18:10:29.481  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 35.0 in stage 888.0 (TID 281) in 768 ms on localhost (executor driver) (36/66)
2018-05-01 18:10:30.100  INFO 16044 --- [Executor task launch worker for task 282] org.apache.spark.executor.Executor       : Finished task 36.0 in stage 888.0 (TID 282). 435588 bytes result sent to driver
2018-05-01 18:10:30.101  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 37.0 in stage 888.0 (TID 283, localhost, executor driver, partition 37, ANY, 5002 bytes)
2018-05-01 18:10:30.101  INFO 16044 --- [Executor task launch worker for task 283] org.apache.spark.executor.Executor       : Running task 37.0 in stage 888.0 (TID 283)
2018-05-01 18:10:30.128  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 36.0 in stage 888.0 (TID 282) in 667 ms on localhost (executor driver) (37/66)
2018-05-01 18:10:30.696  INFO 16044 --- [Executor task launch worker for task 283] org.apache.spark.executor.Executor       : Finished task 37.0 in stage 888.0 (TID 283). 432635 bytes result sent to driver
2018-05-01 18:10:30.697  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 38.0 in stage 888.0 (TID 284, localhost, executor driver, partition 38, ANY, 5003 bytes)
2018-05-01 18:10:30.697  INFO 16044 --- [Executor task launch worker for task 284] org.apache.spark.executor.Executor       : Running task 38.0 in stage 888.0 (TID 284)
2018-05-01 18:10:30.713  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 37.0 in stage 888.0 (TID 283) in 612 ms on localhost (executor driver) (38/66)
2018-05-01 18:10:31.269  INFO 16044 --- [Executor task launch worker for task 284] org.apache.spark.executor.Executor       : Finished task 38.0 in stage 888.0 (TID 284). 433774 bytes result sent to driver
2018-05-01 18:10:31.270  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 39.0 in stage 888.0 (TID 285, localhost, executor driver, partition 39, ANY, 5003 bytes)
2018-05-01 18:10:31.270  INFO 16044 --- [Executor task launch worker for task 285] org.apache.spark.executor.Executor       : Running task 39.0 in stage 888.0 (TID 285)
2018-05-01 18:10:31.285  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 38.0 in stage 888.0 (TID 284) in 589 ms on localhost (executor driver) (39/66)
2018-05-01 18:10:31.900  INFO 16044 --- [Executor task launch worker for task 285] org.apache.spark.executor.Executor       : Finished task 39.0 in stage 888.0 (TID 285). 430075 bytes result sent to driver
2018-05-01 18:10:31.900  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 40.0 in stage 888.0 (TID 286, localhost, executor driver, partition 40, ANY, 5003 bytes)
2018-05-01 18:10:31.900  INFO 16044 --- [Executor task launch worker for task 286] org.apache.spark.executor.Executor       : Running task 40.0 in stage 888.0 (TID 286)
2018-05-01 18:10:31.925  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 39.0 in stage 888.0 (TID 285) in 655 ms on localhost (executor driver) (40/66)
2018-05-01 18:10:32.556  INFO 16044 --- [Executor task launch worker for task 286] org.apache.spark.executor.Executor       : Finished task 40.0 in stage 888.0 (TID 286). 432932 bytes result sent to driver
2018-05-01 18:10:32.556  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 41.0 in stage 888.0 (TID 287, localhost, executor driver, partition 41, ANY, 5003 bytes)
2018-05-01 18:10:32.556  INFO 16044 --- [Executor task launch worker for task 287] org.apache.spark.executor.Executor       : Running task 41.0 in stage 888.0 (TID 287)
2018-05-01 18:10:32.574  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 40.0 in stage 888.0 (TID 286) in 674 ms on localhost (executor driver) (41/66)
2018-05-01 18:10:33.142  INFO 16044 --- [Executor task launch worker for task 287] org.apache.spark.executor.Executor       : Finished task 41.0 in stage 888.0 (TID 287). 431750 bytes result sent to driver
2018-05-01 18:10:33.142  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 42.0 in stage 888.0 (TID 288, localhost, executor driver, partition 42, ANY, 5003 bytes)
2018-05-01 18:10:33.142  INFO 16044 --- [Executor task launch worker for task 288] org.apache.spark.executor.Executor       : Running task 42.0 in stage 888.0 (TID 288)
2018-05-01 18:10:33.159  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 41.0 in stage 888.0 (TID 287) in 603 ms on localhost (executor driver) (42/66)
2018-05-01 18:10:33.883  INFO 16044 --- [Executor task launch worker for task 288] org.apache.spark.executor.Executor       : Finished task 42.0 in stage 888.0 (TID 288). 432078 bytes result sent to driver
2018-05-01 18:10:33.883  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 43.0 in stage 888.0 (TID 289, localhost, executor driver, partition 43, ANY, 5003 bytes)
2018-05-01 18:10:33.883  INFO 16044 --- [Executor task launch worker for task 289] org.apache.spark.executor.Executor       : Running task 43.0 in stage 888.0 (TID 289)
2018-05-01 18:10:33.905  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 42.0 in stage 888.0 (TID 288) in 763 ms on localhost (executor driver) (43/66)
2018-05-01 18:10:34.605  INFO 16044 --- [Executor task launch worker for task 289] org.apache.spark.executor.Executor       : Finished task 43.0 in stage 888.0 (TID 289). 428926 bytes result sent to driver
2018-05-01 18:10:34.605  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 44.0 in stage 888.0 (TID 290, localhost, executor driver, partition 44, ANY, 5003 bytes)
2018-05-01 18:10:34.605  INFO 16044 --- [Executor task launch worker for task 290] org.apache.spark.executor.Executor       : Running task 44.0 in stage 888.0 (TID 290)
2018-05-01 18:10:34.623  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 43.0 in stage 888.0 (TID 289) in 740 ms on localhost (executor driver) (44/66)
2018-05-01 18:10:35.272  INFO 16044 --- [Executor task launch worker for task 290] org.apache.spark.executor.Executor       : Finished task 44.0 in stage 888.0 (TID 290). 432682 bytes result sent to driver
2018-05-01 18:10:35.273  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 45.0 in stage 888.0 (TID 291, localhost, executor driver, partition 45, ANY, 5003 bytes)
2018-05-01 18:10:35.273  INFO 16044 --- [Executor task launch worker for task 291] org.apache.spark.executor.Executor       : Running task 45.0 in stage 888.0 (TID 291)
2018-05-01 18:10:35.290  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 44.0 in stage 888.0 (TID 290) in 684 ms on localhost (executor driver) (45/66)
2018-05-01 18:10:35.927  INFO 16044 --- [Executor task launch worker for task 291] org.apache.spark.executor.Executor       : Finished task 45.0 in stage 888.0 (TID 291). 430122 bytes result sent to driver
2018-05-01 18:10:35.927  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 46.0 in stage 888.0 (TID 292, localhost, executor driver, partition 46, ANY, 5003 bytes)
2018-05-01 18:10:35.927  INFO 16044 --- [Executor task launch worker for task 292] org.apache.spark.executor.Executor       : Running task 46.0 in stage 888.0 (TID 292)
2018-05-01 18:10:35.944  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 45.0 in stage 888.0 (TID 291) in 671 ms on localhost (executor driver) (46/66)
2018-05-01 18:10:36.586  INFO 16044 --- [Executor task launch worker for task 292] org.apache.spark.executor.Executor       : Finished task 46.0 in stage 888.0 (TID 292). 430180 bytes result sent to driver
2018-05-01 18:10:36.587  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 47.0 in stage 888.0 (TID 293, localhost, executor driver, partition 47, ANY, 5003 bytes)
2018-05-01 18:10:36.587  INFO 16044 --- [Executor task launch worker for task 293] org.apache.spark.executor.Executor       : Running task 47.0 in stage 888.0 (TID 293)
2018-05-01 18:10:36.606  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 46.0 in stage 888.0 (TID 292) in 678 ms on localhost (executor driver) (47/66)
2018-05-01 18:10:37.178  INFO 16044 --- [Executor task launch worker for task 293] org.apache.spark.executor.Executor       : Finished task 47.0 in stage 888.0 (TID 293). 433596 bytes result sent to driver
2018-05-01 18:10:37.178  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 48.0 in stage 888.0 (TID 294, localhost, executor driver, partition 48, ANY, 5003 bytes)
2018-05-01 18:10:37.178  INFO 16044 --- [Executor task launch worker for task 294] org.apache.spark.executor.Executor       : Running task 48.0 in stage 888.0 (TID 294)
2018-05-01 18:10:37.194  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 47.0 in stage 888.0 (TID 293) in 607 ms on localhost (executor driver) (48/66)
2018-05-01 18:10:37.792  INFO 16044 --- [Executor task launch worker for task 294] org.apache.spark.executor.Executor       : Finished task 48.0 in stage 888.0 (TID 294). 431478 bytes result sent to driver
2018-05-01 18:10:37.792  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 49.0 in stage 888.0 (TID 295, localhost, executor driver, partition 49, ANY, 5003 bytes)
2018-05-01 18:10:37.792  INFO 16044 --- [Executor task launch worker for task 295] org.apache.spark.executor.Executor       : Running task 49.0 in stage 888.0 (TID 295)
2018-05-01 18:10:37.808  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 48.0 in stage 888.0 (TID 294) in 630 ms on localhost (executor driver) (49/66)
2018-05-01 18:10:38.337  INFO 16044 --- [Executor task launch worker for task 295] org.apache.spark.executor.Executor       : Finished task 49.0 in stage 888.0 (TID 295). 432743 bytes result sent to driver
2018-05-01 18:10:38.337  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 50.0 in stage 888.0 (TID 296, localhost, executor driver, partition 50, ANY, 5003 bytes)
2018-05-01 18:10:38.337  INFO 16044 --- [Executor task launch worker for task 296] org.apache.spark.executor.Executor       : Running task 50.0 in stage 888.0 (TID 296)
2018-05-01 18:10:38.355  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 49.0 in stage 888.0 (TID 295) in 563 ms on localhost (executor driver) (50/66)
2018-05-01 18:10:38.939  INFO 16044 --- [Executor task launch worker for task 296] org.apache.spark.executor.Executor       : Finished task 50.0 in stage 888.0 (TID 296). 430411 bytes result sent to driver
2018-05-01 18:10:38.939  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 51.0 in stage 888.0 (TID 297, localhost, executor driver, partition 51, ANY, 5002 bytes)
2018-05-01 18:10:38.939  INFO 16044 --- [Executor task launch worker for task 297] org.apache.spark.executor.Executor       : Running task 51.0 in stage 888.0 (TID 297)
2018-05-01 18:10:38.955  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 50.0 in stage 888.0 (TID 296) in 618 ms on localhost (executor driver) (51/66)
2018-05-01 18:10:39.497  INFO 16044 --- [Executor task launch worker for task 297] org.apache.spark.executor.Executor       : Finished task 51.0 in stage 888.0 (TID 297). 435039 bytes result sent to driver
2018-05-01 18:10:39.498  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 52.0 in stage 888.0 (TID 298, localhost, executor driver, partition 52, ANY, 5002 bytes)
2018-05-01 18:10:39.498  INFO 16044 --- [Executor task launch worker for task 298] org.apache.spark.executor.Executor       : Running task 52.0 in stage 888.0 (TID 298)
2018-05-01 18:10:39.517  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 51.0 in stage 888.0 (TID 297) in 578 ms on localhost (executor driver) (52/66)
2018-05-01 18:10:40.041  INFO 16044 --- [Executor task launch worker for task 298] org.apache.spark.executor.Executor       : Finished task 52.0 in stage 888.0 (TID 298). 431702 bytes result sent to driver
2018-05-01 18:10:40.041  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 53.0 in stage 888.0 (TID 299, localhost, executor driver, partition 53, ANY, 5002 bytes)
2018-05-01 18:10:40.041  INFO 16044 --- [Executor task launch worker for task 299] org.apache.spark.executor.Executor       : Running task 53.0 in stage 888.0 (TID 299)
2018-05-01 18:10:40.057  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 52.0 in stage 888.0 (TID 298) in 560 ms on localhost (executor driver) (53/66)
2018-05-01 18:10:40.595  INFO 16044 --- [Executor task launch worker for task 299] org.apache.spark.executor.Executor       : Finished task 53.0 in stage 888.0 (TID 299). 431585 bytes result sent to driver
2018-05-01 18:10:40.596  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 54.0 in stage 888.0 (TID 300, localhost, executor driver, partition 54, ANY, 5002 bytes)
2018-05-01 18:10:40.596  INFO 16044 --- [Executor task launch worker for task 300] org.apache.spark.executor.Executor       : Running task 54.0 in stage 888.0 (TID 300)
2018-05-01 18:10:40.613  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 53.0 in stage 888.0 (TID 299) in 572 ms on localhost (executor driver) (54/66)
2018-05-01 18:10:41.223  INFO 16044 --- [Executor task launch worker for task 300] org.apache.spark.executor.Executor       : Finished task 54.0 in stage 888.0 (TID 300). 428900 bytes result sent to driver
2018-05-01 18:10:41.223  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 55.0 in stage 888.0 (TID 301, localhost, executor driver, partition 55, ANY, 5003 bytes)
2018-05-01 18:10:41.224  INFO 16044 --- [Executor task launch worker for task 301] org.apache.spark.executor.Executor       : Running task 55.0 in stage 888.0 (TID 301)
2018-05-01 18:10:41.239  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 54.0 in stage 888.0 (TID 300) in 643 ms on localhost (executor driver) (55/66)
2018-05-01 18:10:41.778  INFO 16044 --- [Executor task launch worker for task 301] org.apache.spark.executor.Executor       : Finished task 55.0 in stage 888.0 (TID 301). 431970 bytes result sent to driver
2018-05-01 18:10:41.778  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 56.0 in stage 888.0 (TID 302, localhost, executor driver, partition 56, ANY, 5003 bytes)
2018-05-01 18:10:41.779  INFO 16044 --- [Executor task launch worker for task 302] org.apache.spark.executor.Executor       : Running task 56.0 in stage 888.0 (TID 302)
2018-05-01 18:10:41.796  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 55.0 in stage 888.0 (TID 301) in 573 ms on localhost (executor driver) (56/66)
2018-05-01 18:10:42.344  INFO 16044 --- [Executor task launch worker for task 302] org.apache.spark.executor.Executor       : Finished task 56.0 in stage 888.0 (TID 302). 430992 bytes result sent to driver
2018-05-01 18:10:42.345  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 57.0 in stage 888.0 (TID 303, localhost, executor driver, partition 57, ANY, 5003 bytes)
2018-05-01 18:10:42.345  INFO 16044 --- [Executor task launch worker for task 303] org.apache.spark.executor.Executor       : Running task 57.0 in stage 888.0 (TID 303)
2018-05-01 18:10:42.361  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 56.0 in stage 888.0 (TID 302) in 583 ms on localhost (executor driver) (57/66)
2018-05-01 18:10:42.947  INFO 16044 --- [Executor task launch worker for task 303] org.apache.spark.executor.Executor       : Finished task 57.0 in stage 888.0 (TID 303). 433983 bytes result sent to driver
2018-05-01 18:10:43.011  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 58.0 in stage 888.0 (TID 304, localhost, executor driver, partition 58, ANY, 5003 bytes)
2018-05-01 18:10:43.011  INFO 16044 --- [Executor task launch worker for task 304] org.apache.spark.executor.Executor       : Running task 58.0 in stage 888.0 (TID 304)
2018-05-01 18:10:43.028  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 57.0 in stage 888.0 (TID 303) in 684 ms on localhost (executor driver) (58/66)
2018-05-01 18:10:43.614  INFO 16044 --- [Executor task launch worker for task 304] org.apache.spark.executor.Executor       : Finished task 58.0 in stage 888.0 (TID 304). 431032 bytes result sent to driver
2018-05-01 18:10:43.614  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 59.0 in stage 888.0 (TID 305, localhost, executor driver, partition 59, ANY, 5003 bytes)
2018-05-01 18:10:43.614  INFO 16044 --- [Executor task launch worker for task 305] org.apache.spark.executor.Executor       : Running task 59.0 in stage 888.0 (TID 305)
2018-05-01 18:10:43.631  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 58.0 in stage 888.0 (TID 304) in 621 ms on localhost (executor driver) (59/66)
2018-05-01 18:10:44.211  INFO 16044 --- [Executor task launch worker for task 305] org.apache.spark.executor.Executor       : Finished task 59.0 in stage 888.0 (TID 305). 433164 bytes result sent to driver
2018-05-01 18:10:44.211  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 60.0 in stage 888.0 (TID 306, localhost, executor driver, partition 60, ANY, 5003 bytes)
2018-05-01 18:10:44.212  INFO 16044 --- [Executor task launch worker for task 306] org.apache.spark.executor.Executor       : Running task 60.0 in stage 888.0 (TID 306)
2018-05-01 18:10:44.227  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 59.0 in stage 888.0 (TID 305) in 613 ms on localhost (executor driver) (60/66)
2018-05-01 18:10:44.788  INFO 16044 --- [Executor task launch worker for task 306] org.apache.spark.executor.Executor       : Finished task 60.0 in stage 888.0 (TID 306). 432214 bytes result sent to driver
2018-05-01 18:10:44.788  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 61.0 in stage 888.0 (TID 307, localhost, executor driver, partition 61, ANY, 5003 bytes)
2018-05-01 18:10:44.789  INFO 16044 --- [Executor task launch worker for task 307] org.apache.spark.executor.Executor       : Running task 61.0 in stage 888.0 (TID 307)
2018-05-01 18:10:44.807  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 60.0 in stage 888.0 (TID 306) in 596 ms on localhost (executor driver) (61/66)
2018-05-01 18:10:45.409  INFO 16044 --- [Executor task launch worker for task 307] org.apache.spark.executor.Executor       : Finished task 61.0 in stage 888.0 (TID 307). 432567 bytes result sent to driver
2018-05-01 18:10:45.409  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 62.0 in stage 888.0 (TID 308, localhost, executor driver, partition 62, ANY, 5003 bytes)
2018-05-01 18:10:45.409  INFO 16044 --- [Executor task launch worker for task 308] org.apache.spark.executor.Executor       : Running task 62.0 in stage 888.0 (TID 308)
2018-05-01 18:10:45.425  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 61.0 in stage 888.0 (TID 307) in 637 ms on localhost (executor driver) (62/66)
2018-05-01 18:10:45.973  INFO 16044 --- [Executor task launch worker for task 308] org.apache.spark.executor.Executor       : Finished task 62.0 in stage 888.0 (TID 308). 431572 bytes result sent to driver
2018-05-01 18:10:45.974  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 63.0 in stage 888.0 (TID 309, localhost, executor driver, partition 63, ANY, 5003 bytes)
2018-05-01 18:10:45.974  INFO 16044 --- [Executor task launch worker for task 309] org.apache.spark.executor.Executor       : Running task 63.0 in stage 888.0 (TID 309)
2018-05-01 18:10:45.989  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 62.0 in stage 888.0 (TID 308) in 580 ms on localhost (executor driver) (63/66)
2018-05-01 18:10:46.516  INFO 16044 --- [Executor task launch worker for task 309] org.apache.spark.executor.Executor       : Finished task 63.0 in stage 888.0 (TID 309). 429910 bytes result sent to driver
2018-05-01 18:10:46.517  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 64.0 in stage 888.0 (TID 310, localhost, executor driver, partition 64, ANY, 5003 bytes)
2018-05-01 18:10:46.517  INFO 16044 --- [Executor task launch worker for task 310] org.apache.spark.executor.Executor       : Running task 64.0 in stage 888.0 (TID 310)
2018-05-01 18:10:46.532  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 63.0 in stage 888.0 (TID 309) in 558 ms on localhost (executor driver) (64/66)
2018-05-01 18:10:47.083  INFO 16044 --- [Executor task launch worker for task 310] org.apache.spark.executor.Executor       : Finished task 64.0 in stage 888.0 (TID 310). 434975 bytes result sent to driver
2018-05-01 18:10:47.084  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 65.0 in stage 888.0 (TID 311, localhost, executor driver, partition 65, ANY, 4992 bytes)
2018-05-01 18:10:47.084  INFO 16044 --- [Executor task launch worker for task 311] org.apache.spark.executor.Executor       : Running task 65.0 in stage 888.0 (TID 311)
2018-05-01 18:10:47.087  INFO 16044 --- [Executor task launch worker for task 311] org.apache.spark.executor.Executor       : Finished task 65.0 in stage 888.0 (TID 311). 777 bytes result sent to driver
2018-05-01 18:10:47.087  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 65.0 in stage 888.0 (TID 311) in 3 ms on localhost (executor driver) (65/66)
2018-05-01 18:10:47.100  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 64.0 in stage 888.0 (TID 310) in 583 ms on localhost (executor driver) (66/66)
2018-05-01 18:10:47.100  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 888.0, whose tasks have all completed, from pool 
2018-05-01 18:10:47.101  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 888 (collect at RecomendationServiceImpl.java:86) finished in 39.106 s
2018-05-01 18:10:47.102  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 62 finished: collect at RecomendationServiceImpl.java:86, took 39.112173 s
2018-05-01 18:10:47.252  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:240
2018-05-01 18:10:47.253  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 63 (isEmpty at ALS.scala:240) with 1 output partitions
2018-05-01 18:10:47.253  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 889 (isEmpty at ALS.scala:240)
2018-05-01 18:10:47.253  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 18:10:47.253  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:10:47.253  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 889 (UnionRDD[475] at union at RecomendationServiceImpl.java:77), which has no missing parents
2018-05-01 18:10:47.255  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_114 stored as values in memory (estimated size 3.3 KB, free 1990.8 MB)
2018-05-01 18:10:47.256  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_114_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.8 MB)
2018-05-01 18:10:47.256  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_114_piece0 in memory on 172.21.241.193:58620 (size: 2.1 KB, free: 1990.8 MB)
2018-05-01 18:10:47.256  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 114 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:10:47.256  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 889 (UnionRDD[475] at union at RecomendationServiceImpl.java:77) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:10:47.256  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 889.0 with 1 tasks
2018-05-01 18:10:50.427  WARN 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Stage 889 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 18:10:50.428  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 889.0 (TID 312, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 18:10:50.429  INFO 16044 --- [Executor task launch worker for task 312] org.apache.spark.executor.Executor       : Running task 0.0 in stage 889.0 (TID 312)
2018-05-01 18:10:53.583  INFO 16044 --- [pool-25-thread-1] c.m.spark.connection.MongoClientCache    : Closing MongoClient: [127.0.0.1:27017]
2018-05-01 18:10:53.584  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_112_piece0 on 172.21.241.193:58620 in memory (size: 419.0 B, free: 1990.8 MB)
2018-05-01 18:10:53.584  INFO 16044 --- [pool-25-thread-1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:8, serverValue:37}] to 127.0.0.1:27017 because the pool has been closed.
2018-05-01 18:10:53.585  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_57_piece0 on 172.21.241.193:58620 in memory (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 18:10:53.586  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_56_piece0 on 172.21.241.193:58620 in memory (size: 419.0 B, free: 1990.8 MB)
2018-05-01 18:10:53.587  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_113_piece0 on 172.21.241.193:58620 in memory (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 18:10:53.721  INFO 16044 --- [Executor task launch worker for task 312] o.a.spark.storage.memory.MemoryStore     : Block rdd_473_0 stored as values in memory (estimated size 36.0 MB, free 1954.8 MB)
2018-05-01 18:10:53.722  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_473_0 in memory on 172.21.241.193:58620 (size: 36.0 MB, free: 1954.8 MB)
2018-05-01 18:10:53.722  INFO 16044 --- [Executor task launch worker for task 312] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 312:
[rdd_473_0]
2018-05-01 18:10:53.723  INFO 16044 --- [Executor task launch worker for task 312] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 889.0 (TID 312). 1551 bytes result sent to driver
2018-05-01 18:10:53.723  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 889.0 (TID 312) in 6466 ms on localhost (executor driver) (1/1)
2018-05-01 18:10:53.724  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 889.0, whose tasks have all completed, from pool 
2018-05-01 18:10:53.724  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 889 (isEmpty at ALS.scala:240) finished in 6.468 s
2018-05-01 18:10:53.724  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 63 finished: isEmpty at ALS.scala:240, took 6.472129 s
2018-05-01 18:10:53.730  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:843
2018-05-01 18:10:53.731  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 64 (isEmpty at ALS.scala:843) with 1 output partitions
2018-05-01 18:10:53.731  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 890 (isEmpty at ALS.scala:843)
2018-05-01 18:10:53.731  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 18:10:53.732  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:10:53.732  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 890 (MapPartitionsRDD[476] at map at ALS.scala:256), which has no missing parents
2018-05-01 18:10:53.733  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_115 stored as values in memory (estimated size 3.6 KB, free 1954.8 MB)
2018-05-01 18:10:53.734  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_115_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1954.8 MB)
2018-05-01 18:10:53.735  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_115_piece0 in memory on 172.21.241.193:58620 (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 18:10:53.736  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 115 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:10:53.736  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 890 (MapPartitionsRDD[476] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:10:53.736  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 890.0 with 1 tasks
2018-05-01 18:10:56.651  WARN 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Stage 890 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 18:10:56.652  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 890.0 (TID 313, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 18:10:56.652  INFO 16044 --- [Executor task launch worker for task 313] org.apache.spark.executor.Executor       : Running task 0.0 in stage 890.0 (TID 313)
2018-05-01 18:10:57.753  INFO 16044 --- [Executor task launch worker for task 313] org.apache.spark.storage.BlockManager    : Found block rdd_473_0 locally
2018-05-01 18:10:57.754  INFO 16044 --- [Executor task launch worker for task 313] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 313:
[rdd_473_0]
2018-05-01 18:10:57.755  INFO 16044 --- [Executor task launch worker for task 313] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 890.0 (TID 313). 1046 bytes result sent to driver
2018-05-01 18:10:57.755  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 890.0 (TID 313) in 4018 ms on localhost (executor driver) (1/1)
2018-05-01 18:10:57.755  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 890.0, whose tasks have all completed, from pool 
2018-05-01 18:10:57.755  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 890 (isEmpty at ALS.scala:843) finished in 4.018 s
2018-05-01 18:10:57.756  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 64 finished: isEmpty at ALS.scala:843, took 4.025145 s
2018-05-01 18:10:57.779  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:857
2018-05-01 18:10:57.779  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 477 (mapPartitions at ALS.scala:1101)
2018-05-01 18:10:57.779  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 480 (map at ALS.scala:1344)
2018-05-01 18:10:57.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 65 (count at ALS.scala:857) with 1 output partitions
2018-05-01 18:10:57.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 893 (count at ALS.scala:857)
2018-05-01 18:10:57.781  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 892)
2018-05-01 18:10:57.781  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 892)
2018-05-01 18:10:57.781  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 891 (MapPartitionsRDD[477] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-05-01 18:10:57.782  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_116 stored as values in memory (estimated size 5.8 KB, free 1954.8 MB)
2018-05-01 18:10:57.783  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_116_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1954.8 MB)
2018-05-01 18:10:57.783  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_116_piece0 in memory on 172.21.241.193:58620 (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 18:10:57.784  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 116 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:10:57.784  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 891 (MapPartitionsRDD[477] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 18:10:57.784  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 891.0 with 2 tasks
2018-05-01 18:11:00.838  WARN 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 891 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 18:11:00.838  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 891.0 (TID 314, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427802 bytes)
2018-05-01 18:11:00.838  INFO 16044 --- [Executor task launch worker for task 314] org.apache.spark.executor.Executor       : Running task 0.0 in stage 891.0 (TID 314)
2018-05-01 18:11:00.985  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_115_piece0 on 172.21.241.193:58620 in memory (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 18:11:01.832  INFO 16044 --- [Executor task launch worker for task 314] org.apache.spark.storage.BlockManager    : Found block rdd_473_0 locally
2018-05-01 18:11:02.081  INFO 16044 --- [Executor task launch worker for task 314] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 891.0 (TID 314). 1027 bytes result sent to driver
2018-05-01 18:11:02.081  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 891.0 (TID 315, localhost, executor driver, partition 1, PROCESS_LOCAL, 5072 bytes)
2018-05-01 18:11:02.081  INFO 16044 --- [Executor task launch worker for task 315] org.apache.spark.executor.Executor       : Running task 1.0 in stage 891.0 (TID 315)
2018-05-01 18:11:02.081  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 891.0 (TID 314) in 4297 ms on localhost (executor driver) (1/2)
2018-05-01 18:11:02.096  INFO 16044 --- [Executor task launch worker for task 315] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 891.0 (TID 315). 855 bytes result sent to driver
2018-05-01 18:11:02.096  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 891.0 (TID 315) in 15 ms on localhost (executor driver) (2/2)
2018-05-01 18:11:02.096  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 891.0, whose tasks have all completed, from pool 
2018-05-01 18:11:02.096  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 891 (mapPartitions at ALS.scala:1101) finished in 4.312 s
2018-05-01 18:11:02.097  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:02.097  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:02.097  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 892, ResultStage 893)
2018-05-01 18:11:02.097  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:02.098  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 892 (MapPartitionsRDD[480] at map at ALS.scala:1344), which has no missing parents
2018-05-01 18:11:02.098  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_117 stored as values in memory (estimated size 7.1 KB, free 1954.8 MB)
2018-05-01 18:11:02.099  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_117_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1954.8 MB)
2018-05-01 18:11:02.099  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_117_piece0 in memory on 172.21.241.193:58620 (size: 3.7 KB, free: 1954.8 MB)
2018-05-01 18:11:02.100  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 117 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:02.100  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 892 (MapPartitionsRDD[480] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 18:11:02.101  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 892.0 with 2 tasks
2018-05-01 18:11:02.101  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 892.0 (TID 316, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 18:11:02.101  INFO 16044 --- [Executor task launch worker for task 316] org.apache.spark.executor.Executor       : Running task 0.0 in stage 892.0 (TID 316)
2018-05-01 18:11:02.103  INFO 16044 --- [Executor task launch worker for task 316] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 2 blocks
2018-05-01 18:11:02.103  INFO 16044 --- [Executor task launch worker for task 316] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:02.103  INFO 16044 --- [Executor task launch worker for task 316] o.a.spark.storage.memory.MemoryStore     : Block rdd_479_0 stored as values in memory (estimated size 16.0 B, free 1954.8 MB)
2018-05-01 18:11:02.104  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_479_0 in memory on 172.21.241.193:58620 (size: 16.0 B, free: 1954.8 MB)
2018-05-01 18:11:02.109  INFO 16044 --- [Executor task launch worker for task 316] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 892.0 (TID 316). 1809 bytes result sent to driver
2018-05-01 18:11:02.109  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 892.0 (TID 317, localhost, executor driver, partition 1, ANY, 4610 bytes)
2018-05-01 18:11:02.109  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 892.0 (TID 316) in 8 ms on localhost (executor driver) (1/2)
2018-05-01 18:11:02.109  INFO 16044 --- [Executor task launch worker for task 317] org.apache.spark.executor.Executor       : Running task 1.0 in stage 892.0 (TID 317)
2018-05-01 18:11:02.111  INFO 16044 --- [Executor task launch worker for task 317] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 2 non-empty blocks out of 2 blocks
2018-05-01 18:11:02.111  INFO 16044 --- [Executor task launch worker for task 317] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:02.247  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_116_piece0 on 172.21.241.193:58620 in memory (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 18:11:02.252  INFO 16044 --- [Executor task launch worker for task 317] o.a.spark.storage.memory.MemoryStore     : Block rdd_479_1 stored as values in memory (estimated size 12.0 MB, free 1942.8 MB)
2018-05-01 18:11:02.252  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_479_1 in memory on 172.21.241.193:58620 (size: 12.0 MB, free: 1942.8 MB)
2018-05-01 18:11:02.518  INFO 16044 --- [Executor task launch worker for task 317] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 892.0 (TID 317). 1981 bytes result sent to driver
2018-05-01 18:11:02.518  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 892.0 (TID 317) in 409 ms on localhost (executor driver) (2/2)
2018-05-01 18:11:02.518  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 892.0, whose tasks have all completed, from pool 
2018-05-01 18:11:02.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 892 (map at ALS.scala:1344) finished in 0.417 s
2018-05-01 18:11:02.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:02.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:02.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 893)
2018-05-01 18:11:02.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:02.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 893 (userOutBlocks MapPartitionsRDD[483] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 18:11:02.520  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_118 stored as values in memory (estimated size 7.7 KB, free 1942.8 MB)
2018-05-01 18:11:02.521  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_118_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1942.8 MB)
2018-05-01 18:11:02.521  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_118_piece0 in memory on 172.21.241.193:58620 (size: 3.9 KB, free: 1942.8 MB)
2018-05-01 18:11:02.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 118 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:02.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 893 (userOutBlocks MapPartitionsRDD[483] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:02.522  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 893.0 with 1 tasks
2018-05-01 18:11:02.522  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 893.0 (TID 318, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 18:11:02.523  INFO 16044 --- [Executor task launch worker for task 318] org.apache.spark.executor.Executor       : Running task 0.0 in stage 893.0 (TID 318)
2018-05-01 18:11:02.524  INFO 16044 --- [Executor task launch worker for task 318] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 18:11:02.524  INFO 16044 --- [Executor task launch worker for task 318] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:02.910  INFO 16044 --- [Executor task launch worker for task 318] o.a.spark.storage.memory.MemoryStore     : Block rdd_482_0 stored as values in memory (estimated size 8.1 MB, free 1934.7 MB)
2018-05-01 18:11:02.911  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_482_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1934.7 MB)
2018-05-01 18:11:02.915  INFO 16044 --- [Executor task launch worker for task 318] o.a.spark.storage.memory.MemoryStore     : Block rdd_483_0 stored as values in memory (estimated size 27.9 KB, free 1934.7 MB)
2018-05-01 18:11:02.915  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_483_0 in memory on 172.21.241.193:58620 (size: 27.9 KB, free: 1934.7 MB)
2018-05-01 18:11:02.916  INFO 16044 --- [Executor task launch worker for task 318] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 893.0 (TID 318). 1834 bytes result sent to driver
2018-05-01 18:11:02.916  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 893.0 (TID 318) in 394 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:02.916  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 893.0, whose tasks have all completed, from pool 
2018-05-01 18:11:02.916  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 893 (count at ALS.scala:857) finished in 0.394 s
2018-05-01 18:11:02.917  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 65 finished: count at ALS.scala:857, took 5.137836 s
2018-05-01 18:11:02.929  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:865
2018-05-01 18:11:02.929  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:02.931  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 485 (map at ALS.scala:1344)
2018-05-01 18:11:02.931  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 66 (count at ALS.scala:865) with 1 output partitions
2018-05-01 18:11:02.931  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 896 (count at ALS.scala:865)
2018-05-01 18:11:02.931  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 895)
2018-05-01 18:11:02.931  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 895)
2018-05-01 18:11:02.931  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 895 (MapPartitionsRDD[485] at map at ALS.scala:1344), which has no missing parents
2018-05-01 18:11:02.932  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_119 stored as values in memory (estimated size 7.3 KB, free 1934.7 MB)
2018-05-01 18:11:02.933  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_119_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1934.7 MB)
2018-05-01 18:11:02.933  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_119_piece0 in memory on 172.21.241.193:58620 (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 18:11:02.933  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 119 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:02.934  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 895 (MapPartitionsRDD[485] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 18:11:02.934  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 895.0 with 2 tasks
2018-05-01 18:11:02.934  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 895.0 (TID 319, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 18:11:02.934  INFO 16044 --- [Executor task launch worker for task 319] org.apache.spark.executor.Executor       : Running task 0.0 in stage 895.0 (TID 319)
2018-05-01 18:11:02.936  INFO 16044 --- [Executor task launch worker for task 319] org.apache.spark.storage.BlockManager    : Found block rdd_479_0 locally
2018-05-01 18:11:02.941  INFO 16044 --- [Executor task launch worker for task 319] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 895.0 (TID 319). 725 bytes result sent to driver
2018-05-01 18:11:02.942  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 895.0 (TID 320, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-05-01 18:11:02.942  INFO 16044 --- [Executor task launch worker for task 320] org.apache.spark.executor.Executor       : Running task 1.0 in stage 895.0 (TID 320)
2018-05-01 18:11:02.943  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 895.0 (TID 319) in 8 ms on localhost (executor driver) (1/2)
2018-05-01 18:11:02.944  INFO 16044 --- [Executor task launch worker for task 320] org.apache.spark.storage.BlockManager    : Found block rdd_479_1 locally
2018-05-01 18:11:03.204  INFO 16044 --- [Executor task launch worker for task 320] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 895.0 (TID 320). 940 bytes result sent to driver
2018-05-01 18:11:03.204  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 895.0 (TID 320) in 262 ms on localhost (executor driver) (2/2)
2018-05-01 18:11:03.204  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 895.0, whose tasks have all completed, from pool 
2018-05-01 18:11:03.205  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 895 (map at ALS.scala:1344) finished in 0.271 s
2018-05-01 18:11:03.205  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:03.205  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:03.205  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 896)
2018-05-01 18:11:03.205  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:03.205  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 896 (itemOutBlocks MapPartitionsRDD[488] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 18:11:03.206  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_120 stored as values in memory (estimated size 7.9 KB, free 1934.7 MB)
2018-05-01 18:11:03.206  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_120_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1934.7 MB)
2018-05-01 18:11:03.207  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_120_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1934.7 MB)
2018-05-01 18:11:03.207  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 120 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:03.207  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 896 (itemOutBlocks MapPartitionsRDD[488] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:03.207  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 896.0 with 1 tasks
2018-05-01 18:11:03.207  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 896.0 (TID 321, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 18:11:03.208  INFO 16044 --- [Executor task launch worker for task 321] org.apache.spark.executor.Executor       : Running task 0.0 in stage 896.0 (TID 321)
2018-05-01 18:11:03.209  INFO 16044 --- [Executor task launch worker for task 321] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 18:11:03.209  INFO 16044 --- [Executor task launch worker for task 321] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:03.373  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_117_piece0 on 172.21.241.193:58620 in memory (size: 3.7 KB, free: 1934.7 MB)
2018-05-01 18:11:03.374  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_118_piece0 on 172.21.241.193:58620 in memory (size: 3.9 KB, free: 1934.7 MB)
2018-05-01 18:11:03.374  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_119_piece0 on 172.21.241.193:58620 in memory (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 18:11:04.319  INFO 16044 --- [Executor task launch worker for task 321] o.a.spark.storage.memory.MemoryStore     : Block rdd_487_0 stored as values in memory (estimated size 8.1 MB, free 1926.6 MB)
2018-05-01 18:11:04.321  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_487_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1926.6 MB)
2018-05-01 18:11:04.324  INFO 16044 --- [Executor task launch worker for task 321] o.a.spark.storage.memory.MemoryStore     : Block rdd_488_0 stored as values in memory (estimated size 54.9 KB, free 1926.5 MB)
2018-05-01 18:11:04.324  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_488_0 in memory on 172.21.241.193:58620 (size: 54.9 KB, free: 1926.6 MB)
2018-05-01 18:11:04.325  INFO 16044 --- [Executor task launch worker for task 321] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 896.0 (TID 321). 1877 bytes result sent to driver
2018-05-01 18:11:04.325  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 896.0 (TID 321) in 1118 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:04.326  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 896.0, whose tasks have all completed, from pool 
2018-05-01 18:11:04.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 896 (count at ALS.scala:865) finished in 1.119 s
2018-05-01 18:11:04.327  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 66 finished: count at ALS.scala:865, took 1.397775 s
2018-05-01 18:11:04.335  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:04.336  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:04.337  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:04.337  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 67 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:04.337  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 899 (aggregate at ALS.scala:1491)
2018-05-01 18:11:04.337  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 898)
2018-05-01 18:11:04.337  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:11:04.337  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 899 (MapPartitionsRDD[491] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:04.338  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_121 stored as values in memory (estimated size 9.1 KB, free 1926.5 MB)
2018-05-01 18:11:04.339  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_121_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.5 MB)
2018-05-01 18:11:04.339  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_121_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.5 MB)
2018-05-01 18:11:04.339  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 121 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:04.339  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 899 (MapPartitionsRDD[491] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:04.340  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 899.0 with 1 tasks
2018-05-01 18:11:04.341  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 899.0 (TID 322, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
2018-05-01 18:11:04.341  INFO 16044 --- [Executor task launch worker for task 322] org.apache.spark.executor.Executor       : Running task 0.0 in stage 899.0 (TID 322)
2018-05-01 18:11:04.342  INFO 16044 --- [Executor task launch worker for task 322] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:04.349  INFO 16044 --- [Executor task launch worker for task 322] o.a.spark.storage.memory.MemoryStore     : Block rdd_489_0 stored as values in memory (estimated size 416.2 KB, free 1926.1 MB)
2018-05-01 18:11:04.349  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_489_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1926.1 MB)
2018-05-01 18:11:04.351  INFO 16044 --- [Executor task launch worker for task 322] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 899.0 (TID 322). 2165 bytes result sent to driver
2018-05-01 18:11:04.351  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 899.0 (TID 322) in 10 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:04.351  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 899.0, whose tasks have all completed, from pool 
2018-05-01 18:11:04.352  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 899 (aggregate at ALS.scala:1491) finished in 0.010 s
2018-05-01 18:11:04.352  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 67 finished: aggregate at ALS.scala:1491, took 0.015853 s
2018-05-01 18:11:04.365  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 490 from persistence list
2018-05-01 18:11:04.366  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 490
2018-05-01 18:11:04.371  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:04.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 489 (map at ALS.scala:1017)
2018-05-01 18:11:04.372  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 495 (flatMap at ALS.scala:1433)
2018-05-01 18:11:04.373  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:04.373  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 68 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:04.373  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 905 (aggregate at ALS.scala:1491)
2018-05-01 18:11:04.373  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 903, ShuffleMapStage 904)
2018-05-01 18:11:04.374  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 903)
2018-05-01 18:11:04.374  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 902 (userFactors-1 MapPartitionsRDD[489] at map at ALS.scala:1017), which has no missing parents
2018-05-01 18:11:04.375  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_122 stored as values in memory (estimated size 7.7 KB, free 1926.1 MB)
2018-05-01 18:11:04.376  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_122_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1926.1 MB)
2018-05-01 18:11:04.376  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_122_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 18:11:04.376  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 122 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:04.376  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 902 (userFactors-1 MapPartitionsRDD[489] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:04.376  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 902.0 with 1 tasks
2018-05-01 18:11:04.377  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 902.0 (TID 323, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 18:11:04.377  INFO 16044 --- [Executor task launch worker for task 323] org.apache.spark.executor.Executor       : Running task 0.0 in stage 902.0 (TID 323)
2018-05-01 18:11:04.378  INFO 16044 --- [Executor task launch worker for task 323] org.apache.spark.storage.BlockManager    : Found block rdd_489_0 locally
2018-05-01 18:11:04.412  INFO 16044 --- [Executor task launch worker for task 323] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 902.0 (TID 323). 897 bytes result sent to driver
2018-05-01 18:11:04.413  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 902.0 (TID 323) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:04.413  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 902.0, whose tasks have all completed, from pool 
2018-05-01 18:11:04.413  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 902 (map at ALS.scala:1017) finished in 0.037 s
2018-05-01 18:11:04.413  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:04.413  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:04.413  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 905, ShuffleMapStage 903)
2018-05-01 18:11:04.413  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:04.413  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 903 (MapPartitionsRDD[495] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:04.414  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_123 stored as values in memory (estimated size 8.8 KB, free 1926.1 MB)
2018-05-01 18:11:04.415  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_123_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.1 MB)
2018-05-01 18:11:04.415  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_123_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 18:11:04.415  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 123 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:04.415  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 903 (MapPartitionsRDD[495] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:04.415  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 903.0 with 1 tasks
2018-05-01 18:11:04.416  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 903.0 (TID 324, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-05-01 18:11:04.416  INFO 16044 --- [Executor task launch worker for task 324] org.apache.spark.executor.Executor       : Running task 0.0 in stage 903.0 (TID 324)
2018-05-01 18:11:04.418  INFO 16044 --- [Executor task launch worker for task 324] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:04.418  INFO 16044 --- [Executor task launch worker for task 324] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:04.418  INFO 16044 --- [Executor task launch worker for task 324] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:04.459  INFO 16044 --- [Executor task launch worker for task 324] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 903.0 (TID 324). 1327 bytes result sent to driver
2018-05-01 18:11:04.460  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 903.0 (TID 324) in 44 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:04.460  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 903.0, whose tasks have all completed, from pool 
2018-05-01 18:11:04.460  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 903 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 18:11:04.460  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:04.460  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:04.460  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 905)
2018-05-01 18:11:04.460  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:04.461  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 905 (MapPartitionsRDD[501] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:04.461  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_124 stored as values in memory (estimated size 12.6 KB, free 1926.1 MB)
2018-05-01 18:11:04.462  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_124_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1926.1 MB)
2018-05-01 18:11:04.463  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_124_piece0 in memory on 172.21.241.193:58620 (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 18:11:04.463  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 124 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:04.463  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 905 (MapPartitionsRDD[501] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:04.464  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 905.0 with 1 tasks
2018-05-01 18:11:04.464  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 905.0 (TID 325, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:04.464  INFO 16044 --- [Executor task launch worker for task 325] org.apache.spark.executor.Executor       : Running task 0.0 in stage 905.0 (TID 325)
2018-05-01 18:11:04.466  INFO 16044 --- [Executor task launch worker for task 325] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:04.466  INFO 16044 --- [Executor task launch worker for task 325] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:04.466  INFO 16044 --- [Executor task launch worker for task 325] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:04.732  INFO 16044 --- [Executor task launch worker for task 325] o.a.spark.storage.memory.MemoryStore     : Block rdd_500_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 18:11:04.732  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_500_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 18:11:04.735  INFO 16044 --- [Executor task launch worker for task 325] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 905.0 (TID 325). 2595 bytes result sent to driver
2018-05-01 18:11:04.736  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 905.0 (TID 325) in 272 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:04.736  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 905.0, whose tasks have all completed, from pool 
2018-05-01 18:11:04.736  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 905 (aggregate at ALS.scala:1491) finished in 0.272 s
2018-05-01 18:11:04.737  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 68 finished: aggregate at ALS.scala:1491, took 0.366212 s
2018-05-01 18:11:04.752  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 489 from persistence list
2018-05-01 18:11:04.752  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 489
2018-05-01 18:11:04.756  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:04.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:04.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:04.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:04.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:04.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:04.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 505 (flatMap at ALS.scala:1433)
2018-05-01 18:11:04.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 69 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:04.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 912 (aggregate at ALS.scala:1491)
2018-05-01 18:11:04.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 907, ShuffleMapStage 911)
2018-05-01 18:11:04.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 911)
2018-05-01 18:11:04.759  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 911 (MapPartitionsRDD[505] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:04.759  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_125 stored as values in memory (estimated size 11.8 KB, free 1925.7 MB)
2018-05-01 18:11:04.760  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_125_piece0 stored as bytes in memory (estimated size 5.6 KB, free 1925.7 MB)
2018-05-01 18:11:04.760  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_125_piece0 in memory on 172.21.241.193:58620 (size: 5.6 KB, free: 1925.7 MB)
2018-05-01 18:11:04.761  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 125 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:04.761  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 911 (MapPartitionsRDD[505] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:04.762  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 911.0 with 1 tasks
2018-05-01 18:11:04.762  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 911.0 (TID 326, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:04.762  INFO 16044 --- [Executor task launch worker for task 326] org.apache.spark.executor.Executor       : Running task 0.0 in stage 911.0 (TID 326)
2018-05-01 18:11:04.764  INFO 16044 --- [Executor task launch worker for task 326] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:04.764  INFO 16044 --- [Executor task launch worker for task 326] org.apache.spark.storage.BlockManager    : Found block rdd_500_0 locally
2018-05-01 18:11:04.793  INFO 16044 --- [Executor task launch worker for task 326] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 911.0 (TID 326). 1069 bytes result sent to driver
2018-05-01 18:11:04.794  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 911.0 (TID 326) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:04.794  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 911.0, whose tasks have all completed, from pool 
2018-05-01 18:11:04.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 911 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 18:11:04.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:04.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:04.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 912)
2018-05-01 18:11:04.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:04.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 912 (MapPartitionsRDD[511] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:04.796  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_126 stored as values in memory (estimated size 14.3 KB, free 1925.7 MB)
2018-05-01 18:11:04.797  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_126_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1925.6 MB)
2018-05-01 18:11:04.798  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_126_piece0 in memory on 172.21.241.193:58620 (size: 6.6 KB, free: 1925.7 MB)
2018-05-01 18:11:04.798  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 126 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:04.798  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 912 (MapPartitionsRDD[511] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:04.798  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 912.0 with 1 tasks
2018-05-01 18:11:04.798  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 912.0 (TID 327, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:04.798  INFO 16044 --- [Executor task launch worker for task 327] org.apache.spark.executor.Executor       : Running task 0.0 in stage 912.0 (TID 327)
2018-05-01 18:11:04.800  INFO 16044 --- [Executor task launch worker for task 327] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:04.800  INFO 16044 --- [Executor task launch worker for task 327] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:04.800  INFO 16044 --- [Executor task launch worker for task 327] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:05.067  INFO 16044 --- [Executor task launch worker for task 327] o.a.spark.storage.memory.MemoryStore     : Block rdd_510_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 18:11:05.067  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_510_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 18:11:05.069  INFO 16044 --- [Executor task launch worker for task 327] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 912.0 (TID 327). 2595 bytes result sent to driver
2018-05-01 18:11:05.070  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 912.0 (TID 327) in 272 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:05.070  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 912.0, whose tasks have all completed, from pool 
2018-05-01 18:11:05.070  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 912 (aggregate at ALS.scala:1491) finished in 0.272 s
2018-05-01 18:11:05.070  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 69 finished: aggregate at ALS.scala:1491, took 0.313379 s
2018-05-01 18:11:05.086  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 500 from persistence list
2018-05-01 18:11:05.087  INFO 16044 --- [block-manager-slave-async-thread-pool-12] org.apache.spark.storage.BlockManager    : Removing RDD 500
2018-05-01 18:11:05.092  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:05.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 515 (flatMap at ALS.scala:1433)
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 70 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 920 (aggregate at ALS.scala:1491)
2018-05-01 18:11:05.093  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 919, ShuffleMapStage 914)
2018-05-01 18:11:05.094  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 919)
2018-05-01 18:11:05.094  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 919 (MapPartitionsRDD[515] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:05.095  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_127 stored as values in memory (estimated size 13.4 KB, free 1926.0 MB)
2018-05-01 18:11:05.097  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_127_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1926.0 MB)
2018-05-01 18:11:05.097  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_127_piece0 in memory on 172.21.241.193:58620 (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 18:11:05.097  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 127 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:05.098  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 919 (MapPartitionsRDD[515] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:05.098  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 919.0 with 1 tasks
2018-05-01 18:11:05.098  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 919.0 (TID 328, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:05.098  INFO 16044 --- [Executor task launch worker for task 328] org.apache.spark.executor.Executor       : Running task 0.0 in stage 919.0 (TID 328)
2018-05-01 18:11:05.100  INFO 16044 --- [Executor task launch worker for task 328] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:05.100  INFO 16044 --- [Executor task launch worker for task 328] org.apache.spark.storage.BlockManager    : Found block rdd_510_0 locally
2018-05-01 18:11:05.126  INFO 16044 --- [Executor task launch worker for task 328] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 919.0 (TID 328). 1026 bytes result sent to driver
2018-05-01 18:11:05.126  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 919.0 (TID 328) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:05.126  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 919.0, whose tasks have all completed, from pool 
2018-05-01 18:11:05.127  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 919 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 18:11:05.127  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:05.127  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:05.127  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 920)
2018-05-01 18:11:05.127  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:05.127  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 920 (MapPartitionsRDD[521] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:05.128  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_128 stored as values in memory (estimated size 15.8 KB, free 1926.0 MB)
2018-05-01 18:11:05.129  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_128_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1926.0 MB)
2018-05-01 18:11:05.130  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_128_piece0 in memory on 172.21.241.193:58620 (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 18:11:05.130  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 128 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:05.130  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 920 (MapPartitionsRDD[521] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:05.130  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 920.0 with 1 tasks
2018-05-01 18:11:05.131  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 920.0 (TID 329, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:05.131  INFO 16044 --- [Executor task launch worker for task 329] org.apache.spark.executor.Executor       : Running task 0.0 in stage 920.0 (TID 329)
2018-05-01 18:11:05.133  INFO 16044 --- [Executor task launch worker for task 329] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:05.133  INFO 16044 --- [Executor task launch worker for task 329] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:05.133  INFO 16044 --- [Executor task launch worker for task 329] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:05.414  INFO 16044 --- [Executor task launch worker for task 329] o.a.spark.storage.memory.MemoryStore     : Block rdd_520_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 18:11:05.414  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_520_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 18:11:05.418  INFO 16044 --- [Executor task launch worker for task 329] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 920.0 (TID 329). 2595 bytes result sent to driver
2018-05-01 18:11:05.419  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 920.0 (TID 329) in 288 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:05.419  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 920.0, whose tasks have all completed, from pool 
2018-05-01 18:11:05.419  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 920 (aggregate at ALS.scala:1491) finished in 0.288 s
2018-05-01 18:11:05.419  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 70 finished: aggregate at ALS.scala:1491, took 0.327411 s
2018-05-01 18:11:05.435  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 510 from persistence list
2018-05-01 18:11:05.436  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 510
2018-05-01 18:11:05.441  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:05.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:05.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:05.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:05.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:05.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:05.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:05.443  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:05.443  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 525 (flatMap at ALS.scala:1433)
2018-05-01 18:11:05.443  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 71 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:05.443  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 929 (aggregate at ALS.scala:1491)
2018-05-01 18:11:05.443  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 928, ShuffleMapStage 922)
2018-05-01 18:11:05.443  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 928)
2018-05-01 18:11:05.444  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 928 (MapPartitionsRDD[525] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:05.445  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_129 stored as values in memory (estimated size 14.9 KB, free 1925.6 MB)
2018-05-01 18:11:05.446  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_129_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1925.6 MB)
2018-05-01 18:11:05.446  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_129_piece0 in memory on 172.21.241.193:58620 (size: 7.1 KB, free: 1925.7 MB)
2018-05-01 18:11:05.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 129 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:05.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 928 (MapPartitionsRDD[525] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:05.446  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 928.0 with 1 tasks
2018-05-01 18:11:05.447  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 928.0 (TID 330, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:05.447  INFO 16044 --- [Executor task launch worker for task 330] org.apache.spark.executor.Executor       : Running task 0.0 in stage 928.0 (TID 330)
2018-05-01 18:11:05.448  INFO 16044 --- [Executor task launch worker for task 330] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:05.448  INFO 16044 --- [Executor task launch worker for task 330] org.apache.spark.storage.BlockManager    : Found block rdd_520_0 locally
2018-05-01 18:11:05.484  INFO 16044 --- [Executor task launch worker for task 330] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 928.0 (TID 330). 1069 bytes result sent to driver
2018-05-01 18:11:05.485  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 928.0 (TID 330) in 38 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:05.485  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 928.0, whose tasks have all completed, from pool 
2018-05-01 18:11:05.485  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 928 (flatMap at ALS.scala:1433) finished in 0.038 s
2018-05-01 18:11:05.485  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:05.485  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:05.485  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 929)
2018-05-01 18:11:05.485  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:05.486  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 929 (MapPartitionsRDD[531] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:05.487  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_130 stored as values in memory (estimated size 17.4 KB, free 1925.6 MB)
2018-05-01 18:11:05.488  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_130_piece0 stored as bytes in memory (estimated size 7.9 KB, free 1925.6 MB)
2018-05-01 18:11:05.489  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_130_piece0 in memory on 172.21.241.193:58620 (size: 7.9 KB, free: 1925.7 MB)
2018-05-01 18:11:05.489  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 130 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:05.489  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 929 (MapPartitionsRDD[531] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:05.489  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 929.0 with 1 tasks
2018-05-01 18:11:05.490  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 929.0 (TID 331, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:05.490  INFO 16044 --- [Executor task launch worker for task 331] org.apache.spark.executor.Executor       : Running task 0.0 in stage 929.0 (TID 331)
2018-05-01 18:11:05.492  INFO 16044 --- [Executor task launch worker for task 331] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:05.492  INFO 16044 --- [Executor task launch worker for task 331] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:05.492  INFO 16044 --- [Executor task launch worker for task 331] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:05.758  INFO 16044 --- [Executor task launch worker for task 331] o.a.spark.storage.memory.MemoryStore     : Block rdd_530_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 18:11:05.760  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_530_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 18:11:05.761  INFO 16044 --- [Executor task launch worker for task 331] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 929.0 (TID 331). 2595 bytes result sent to driver
2018-05-01 18:11:05.762  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 929.0 (TID 331) in 272 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:05.762  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 929.0, whose tasks have all completed, from pool 
2018-05-01 18:11:05.762  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 929 (aggregate at ALS.scala:1491) finished in 0.272 s
2018-05-01 18:11:05.763  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 71 finished: aggregate at ALS.scala:1491, took 0.321078 s
2018-05-01 18:11:05.781  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 520 from persistence list
2018-05-01 18:11:05.782  INFO 16044 --- [block-manager-slave-async-thread-pool-12] org.apache.spark.storage.BlockManager    : Removing RDD 520
2018-05-01 18:11:05.786  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:05.786  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:05.786  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:05.787  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:05.788  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:05.788  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:05.788  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:05.789  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:05.789  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:05.789  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 535 (flatMap at ALS.scala:1433)
2018-05-01 18:11:05.789  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 72 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:05.789  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 939 (aggregate at ALS.scala:1491)
2018-05-01 18:11:05.789  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 933, ShuffleMapStage 938)
2018-05-01 18:11:05.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 938)
2018-05-01 18:11:05.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 938 (MapPartitionsRDD[535] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:05.791  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_131 stored as values in memory (estimated size 16.5 KB, free 1925.9 MB)
2018-05-01 18:11:05.792  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_131_piece0 stored as bytes in memory (estimated size 7.8 KB, free 1925.9 MB)
2018-05-01 18:11:05.792  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_131_piece0 in memory on 172.21.241.193:58620 (size: 7.8 KB, free: 1926.1 MB)
2018-05-01 18:11:05.792  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 131 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:05.792  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 938 (MapPartitionsRDD[535] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:05.792  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 938.0 with 1 tasks
2018-05-01 18:11:05.793  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 938.0 (TID 332, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:05.793  INFO 16044 --- [Executor task launch worker for task 332] org.apache.spark.executor.Executor       : Running task 0.0 in stage 938.0 (TID 332)
2018-05-01 18:11:05.794  INFO 16044 --- [Executor task launch worker for task 332] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:05.794  INFO 16044 --- [Executor task launch worker for task 332] org.apache.spark.storage.BlockManager    : Found block rdd_530_0 locally
2018-05-01 18:11:05.855  INFO 16044 --- [Executor task launch worker for task 332] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 938.0 (TID 332). 1069 bytes result sent to driver
2018-05-01 18:11:05.856  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 938.0 (TID 332) in 63 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:05.856  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 938.0, whose tasks have all completed, from pool 
2018-05-01 18:11:05.856  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 938 (flatMap at ALS.scala:1433) finished in 0.063 s
2018-05-01 18:11:05.856  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:05.856  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:05.856  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 939)
2018-05-01 18:11:05.856  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:05.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 939 (MapPartitionsRDD[541] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:05.858  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_132 stored as values in memory (estimated size 18.9 KB, free 1925.9 MB)
2018-05-01 18:11:05.859  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_132_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1925.9 MB)
2018-05-01 18:11:05.859  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_132_piece0 in memory on 172.21.241.193:58620 (size: 8.6 KB, free: 1926.1 MB)
2018-05-01 18:11:05.859  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 132 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:05.859  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 939 (MapPartitionsRDD[541] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:05.859  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 939.0 with 1 tasks
2018-05-01 18:11:05.860  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 939.0 (TID 333, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:05.860  INFO 16044 --- [Executor task launch worker for task 333] org.apache.spark.executor.Executor       : Running task 0.0 in stage 939.0 (TID 333)
2018-05-01 18:11:05.862  INFO 16044 --- [Executor task launch worker for task 333] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:05.862  INFO 16044 --- [Executor task launch worker for task 333] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:05.862  INFO 16044 --- [Executor task launch worker for task 333] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:06.169  INFO 16044 --- [Executor task launch worker for task 333] o.a.spark.storage.memory.MemoryStore     : Block rdd_540_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 18:11:06.169  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_540_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 18:11:06.173  INFO 16044 --- [Executor task launch worker for task 333] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 939.0 (TID 333). 2595 bytes result sent to driver
2018-05-01 18:11:06.173  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 939.0 (TID 333) in 313 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:06.173  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 939.0, whose tasks have all completed, from pool 
2018-05-01 18:11:06.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 939 (aggregate at ALS.scala:1491) finished in 0.314 s
2018-05-01 18:11:06.174  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 72 finished: aggregate at ALS.scala:1491, took 0.388162 s
2018-05-01 18:11:06.189  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 530 from persistence list
2018-05-01 18:11:06.190  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 530
2018-05-01 18:11:06.194  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:06.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:06.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:06.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:06.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:06.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:06.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:06.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:06.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:06.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:06.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 545 (flatMap at ALS.scala:1433)
2018-05-01 18:11:06.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 73 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:06.196  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 950 (aggregate at ALS.scala:1491)
2018-05-01 18:11:06.196  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 949, ShuffleMapStage 941)
2018-05-01 18:11:06.197  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 949)
2018-05-01 18:11:06.197  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 949 (MapPartitionsRDD[545] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:06.199  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_133 stored as values in memory (estimated size 18.0 KB, free 1925.5 MB)
2018-05-01 18:11:06.200  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_133_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1925.5 MB)
2018-05-01 18:11:06.200  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_133_piece0 in memory on 172.21.241.193:58620 (size: 8.4 KB, free: 1925.7 MB)
2018-05-01 18:11:06.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 133 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:06.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 949 (MapPartitionsRDD[545] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:06.200  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 949.0 with 1 tasks
2018-05-01 18:11:06.201  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 949.0 (TID 334, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:06.201  INFO 16044 --- [Executor task launch worker for task 334] org.apache.spark.executor.Executor       : Running task 0.0 in stage 949.0 (TID 334)
2018-05-01 18:11:06.202  INFO 16044 --- [Executor task launch worker for task 334] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:06.203  INFO 16044 --- [Executor task launch worker for task 334] org.apache.spark.storage.BlockManager    : Found block rdd_540_0 locally
2018-05-01 18:11:06.234  INFO 16044 --- [Executor task launch worker for task 334] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 949.0 (TID 334). 1069 bytes result sent to driver
2018-05-01 18:11:06.234  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 949.0 (TID 334) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:06.234  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 949.0, whose tasks have all completed, from pool 
2018-05-01 18:11:06.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 949 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 18:11:06.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:06.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:06.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 950)
2018-05-01 18:11:06.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:06.235  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 950 (MapPartitionsRDD[551] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:06.236  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_134 stored as values in memory (estimated size 20.5 KB, free 1925.5 MB)
2018-05-01 18:11:06.236  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_134_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1925.5 MB)
2018-05-01 18:11:06.237  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_134_piece0 in memory on 172.21.241.193:58620 (size: 9.3 KB, free: 1925.7 MB)
2018-05-01 18:11:06.237  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 134 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:06.237  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 950 (MapPartitionsRDD[551] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:06.237  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 950.0 with 1 tasks
2018-05-01 18:11:06.238  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 950.0 (TID 335, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:06.238  INFO 16044 --- [Executor task launch worker for task 335] org.apache.spark.executor.Executor       : Running task 0.0 in stage 950.0 (TID 335)
2018-05-01 18:11:06.240  INFO 16044 --- [Executor task launch worker for task 335] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:06.240  INFO 16044 --- [Executor task launch worker for task 335] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:06.240  INFO 16044 --- [Executor task launch worker for task 335] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:06.499  INFO 16044 --- [Executor task launch worker for task 335] o.a.spark.storage.memory.MemoryStore     : Block rdd_550_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 18:11:06.499  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_550_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 18:11:06.501  INFO 16044 --- [Executor task launch worker for task 335] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 950.0 (TID 335). 2595 bytes result sent to driver
2018-05-01 18:11:06.501  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 950.0 (TID 335) in 263 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:06.501  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 950.0, whose tasks have all completed, from pool 
2018-05-01 18:11:06.502  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 950 (aggregate at ALS.scala:1491) finished in 0.264 s
2018-05-01 18:11:06.502  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 73 finished: aggregate at ALS.scala:1491, took 0.308119 s
2018-05-01 18:11:06.519  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 540 from persistence list
2018-05-01 18:11:06.520  INFO 16044 --- [block-manager-slave-async-thread-pool-12] org.apache.spark.storage.BlockManager    : Removing RDD 540
2018-05-01 18:11:06.524  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:06.525  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:06.525  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:06.525  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:06.525  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:06.525  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:06.525  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:06.526  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:06.526  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:06.526  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:06.526  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:06.526  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 555 (flatMap at ALS.scala:1433)
2018-05-01 18:11:06.526  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 74 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:06.526  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 962 (aggregate at ALS.scala:1491)
2018-05-01 18:11:06.526  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 952, ShuffleMapStage 961)
2018-05-01 18:11:06.527  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 961)
2018-05-01 18:11:06.527  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 961 (MapPartitionsRDD[555] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:06.528  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_135 stored as values in memory (estimated size 19.6 KB, free 1925.8 MB)
2018-05-01 18:11:06.530  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_135_piece0 stored as bytes in memory (estimated size 9.1 KB, free 1925.8 MB)
2018-05-01 18:11:06.531  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_135_piece0 in memory on 172.21.241.193:58620 (size: 9.1 KB, free: 1926.0 MB)
2018-05-01 18:11:06.531  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 135 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:06.531  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 961 (MapPartitionsRDD[555] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:06.531  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 961.0 with 1 tasks
2018-05-01 18:11:06.533  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 961.0 (TID 336, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:06.533  INFO 16044 --- [Executor task launch worker for task 336] org.apache.spark.executor.Executor       : Running task 0.0 in stage 961.0 (TID 336)
2018-05-01 18:11:06.534  INFO 16044 --- [Executor task launch worker for task 336] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:06.535  INFO 16044 --- [Executor task launch worker for task 336] org.apache.spark.storage.BlockManager    : Found block rdd_550_0 locally
2018-05-01 18:11:06.574  INFO 16044 --- [Executor task launch worker for task 336] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 961.0 (TID 336). 1069 bytes result sent to driver
2018-05-01 18:11:06.575  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 961.0 (TID 336) in 43 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:06.575  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 961.0, whose tasks have all completed, from pool 
2018-05-01 18:11:06.575  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 961 (flatMap at ALS.scala:1433) finished in 0.043 s
2018-05-01 18:11:06.575  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:06.575  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:06.575  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 962)
2018-05-01 18:11:06.575  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:06.575  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 962 (MapPartitionsRDD[561] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:06.576  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_136 stored as values in memory (estimated size 22.0 KB, free 1925.8 MB)
2018-05-01 18:11:06.577  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_136_piece0 stored as bytes in memory (estimated size 9.9 KB, free 1925.8 MB)
2018-05-01 18:11:06.577  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_136_piece0 in memory on 172.21.241.193:58620 (size: 9.9 KB, free: 1926.0 MB)
2018-05-01 18:11:06.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 136 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:06.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 962 (MapPartitionsRDD[561] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:06.578  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 962.0 with 1 tasks
2018-05-01 18:11:06.578  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 962.0 (TID 337, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:06.578  INFO 16044 --- [Executor task launch worker for task 337] org.apache.spark.executor.Executor       : Running task 0.0 in stage 962.0 (TID 337)
2018-05-01 18:11:06.580  INFO 16044 --- [Executor task launch worker for task 337] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:06.580  INFO 16044 --- [Executor task launch worker for task 337] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:06.580  INFO 16044 --- [Executor task launch worker for task 337] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:06.849  INFO 16044 --- [Executor task launch worker for task 337] o.a.spark.storage.memory.MemoryStore     : Block rdd_560_0 stored as values in memory (estimated size 820.5 KB, free 1925.0 MB)
2018-05-01 18:11:06.849  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_560_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 18:11:06.853  INFO 16044 --- [Executor task launch worker for task 337] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 962.0 (TID 337). 2595 bytes result sent to driver
2018-05-01 18:11:06.854  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 962.0 (TID 337) in 276 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:06.854  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 962.0, whose tasks have all completed, from pool 
2018-05-01 18:11:06.854  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 962 (aggregate at ALS.scala:1491) finished in 0.276 s
2018-05-01 18:11:06.854  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 74 finished: aggregate at ALS.scala:1491, took 0.329954 s
2018-05-01 18:11:06.870  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 550 from persistence list
2018-05-01 18:11:06.870  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 550
2018-05-01 18:11:06.876  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:06.876  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:06.877  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:06.877  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:06.877  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:06.877  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:06.877  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:06.877  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:06.877  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:06.877  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:06.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:06.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:06.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 565 (flatMap at ALS.scala:1433)
2018-05-01 18:11:06.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 75 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:06.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 975 (aggregate at ALS.scala:1491)
2018-05-01 18:11:06.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 964, ShuffleMapStage 974)
2018-05-01 18:11:06.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 974)
2018-05-01 18:11:06.879  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 974 (MapPartitionsRDD[565] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:06.882  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_137 stored as values in memory (estimated size 21.1 KB, free 1925.4 MB)
2018-05-01 18:11:06.883  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_137_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1925.4 MB)
2018-05-01 18:11:06.883  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_137_piece0 in memory on 172.21.241.193:58620 (size: 9.7 KB, free: 1925.6 MB)
2018-05-01 18:11:06.883  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 137 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:06.884  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 974 (MapPartitionsRDD[565] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:06.884  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 974.0 with 1 tasks
2018-05-01 18:11:06.884  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 974.0 (TID 338, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:06.884  INFO 16044 --- [Executor task launch worker for task 338] org.apache.spark.executor.Executor       : Running task 0.0 in stage 974.0 (TID 338)
2018-05-01 18:11:06.886  INFO 16044 --- [Executor task launch worker for task 338] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:06.886  INFO 16044 --- [Executor task launch worker for task 338] org.apache.spark.storage.BlockManager    : Found block rdd_560_0 locally
2018-05-01 18:11:06.921  INFO 16044 --- [Executor task launch worker for task 338] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 974.0 (TID 338). 1112 bytes result sent to driver
2018-05-01 18:11:06.921  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 974.0 (TID 338) in 37 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:06.921  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 974.0, whose tasks have all completed, from pool 
2018-05-01 18:11:06.922  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 974 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 18:11:06.922  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:06.922  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:06.922  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 975)
2018-05-01 18:11:06.922  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:06.923  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 975 (MapPartitionsRDD[571] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:06.925  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_138 stored as values in memory (estimated size 23.6 KB, free 1925.3 MB)
2018-05-01 18:11:06.926  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_138_piece0 stored as bytes in memory (estimated size 10.6 KB, free 1925.3 MB)
2018-05-01 18:11:06.927  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_138_piece0 in memory on 172.21.241.193:58620 (size: 10.6 KB, free: 1925.6 MB)
2018-05-01 18:11:06.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 138 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:06.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 975 (MapPartitionsRDD[571] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:06.928  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 975.0 with 1 tasks
2018-05-01 18:11:06.928  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 975.0 (TID 339, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:06.928  INFO 16044 --- [Executor task launch worker for task 339] org.apache.spark.executor.Executor       : Running task 0.0 in stage 975.0 (TID 339)
2018-05-01 18:11:06.930  INFO 16044 --- [Executor task launch worker for task 339] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:06.930  INFO 16044 --- [Executor task launch worker for task 339] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:06.930  INFO 16044 --- [Executor task launch worker for task 339] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:07.201  INFO 16044 --- [Executor task launch worker for task 339] o.a.spark.storage.memory.MemoryStore     : Block rdd_570_0 stored as values in memory (estimated size 416.2 KB, free 1924.9 MB)
2018-05-01 18:11:07.202  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_570_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 18:11:07.204  INFO 16044 --- [Executor task launch worker for task 339] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 975.0 (TID 339). 2595 bytes result sent to driver
2018-05-01 18:11:07.204  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 975.0 (TID 339) in 276 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:07.204  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 975.0, whose tasks have all completed, from pool 
2018-05-01 18:11:07.205  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 975 (aggregate at ALS.scala:1491) finished in 0.277 s
2018-05-01 18:11:07.205  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 75 finished: aggregate at ALS.scala:1491, took 0.329405 s
2018-05-01 18:11:07.222  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 560 from persistence list
2018-05-01 18:11:07.222  INFO 16044 --- [block-manager-slave-async-thread-pool-12] org.apache.spark.storage.BlockManager    : Removing RDD 560
2018-05-01 18:11:07.227  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:07.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:07.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:07.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:07.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:07.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:07.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:07.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:07.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:07.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:07.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:07.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:07.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:07.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 575 (flatMap at ALS.scala:1433)
2018-05-01 18:11:07.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 76 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:07.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 989 (aggregate at ALS.scala:1491)
2018-05-01 18:11:07.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 988, ShuffleMapStage 979)
2018-05-01 18:11:07.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 988)
2018-05-01 18:11:07.230  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 988 (MapPartitionsRDD[575] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:07.231  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_139 stored as values in memory (estimated size 22.7 KB, free 1925.7 MB)
2018-05-01 18:11:07.232  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_139_piece0 stored as bytes in memory (estimated size 10.4 KB, free 1925.7 MB)
2018-05-01 18:11:07.232  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_139_piece0 in memory on 172.21.241.193:58620 (size: 10.4 KB, free: 1926.0 MB)
2018-05-01 18:11:07.232  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 139 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:07.233  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 988 (MapPartitionsRDD[575] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:07.233  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 988.0 with 1 tasks
2018-05-01 18:11:07.233  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 988.0 (TID 340, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:07.233  INFO 16044 --- [Executor task launch worker for task 340] org.apache.spark.executor.Executor       : Running task 0.0 in stage 988.0 (TID 340)
2018-05-01 18:11:07.235  INFO 16044 --- [Executor task launch worker for task 340] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:07.235  INFO 16044 --- [Executor task launch worker for task 340] org.apache.spark.storage.BlockManager    : Found block rdd_570_0 locally
2018-05-01 18:11:07.274  INFO 16044 --- [Executor task launch worker for task 340] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 988.0 (TID 340). 1026 bytes result sent to driver
2018-05-01 18:11:07.274  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 988.0 (TID 340) in 41 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:07.274  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 988.0, whose tasks have all completed, from pool 
2018-05-01 18:11:07.275  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 988 (flatMap at ALS.scala:1433) finished in 0.042 s
2018-05-01 18:11:07.275  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:07.275  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:07.275  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 989)
2018-05-01 18:11:07.275  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:07.275  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 989 (MapPartitionsRDD[581] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:07.277  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_140 stored as values in memory (estimated size 25.1 KB, free 1925.7 MB)
2018-05-01 18:11:07.278  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_140_piece0 stored as bytes in memory (estimated size 11.2 KB, free 1925.7 MB)
2018-05-01 18:11:07.278  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_140_piece0 in memory on 172.21.241.193:58620 (size: 11.2 KB, free: 1926.0 MB)
2018-05-01 18:11:07.278  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 140 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:07.278  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 989 (MapPartitionsRDD[581] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:07.278  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 989.0 with 1 tasks
2018-05-01 18:11:07.279  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 989.0 (TID 341, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:07.279  INFO 16044 --- [Executor task launch worker for task 341] org.apache.spark.executor.Executor       : Running task 0.0 in stage 989.0 (TID 341)
2018-05-01 18:11:07.281  INFO 16044 --- [Executor task launch worker for task 341] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:07.281  INFO 16044 --- [Executor task launch worker for task 341] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:07.281  INFO 16044 --- [Executor task launch worker for task 341] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:07.548  INFO 16044 --- [Executor task launch worker for task 341] o.a.spark.storage.memory.MemoryStore     : Block rdd_580_0 stored as values in memory (estimated size 820.5 KB, free 1924.9 MB)
2018-05-01 18:11:07.549  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_580_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 18:11:07.552  INFO 16044 --- [Executor task launch worker for task 341] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 989.0 (TID 341). 2595 bytes result sent to driver
2018-05-01 18:11:07.552  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 989.0 (TID 341) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:07.552  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 989.0, whose tasks have all completed, from pool 
2018-05-01 18:11:07.553  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 989 (aggregate at ALS.scala:1491) finished in 0.275 s
2018-05-01 18:11:07.553  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 76 finished: aggregate at ALS.scala:1491, took 0.326574 s
2018-05-01 18:11:07.569  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 570 from persistence list
2018-05-01 18:11:07.569  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 570
2018-05-01 18:11:07.576  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:07.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:07.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 585 (flatMap at ALS.scala:1433)
2018-05-01 18:11:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 77 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1004 (aggregate at ALS.scala:1491)
2018-05-01 18:11:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1003, ShuffleMapStage 991)
2018-05-01 18:11:07.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1003)
2018-05-01 18:11:07.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1003 (MapPartitionsRDD[585] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:07.581  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_141 stored as values in memory (estimated size 24.2 KB, free 1925.2 MB)
2018-05-01 18:11:07.582  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_141_piece0 stored as bytes in memory (estimated size 11.0 KB, free 1925.2 MB)
2018-05-01 18:11:07.582  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_141_piece0 in memory on 172.21.241.193:58620 (size: 11.0 KB, free: 1925.6 MB)
2018-05-01 18:11:07.582  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 141 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:07.582  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1003 (MapPartitionsRDD[585] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:07.582  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1003.0 with 1 tasks
2018-05-01 18:11:07.583  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1003.0 (TID 342, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:07.583  INFO 16044 --- [Executor task launch worker for task 342] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1003.0 (TID 342)
2018-05-01 18:11:07.585  INFO 16044 --- [Executor task launch worker for task 342] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:07.585  INFO 16044 --- [Executor task launch worker for task 342] org.apache.spark.storage.BlockManager    : Found block rdd_580_0 locally
2018-05-01 18:11:07.618  INFO 16044 --- [Executor task launch worker for task 342] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1003.0 (TID 342). 1069 bytes result sent to driver
2018-05-01 18:11:07.618  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1003.0 (TID 342) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:07.619  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1003.0, whose tasks have all completed, from pool 
2018-05-01 18:11:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1003 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 18:11:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1004)
2018-05-01 18:11:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1004 (MapPartitionsRDD[591] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:07.621  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_142 stored as values in memory (estimated size 26.7 KB, free 1925.2 MB)
2018-05-01 18:11:07.646  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_142_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1925.2 MB)
2018-05-01 18:11:07.646  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_142_piece0 in memory on 172.21.241.193:58620 (size: 11.9 KB, free: 1925.6 MB)
2018-05-01 18:11:07.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 142 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:07.647  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1004 (MapPartitionsRDD[591] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:07.647  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_122_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1925.6 MB)
2018-05-01 18:11:07.648  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1004.0 with 1 tasks
2018-05-01 18:11:07.648  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1004.0 (TID 343, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:07.648  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_126_piece0 on 172.21.241.193:58620 in memory (size: 6.6 KB, free: 1925.6 MB)
2018-05-01 18:11:07.648  INFO 16044 --- [Executor task launch worker for task 343] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1004.0 (TID 343)
2018-05-01 18:11:07.649  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_120_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1925.6 MB)
2018-05-01 18:11:07.650  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_136_piece0 on 172.21.241.193:58620 in memory (size: 9.9 KB, free: 1925.6 MB)
2018-05-01 18:11:07.650  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_124_piece0 on 172.21.241.193:58620 in memory (size: 5.8 KB, free: 1925.6 MB)
2018-05-01 18:11:07.651  INFO 16044 --- [Executor task launch worker for task 343] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:07.651  INFO 16044 --- [Executor task launch worker for task 343] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:07.651  INFO 16044 --- [Executor task launch worker for task 343] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:07.651  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_129_piece0 on 172.21.241.193:58620 in memory (size: 7.1 KB, free: 1925.6 MB)
2018-05-01 18:11:07.652  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_121_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1925.6 MB)
2018-05-01 18:11:07.653  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_135_piece0 on 172.21.241.193:58620 in memory (size: 9.1 KB, free: 1925.6 MB)
2018-05-01 18:11:07.653  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_140_piece0 on 172.21.241.193:58620 in memory (size: 11.2 KB, free: 1925.6 MB)
2018-05-01 18:11:07.654  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_132_piece0 on 172.21.241.193:58620 in memory (size: 8.6 KB, free: 1925.6 MB)
2018-05-01 18:11:07.655  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_125_piece0 on 172.21.241.193:58620 in memory (size: 5.6 KB, free: 1925.7 MB)
2018-05-01 18:11:07.655  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_131_piece0 on 172.21.241.193:58620 in memory (size: 7.8 KB, free: 1925.7 MB)
2018-05-01 18:11:07.656  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_123_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1925.7 MB)
2018-05-01 18:11:07.656  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_127_piece0 on 172.21.241.193:58620 in memory (size: 6.4 KB, free: 1925.7 MB)
2018-05-01 18:11:07.657  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_139_piece0 on 172.21.241.193:58620 in memory (size: 10.4 KB, free: 1925.7 MB)
2018-05-01 18:11:07.658  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_134_piece0 on 172.21.241.193:58620 in memory (size: 9.3 KB, free: 1925.7 MB)
2018-05-01 18:11:07.658  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_137_piece0 on 172.21.241.193:58620 in memory (size: 9.7 KB, free: 1925.7 MB)
2018-05-01 18:11:07.658  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_133_piece0 on 172.21.241.193:58620 in memory (size: 8.4 KB, free: 1925.7 MB)
2018-05-01 18:11:07.659  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_128_piece0 on 172.21.241.193:58620 in memory (size: 7.3 KB, free: 1925.7 MB)
2018-05-01 18:11:07.659  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_138_piece0 on 172.21.241.193:58620 in memory (size: 10.6 KB, free: 1925.7 MB)
2018-05-01 18:11:07.660  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_130_piece0 on 172.21.241.193:58620 in memory (size: 7.9 KB, free: 1925.7 MB)
2018-05-01 18:11:07.922  INFO 16044 --- [Executor task launch worker for task 343] o.a.spark.storage.memory.MemoryStore     : Block rdd_590_0 stored as values in memory (estimated size 416.2 KB, free 1925.3 MB)
2018-05-01 18:11:07.923  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_590_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 18:11:07.924  INFO 16044 --- [Executor task launch worker for task 343] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1004.0 (TID 343). 2595 bytes result sent to driver
2018-05-01 18:11:07.925  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1004.0 (TID 343) in 277 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:07.925  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1004.0, whose tasks have all completed, from pool 
2018-05-01 18:11:07.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1004 (aggregate at ALS.scala:1491) finished in 0.277 s
2018-05-01 18:11:07.926  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 77 finished: aggregate at ALS.scala:1491, took 0.350151 s
2018-05-01 18:11:07.942  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 580 from persistence list
2018-05-01 18:11:07.942  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 580
2018-05-01 18:11:07.947  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 595 (flatMap at ALS.scala:1433)
2018-05-01 18:11:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 78 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1020 (aggregate at ALS.scala:1491)
2018-05-01 18:11:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1019, ShuffleMapStage 1008)
2018-05-01 18:11:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1019)
2018-05-01 18:11:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1019 (MapPartitionsRDD[595] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:07.953  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_143 stored as values in memory (estimated size 25.8 KB, free 1926.1 MB)
2018-05-01 18:11:07.954  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_143_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1926.0 MB)
2018-05-01 18:11:07.955  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_143_piece0 in memory on 172.21.241.193:58620 (size: 11.7 KB, free: 1926.1 MB)
2018-05-01 18:11:07.955  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 143 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:07.955  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1019 (MapPartitionsRDD[595] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:07.955  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1019.0 with 1 tasks
2018-05-01 18:11:07.955  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1019.0 (TID 344, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:07.956  INFO 16044 --- [Executor task launch worker for task 344] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1019.0 (TID 344)
2018-05-01 18:11:07.959  INFO 16044 --- [Executor task launch worker for task 344] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:07.959  INFO 16044 --- [Executor task launch worker for task 344] org.apache.spark.storage.BlockManager    : Found block rdd_590_0 locally
2018-05-01 18:11:07.990  INFO 16044 --- [Executor task launch worker for task 344] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1019.0 (TID 344). 1069 bytes result sent to driver
2018-05-01 18:11:07.991  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1019.0 (TID 344) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:07.991  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1019.0, whose tasks have all completed, from pool 
2018-05-01 18:11:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1019 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 18:11:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1020)
2018-05-01 18:11:07.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:07.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1020 (MapPartitionsRDD[601] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:07.993  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_144 stored as values in memory (estimated size 28.2 KB, free 1926.0 MB)
2018-05-01 18:11:07.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_144_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1926.0 MB)
2018-05-01 18:11:07.995  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_144_piece0 in memory on 172.21.241.193:58620 (size: 12.5 KB, free: 1926.1 MB)
2018-05-01 18:11:07.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 144 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:07.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1020 (MapPartitionsRDD[601] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:07.995  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1020.0 with 1 tasks
2018-05-01 18:11:07.996  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1020.0 (TID 345, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:07.996  INFO 16044 --- [Executor task launch worker for task 345] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1020.0 (TID 345)
2018-05-01 18:11:07.998  INFO 16044 --- [Executor task launch worker for task 345] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:07.998  INFO 16044 --- [Executor task launch worker for task 345] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:07.998  INFO 16044 --- [Executor task launch worker for task 345] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:08.286  INFO 16044 --- [Executor task launch worker for task 345] o.a.spark.storage.memory.MemoryStore     : Block rdd_600_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 18:11:08.286  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_600_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 18:11:08.289  INFO 16044 --- [Executor task launch worker for task 345] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1020.0 (TID 345). 2595 bytes result sent to driver
2018-05-01 18:11:08.290  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1020.0 (TID 345) in 295 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:08.290  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1020.0, whose tasks have all completed, from pool 
2018-05-01 18:11:08.290  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1020 (aggregate at ALS.scala:1491) finished in 0.295 s
2018-05-01 18:11:08.290  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 78 finished: aggregate at ALS.scala:1491, took 0.343299 s
2018-05-01 18:11:08.307  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 590 from persistence list
2018-05-01 18:11:08.308  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 590
2018-05-01 18:11:08.312  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:08.312  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:08.312  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:08.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:08.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:08.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:08.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:08.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:08.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:08.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:08.314  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:08.314  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:08.314  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:08.314  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:08.314  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:08.315  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:08.315  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 605 (flatMap at ALS.scala:1433)
2018-05-01 18:11:08.315  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 79 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:08.315  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1037 (aggregate at ALS.scala:1491)
2018-05-01 18:11:08.315  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1036, ShuffleMapStage 1022)
2018-05-01 18:11:08.315  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1036)
2018-05-01 18:11:08.315  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1036 (MapPartitionsRDD[605] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:08.317  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_145 stored as values in memory (estimated size 27.3 KB, free 1925.6 MB)
2018-05-01 18:11:08.318  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_145_piece0 stored as bytes in memory (estimated size 12.4 KB, free 1925.6 MB)
2018-05-01 18:11:08.318  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_145_piece0 in memory on 172.21.241.193:58620 (size: 12.4 KB, free: 1925.7 MB)
2018-05-01 18:11:08.318  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 145 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:08.318  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1036 (MapPartitionsRDD[605] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:08.318  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1036.0 with 1 tasks
2018-05-01 18:11:08.319  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1036.0 (TID 346, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:08.319  INFO 16044 --- [Executor task launch worker for task 346] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1036.0 (TID 346)
2018-05-01 18:11:08.320  INFO 16044 --- [Executor task launch worker for task 346] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:08.321  INFO 16044 --- [Executor task launch worker for task 346] org.apache.spark.storage.BlockManager    : Found block rdd_600_0 locally
2018-05-01 18:11:08.351  INFO 16044 --- [Executor task launch worker for task 346] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1036.0 (TID 346). 1069 bytes result sent to driver
2018-05-01 18:11:08.352  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1036.0 (TID 346) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:08.352  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1036.0, whose tasks have all completed, from pool 
2018-05-01 18:11:08.352  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1036 (flatMap at ALS.scala:1433) finished in 0.034 s
2018-05-01 18:11:08.352  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:08.352  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:08.352  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1037)
2018-05-01 18:11:08.352  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:08.352  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1037 (MapPartitionsRDD[611] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:08.354  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_146 stored as values in memory (estimated size 29.8 KB, free 1925.5 MB)
2018-05-01 18:11:08.355  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_146_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1925.5 MB)
2018-05-01 18:11:08.355  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_146_piece0 in memory on 172.21.241.193:58620 (size: 13.2 KB, free: 1925.7 MB)
2018-05-01 18:11:08.355  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 146 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:08.356  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1037 (MapPartitionsRDD[611] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:08.356  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1037.0 with 1 tasks
2018-05-01 18:11:08.356  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1037.0 (TID 347, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:08.356  INFO 16044 --- [Executor task launch worker for task 347] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1037.0 (TID 347)
2018-05-01 18:11:08.358  INFO 16044 --- [Executor task launch worker for task 347] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:08.358  INFO 16044 --- [Executor task launch worker for task 347] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:08.358  INFO 16044 --- [Executor task launch worker for task 347] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:08.614  INFO 16044 --- [Executor task launch worker for task 347] o.a.spark.storage.memory.MemoryStore     : Block rdd_610_0 stored as values in memory (estimated size 416.2 KB, free 1925.1 MB)
2018-05-01 18:11:08.615  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_610_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 18:11:08.617  INFO 16044 --- [Executor task launch worker for task 347] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1037.0 (TID 347). 2595 bytes result sent to driver
2018-05-01 18:11:08.617  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1037.0 (TID 347) in 261 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:08.617  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1037.0, whose tasks have all completed, from pool 
2018-05-01 18:11:08.617  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1037 (aggregate at ALS.scala:1491) finished in 0.261 s
2018-05-01 18:11:08.618  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 79 finished: aggregate at ALS.scala:1491, took 0.305860 s
2018-05-01 18:11:08.636  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 600 from persistence list
2018-05-01 18:11:08.637  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 600
2018-05-01 18:11:08.643  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:08.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:08.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:08.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:08.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:08.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:08.645  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:08.645  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:08.645  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:08.645  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:08.645  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:08.645  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:08.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:08.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:08.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:08.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:08.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:08.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 615 (flatMap at ALS.scala:1433)
2018-05-01 18:11:08.648  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 80 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:08.648  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1055 (aggregate at ALS.scala:1491)
2018-05-01 18:11:08.649  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1054, ShuffleMapStage 1041)
2018-05-01 18:11:08.649  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1054)
2018-05-01 18:11:08.649  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1054 (MapPartitionsRDD[615] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:08.651  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_147 stored as values in memory (estimated size 28.9 KB, free 1925.9 MB)
2018-05-01 18:11:08.651  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_147_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1925.9 MB)
2018-05-01 18:11:08.652  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_147_piece0 in memory on 172.21.241.193:58620 (size: 13.0 KB, free: 1926.1 MB)
2018-05-01 18:11:08.652  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 147 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:08.652  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1054 (MapPartitionsRDD[615] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:08.652  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1054.0 with 1 tasks
2018-05-01 18:11:08.653  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1054.0 (TID 348, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:08.653  INFO 16044 --- [Executor task launch worker for task 348] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1054.0 (TID 348)
2018-05-01 18:11:08.655  INFO 16044 --- [Executor task launch worker for task 348] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:08.655  INFO 16044 --- [Executor task launch worker for task 348] org.apache.spark.storage.BlockManager    : Found block rdd_610_0 locally
2018-05-01 18:11:08.662  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:11:08.683  INFO 16044 --- [Executor task launch worker for task 348] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1054.0 (TID 348). 1069 bytes result sent to driver
2018-05-01 18:11:08.684  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1054.0 (TID 348) in 31 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:08.684  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1054.0, whose tasks have all completed, from pool 
2018-05-01 18:11:08.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1054 (flatMap at ALS.scala:1433) finished in 0.031 s
2018-05-01 18:11:08.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:08.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:08.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1055)
2018-05-01 18:11:08.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:08.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1055 (MapPartitionsRDD[621] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:08.687  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_148 stored as values in memory (estimated size 31.3 KB, free 1925.8 MB)
2018-05-01 18:11:08.688  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_148_piece0 stored as bytes in memory (estimated size 13.8 KB, free 1925.8 MB)
2018-05-01 18:11:08.688  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_148_piece0 in memory on 172.21.241.193:58620 (size: 13.8 KB, free: 1926.1 MB)
2018-05-01 18:11:08.688  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 148 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:08.689  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1055 (MapPartitionsRDD[621] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:08.689  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1055.0 with 1 tasks
2018-05-01 18:11:08.689  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1055.0 (TID 349, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:08.689  INFO 16044 --- [Executor task launch worker for task 349] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1055.0 (TID 349)
2018-05-01 18:11:08.691  INFO 16044 --- [Executor task launch worker for task 349] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:08.691  INFO 16044 --- [Executor task launch worker for task 349] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:08.691  INFO 16044 --- [Executor task launch worker for task 349] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:08.967  INFO 16044 --- [Executor task launch worker for task 349] o.a.spark.storage.memory.MemoryStore     : Block rdd_620_0 stored as values in memory (estimated size 820.5 KB, free 1925.0 MB)
2018-05-01 18:11:08.967  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_620_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 18:11:08.971  INFO 16044 --- [Executor task launch worker for task 349] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1055.0 (TID 349). 2595 bytes result sent to driver
2018-05-01 18:11:08.971  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1055.0 (TID 349) in 282 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:08.972  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1055.0, whose tasks have all completed, from pool 
2018-05-01 18:11:08.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1055 (aggregate at ALS.scala:1491) finished in 0.283 s
2018-05-01 18:11:08.972  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 80 finished: aggregate at ALS.scala:1491, took 0.328876 s
2018-05-01 18:11:08.988  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 610 from persistence list
2018-05-01 18:11:08.988  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 610
2018-05-01 18:11:08.992  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:08.993  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:08.993  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:08.993  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:08.993  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:08.993  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:08.993  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:08.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:08.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:08.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:08.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:08.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:08.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:08.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:08.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:08.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:08.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:08.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 64 is 150 bytes
2018-05-01 18:11:08.997  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 625 (flatMap at ALS.scala:1433)
2018-05-01 18:11:08.997  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 81 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:08.997  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1074 (aggregate at ALS.scala:1491)
2018-05-01 18:11:08.997  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1073, ShuffleMapStage 1057)
2018-05-01 18:11:08.998  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1073)
2018-05-01 18:11:08.998  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1073 (MapPartitionsRDD[625] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:09.000  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_149 stored as values in memory (estimated size 30.4 KB, free 1925.4 MB)
2018-05-01 18:11:09.000  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_149_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1925.4 MB)
2018-05-01 18:11:09.000  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_149_piece0 in memory on 172.21.241.193:58620 (size: 13.6 KB, free: 1925.6 MB)
2018-05-01 18:11:09.001  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 149 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:09.001  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1073 (MapPartitionsRDD[625] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:09.001  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1073.0 with 1 tasks
2018-05-01 18:11:09.001  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1073.0 (TID 350, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:09.002  INFO 16044 --- [Executor task launch worker for task 350] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1073.0 (TID 350)
2018-05-01 18:11:09.005  INFO 16044 --- [Executor task launch worker for task 350] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:09.005  INFO 16044 --- [Executor task launch worker for task 350] org.apache.spark.storage.BlockManager    : Found block rdd_620_0 locally
2018-05-01 18:11:09.061  INFO 16044 --- [Executor task launch worker for task 350] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1073.0 (TID 350). 1069 bytes result sent to driver
2018-05-01 18:11:09.061  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1073.0 (TID 350) in 60 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:09.062  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1073.0, whose tasks have all completed, from pool 
2018-05-01 18:11:09.062  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1073 (flatMap at ALS.scala:1433) finished in 0.061 s
2018-05-01 18:11:09.062  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:09.062  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:09.062  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1074)
2018-05-01 18:11:09.062  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:09.063  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1074 (MapPartitionsRDD[631] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:09.065  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_150 stored as values in memory (estimated size 32.9 KB, free 1925.4 MB)
2018-05-01 18:11:09.065  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_150_piece0 stored as bytes in memory (estimated size 14.7 KB, free 1925.3 MB)
2018-05-01 18:11:09.066  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_150_piece0 in memory on 172.21.241.193:58620 (size: 14.7 KB, free: 1925.6 MB)
2018-05-01 18:11:09.066  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 150 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:09.066  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1074 (MapPartitionsRDD[631] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:09.066  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1074.0 with 1 tasks
2018-05-01 18:11:09.066  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1074.0 (TID 351, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:09.066  INFO 16044 --- [Executor task launch worker for task 351] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1074.0 (TID 351)
2018-05-01 18:11:09.068  INFO 16044 --- [Executor task launch worker for task 351] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:09.068  INFO 16044 --- [Executor task launch worker for task 351] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:09.068  INFO 16044 --- [Executor task launch worker for task 351] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:09.335  INFO 16044 --- [Executor task launch worker for task 351] o.a.spark.storage.memory.MemoryStore     : Block rdd_630_0 stored as values in memory (estimated size 416.2 KB, free 1924.9 MB)
2018-05-01 18:11:09.336  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_630_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 18:11:09.338  INFO 16044 --- [Executor task launch worker for task 351] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1074.0 (TID 351). 2595 bytes result sent to driver
2018-05-01 18:11:09.338  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1074.0 (TID 351) in 272 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:09.338  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1074.0, whose tasks have all completed, from pool 
2018-05-01 18:11:09.338  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1074 (aggregate at ALS.scala:1491) finished in 0.272 s
2018-05-01 18:11:09.339  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 81 finished: aggregate at ALS.scala:1491, took 0.346680 s
2018-05-01 18:11:09.354  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 620 from persistence list
2018-05-01 18:11:09.354  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 620
2018-05-01 18:11:09.359  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:09.359  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:09.359  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:09.360  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:09.360  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:09.360  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:09.360  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:09.360  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:09.360  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:09.360  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:09.361  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:09.361  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:09.361  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:09.361  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:09.361  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:09.361  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:09.361  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:09.362  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 64 is 150 bytes
2018-05-01 18:11:09.362  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 65 is 150 bytes
2018-05-01 18:11:09.362  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 635 (flatMap at ALS.scala:1433)
2018-05-01 18:11:09.362  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 82 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:09.362  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1094 (aggregate at ALS.scala:1491)
2018-05-01 18:11:09.362  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1078, ShuffleMapStage 1093)
2018-05-01 18:11:09.363  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1093)
2018-05-01 18:11:09.363  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1093 (MapPartitionsRDD[635] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:09.365  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_151 stored as values in memory (estimated size 32.0 KB, free 1925.7 MB)
2018-05-01 18:11:09.366  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_151_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1925.7 MB)
2018-05-01 18:11:09.366  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_151_piece0 in memory on 172.21.241.193:58620 (size: 14.3 KB, free: 1926.0 MB)
2018-05-01 18:11:09.367  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 151 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:09.367  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1093 (MapPartitionsRDD[635] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:09.367  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1093.0 with 1 tasks
2018-05-01 18:11:09.367  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1093.0 (TID 352, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:09.367  INFO 16044 --- [Executor task launch worker for task 352] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1093.0 (TID 352)
2018-05-01 18:11:09.369  INFO 16044 --- [Executor task launch worker for task 352] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:09.369  INFO 16044 --- [Executor task launch worker for task 352] org.apache.spark.storage.BlockManager    : Found block rdd_630_0 locally
2018-05-01 18:11:09.395  INFO 16044 --- [Executor task launch worker for task 352] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1093.0 (TID 352). 1069 bytes result sent to driver
2018-05-01 18:11:09.396  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1093.0 (TID 352) in 29 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:09.397  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1093.0, whose tasks have all completed, from pool 
2018-05-01 18:11:09.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1093 (flatMap at ALS.scala:1433) finished in 0.030 s
2018-05-01 18:11:09.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:09.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:09.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1094)
2018-05-01 18:11:09.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:09.398  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1094 (MapPartitionsRDD[641] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:09.399  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_152 stored as values in memory (estimated size 34.4 KB, free 1925.7 MB)
2018-05-01 18:11:09.400  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_152_piece0 stored as bytes in memory (estimated size 15.5 KB, free 1925.7 MB)
2018-05-01 18:11:09.401  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_152_piece0 in memory on 172.21.241.193:58620 (size: 15.5 KB, free: 1926.0 MB)
2018-05-01 18:11:09.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 152 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:09.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1094 (MapPartitionsRDD[641] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:09.401  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1094.0 with 1 tasks
2018-05-01 18:11:09.401  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1094.0 (TID 353, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:09.401  INFO 16044 --- [Executor task launch worker for task 353] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1094.0 (TID 353)
2018-05-01 18:11:09.403  INFO 16044 --- [Executor task launch worker for task 353] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:09.403  INFO 16044 --- [Executor task launch worker for task 353] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:09.404  INFO 16044 --- [Executor task launch worker for task 353] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 18:11:09.673  INFO 16044 --- [Executor task launch worker for task 353] o.a.spark.storage.memory.MemoryStore     : Block rdd_640_0 stored as values in memory (estimated size 820.5 KB, free 1924.8 MB)
2018-05-01 18:11:09.674  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_640_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 18:11:09.677  INFO 16044 --- [Executor task launch worker for task 353] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1094.0 (TID 353). 2595 bytes result sent to driver
2018-05-01 18:11:09.678  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1094.0 (TID 353) in 277 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:09.678  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1094.0, whose tasks have all completed, from pool 
2018-05-01 18:11:09.678  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1094 (aggregate at ALS.scala:1491) finished in 0.277 s
2018-05-01 18:11:09.678  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 82 finished: aggregate at ALS.scala:1491, took 0.319264 s
2018-05-01 18:11:09.699  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 630 from persistence list
2018-05-01 18:11:09.700  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 630
2018-05-01 18:11:09.705  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:09.706  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:09.706  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:09.707  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:09.707  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:09.707  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:09.707  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:09.707  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:09.707  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:09.707  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:09.708  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:09.708  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:09.708  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:09.708  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:09.708  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:09.708  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:09.709  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:09.709  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 64 is 150 bytes
2018-05-01 18:11:09.709  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 65 is 150 bytes
2018-05-01 18:11:09.709  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 66 is 150 bytes
2018-05-01 18:11:09.709  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 645 (flatMap at ALS.scala:1433)
2018-05-01 18:11:09.709  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 83 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:09.709  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1115 (aggregate at ALS.scala:1491)
2018-05-01 18:11:09.709  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1096, ShuffleMapStage 1114)
2018-05-01 18:11:09.710  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1114)
2018-05-01 18:11:09.710  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1114 (MapPartitionsRDD[645] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:09.712  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_153 stored as values in memory (estimated size 33.5 KB, free 1925.2 MB)
2018-05-01 18:11:09.713  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_153_piece0 stored as bytes in memory (estimated size 15.2 KB, free 1925.2 MB)
2018-05-01 18:11:09.714  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_153_piece0 in memory on 172.21.241.193:58620 (size: 15.2 KB, free: 1925.6 MB)
2018-05-01 18:11:09.714  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 153 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:09.714  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1114 (MapPartitionsRDD[645] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:09.714  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1114.0 with 1 tasks
2018-05-01 18:11:09.715  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1114.0 (TID 354, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:09.715  INFO 16044 --- [Executor task launch worker for task 354] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1114.0 (TID 354)
2018-05-01 18:11:09.716  INFO 16044 --- [Executor task launch worker for task 354] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:09.717  INFO 16044 --- [Executor task launch worker for task 354] org.apache.spark.storage.BlockManager    : Found block rdd_640_0 locally
2018-05-01 18:11:09.750  INFO 16044 --- [Executor task launch worker for task 354] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1114.0 (TID 354). 1026 bytes result sent to driver
2018-05-01 18:11:09.751  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1114.0 (TID 354) in 37 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:09.751  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1114.0, whose tasks have all completed, from pool 
2018-05-01 18:11:09.751  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1114 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 18:11:09.751  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:09.751  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:09.751  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1115)
2018-05-01 18:11:09.751  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:09.751  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1115 (MapPartitionsRDD[651] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:09.753  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_154 stored as values in memory (estimated size 36.0 KB, free 1925.2 MB)
2018-05-01 18:11:09.754  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_154_piece0 stored as bytes in memory (estimated size 16.3 KB, free 1925.2 MB)
2018-05-01 18:11:09.754  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_154_piece0 in memory on 172.21.241.193:58620 (size: 16.3 KB, free: 1925.6 MB)
2018-05-01 18:11:09.754  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 154 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:09.755  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1115 (MapPartitionsRDD[651] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:09.755  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1115.0 with 1 tasks
2018-05-01 18:11:09.755  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1115.0 (TID 355, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:09.755  INFO 16044 --- [Executor task launch worker for task 355] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1115.0 (TID 355)
2018-05-01 18:11:09.757  INFO 16044 --- [Executor task launch worker for task 355] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:09.758  INFO 16044 --- [Executor task launch worker for task 355] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:09.758  INFO 16044 --- [Executor task launch worker for task 355] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 18:11:10.022  INFO 16044 --- [Executor task launch worker for task 355] o.a.spark.storage.memory.MemoryStore     : Block rdd_650_0 stored as values in memory (estimated size 416.2 KB, free 1924.8 MB)
2018-05-01 18:11:10.022  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_650_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 18:11:10.024  INFO 16044 --- [Executor task launch worker for task 355] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1115.0 (TID 355). 2595 bytes result sent to driver
2018-05-01 18:11:10.024  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1115.0 (TID 355) in 269 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:10.024  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1115.0, whose tasks have all completed, from pool 
2018-05-01 18:11:10.025  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1115 (aggregate at ALS.scala:1491) finished in 0.270 s
2018-05-01 18:11:10.025  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 83 finished: aggregate at ALS.scala:1491, took 0.320077 s
2018-05-01 18:11:10.043  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 640 from persistence list
2018-05-01 18:11:10.044  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 640
2018-05-01 18:11:10.049  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:10.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:10.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:10.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:10.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:10.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:10.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:10.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:10.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:10.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:10.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:10.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:10.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:10.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:10.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:10.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:10.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:10.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 64 is 150 bytes
2018-05-01 18:11:10.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 65 is 150 bytes
2018-05-01 18:11:10.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 66 is 150 bytes
2018-05-01 18:11:10.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 67 is 150 bytes
2018-05-01 18:11:10.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 655 (flatMap at ALS.scala:1433)
2018-05-01 18:11:10.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 84 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:10.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1137 (aggregate at ALS.scala:1491)
2018-05-01 18:11:10.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1119, ShuffleMapStage 1136)
2018-05-01 18:11:10.054  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1136)
2018-05-01 18:11:10.054  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1136 (MapPartitionsRDD[655] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:10.056  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_155 stored as values in memory (estimated size 35.1 KB, free 1925.5 MB)
2018-05-01 18:11:10.057  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_155_piece0 stored as bytes in memory (estimated size 15.9 KB, free 1925.5 MB)
2018-05-01 18:11:10.058  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_155_piece0 in memory on 172.21.241.193:58620 (size: 15.9 KB, free: 1926.0 MB)
2018-05-01 18:11:10.058  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 155 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:10.058  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1136 (MapPartitionsRDD[655] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:10.058  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1136.0 with 1 tasks
2018-05-01 18:11:10.058  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1136.0 (TID 356, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:10.059  INFO 16044 --- [Executor task launch worker for task 356] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1136.0 (TID 356)
2018-05-01 18:11:10.061  INFO 16044 --- [Executor task launch worker for task 356] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:10.063  INFO 16044 --- [Executor task launch worker for task 356] org.apache.spark.storage.BlockManager    : Found block rdd_650_0 locally
2018-05-01 18:11:10.091  INFO 16044 --- [Executor task launch worker for task 356] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1136.0 (TID 356). 1069 bytes result sent to driver
2018-05-01 18:11:10.091  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1136.0 (TID 356) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:10.092  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1136.0, whose tasks have all completed, from pool 
2018-05-01 18:11:10.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1136 (flatMap at ALS.scala:1433) finished in 0.034 s
2018-05-01 18:11:10.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:10.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:10.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1137)
2018-05-01 18:11:10.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:10.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1137 (MapPartitionsRDD[661] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:10.094  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_156 stored as values in memory (estimated size 37.5 KB, free 1925.5 MB)
2018-05-01 18:11:10.095  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_156_piece0 stored as bytes in memory (estimated size 16.8 KB, free 1925.4 MB)
2018-05-01 18:11:10.095  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_156_piece0 in memory on 172.21.241.193:58620 (size: 16.8 KB, free: 1925.9 MB)
2018-05-01 18:11:10.095  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 156 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:10.096  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1137 (MapPartitionsRDD[661] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:10.096  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1137.0 with 1 tasks
2018-05-01 18:11:10.096  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1137.0 (TID 357, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:10.096  INFO 16044 --- [Executor task launch worker for task 357] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1137.0 (TID 357)
2018-05-01 18:11:10.099  INFO 16044 --- [Executor task launch worker for task 357] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:10.099  INFO 16044 --- [Executor task launch worker for task 357] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:10.099  INFO 16044 --- [Executor task launch worker for task 357] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:10.372  INFO 16044 --- [Executor task launch worker for task 357] o.a.spark.storage.memory.MemoryStore     : Block rdd_660_0 stored as values in memory (estimated size 820.5 KB, free 1924.6 MB)
2018-05-01 18:11:10.373  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_660_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 18:11:10.376  INFO 16044 --- [Executor task launch worker for task 357] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1137.0 (TID 357). 2595 bytes result sent to driver
2018-05-01 18:11:10.376  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1137.0 (TID 357) in 280 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:10.376  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1137.0, whose tasks have all completed, from pool 
2018-05-01 18:11:10.377  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1137 (aggregate at ALS.scala:1491) finished in 0.281 s
2018-05-01 18:11:10.377  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 84 finished: aggregate at ALS.scala:1491, took 0.327752 s
2018-05-01 18:11:10.393  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 650 from persistence list
2018-05-01 18:11:10.394  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 650
2018-05-01 18:11:10.399  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:10.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:10.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:10.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:10.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:10.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:10.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:10.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:10.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:10.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:10.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:10.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:10.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:10.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:10.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:10.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:10.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:10.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 64 is 150 bytes
2018-05-01 18:11:10.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 65 is 150 bytes
2018-05-01 18:11:10.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 66 is 150 bytes
2018-05-01 18:11:10.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 67 is 150 bytes
2018-05-01 18:11:10.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 68 is 150 bytes
2018-05-01 18:11:10.403  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 665 (flatMap at ALS.scala:1433)
2018-05-01 18:11:10.403  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 85 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:10.403  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1160 (aggregate at ALS.scala:1491)
2018-05-01 18:11:10.403  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1159, ShuffleMapStage 1139)
2018-05-01 18:11:10.403  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1159)
2018-05-01 18:11:10.404  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1159 (MapPartitionsRDD[665] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:10.406  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_157 stored as values in memory (estimated size 36.6 KB, free 1925.0 MB)
2018-05-01 18:11:10.407  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_157_piece0 stored as bytes in memory (estimated size 16.6 KB, free 1925.0 MB)
2018-05-01 18:11:10.407  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_157_piece0 in memory on 172.21.241.193:58620 (size: 16.6 KB, free: 1925.5 MB)
2018-05-01 18:11:10.407  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 157 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:10.407  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1159 (MapPartitionsRDD[665] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:10.408  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1159.0 with 1 tasks
2018-05-01 18:11:10.409  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1159.0 (TID 358, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:10.409  INFO 16044 --- [Executor task launch worker for task 358] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1159.0 (TID 358)
2018-05-01 18:11:10.411  INFO 16044 --- [Executor task launch worker for task 358] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:10.411  INFO 16044 --- [Executor task launch worker for task 358] org.apache.spark.storage.BlockManager    : Found block rdd_660_0 locally
2018-05-01 18:11:10.446  INFO 16044 --- [Executor task launch worker for task 358] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1159.0 (TID 358). 1069 bytes result sent to driver
2018-05-01 18:11:10.446  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1159.0 (TID 358) in 37 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:10.446  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1159.0, whose tasks have all completed, from pool 
2018-05-01 18:11:10.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1159 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 18:11:10.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:10.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:10.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1160)
2018-05-01 18:11:10.447  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:10.447  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1160 (MapPartitionsRDD[671] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:10.449  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_158 stored as values in memory (estimated size 39.1 KB, free 1925.0 MB)
2018-05-01 18:11:10.449  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_158_piece0 stored as bytes in memory (estimated size 17.6 KB, free 1924.9 MB)
2018-05-01 18:11:10.450  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_158_piece0 in memory on 172.21.241.193:58620 (size: 17.6 KB, free: 1925.5 MB)
2018-05-01 18:11:10.450  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 158 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:10.450  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1160 (MapPartitionsRDD[671] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:10.450  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1160.0 with 1 tasks
2018-05-01 18:11:10.451  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1160.0 (TID 359, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:10.451  INFO 16044 --- [Executor task launch worker for task 359] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1160.0 (TID 359)
2018-05-01 18:11:10.453  INFO 16044 --- [Executor task launch worker for task 359] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:10.453  INFO 16044 --- [Executor task launch worker for task 359] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:10.453  INFO 16044 --- [Executor task launch worker for task 359] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:10.712  INFO 16044 --- [Executor task launch worker for task 359] o.a.spark.storage.memory.MemoryStore     : Block rdd_670_0 stored as values in memory (estimated size 416.2 KB, free 1924.5 MB)
2018-05-01 18:11:10.712  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_670_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 18:11:10.714  INFO 16044 --- [Executor task launch worker for task 359] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1160.0 (TID 359). 2595 bytes result sent to driver
2018-05-01 18:11:10.715  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1160.0 (TID 359) in 265 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:10.715  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1160.0, whose tasks have all completed, from pool 
2018-05-01 18:11:10.715  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1160 (aggregate at ALS.scala:1491) finished in 0.265 s
2018-05-01 18:11:10.715  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 85 finished: aggregate at ALS.scala:1491, took 0.316021 s
2018-05-01 18:11:10.744  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 660 from persistence list
2018-05-01 18:11:10.744  INFO 16044 --- [block-manager-slave-async-thread-pool-9] org.apache.spark.storage.BlockManager    : Removing RDD 660
2018-05-01 18:11:10.753  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 18:11:10.755  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:10.755  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:10.756  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:10.756  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:10.756  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:10.756  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:10.756  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:10.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:10.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:10.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:10.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:10.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:10.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:10.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:10.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:10.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:10.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 64 is 150 bytes
2018-05-01 18:11:10.759  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 65 is 150 bytes
2018-05-01 18:11:10.759  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 66 is 150 bytes
2018-05-01 18:11:10.759  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 67 is 150 bytes
2018-05-01 18:11:10.759  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 68 is 150 bytes
2018-05-01 18:11:10.759  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 69 is 150 bytes
2018-05-01 18:11:10.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 675 (flatMap at ALS.scala:1433)
2018-05-01 18:11:10.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 86 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 18:11:10.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1184 (aggregate at ALS.scala:1491)
2018-05-01 18:11:10.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1164, ShuffleMapStage 1183)
2018-05-01 18:11:10.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1183)
2018-05-01 18:11:10.761  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1183 (MapPartitionsRDD[675] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:10.763  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_159 stored as values in memory (estimated size 38.2 KB, free 1925.3 MB)
2018-05-01 18:11:10.765  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_159_piece0 stored as bytes in memory (estimated size 17.2 KB, free 1925.3 MB)
2018-05-01 18:11:10.767  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_159_piece0 in memory on 172.21.241.193:58620 (size: 17.2 KB, free: 1925.9 MB)
2018-05-01 18:11:10.767  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 159 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:10.768  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1183 (MapPartitionsRDD[675] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:10.768  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1183.0 with 1 tasks
2018-05-01 18:11:10.768  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1183.0 (TID 360, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:10.769  INFO 16044 --- [Executor task launch worker for task 360] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1183.0 (TID 360)
2018-05-01 18:11:10.771  INFO 16044 --- [Executor task launch worker for task 360] org.apache.spark.storage.BlockManager    : Found block rdd_483_0 locally
2018-05-01 18:11:10.772  INFO 16044 --- [Executor task launch worker for task 360] org.apache.spark.storage.BlockManager    : Found block rdd_670_0 locally
2018-05-01 18:11:10.801  INFO 16044 --- [Executor task launch worker for task 360] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1183.0 (TID 360). 1069 bytes result sent to driver
2018-05-01 18:11:10.801  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1183.0 (TID 360) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:10.801  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1183.0, whose tasks have all completed, from pool 
2018-05-01 18:11:10.801  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1183 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 18:11:10.801  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:10.801  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:10.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1184)
2018-05-01 18:11:10.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:10.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1184 (MapPartitionsRDD[681] at values at ALS.scala:1491), which has no missing parents
2018-05-01 18:11:10.804  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_160 stored as values in memory (estimated size 40.6 KB, free 1925.2 MB)
2018-05-01 18:11:10.806  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_160_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1925.2 MB)
2018-05-01 18:11:10.806  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_160_piece0 in memory on 172.21.241.193:58620 (size: 18.1 KB, free: 1925.9 MB)
2018-05-01 18:11:10.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 160 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:10.807  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1184 (MapPartitionsRDD[681] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:10.807  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1184.0 with 1 tasks
2018-05-01 18:11:10.807  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1184.0 (TID 361, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 18:11:10.808  INFO 16044 --- [Executor task launch worker for task 361] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1184.0 (TID 361)
2018-05-01 18:11:10.810  INFO 16044 --- [Executor task launch worker for task 361] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:10.810  INFO 16044 --- [Executor task launch worker for task 361] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:10.811  INFO 16044 --- [Executor task launch worker for task 361] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 18:11:11.114  INFO 16044 --- [Executor task launch worker for task 361] o.a.spark.storage.memory.MemoryStore     : Block rdd_680_0 stored as values in memory (estimated size 820.5 KB, free 1924.4 MB)
2018-05-01 18:11:11.114  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_680_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 18:11:11.117  INFO 16044 --- [Executor task launch worker for task 361] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1184.0 (TID 361). 2595 bytes result sent to driver
2018-05-01 18:11:11.118  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1184.0 (TID 361) in 311 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:11.118  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1184.0, whose tasks have all completed, from pool 
2018-05-01 18:11:11.118  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1184 (aggregate at ALS.scala:1491) finished in 0.311 s
2018-05-01 18:11:11.119  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 86 finished: aggregate at ALS.scala:1491, took 0.364733 s
2018-05-01 18:11:11.136  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 670 from persistence list
2018-05-01 18:11:11.136  INFO 16044 --- [block-manager-slave-async-thread-pool-13] org.apache.spark.storage.BlockManager    : Removing RDD 670
2018-05-01 18:11:11.154  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:279
2018-05-01 18:11:11.155  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:11.156  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:11.156  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:11.156  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:11.156  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:11.157  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:11.157  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:11.157  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:11.157  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:11.157  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:11.157  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:11.158  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:11.158  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:11.158  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:11.158  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:11.158  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:11.158  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 64 is 150 bytes
2018-05-01 18:11:11.158  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 65 is 150 bytes
2018-05-01 18:11:11.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 66 is 150 bytes
2018-05-01 18:11:11.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 67 is 150 bytes
2018-05-01 18:11:11.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 68 is 150 bytes
2018-05-01 18:11:11.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 69 is 150 bytes
2018-05-01 18:11:11.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 70 is 150 bytes
2018-05-01 18:11:11.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 685 (flatMap at ALS.scala:1433)
2018-05-01 18:11:11.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 87 (count at ALS.scala:279) with 1 output partitions
2018-05-01 18:11:11.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1209 (count at ALS.scala:279)
2018-05-01 18:11:11.160  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1186, ShuffleMapStage 1208)
2018-05-01 18:11:11.161  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 1208)
2018-05-01 18:11:11.161  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 1208 (MapPartitionsRDD[685] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 18:11:11.163  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_161 stored as values in memory (estimated size 39.7 KB, free 1924.8 MB)
2018-05-01 18:11:11.164  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_161_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1924.8 MB)
2018-05-01 18:11:11.164  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_161_piece0 in memory on 172.21.241.193:58620 (size: 17.9 KB, free: 1925.5 MB)
2018-05-01 18:11:11.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 161 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:11.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 1208 (MapPartitionsRDD[685] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:11.165  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1208.0 with 1 tasks
2018-05-01 18:11:11.165  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1208.0 (TID 362, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 18:11:11.165  INFO 16044 --- [Executor task launch worker for task 362] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1208.0 (TID 362)
2018-05-01 18:11:11.167  INFO 16044 --- [Executor task launch worker for task 362] org.apache.spark.storage.BlockManager    : Found block rdd_488_0 locally
2018-05-01 18:11:11.167  INFO 16044 --- [Executor task launch worker for task 362] org.apache.spark.storage.BlockManager    : Found block rdd_680_0 locally
2018-05-01 18:11:11.202  INFO 16044 --- [Executor task launch worker for task 362] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1208.0 (TID 362). 1112 bytes result sent to driver
2018-05-01 18:11:11.202  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1208.0 (TID 362) in 37 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:11.202  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1208.0, whose tasks have all completed, from pool 
2018-05-01 18:11:11.203  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 1208 (flatMap at ALS.scala:1433) finished in 0.038 s
2018-05-01 18:11:11.203  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 18:11:11.203  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 18:11:11.203  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 1209)
2018-05-01 18:11:11.203  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 18:11:11.203  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1209 (users MapPartitionsRDD[701] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 18:11:11.206  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_162 stored as values in memory (estimated size 41.6 KB, free 1924.7 MB)
2018-05-01 18:11:11.207  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_162_piece0 stored as bytes in memory (estimated size 18.6 KB, free 1924.7 MB)
2018-05-01 18:11:11.208  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_162_piece0 in memory on 172.21.241.193:58620 (size: 18.6 KB, free: 1925.4 MB)
2018-05-01 18:11:11.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 162 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:11.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1209 (users MapPartitionsRDD[701] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:11.208  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1209.0 with 1 tasks
2018-05-01 18:11:11.208  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1209.0 (TID 363, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 18:11:11.209  INFO 16044 --- [Executor task launch worker for task 363] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1209.0 (TID 363)
2018-05-01 18:11:11.211  INFO 16044 --- [Executor task launch worker for task 363] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:11.211  INFO 16044 --- [Executor task launch worker for task 363] org.apache.spark.storage.BlockManager    : Found block rdd_482_0 locally
2018-05-01 18:11:11.211  INFO 16044 --- [Executor task launch worker for task 363] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 18:11:11.211  INFO 16044 --- [Executor task launch worker for task 363] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 18:11:11.592  INFO 16044 --- [Executor task launch worker for task 363] o.a.spark.storage.memory.MemoryStore     : Block rdd_701_0 stored as values in memory (estimated size 970.8 KB, free 1923.8 MB)
2018-05-01 18:11:11.593  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_701_0 in memory on 172.21.241.193:58620 (size: 970.8 KB, free: 1924.5 MB)
2018-05-01 18:11:11.594  INFO 16044 --- [Executor task launch worker for task 363] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1209.0 (TID 363). 1873 bytes result sent to driver
2018-05-01 18:11:11.595  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1209.0 (TID 363) in 387 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:11.595  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1209.0, whose tasks have all completed, from pool 
2018-05-01 18:11:11.595  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1209 (count at ALS.scala:279) finished in 0.387 s
2018-05-01 18:11:11.595  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 87 finished: count at ALS.scala:279, took 0.441009 s
2018-05-01 18:11:11.598  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:280
2018-05-01 18:11:11.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 49 is 161 bytes
2018-05-01 18:11:11.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 48 is 161 bytes
2018-05-01 18:11:11.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 52 is 150 bytes
2018-05-01 18:11:11.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 50 is 161 bytes
2018-05-01 18:11:11.600  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 51 is 150 bytes
2018-05-01 18:11:11.600  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 53 is 150 bytes
2018-05-01 18:11:11.600  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 54 is 150 bytes
2018-05-01 18:11:11.600  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 55 is 150 bytes
2018-05-01 18:11:11.601  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 56 is 150 bytes
2018-05-01 18:11:11.601  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 57 is 150 bytes
2018-05-01 18:11:11.601  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 58 is 150 bytes
2018-05-01 18:11:11.601  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 59 is 150 bytes
2018-05-01 18:11:11.601  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 60 is 150 bytes
2018-05-01 18:11:11.602  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 61 is 150 bytes
2018-05-01 18:11:11.602  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 62 is 150 bytes
2018-05-01 18:11:11.602  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 63 is 150 bytes
2018-05-01 18:11:11.602  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 64 is 150 bytes
2018-05-01 18:11:11.603  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 65 is 150 bytes
2018-05-01 18:11:11.603  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 66 is 150 bytes
2018-05-01 18:11:11.603  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 67 is 150 bytes
2018-05-01 18:11:11.603  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 68 is 150 bytes
2018-05-01 18:11:11.604  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 69 is 150 bytes
2018-05-01 18:11:11.605  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 70 is 150 bytes
2018-05-01 18:11:11.606  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 88 (count at ALS.scala:280) with 1 output partitions
2018-05-01 18:11:11.606  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1233 (count at ALS.scala:280)
2018-05-01 18:11:11.606  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1232, ShuffleMapStage 1213)
2018-05-01 18:11:11.607  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:11:11.607  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1233 (products MapPartitionsRDD[702] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 18:11:11.610  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_163 stored as values in memory (estimated size 40.1 KB, free 1923.7 MB)
2018-05-01 18:11:11.611  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_163_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1923.7 MB)
2018-05-01 18:11:11.611  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_163_piece0 in memory on 172.21.241.193:58620 (size: 18.1 KB, free: 1924.5 MB)
2018-05-01 18:11:11.611  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 163 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:11.612  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1233 (products MapPartitionsRDD[702] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:11.612  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1233.0 with 1 tasks
2018-05-01 18:11:11.612  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1233.0 (TID 364, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 18:11:11.612  INFO 16044 --- [Executor task launch worker for task 364] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1233.0 (TID 364)
2018-05-01 18:11:11.615  INFO 16044 --- [Executor task launch worker for task 364] org.apache.spark.storage.BlockManager    : Found block rdd_487_0 locally
2018-05-01 18:11:11.615  INFO 16044 --- [Executor task launch worker for task 364] org.apache.spark.storage.BlockManager    : Found block rdd_680_0 locally
2018-05-01 18:11:11.700  INFO 16044 --- [Executor task launch worker for task 364] o.a.spark.storage.memory.MemoryStore     : Block rdd_702_0 stored as values in memory (estimated size 1914.2 KB, free 1921.8 MB)
2018-05-01 18:11:11.701  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_702_0 in memory on 172.21.241.193:58620 (size: 1914.2 KB, free: 1922.6 MB)
2018-05-01 18:11:11.702  INFO 16044 --- [Executor task launch worker for task 364] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1233.0 (TID 364). 1615 bytes result sent to driver
2018-05-01 18:11:11.703  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1233.0 (TID 364) in 90 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:11.703  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1233.0, whose tasks have all completed, from pool 
2018-05-01 18:11:11.703  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1233 (count at ALS.scala:280) finished in 0.091 s
2018-05-01 18:11:11.703  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 88 finished: count at ALS.scala:280, took 0.105021 s
2018-05-01 18:11:11.711  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 18:11:11.713  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 71 is 150 bytes
2018-05-01 18:11:11.713  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 89 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 18:11:11.713  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1258 (first at MatrixFactorizationModel.scala:67)
2018-05-01 18:11:11.713  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1235, ShuffleMapStage 1257)
2018-05-01 18:11:11.714  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:11:11.714  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1258 (users MapPartitionsRDD[701] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 18:11:11.716  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_164 stored as values in memory (estimated size 41.8 KB, free 1921.8 MB)
2018-05-01 18:11:11.716  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_164_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1921.8 MB)
2018-05-01 18:11:11.717  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_164_piece0 in memory on 172.21.241.193:58620 (size: 18.7 KB, free: 1922.6 MB)
2018-05-01 18:11:11.717  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 164 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:11.717  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1258 (users MapPartitionsRDD[701] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:11.717  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1258.0 with 1 tasks
2018-05-01 18:11:11.717  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1258.0 (TID 365, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 18:11:11.718  INFO 16044 --- [Executor task launch worker for task 365] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1258.0 (TID 365)
2018-05-01 18:11:11.720  INFO 16044 --- [Executor task launch worker for task 365] org.apache.spark.storage.BlockManager    : Found block rdd_701_0 locally
2018-05-01 18:11:11.720  INFO 16044 --- [Executor task launch worker for task 365] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 365:
[rdd_701_0]
2018-05-01 18:11:11.720  INFO 16044 --- [Executor task launch worker for task 365] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1258.0 (TID 365). 952 bytes result sent to driver
2018-05-01 18:11:11.720  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1258.0 (TID 365) in 3 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:11.720  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1258.0, whose tasks have all completed, from pool 
2018-05-01 18:11:11.721  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1258 (first at MatrixFactorizationModel.scala:67) finished in 0.003 s
2018-05-01 18:11:11.721  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 89 finished: first at MatrixFactorizationModel.scala:67, took 0.009593 s
2018-05-01 18:11:11.727  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 18:11:11.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 90 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 18:11:11.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1282 (first at MatrixFactorizationModel.scala:67)
2018-05-01 18:11:11.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1262, ShuffleMapStage 1281)
2018-05-01 18:11:11.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:11:11.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1282 (products MapPartitionsRDD[702] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 18:11:11.731  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_165 stored as values in memory (estimated size 40.2 KB, free 1921.7 MB)
2018-05-01 18:11:11.731  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_165_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1921.7 MB)
2018-05-01 18:11:11.732  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_165_piece0 in memory on 172.21.241.193:58620 (size: 18.2 KB, free: 1922.6 MB)
2018-05-01 18:11:11.732  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 165 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:11.732  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1282 (products MapPartitionsRDD[702] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:11.732  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1282.0 with 1 tasks
2018-05-01 18:11:11.732  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1282.0 (TID 366, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 18:11:11.733  INFO 16044 --- [Executor task launch worker for task 366] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1282.0 (TID 366)
2018-05-01 18:11:11.735  INFO 16044 --- [Executor task launch worker for task 366] org.apache.spark.storage.BlockManager    : Found block rdd_702_0 locally
2018-05-01 18:11:11.735  INFO 16044 --- [Executor task launch worker for task 366] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 366:
[rdd_702_0]
2018-05-01 18:11:11.735  INFO 16044 --- [Executor task launch worker for task 366] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1282.0 (TID 366). 909 bytes result sent to driver
2018-05-01 18:11:11.736  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1282.0 (TID 366) in 4 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:11.736  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1282.0, whose tasks have all completed, from pool 
2018-05-01 18:11:11.736  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1282 (first at MatrixFactorizationModel.scala:67) finished in 0.004 s
2018-05-01 18:11:11.737  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 90 finished: first at MatrixFactorizationModel.scala:67, took 0.010102 s
2018-05-01 18:11:11.742  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: lookup at MatrixFactorizationModel.scala:168
2018-05-01 18:11:11.744  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 91 (lookup at MatrixFactorizationModel.scala:168) with 1 output partitions
2018-05-01 18:11:11.744  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1307 (lookup at MatrixFactorizationModel.scala:168)
2018-05-01 18:11:11.744  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1306, ShuffleMapStage 1284)
2018-05-01 18:11:11.744  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:11:11.744  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1307 (users MapPartitionsRDD[701] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 18:11:11.746  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_166 stored as values in memory (estimated size 41.9 KB, free 1921.7 MB)
2018-05-01 18:11:11.747  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_166_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1921.7 MB)
2018-05-01 18:11:11.747  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_166_piece0 in memory on 172.21.241.193:58620 (size: 18.8 KB, free: 1922.5 MB)
2018-05-01 18:11:11.748  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 166 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:11.748  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1307 (users MapPartitionsRDD[701] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:11.748  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1307.0 with 1 tasks
2018-05-01 18:11:11.748  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1307.0 (TID 367, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 18:11:11.748  INFO 16044 --- [Executor task launch worker for task 367] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1307.0 (TID 367)
2018-05-01 18:11:11.750  INFO 16044 --- [Executor task launch worker for task 367] org.apache.spark.storage.BlockManager    : Found block rdd_701_0 locally
2018-05-01 18:11:11.751  INFO 16044 --- [Executor task launch worker for task 367] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1307.0 (TID 367). 942 bytes result sent to driver
2018-05-01 18:11:11.752  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1307.0 (TID 367) in 4 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:11.752  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1307.0, whose tasks have all completed, from pool 
2018-05-01 18:11:11.752  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1307 (lookup at MatrixFactorizationModel.scala:168) finished in 0.004 s
2018-05-01 18:11:11.752  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 91 finished: lookup at MatrixFactorizationModel.scala:168, took 0.010509 s
2018-05-01 18:11:11.758  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.SparkContext            : Starting job: top at MatrixFactorizationModel.scala:259
2018-05-01 18:11:11.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 92 (top at MatrixFactorizationModel.scala:259) with 1 output partitions
2018-05-01 18:11:11.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1331 (top at MatrixFactorizationModel.scala:259)
2018-05-01 18:11:11.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 1311, ShuffleMapStage 1330)
2018-05-01 18:11:11.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 18:11:11.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1331 (MapPartitionsRDD[704] at top at MatrixFactorizationModel.scala:259), which has no missing parents
2018-05-01 18:11:11.762  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_167 stored as values in memory (estimated size 41.2 KB, free 1921.6 MB)
2018-05-01 18:11:11.763  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_167_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1921.6 MB)
2018-05-01 18:11:11.763  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_167_piece0 in memory on 172.21.241.193:58620 (size: 18.7 KB, free: 1922.5 MB)
2018-05-01 18:11:11.764  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 167 from broadcast at DAGScheduler.scala:1006
2018-05-01 18:11:11.764  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1331 (MapPartitionsRDD[704] at top at MatrixFactorizationModel.scala:259) (first 15 tasks are for partitions Vector(0))
2018-05-01 18:11:11.765  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1331.0 with 1 tasks
2018-05-01 18:11:11.765  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1331.0 (TID 368, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 18:11:11.765  INFO 16044 --- [Executor task launch worker for task 368] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1331.0 (TID 368)
2018-05-01 18:11:11.767  INFO 16044 --- [Executor task launch worker for task 368] org.apache.spark.storage.BlockManager    : Found block rdd_702_0 locally
2018-05-01 18:11:11.772  INFO 16044 --- [Executor task launch worker for task 368] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1331.0 (TID 368). 1566 bytes result sent to driver
2018-05-01 18:11:11.772  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1331.0 (TID 368) in 7 ms on localhost (executor driver) (1/1)
2018-05-01 18:11:11.772  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1331.0, whose tasks have all completed, from pool 
2018-05-01 18:11:11.773  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1331 (top at MatrixFactorizationModel.scala:259) finished in 0.007 s
2018-05-01 18:11:11.773  INFO 16044 --- [http-nio-3333-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 92 finished: top at MatrixFactorizationModel.scala:259, took 0.014765 s
2018-05-01 18:11:11.773  INFO 16044 --- [http-nio-3333-exec-5] c.j.p.s.impl.RecomendationServiceImpl    : Recommendations for1
2018-05-01 18:11:11.773  INFO 16044 --- [http-nio-3333-exec-5] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1214-- Rating : 1.001488199115922
2018-05-01 18:11:11.777  INFO 16044 --- [http-nio-3333-exec-5] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1200-- Rating : 0.9726338059237726
2018-05-01 18:11:11.779  INFO 16044 --- [http-nio-3333-exec-5] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 541-- Rating : 0.9319241686402148
2018-05-01 18:11:11.781  INFO 16044 --- [http-nio-3333-exec-5] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1196-- Rating : 0.92663024664083
2018-05-01 18:11:11.784  INFO 16044 --- [http-nio-3333-exec-5] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1240-- Rating : 0.9239596463832118
2018-05-01 18:16:04.616  INFO 16044 --- [block-manager-slave-async-thread-pool-19] org.apache.spark.storage.BlockManager    : Removing RDD 473
2018-05-01 18:16:04.617  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 473
2018-05-01 18:16:04.618  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 53
2018-05-01 18:16:04.618  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 66
2018-05-01 18:16:04.618  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_151_piece0 on 172.21.241.193:58620 in memory (size: 14.3 KB, free: 1958.5 MB)
2018-05-01 18:16:04.619  INFO 16044 --- [block-manager-slave-async-thread-pool-23] org.apache.spark.storage.BlockManager    : Removing RDD 620
2018-05-01 18:16:04.619  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 620
2018-05-01 18:16:04.620  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 49
2018-05-01 18:16:04.620  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 65
2018-05-01 18:16:04.620  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_154_piece0 on 172.21.241.193:58620 in memory (size: 16.3 KB, free: 1958.6 MB)
2018-05-01 18:16:04.622  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_162_piece0 on 172.21.241.193:58620 in memory (size: 18.6 KB, free: 1958.6 MB)
2018-05-01 18:16:04.622  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 62
2018-05-01 18:16:04.622  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 69
2018-05-01 18:16:04.622  INFO 16044 --- [block-manager-slave-async-thread-pool-23] org.apache.spark.storage.BlockManager    : Removing RDD 487
2018-05-01 18:16:04.622  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 487
2018-05-01 18:16:04.623  INFO 16044 --- [block-manager-slave-async-thread-pool-21] org.apache.spark.storage.BlockManager    : Removing RDD 570
2018-05-01 18:16:04.624  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 570
2018-05-01 18:16:04.624  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 61
2018-05-01 18:16:04.625  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_159_piece0 on 172.21.241.193:58620 in memory (size: 17.2 KB, free: 1966.7 MB)
2018-05-01 18:16:04.625  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_160_piece0 on 172.21.241.193:58620 in memory (size: 18.1 KB, free: 1966.7 MB)
2018-05-01 18:16:04.626  INFO 16044 --- [block-manager-slave-async-thread-pool-23] org.apache.spark.storage.BlockManager    : Removing RDD 580
2018-05-01 18:16:04.626  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 580
2018-05-01 18:16:04.626  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_149_piece0 on 172.21.241.193:58620 in memory (size: 13.6 KB, free: 1966.7 MB)
2018-05-01 18:16:04.627  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_167_piece0 on 172.21.241.193:58620 in memory (size: 18.7 KB, free: 1966.7 MB)
2018-05-01 18:16:04.628  INFO 16044 --- [block-manager-slave-async-thread-pool-25] org.apache.spark.storage.BlockManager    : Removing RDD 520
2018-05-01 18:16:04.628  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 520
2018-05-01 18:16:04.628  INFO 16044 --- [block-manager-slave-async-thread-pool-22] org.apache.spark.storage.BlockManager    : Removing RDD 640
2018-05-01 18:16:04.628  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 640
2018-05-01 18:16:04.628  INFO 16044 --- [block-manager-slave-async-thread-pool-19] org.apache.spark.storage.BlockManager    : Removing RDD 560
2018-05-01 18:16:04.629  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 560
2018-05-01 18:16:04.629  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 59
2018-05-01 18:16:04.629  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_144_piece0 on 172.21.241.193:58620 in memory (size: 12.5 KB, free: 1966.8 MB)
2018-05-01 18:16:04.630  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_156_piece0 on 172.21.241.193:58620 in memory (size: 16.8 KB, free: 1966.8 MB)
2018-05-01 18:16:04.630  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_155_piece0 on 172.21.241.193:58620 in memory (size: 15.9 KB, free: 1966.8 MB)
2018-05-01 18:16:04.631  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 58
2018-05-01 18:16:04.631  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 60
2018-05-01 18:16:04.631  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 67
2018-05-01 18:16:04.631  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 71
2018-05-01 18:16:04.632  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 55
2018-05-01 18:16:04.632  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_166_piece0 on 172.21.241.193:58620 in memory (size: 18.8 KB, free: 1966.8 MB)
2018-05-01 18:16:04.633  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 56
2018-05-01 18:16:04.633  INFO 16044 --- [block-manager-slave-async-thread-pool-29] org.apache.spark.storage.BlockManager    : Removing RDD 660
2018-05-01 18:16:04.633  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 660
2018-05-01 18:16:04.633  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 57
2018-05-01 18:16:04.634  INFO 16044 --- [block-manager-slave-async-thread-pool-26] org.apache.spark.storage.BlockManager    : Removing RDD 680
2018-05-01 18:16:04.634  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 680
2018-05-01 18:16:04.634  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_146_piece0 on 172.21.241.193:58620 in memory (size: 13.2 KB, free: 1967.6 MB)
2018-05-01 18:16:04.635  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_164_piece0 on 172.21.241.193:58620 in memory (size: 18.7 KB, free: 1967.6 MB)
2018-05-01 18:16:04.636  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 50
2018-05-01 18:16:04.636  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_163_piece0 on 172.21.241.193:58620 in memory (size: 18.1 KB, free: 1967.7 MB)
2018-05-01 18:16:04.637  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 48
2018-05-01 18:16:04.637  INFO 16044 --- [block-manager-slave-async-thread-pool-26] org.apache.spark.storage.BlockManager    : Removing RDD 530
2018-05-01 18:16:04.637  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 530
2018-05-01 18:16:04.637  INFO 16044 --- [block-manager-slave-async-thread-pool-24] org.apache.spark.storage.BlockManager    : Removing RDD 702
2018-05-01 18:16:04.637  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 702
2018-05-01 18:16:04.638  INFO 16044 --- [block-manager-slave-async-thread-pool-26] org.apache.spark.storage.BlockManager    : Removing RDD 590
2018-05-01 18:16:04.638  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 590
2018-05-01 18:16:04.639  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_153_piece0 on 172.21.241.193:58620 in memory (size: 15.2 KB, free: 1969.5 MB)
2018-05-01 18:16:04.639  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_150_piece0 on 172.21.241.193:58620 in memory (size: 14.7 KB, free: 1969.6 MB)
2018-05-01 18:16:04.640  INFO 16044 --- [block-manager-slave-async-thread-pool-24] org.apache.spark.storage.BlockManager    : Removing RDD 479
2018-05-01 18:16:04.640  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 479
2018-05-01 18:16:04.641  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_161_piece0 on 172.21.241.193:58620 in memory (size: 17.9 KB, free: 1981.6 MB)
2018-05-01 18:16:04.641  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_147_piece0 on 172.21.241.193:58620 in memory (size: 13.0 KB, free: 1981.6 MB)
2018-05-01 18:16:04.641  INFO 16044 --- [block-manager-slave-async-thread-pool-28] org.apache.spark.storage.BlockManager    : Removing RDD 670
2018-05-01 18:16:04.642  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 670
2018-05-01 18:16:04.642  INFO 16044 --- [block-manager-slave-async-thread-pool-26] org.apache.spark.storage.BlockManager    : Removing RDD 650
2018-05-01 18:16:04.642  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 650
2018-05-01 18:16:04.642  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 54
2018-05-01 18:16:04.642  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 70
2018-05-01 18:16:04.642  INFO 16044 --- [block-manager-slave-async-thread-pool-31] org.apache.spark.storage.BlockManager    : Removing RDD 701
2018-05-01 18:16:04.643  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 701
2018-05-01 18:16:04.643  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_157_piece0 on 172.21.241.193:58620 in memory (size: 16.6 KB, free: 1982.6 MB)
2018-05-01 18:16:04.643  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_148_piece0 on 172.21.241.193:58620 in memory (size: 13.8 KB, free: 1982.6 MB)
2018-05-01 18:16:04.644  INFO 16044 --- [block-manager-slave-async-thread-pool-26] org.apache.spark.storage.BlockManager    : Removing RDD 540
2018-05-01 18:16:04.644  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 540
2018-05-01 18:16:04.644  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 68
2018-05-01 18:16:04.644  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_141_piece0 on 172.21.241.193:58620 in memory (size: 11.0 KB, free: 1982.6 MB)
2018-05-01 18:16:04.645  INFO 16044 --- [block-manager-slave-async-thread-pool-31] org.apache.spark.storage.BlockManager    : Removing RDD 488
2018-05-01 18:16:04.645  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 488
2018-05-01 18:16:04.645  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 63
2018-05-01 18:16:04.646  INFO 16044 --- [block-manager-slave-async-thread-pool-31] org.apache.spark.storage.BlockManager    : Removing RDD 482
2018-05-01 18:16:04.647  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 482
2018-05-01 18:16:04.647  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_158_piece0 on 172.21.241.193:58620 in memory (size: 17.6 KB, free: 1990.7 MB)
2018-05-01 18:16:04.648  INFO 16044 --- [block-manager-slave-async-thread-pool-31] org.apache.spark.storage.BlockManager    : Removing RDD 483
2018-05-01 18:16:04.648  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 483
2018-05-01 18:16:04.648  INFO 16044 --- [block-manager-slave-async-thread-pool-28] org.apache.spark.storage.BlockManager    : Removing RDD 700
2018-05-01 18:16:04.648  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 700
2018-05-01 18:16:04.648  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_152_piece0 on 172.21.241.193:58620 in memory (size: 15.5 KB, free: 1990.7 MB)
2018-05-01 18:16:04.649  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_142_piece0 on 172.21.241.193:58620 in memory (size: 11.9 KB, free: 1990.8 MB)
2018-05-01 18:16:04.649  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 64
2018-05-01 18:16:04.649  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_165_piece0 on 172.21.241.193:58620 in memory (size: 18.2 KB, free: 1990.8 MB)
2018-05-01 18:16:04.650  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 51
2018-05-01 18:16:04.650  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_143_piece0 on 172.21.241.193:58620 in memory (size: 11.7 KB, free: 1990.8 MB)
2018-05-01 18:16:04.650  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 52
2018-05-01 18:16:04.650  INFO 16044 --- [block-manager-slave-async-thread-pool-28] org.apache.spark.storage.BlockManager    : Removing RDD 550
2018-05-01 18:16:04.651  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 550
2018-05-01 18:16:04.651  INFO 16044 --- [block-manager-slave-async-thread-pool-26] org.apache.spark.storage.BlockManager    : Removing RDD 610
2018-05-01 18:16:04.651  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 610
2018-05-01 18:16:04.651  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_145_piece0 on 172.21.241.193:58620 in memory (size: 12.4 KB, free: 1990.8 MB)
2018-05-01 18:16:04.652  INFO 16044 --- [block-manager-slave-async-thread-pool-26] org.apache.spark.storage.BlockManager    : Removing RDD 630
2018-05-01 18:16:04.652  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 630
2018-05-01 18:16:04.652  INFO 16044 --- [block-manager-slave-async-thread-pool-20] org.apache.spark.storage.BlockManager    : Removing RDD 500
2018-05-01 18:16:04.652  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 500
2018-05-01 18:16:04.652  INFO 16044 --- [block-manager-slave-async-thread-pool-28] org.apache.spark.storage.BlockManager    : Removing RDD 489
2018-05-01 18:16:04.652  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 489
2018-05-01 18:16:04.652  INFO 16044 --- [block-manager-slave-async-thread-pool-30] org.apache.spark.storage.BlockManager    : Removing RDD 695
2018-05-01 18:16:04.653  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 695
2018-05-01 18:16:04.653  INFO 16044 --- [block-manager-slave-async-thread-pool-24] org.apache.spark.storage.BlockManager    : Removing RDD 510
2018-05-01 18:16:04.653  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 510
2018-05-01 18:16:04.653  INFO 16044 --- [block-manager-slave-async-thread-pool-28] org.apache.spark.storage.BlockManager    : Removing RDD 600
2018-05-01 18:16:04.653  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 600
2018-05-01 18:16:04.654  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_114_piece0 on 172.21.241.193:58620 in memory (size: 2.1 KB, free: 1990.8 MB)
2018-05-01 18:16:08.662  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:21:08.663  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:26:08.664  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:31:08.666  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:36:08.665  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:41:08.665  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:46:08.664  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:51:08.617  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 18:56:08.541  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:01:08.464  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:06:08.390  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:11:08.335  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:16:08.282  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:21:08.228  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:26:08.185  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:31:08.147  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:36:08.108  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:41:08.069  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:46:08.031  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:51:07.992  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 19:56:07.954  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 20:01:07.937  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 20:06:07.920  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 20:36:11.866  WARN 16044 --- [driver-heartbeater] org.apache.spark.executor.Executor       : Issue communicating with driver in heartbeater

org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[scala-library-2.11.12.jar:na]
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:726) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:755) [spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:755) [spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:755) [spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954) [spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:755) [spark-core_2.11-2.2.0.jar:2.2.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223) ~[scala-library-2.11.12.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227) ~[scala-library-2.11.12.jar:na]
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	... 14 common frames omitted

2018-05-01 20:36:21.869  WARN 16044 --- [driver-heartbeater] org.apache.spark.executor.Executor       : Issue communicating with driver in heartbeater

org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[scala-library-2.11.12.jar:na]
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:726) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:755) [spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:755) [spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:755) [spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954) [spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:755) [spark-core_2.11-2.2.0.jar:2.2.0]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223) ~[scala-library-2.11.12.jar:na]
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227) ~[scala-library-2.11.12.jar:na]
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.11-2.2.0.jar:2.2.0]
	... 14 common frames omitted

2018-05-01 20:36:30.793  WARN 16044 --- [heartbeat-receiver-event-loop-thread] org.apache.spark.rpc.netty.NettyRpcEnv   : Ignored message: HeartbeatResponse(false)
2018-05-01 20:36:30.794  WARN 16044 --- [heartbeat-receiver-event-loop-thread] org.apache.spark.rpc.netty.NettyRpcEnv   : Ignored message: HeartbeatResponse(false)
2018-05-01 20:39:35.665  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 20:44:35.667  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 20:49:35.669  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 20:54:35.671  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 20:59:35.672  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:04:35.674  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:09:35.677  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:14:35.678  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:19:35.680  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:24:35.682  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:29:35.683  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:34:35.684  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:39:35.687  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:44:35.688  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:49:35.690  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:54:35.691  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 21:59:35.693  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:04:35.695  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:09:35.697  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:14:35.699  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:19:35.700  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:24:35.703  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:29:35.704  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:34:35.706  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:39:35.707  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:44:35.709  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:49:35.710  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:54:35.712  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 22:59:35.713  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:04:35.714  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:09:35.717  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:14:35.719  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:19:35.720  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:24:35.722  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:29:35.725  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:34:35.725  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:39:35.727  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:44:35.729  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:49:35.731  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:54:35.733  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 23:59:35.734  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:04:35.735  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:09:35.737  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:14:35.739  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:19:35.740  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:24:35.741  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:29:35.743  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:34:35.744  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:39:35.745  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:44:35.747  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:49:35.748  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:54:35.749  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 00:59:35.750  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:04:35.751  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:09:35.754  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:14:35.756  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:19:35.757  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:24:35.759  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:29:35.762  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:34:35.763  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:39:35.765  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:44:35.765  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:49:35.768  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:54:35.769  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 01:59:35.771  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:04:35.771  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:09:35.775  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:14:35.776  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:19:35.778  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:24:35.780  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:29:35.782  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:34:35.783  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:39:35.786  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:44:35.787  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:49:35.788  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:54:35.790  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 02:59:35.791  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:04:35.793  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:09:35.797  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:14:35.798  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:19:35.800  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:24:35.802  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:29:35.805  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:34:35.806  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:39:35.811  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:44:35.814  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:49:35.818  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:54:35.826  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 03:59:35.902  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:04:35.976  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:09:36.052  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:14:36.114  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:19:36.170  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:24:36.225  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:29:36.277  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:34:36.316  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:39:36.356  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:44:36.395  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:49:36.436  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:54:36.476  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 04:59:36.516  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:04:36.546  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:09:36.565  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:14:36.581  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:19:36.600  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:24:36.616  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:29:36.633  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:34:36.650  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:39:36.663  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:44:36.673  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:49:36.683  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:54:36.694  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 05:59:36.704  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:04:36.713  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:09:36.724  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:14:36.729  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:19:36.734  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:24:36.739  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:29:36.745  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:34:36.749  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:39:36.756  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:44:36.762  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:49:36.765  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:54:36.769  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 06:59:36.773  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:04:36.776  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:09:36.780  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:14:36.784  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:19:36.788  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:24:36.792  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:29:36.797  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:34:36.800  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:39:36.805  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:44:36.809  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:49:36.813  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:54:36.814  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 07:59:36.817  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:04:36.818  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:09:36.820  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:14:36.822  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:19:36.824  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:24:36.826  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:29:36.828  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:34:36.831  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:39:36.834  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:44:36.835  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:49:36.837  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:54:36.839  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 08:59:36.841  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 09:04:36.842  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 09:09:36.845  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 09:14:36.846  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 09:19:36.847  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 09:24:36.848  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 09:29:36.850  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 09:34:36.851  INFO 16044 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 09:36:46.660 ERROR 16044 --- [DiscoveryClient-HeartbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error

com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused: connect
	at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187) ~[jersey-apache-client4-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.sun.jersey.api.client.Client.handle(Client.java:652) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource.handle(WebResource.java:682) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource$Builder.put(WebResource.java:529) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:102) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:89) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:832) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1396) [eureka-client-1.4.12.jar:1.4.12]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_131]
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:121) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:180) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:144) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:134) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.DefaultRequestDirector.tryConnect(DefaultRequestDirector.java:610) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:445) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:118) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) ~[httpclient-4.5.3.jar:4.5.3]
	at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:173) ~[jersey-apache-client4-1.19.1.jar:1.19.1]
	... 26 common frames omitted

2018-05-02 09:36:46.669  WARN 16044 --- [DiscoveryClient-HeartbeatExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failure
2018-05-02 09:36:48.672 ERROR 16044 --- [DiscoveryClient-HeartbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error

com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused: connect
	at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187) ~[jersey-apache-client4-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.sun.jersey.api.client.Client.handle(Client.java:652) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource.handle(WebResource.java:682) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource$Builder.put(WebResource.java:529) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:102) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:832) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1396) [eureka-client-1.4.12.jar:1.4.12]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_131]
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:121) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:180) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:144) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:134) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.DefaultRequestDirector.tryConnect(DefaultRequestDirector.java:610) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:445) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:118) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) ~[httpclient-4.5.3.jar:4.5.3]
	at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:173) ~[jersey-apache-client4-1.19.1.jar:1.19.1]
	... 27 common frames omitted

2018-05-02 09:36:48.677  WARN 16044 --- [DiscoveryClient-HeartbeatExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failure
2018-05-02 09:36:48.681 ERROR 16044 --- [DiscoveryClient-HeartbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - was unable to send heartbeat!

com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:832) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1396) [eureka-client-1.4.12.jar:1.4.12]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]

2018-05-02 10:28:59.066  INFO 15204 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-02 10:28:59.096  INFO 15204 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@22323bce: startup date [Wed May 02 10:28:59 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@ea3bdcd
2018-05-02 10:29:00.965  INFO 15204 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-02 10:29:01.003  INFO 15204 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-02 10:29:01.017  INFO 15204 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-02 10:29:01.387  INFO 15204 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=b50ca5e2-6e9d-3b20-a222-3e414a829afc
2018-05-02 10:29:01.433  INFO 15204 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-02 10:29:01.567  INFO 15204 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$35d4f0e8] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-02 10:29:01.615  INFO 15204 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$51eef3e5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-02 10:29:02.291  INFO 15204 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-02 10:29:02.307  INFO 15204 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-02 10:29:02.308  INFO 15204 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-02 10:29:02.477  INFO 15204 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-02 10:29:02.478  INFO 15204 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3382 ms
2018-05-02 10:29:02.812  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-02 10:29:02.814  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-02 10:29:02.819  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-02 10:29:02.819  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-02 10:29:02.820  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-02 10:29:02.821  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-02 10:29:02.822  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-02 10:29:02.823  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-02 10:29:02.824  INFO 15204 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-02 10:29:03.357  INFO 15204 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-02 10:29:04.153  INFO 15204 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-02 10:29:04.709  INFO 15204 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-02 10:29:04.711  INFO 15204 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-02 10:29:05.467  INFO 15204 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-02 10:29:05.778  INFO 15204 --- [cluster-ClusterId{value='5ae968c0b11f8e3b64044e82', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Exception in monitor thread while connecting to server localhost:27017

com.mongodb.MongoSocketOpenException: Exception opening socket
	at com.mongodb.connection.SocketStream.open(SocketStream.java:63) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.InternalStreamConnection.open(InternalStreamConnection.java:115) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:113) ~[mongodb-driver-core-3.4.3.jar:na]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_131]
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at com.mongodb.connection.SocketStreamHelper.initialize(SocketStreamHelper.java:57) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.SocketStream.open(SocketStream.java:58) ~[mongodb-driver-core-3.4.3.jar:na]
	... 3 common frames omitted

2018-05-02 10:29:05.891  INFO 15204 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-02 10:29:05.915  INFO 15204 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-02 10:29:05.916  INFO 15204 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-02 10:29:05.919  INFO 15204 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-02 10:29:05.921  INFO 15204 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-02 10:29:05.922  INFO 15204 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-02 10:29:06.636  INFO 15204 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 51877.
2018-05-02 10:29:06.662  INFO 15204 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-02 10:29:06.685  INFO 15204 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-02 10:29:06.689  INFO 15204 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-02 10:29:06.690  INFO 15204 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-02 10:29:06.706  INFO 15204 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-d30633a5-fff7-4d95-867f-33bdd1a75ddb
2018-05-02 10:29:06.732  INFO 15204 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-02 10:29:06.776  INFO 15204 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-02 10:29:06.844  INFO 15204 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @11099ms
2018-05-02 10:29:06.903  INFO 15204 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-02 10:29:06.920  INFO 15204 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @11175ms
2018-05-02 10:29:06.943  INFO 15204 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@48e797e6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-02 10:29:06.943  INFO 15204 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-02 10:29:06.968  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@38f83bb7{/jobs,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.969  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@84e4048{/jobs/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.970  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@274a3adb{/jobs/job,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.973  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@44a15a37{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.974  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@20cd311b{/stages,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.976  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@340eb8cc{/stages/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.977  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@16c64a20{/stages/stage,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.978  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@b6482b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.981  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@9dbbbb7{/stages/pool,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.982  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@339dcf54{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.983  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4827871a{/storage,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.984  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@55c705f6{/storage/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.985  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1160a603{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.986  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@189ae091{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.987  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@36f88f1d{/environment,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.990  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@71a5d72f{/environment/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.992  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4205e645{/executors,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.993  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@29de4c0{/executors/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.994  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6781cd6d{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-02 10:29:06.995  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@25c1bad4{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.005  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1fe74408{/static,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.006  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4e8ec90{/,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.008  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@18524505{/api,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.011  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7a91e3f8{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.012  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@709c1799{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.016  INFO 15204 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-02 10:29:07.104  INFO 15204 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-02 10:29:07.132  INFO 15204 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51890.
2018-05-02 10:29:07.133  INFO 15204 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:51890
2018-05-02 10:29:07.135  INFO 15204 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-02 10:29:07.139  INFO 15204 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 51890, None)
2018-05-02 10:29:07.144  INFO 15204 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:51890 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 51890, None)
2018-05-02 10:29:07.149  INFO 15204 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 51890, None)
2018-05-02 10:29:07.150  INFO 15204 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 51890, None)
2018-05-02 10:29:07.172  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@409a8f3{/metrics/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.256  INFO 15204 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-02 10:29:07.258  INFO 15204 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-02 10:29:07.272  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7ce540e3{/SQL,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.273  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6e8dc630{/SQL/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.274  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@355df5fa{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.278  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@78f3a456{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.280  INFO 15204 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@13ad1efb{/static/sql,null,AVAILABLE,@Spark}
2018-05-02 10:29:07.897  WARN 15204 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-02 10:29:08.172  INFO 15204 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-02 10:29:08.972  INFO 15204 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-02 10:29:08.976  INFO 15204 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-02 10:29:08.982  INFO 15204 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-02 10:29:08.984  INFO 15204 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-02 10:29:08.987  INFO 15204 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-02 10:29:08.991  INFO 15204 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-02 10:29:08.993  INFO 15204 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-02 10:29:09.974  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-02 10:29:09.975  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:09.976  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:09.981  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-02 10:29:09.982  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-02 10:29:09.985  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:09.987  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-02 10:29:09.988  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-02 10:29:09.989  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:09.990  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-02 10:29:09.991  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-02 10:29:09.992  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:09.993  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:09.998  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:29:09.999  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:10.000  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:10.001  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-02 10:29:10.003  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:29:10.006  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:10.008  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-02 10:29:10.010  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:29:10.011  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:10.013  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-02 10:29:10.014  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:10.015  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-02 10:29:10.017  INFO 15204 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:29:10.492  INFO 15204 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@22323bce: startup date [Wed May 02 10:28:59 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@ea3bdcd
2018-05-02 10:29:10.574  INFO 15204 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:29:10.575  INFO 15204 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:29:10.606  INFO 15204 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-02 10:29:10.657  INFO 15204 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:29:11.220  WARN 15204 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-02 10:29:11.352  WARN 15204 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-02 10:29:11.352  INFO 15204 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-02 10:29:11.365  WARN 15204 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-02 10:29:11.366  INFO 15204 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-02 10:29:11.478  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-02 10:29:11.493  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-02 10:29:11.494  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-02 10:29:11.497  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-02 10:29:11.498  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-02 10:29:11.501  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-02 10:29:11.505  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-02 10:29:11.520  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-02 10:29:11.536  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-02 10:29:11.553  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=22323bce,type=ConfigurationPropertiesRebinder]
2018-05-02 10:29:11.560  INFO 15204 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-02 10:29:11.768  INFO 15204 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-02 10:29:11.780  INFO 15204 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-02 10:29:11.938  INFO 15204 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-02 10:29:11.939  INFO 15204 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-02 10:29:12.119  INFO 15204 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-02 10:29:12.119  INFO 15204 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-02 10:29:12.501  INFO 15204 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 10:29:12.609  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-02 10:29:12.610  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-02 10:29:12.611  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-02 10:29:12.617  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-02 10:29:12.617  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-02 10:29:12.618  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-02 10:29:12.621  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-02 10:29:12.812  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-02 10:29:12.814  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-02 10:29:12.818  INFO 15204 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-02 10:29:12.821  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525246152821 with initial instances count: 1
2018-05-02 10:29:12.854  INFO 15204 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-02 10:29:12.857  INFO 15204 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525246152857, current=UP, previous=STARTING]
2018-05-02 10:29:12.860  INFO 15204 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-02 10:29:12.901  INFO 15204 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-02 10:29:12.928  INFO 15204 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-02 10:29:12.928  INFO 15204 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-02 10:29:12.953  INFO 15204 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-02 10:29:12.977  INFO 15204 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-02 10:29:13.055  INFO 15204 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-02 10:29:13.056  INFO 15204 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-02 10:29:13.062  INFO 15204 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 16.31 seconds (JVM running for 17.317)
2018-05-02 10:29:54.153  INFO 15204 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-02 10:29:54.157  INFO 15204 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-02 10:29:54.219  INFO 15204 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 60 ms
2018-05-02 10:30:32.878  INFO 15204 --- [cluster-ClusterId{value='5ae968c0b11f8e3b64044e82', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:9, serverValue:5}] to localhost:27017
2018-05-02 10:30:32.881  INFO 15204 --- [cluster-ClusterId{value='5ae968c0b11f8e3b64044e82', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=745086}
2018-05-02 10:30:32.883  INFO 15204 --- [cluster-ClusterId{value='5ae968c0b11f8e3b64044e82', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-02 10:34:12.624  INFO 15204 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 10:36:56.622  INFO 25308 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-02 10:36:56.645  INFO 25308 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@451514c4: startup date [Wed May 02 10:36:56 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@4a1d4500
2018-05-02 10:36:59.546  INFO 25308 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-02 10:36:59.574  INFO 25308 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-02 10:36:59.582  INFO 25308 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-02 10:37:00.080  INFO 25308 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-02 10:37:00.164  INFO 25308 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-02 10:37:00.469  INFO 25308 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$504d7d65] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-02 10:37:00.573  INFO 25308 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6c678062] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-02 10:37:01.108  INFO 25308 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-02 10:37:01.119  INFO 25308 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-02 10:37:01.120  INFO 25308 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-02 10:37:01.185  INFO 25308 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-02 10:37:01.185  INFO 25308 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 4541 ms
2018-05-02 10:37:01.486  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-02 10:37:01.487  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-02 10:37:01.492  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-02 10:37:01.492  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-02 10:37:01.492  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-02 10:37:01.492  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-02 10:37:01.493  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-02 10:37:01.494  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-02 10:37:01.494  INFO 25308 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-02 10:37:01.845  INFO 25308 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-02 10:37:02.505  INFO 25308 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-02 10:37:03.072  INFO 25308 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-02 10:37:03.073  INFO 25308 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-02 10:37:03.122  INFO 25308 --- [cluster-ClusterId{value='5ae96a9fb11f8e62dceca365', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:6}] to localhost:27017
2018-05-02 10:37:03.125  INFO 25308 --- [cluster-ClusterId{value='5ae96a9fb11f8e62dceca365', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=650272}
2018-05-02 10:37:03.126  INFO 25308 --- [cluster-ClusterId{value='5ae96a9fb11f8e62dceca365', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-02 10:37:03.530  INFO 25308 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-02 10:37:03.702  WARN 25308 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-02 10:37:03.815  INFO 25308 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-02 10:37:03.827  INFO 25308 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-02 10:37:03.827  INFO 25308 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-02 10:37:03.828  INFO 25308 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-02 10:37:03.829  INFO 25308 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-02 10:37:03.830  INFO 25308 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-02 10:37:04.199  INFO 25308 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 52243.
2018-05-02 10:37:04.214  INFO 25308 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-02 10:37:04.233  INFO 25308 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-02 10:37:04.236  INFO 25308 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-02 10:37:04.237  INFO 25308 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-02 10:37:04.245  INFO 25308 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-3bcb3181-f8c4-4db0-9658-b6d4f631a243
2018-05-02 10:37:04.280  INFO 25308 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-02 10:37:04.329  INFO 25308 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-02 10:37:04.400  INFO 25308 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @13722ms
2018-05-02 10:37:04.465  INFO 25308 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-02 10:37:04.510  INFO 25308 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @13832ms
2018-05-02 10:37:04.530  INFO 25308 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@7edbdc5e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-02 10:37:04.531  INFO 25308 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-02 10:37:04.552  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@411ac6e5{/jobs,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.552  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3c3ca629{/jobs/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.553  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@18118260{/jobs/job,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.553  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@13c825b0{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.554  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5d34faf5{/stages,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.555  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2b56a0f1{/stages/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.556  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@235a07d0{/stages/stage,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.557  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7c86c773{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.557  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@19b7019b{/stages/pool,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.558  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@55f95923{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.558  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5d9a2874{/storage,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.559  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2816d5f4{/storage/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.559  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5a90d391{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.561  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3e670091{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.561  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@18cdf811{/environment,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.562  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@388e9f4c{/environment/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.563  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@667a3733{/executors,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.564  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4fd07409{/executors/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.564  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6bf48155{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.565  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@639a94fa{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.570  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7742549c{/static,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.571  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1c3fa21{/,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.572  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5e58f18f{/api,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.573  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@fd12124{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.574  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7c680020{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.576  INFO 25308 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-02 10:37:04.688  INFO 25308 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-02 10:37:04.721  INFO 25308 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52257.
2018-05-02 10:37:04.722  INFO 25308 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:52257
2018-05-02 10:37:04.724  INFO 25308 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-02 10:37:04.726  INFO 25308 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 52257, None)
2018-05-02 10:37:04.731  INFO 25308 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:52257 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 52257, None)
2018-05-02 10:37:04.735  INFO 25308 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 52257, None)
2018-05-02 10:37:04.736  INFO 25308 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 52257, None)
2018-05-02 10:37:04.753  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@405d08f3{/metrics/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.816  INFO 25308 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-02 10:37:04.817  INFO 25308 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-02 10:37:04.824  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4a6c87f5{/SQL,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.824  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7e055139{/SQL/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.825  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@30987478{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.825  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@50e7475f{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-02 10:37:04.827  INFO 25308 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@12fea6b{/static/sql,null,AVAILABLE,@Spark}
2018-05-02 10:37:05.451  WARN 25308 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-02 10:37:05.740  INFO 25308 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-02 10:37:06.828  INFO 25308 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations/],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-02 10:37:06.832  INFO 25308 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-02 10:37:06.838  INFO 25308 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-02 10:37:06.840  INFO 25308 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-02 10:37:06.842  INFO 25308 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-02 10:37:06.846  INFO 25308 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-02 10:37:06.847  INFO 25308 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-02 10:37:08.224  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-02 10:37:08.226  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-02 10:37:08.228  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.229  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-02 10:37:08.229  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.230  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-02 10:37:08.233  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.234  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-02 10:37:08.235  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:37:08.235  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.238  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.239  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.242  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-02 10:37:08.242  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-02 10:37:08.243  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.246  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.248  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.250  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-02 10:37:08.251  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.253  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-02 10:37:08.254  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.255  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:37:08.257  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:37:08.257  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:37:08.257  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-02 10:37:08.258  INFO 25308 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-02 10:37:09.173  INFO 25308 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@451514c4: startup date [Wed May 02 10:36:56 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@4a1d4500
2018-05-02 10:37:09.336  INFO 25308 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:37:09.336  INFO 25308 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:37:09.384  INFO 25308 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-02 10:37:09.457  INFO 25308 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:37:10.446  INFO 25308 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2018-05-02 10:37:10.633  WARN 25308 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-02 10:37:10.634  INFO 25308 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-02 10:37:10.646  WARN 25308 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-02 10:37:10.646  INFO 25308 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-02 10:37:10.777  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-02 10:37:10.793  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-02 10:37:10.795  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-02 10:37:10.799  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-02 10:37:10.800  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-02 10:37:10.800  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-02 10:37:10.806  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-02 10:37:10.827  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-02 10:37:10.843  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-02 10:37:10.868  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=451514c4,type=ConfigurationPropertiesRebinder]
2018-05-02 10:37:10.884  INFO 25308 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-02 10:37:11.299  INFO 25308 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-02 10:37:11.307  INFO 25308 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-02 10:37:11.440  INFO 25308 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-02 10:37:11.441  INFO 25308 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-02 10:37:11.619  INFO 25308 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-02 10:37:11.619  INFO 25308 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-02 10:37:12.042  INFO 25308 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 10:37:12.183  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-02 10:37:12.183  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-02 10:37:12.183  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-02 10:37:12.183  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-02 10:37:12.185  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-02 10:37:12.185  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-02 10:37:12.185  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-02 10:37:14.573 ERROR 25308 --- [restartedMain] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error

com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused: connect
	at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187) ~[jersey-apache-client4-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.sun.jersey.api.client.Client.handle(Client.java:652) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource.handle(WebResource.java:682) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource$Builder.get(WebResource.java:509) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.getApplicationsInternal(AbstractJerseyEurekaHttpClient.java:194) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.getApplications(AbstractJerseyEurekaHttpClient.java:165) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1030) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:944) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:444) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:304) [eureka-client-1.4.12.jar:1.4.12]
	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:51) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:192) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$73d07981.CGLIB$eurekaClient$1(<generated>) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$73d07981$$FastClassBySpringCGLIB$$133eafc5.invoke(<generated>) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) [spring-core-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$73d07981.eurekaClient(<generated>) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory$2.getObject(AbstractBeanFactory.java:345) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:359) [spring-cloud-context-1.1.6.RELEASE.jar:1.1.6.RELEASE]
	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:176) [spring-cloud-context-1.1.6.RELEASE.jar:1.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:340) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35) [spring-aop-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:192) [spring-aop-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at com.sun.proxy.$Proxy140.getApplications(Unknown Source) [na:na]
	at org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration.maybeInitializeClient(EurekaDiscoveryClientConfiguration.java:120) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration.start(EurekaDiscoveryClientConfiguration.java:97) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:175) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:50) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:348) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:151) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:114) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:880) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_131]
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:121) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:180) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:144) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:134) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.DefaultRequestDirector.tryConnect(DefaultRequestDirector.java:610) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:445) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:118) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) ~[httpclient-4.5.3.jar:4.5.3]
	at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:173) ~[jersey-apache-client4-1.19.1.jar:1.19.1]
	... 72 common frames omitted

2018-05-02 10:37:14.578  WARN 25308 --- [restartedMain] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failure
2018-05-02 10:37:14.580 ERROR 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - was unable to refresh its cache! status = Cannot execute request on any known server

com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1030) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:944) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:444) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:304) [eureka-client-1.4.12.jar:1.4.12]
	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:51) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:192) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$73d07981.CGLIB$eurekaClient$1(<generated>) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$73d07981$$FastClassBySpringCGLIB$$133eafc5.invoke(<generated>) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) [spring-core-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$73d07981.eurekaClient(<generated>) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory$2.getObject(AbstractBeanFactory.java:345) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:359) [spring-cloud-context-1.1.6.RELEASE.jar:1.1.6.RELEASE]
	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:176) [spring-cloud-context-1.1.6.RELEASE.jar:1.1.6.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:340) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) [spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35) [spring-aop-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:192) [spring-aop-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at com.sun.proxy.$Proxy140.getApplications(Unknown Source) [na:na]
	at org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration.maybeInitializeClient(EurekaDiscoveryClientConfiguration.java:120) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration.start(EurekaDiscoveryClientConfiguration.java:97) [spring-cloud-netflix-eureka-client-1.2.3.RELEASE.jar:1.2.3.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:175) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:50) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:348) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:151) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:114) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:880) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]

2018-05-02 10:37:14.584  WARN 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Using default backup registry implementation which does not do anything.
2018-05-02 10:37:14.587  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-02 10:37:14.592  INFO 25308 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-02 10:37:14.595  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525246634594 with initial instances count: 0
2018-05-02 10:37:14.617  INFO 25308 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-02 10:37:14.618  INFO 25308 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525246634618, current=UP, previous=STARTING]
2018-05-02 10:37:14.621  INFO 25308 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-02 10:37:14.691  INFO 25308 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-02 10:37:14.691  INFO 25308 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-02 10:37:14.708  INFO 25308 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-02 10:37:14.725  INFO 25308 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-02 10:37:14.809  INFO 25308 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-02 10:37:14.810  INFO 25308 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-02 10:37:14.816  INFO 25308 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 21.361 seconds (JVM running for 24.139)
2018-05-02 10:37:15.367  INFO 25308 --- [RMI TCP Connection(5)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:8}] to localhost:27017
2018-05-02 10:37:16.637 ERROR 25308 --- [DiscoveryClient-InstanceInfoReplicator-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error

com.sun.jersey.api.client.ClientHandlerException: java.net.ConnectException: Connection refused: connect
	at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187) ~[jersey-apache-client4-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.sun.jersey.api.client.Client.handle(Client.java:652) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource.handle(WebResource.java:682) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570) ~[jersey-client-1.19.1.jar:1.19.1]
	at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.register(AbstractJerseyEurekaHttpClient.java:56) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:815) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:104) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:88) [eureka-client-1.4.12.jar:1.4.12]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_131]
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:121) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:180) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:144) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:134) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.DefaultRequestDirector.tryConnect(DefaultRequestDirector.java:610) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:445) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:835) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:118) ~[httpclient-4.5.3.jar:4.5.3]
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56) ~[httpclient-4.5.3.jar:4.5.3]
	at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:173) ~[jersey-apache-client4-1.19.1.jar:1.19.1]
	... 30 common frames omitted

2018-05-02 10:37:16.642  WARN 25308 --- [DiscoveryClient-InstanceInfoReplicator-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failure
2018-05-02 10:37:16.642  WARN 25308 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration failed Cannot execute request on any known server

com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:815) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:104) [eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:88) [eureka-client-1.4.12.jar:1.4.12]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]

2018-05-02 10:37:16.644  WARN 25308 --- [DiscoveryClient-InstanceInfoReplicator-0] c.n.discovery.InstanceInfoReplicator     : There was a problem with the instance info replicator

com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:815) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:104) ~[eureka-client-1.4.12.jar:1.4.12]
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:88) [eureka-client-1.4.12.jar:1.4.12]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_131]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]

2018-05-02 10:37:44.588  INFO 25308 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-02 10:37:44.588  INFO 25308 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-02 10:37:44.589  INFO 25308 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-02 10:37:44.590  INFO 25308 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-02 10:37:44.590  INFO 25308 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-02 10:37:44.590  INFO 25308 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-02 10:37:44.590  INFO 25308 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-02 10:37:44.640  INFO 25308 --- [DiscoveryClient-HeartbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - Re-registering apps/RECOMENDATION-SERVICE2
2018-05-02 10:37:44.641  INFO 25308 --- [DiscoveryClient-HeartbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-02 10:37:44.679  INFO 25308 --- [DiscoveryClient-HeartbeatExecutor-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-02 10:37:44.692  INFO 25308 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-02 10:37:46.645  INFO 25308 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-02 10:37:46.656  INFO 25308 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-02 10:37:54.290  INFO 25308 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-02 10:37:54.291  INFO 25308 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-02 10:37:54.322  INFO 25308 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 30 ms
2018-05-02 10:42:12.189  INFO 25308 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 10:47:12.190  INFO 25308 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 10:52:12.193  INFO 25308 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 10:53:39.102  INFO 14400 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-02 10:53:39.114  INFO 14400 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7a027ff0: startup date [Wed May 02 10:53:39 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3bc6718a
2018-05-02 10:53:40.705  INFO 14400 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-02 10:53:40.731  INFO 14400 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-02 10:53:40.739  INFO 14400 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-02 10:53:41.002  INFO 14400 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-02 10:53:41.033  INFO 14400 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-02 10:53:41.152  INFO 14400 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c11eba2b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-02 10:53:41.195  INFO 14400 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$dd38bd28] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-02 10:53:41.678  INFO 14400 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-02 10:53:41.685  INFO 14400 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-02 10:53:41.686  INFO 14400 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-02 10:53:41.743  INFO 14400 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-02 10:53:41.744  INFO 14400 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2629 ms
2018-05-02 10:53:42.053  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-02 10:53:42.057  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-02 10:53:42.062  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-02 10:53:42.062  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-02 10:53:42.062  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-02 10:53:42.062  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-02 10:53:42.063  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-02 10:53:42.063  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-02 10:53:42.063  INFO 14400 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-02 10:53:42.411  INFO 14400 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-02 10:53:42.969  INFO 14400 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-02 10:53:43.517  INFO 14400 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-02 10:53:43.518  INFO 14400 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-02 10:53:43.571  INFO 14400 --- [cluster-ClusterId{value='5ae96e87b11f8e384020f0c1', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:12}] to localhost:27017
2018-05-02 10:53:43.574  INFO 14400 --- [cluster-ClusterId{value='5ae96e87b11f8e384020f0c1', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=651458}
2018-05-02 10:53:43.576  INFO 14400 --- [cluster-ClusterId{value='5ae96e87b11f8e384020f0c1', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-02 10:53:43.966  INFO 14400 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-02 10:53:44.122  WARN 14400 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-02 10:53:44.230  INFO 14400 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-02 10:53:44.243  INFO 14400 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-02 10:53:44.244  INFO 14400 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-02 10:53:44.244  INFO 14400 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-02 10:53:44.246  INFO 14400 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-02 10:53:44.246  INFO 14400 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-02 10:53:44.566  INFO 14400 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 52923.
2018-05-02 10:53:44.583  INFO 14400 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-02 10:53:44.598  INFO 14400 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-02 10:53:44.601  INFO 14400 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-02 10:53:44.601  INFO 14400 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-02 10:53:44.607  INFO 14400 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-80c4c3b5-47f2-4775-b8ff-a0f47e45c27b
2018-05-02 10:53:44.628  INFO 14400 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-02 10:53:44.669  INFO 14400 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-02 10:53:44.733  INFO 14400 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8372ms
2018-05-02 10:53:44.782  INFO 14400 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-02 10:53:44.797  INFO 14400 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8436ms
2018-05-02 10:53:44.814  INFO 14400 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@4668d1eb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-02 10:53:44.815  INFO 14400 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-02 10:53:44.834  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7db1f72a{/jobs,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.835  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6281d4b3{/jobs/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.835  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3bb91fbb{/jobs/job,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.835  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@c86d4a7{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.836  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@78c0e38f{/stages,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.838  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6a2223c1{/stages/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.838  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6077f73e{/stages/stage,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.839  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@71d15733{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.839  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3205e013{/stages/pool,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.840  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@63a2d760{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.840  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@476e99b0{/storage,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.840  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@213ccb49{/storage/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.841  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7fcba19e{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.842  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6c155a00{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.843  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5a2a629a{/environment,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.844  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1246d77b{/environment/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.844  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1c63d566{/executors,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.845  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4694f264{/executors/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.845  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7362399f{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.846  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@182186e0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.850  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4ba5c4ec{/static,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.850  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@d08c792{/,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.851  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@52e9af99{/api,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.851  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2459beff{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.852  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6c87ebd3{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-02 10:53:44.853  INFO 14400 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-02 10:53:44.934  INFO 14400 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-02 10:53:44.959  INFO 14400 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52936.
2018-05-02 10:53:44.960  INFO 14400 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:52936
2018-05-02 10:53:44.961  INFO 14400 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-02 10:53:44.963  INFO 14400 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 52936, None)
2018-05-02 10:53:44.966  INFO 14400 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:52936 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 52936, None)
2018-05-02 10:53:44.969  INFO 14400 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 52936, None)
2018-05-02 10:53:44.969  INFO 14400 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 52936, None)
2018-05-02 10:53:44.980  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@752a7b1d{/metrics/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:45.024  INFO 14400 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-02 10:53:45.024  INFO 14400 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-02 10:53:45.029  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4789c90f{/SQL,null,AVAILABLE,@Spark}
2018-05-02 10:53:45.030  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@60c04e00{/SQL/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:45.030  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1bf1eb4a{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-02 10:53:45.031  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1c5e9e17{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-02 10:53:45.032  INFO 14400 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@a0b2a96{/static/sql,null,AVAILABLE,@Spark}
2018-05-02 10:53:45.547  WARN 14400 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-02 10:53:45.735  INFO 14400 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-02 10:53:46.326  INFO 14400 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations/],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-02 10:53:46.329  INFO 14400 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-02 10:53:46.332  INFO 14400 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-02 10:53:46.333  INFO 14400 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-02 10:53:46.334  INFO 14400 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-02 10:53:46.336  INFO 14400 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-02 10:53:46.336  INFO 14400 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-02 10:53:47.149  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-02 10:53:47.150  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.151  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-02 10:53:47.152  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.153  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.153  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-02 10:53:47.155  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.156  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-02 10:53:47.156  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.156  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-02 10:53:47.158  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.159  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:53:47.159  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-02 10:53:47.159  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-02 10:53:47.160  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-02 10:53:47.161  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.161  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.161  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.162  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-02 10:53:47.162  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.162  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:53:47.162  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-02 10:53:47.164  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-02 10:53:47.164  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-02 10:53:47.164  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.165  INFO 14400 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-02 10:53:47.602  INFO 14400 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7a027ff0: startup date [Wed May 02 10:53:39 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3bc6718a
2018-05-02 10:53:47.672  INFO 14400 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:53:47.672  INFO 14400 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:53:47.720  INFO 14400 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-02 10:53:47.752  INFO 14400 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-02 10:53:48.214  WARN 14400 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-02 10:53:48.288  WARN 14400 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-02 10:53:48.288  INFO 14400 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-02 10:53:48.294  WARN 14400 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-02 10:53:48.294  INFO 14400 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-02 10:53:48.377  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-02 10:53:48.386  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-02 10:53:48.387  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-02 10:53:48.390  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-02 10:53:48.390  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-02 10:53:48.390  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-02 10:53:48.394  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-02 10:53:48.408  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-02 10:53:48.418  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-02 10:53:48.431  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=7a027ff0,type=ConfigurationPropertiesRebinder]
2018-05-02 10:53:48.438  INFO 14400 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-02 10:53:48.744  INFO 14400 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-02 10:53:48.751  INFO 14400 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-02 10:53:48.841  INFO 14400 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-02 10:53:48.841  INFO 14400 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-02 10:53:48.946  INFO 14400 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-02 10:53:48.946  INFO 14400 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-02 10:53:49.233  INFO 14400 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 10:53:49.338  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-02 10:53:49.338  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-02 10:53:49.338  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-02 10:53:49.338  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-02 10:53:49.340  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-02 10:53:49.340  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-02 10:53:49.340  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-02 10:53:49.502  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-02 10:53:49.505  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-02 10:53:49.507  INFO 14400 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-02 10:53:49.510  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525247629510 with initial instances count: 1
2018-05-02 10:53:49.532  INFO 14400 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-02 10:53:49.535  INFO 14400 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525247629535, current=UP, previous=STARTING]
2018-05-02 10:53:49.537  INFO 14400 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-02 10:53:49.584  INFO 14400 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-02 10:53:49.596  INFO 14400 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-02 10:53:49.596  INFO 14400 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-02 10:53:49.611  INFO 14400 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-02 10:53:49.625  INFO 14400 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-02 10:53:49.694  INFO 14400 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-02 10:53:49.696  INFO 14400 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-02 10:53:49.702  INFO 14400 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.023 seconds (JVM running for 13.342)
2018-05-02 10:53:50.104  INFO 14400 --- [RMI TCP Connection(2)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:13}] to localhost:27017
2018-05-02 10:58:49.342  INFO 14400 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 11:01:02.511  INFO 14400 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-02 11:01:02.513  INFO 14400 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-02 11:01:02.535  INFO 14400 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms
2018-05-02 11:03:49.342  INFO 14400 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 11:08:49.343  INFO 14400 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 11:13:49.346  INFO 14400 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-02 11:18:49.347  INFO 14400 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
