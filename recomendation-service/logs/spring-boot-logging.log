2018-05-01 16:36:40.773  INFO 5508 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 16:36:40.784  INFO 5508 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@74072972: startup date [Tue May 01 16:36:40 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3197a157
2018-05-01 16:36:40.931  WARN 5508 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.jcombat.profile.ProfileMicroserviceServerApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
2018-05-01 16:36:40.941 ERROR 5508 --- [restartedMain] o.s.boot.SpringApplication               : Application startup failed

org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.jcombat.profile.ProfileMicroserviceServerApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:181) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:308) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:228) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:272) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:92) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:687) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:525) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]
Caused by: org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.checkCandidate(ClassPathBeanDefinitionScanner.java:345) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.doScan(ClassPathBeanDefinitionScanner.java:283) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ComponentScanAnnotationParser.parse(ComponentScanAnnotationParser.java:135) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.doProcessConfigurationClass(ConfigurationClassParser.java:287) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:245) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:198) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:167) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	... 18 common frames omitted

2018-05-01 16:37:38.890  INFO 17436 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 16:37:38.901  INFO 17436 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@55fda42c: startup date [Tue May 01 16:37:38 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@629a8bd7
2018-05-01 16:37:38.967  WARN 17436 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.jcombat.profile.ProfileMicroserviceServerApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
2018-05-01 16:37:38.976 ERROR 17436 --- [restartedMain] o.s.boot.SpringApplication               : Application startup failed

org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [com.jcombat.profile.ProfileMicroserviceServerApplication]; nested exception is org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:181) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:308) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:228) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:272) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:92) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:687) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:525) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]
Caused by: org.springframework.context.annotation.ConflictingBeanDefinitionException: Annotation-specified bean name 'sparkConfig' for bean class [com.jcombat.profile.movie.config.SparkConfig] conflicts with existing, non-compatible bean definition of same name and class [com.jcombat.profile.config.SparkConfig]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.checkCandidate(ClassPathBeanDefinitionScanner.java:345) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ClassPathBeanDefinitionScanner.doScan(ClassPathBeanDefinitionScanner.java:283) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ComponentScanAnnotationParser.parse(ComponentScanAnnotationParser.java:135) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.doProcessConfigurationClass(ConfigurationClassParser.java:287) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:245) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:198) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:167) ~[spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	... 18 common frames omitted

2018-05-01 16:38:20.888  INFO 18064 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 16:38:20.899  INFO 18064 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b05d6e4: startup date [Tue May 01 16:38:20 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@54b0b8c1
2018-05-01 16:38:22.352  INFO 18064 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 16:38:22.377  INFO 18064 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 16:38:22.386  INFO 18064 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 16:38:22.619  INFO 18064 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 16:38:22.651  INFO 18064 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 16:38:22.759  INFO 18064 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$776de761] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 16:38:22.795  INFO 18064 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$9387ea5e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 16:38:23.266  INFO 18064 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 2222 (http)
2018-05-01 16:38:23.274  INFO 18064 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 16:38:23.275  INFO 18064 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 16:38:23.328  INFO 18064 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 16:38:23.329  INFO 18064 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2430 ms
2018-05-01 16:38:23.610  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 16:38:23.611  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 16:38:23.617  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 16:38:23.618  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 16:38:23.618  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 16:38:23.618  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 16:38:23.619  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 16:38:23.619  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 16:38:23.619  INFO 18064 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 16:38:23.940  INFO 18064 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:24.502  INFO 18064 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:25.006  INFO 18064 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 16:38:25.007  INFO 18064 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 16:38:25.061  INFO 18064 --- [cluster-ClusterId{value='5ae86dd1b11f8e4690d84829', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:60}] to localhost:27017
2018-05-01 16:38:25.065  INFO 18064 --- [cluster-ClusterId{value='5ae86dd1b11f8e4690d84829', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=640395}
2018-05-01 16:38:25.067  INFO 18064 --- [cluster-ClusterId{value='5ae86dd1b11f8e4690d84829', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 16:38:25.441  INFO 18064 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 16:38:25.597  WARN 18064 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 16:38:25.708  INFO 18064 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 16:38:25.720  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 16:38:25.721  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 16:38:25.722  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 16:38:25.723  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 16:38:25.724  INFO 18064 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 16:38:26.026  INFO 18064 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 56950.
2018-05-01 16:38:26.042  INFO 18064 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 16:38:26.058  INFO 18064 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 16:38:26.061  INFO 18064 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 16:38:26.061  INFO 18064 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 16:38:26.069  INFO 18064 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-fc54495b-2f0b-4242-9094-88281bab85dd
2018-05-01 16:38:26.096  INFO 18064 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 16:38:26.133  INFO 18064 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 16:38:26.187  INFO 18064 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @7792ms
2018-05-01 16:38:26.232  INFO 18064 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 16:38:26.246  INFO 18064 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @7851ms
2018-05-01 16:38:26.259  WARN 18064 --- [restartedMain] org.apache.spark.util.Utils              : Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-05-01 16:38:26.266  INFO 18064 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@f42a1a3{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2018-05-01 16:38:26.266  INFO 18064 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4041.
2018-05-01 16:38:26.302  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@52174394{/jobs,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.303  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@76f14a4e{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.303  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@44181c91{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.304  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@765cffe2{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.306  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@744ddb2a{/stages,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.306  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@630551b1{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.307  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2f305012{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.308  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@46bf0446{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.308  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@553f843{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.308  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4365ca3a{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.309  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1018a707{/storage,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.309  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@332e4df6{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.311  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7263abe8{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.311  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@56b19469{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.312  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2ee74398{/environment,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.312  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6ad4716c{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.313  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1b0f3088{/executors,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.313  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@79e5ff6{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.314  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@68d13f64{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.314  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1381b2b7{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.319  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3e909511{/static,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.320  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@92165e5{/,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.321  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@cb24070{/api,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.321  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74b081b1{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.322  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@117d7c18{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.323  INFO 18064 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4041
2018-05-01 16:38:26.407  INFO 18064 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 16:38:26.436  INFO 18064 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56965.
2018-05-01 16:38:26.437  INFO 18064 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:56965
2018-05-01 16:38:26.438  INFO 18064 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 16:38:26.439  INFO 18064 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 56965, None)
2018-05-01 16:38:26.443  INFO 18064 --- [dispatcher-event-loop-0] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:56965 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 56965, None)
2018-05-01 16:38:26.447  INFO 18064 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 56965, None)
2018-05-01 16:38:26.447  INFO 18064 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 56965, None)
2018-05-01 16:38:26.461  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5bdead75{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.511  INFO 18064 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 16:38:26.511  INFO 18064 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 16:38:26.516  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6c7a0628{/SQL,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.517  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@33cf606a{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.518  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@27bca603{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.518  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@262746cf{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:26.520  INFO 18064 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3e537902{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 16:38:27.077  WARN 18064 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 16:38:27.285  INFO 18064 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 16:38:27.884  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 16:38:27.886  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 16:38:27.889  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 16:38:27.890  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 16:38:27.890  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 16:38:27.892  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 16:38:27.892  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 16:38:28.707  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 16:38:28.708  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.709  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:28.709  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:28.710  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 16:38:28.710  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.711  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 16:38:28.711  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.712  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.714  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.715  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 16:38:28.716  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.717  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 16:38:28.717  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.717  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 16:38:28.718  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 16:38:28.718  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.719  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 16:38:28.719  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.719  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.720  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 16:38:28.721  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 16:38:28.721  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.722  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 16:38:28.722  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:28.723  INFO 18064 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:29.187  INFO 18064 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b05d6e4: startup date [Tue May 01 16:38:20 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@54b0b8c1
2018-05-01 16:38:29.257  INFO 18064 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:29.257  INFO 18064 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:29.286  INFO 18064 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 16:38:29.320  INFO 18064 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:29.779  WARN 18064 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 16:38:29.865  WARN 18064 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 16:38:29.866  INFO 18064 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 16:38:29.871  WARN 18064 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 16:38:29.871  INFO 18064 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 16:38:29.954  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 16:38:29.964  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 16:38:29.965  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 16:38:29.969  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 16:38:29.970  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 16:38:29.971  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 16:38:29.974  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 16:38:29.988  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 16:38:29.999  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 16:38:30.016  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=6b05d6e4,type=ConfigurationPropertiesRebinder]
2018-05-01 16:38:30.024  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 16:38:30.400  INFO 18064 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 16:38:30.407  INFO 18064 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 16:38:30.497  INFO 18064 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 16:38:30.498  INFO 18064 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 16:38:30.602  INFO 18064 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 16:38:30.602  INFO 18064 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 16:38:30.897  INFO 18064 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:38:31.013  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 16:38:31.013  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 16:38:31.013  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 16:38:31.014  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 16:38:31.014  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 16:38:31.015  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 16:38:31.015  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 16:38:31.196  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 16:38:31.198  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 16:38:31.201  INFO 18064 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 16:38:31.205  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525181911205 with initial instances count: 1
2018-05-01 16:38:31.228  INFO 18064 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application qqqqqqq with eureka with status UP
2018-05-01 16:38:31.229  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525181911229, current=UP, previous=STARTING]
2018-05-01 16:38:31.232  INFO 18064 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222: registering service...
2018-05-01 16:38:31.279  INFO 18064 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222 - registration status: 204
2018-05-01 16:38:31.300  INFO 18064 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 16:38:31.300  INFO 18064 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 16:38:31.320  INFO 18064 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 16:38:31.337  INFO 18064 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 16:38:31.384 ERROR 18064 --- [restartedMain] o.a.coyote.http11.Http11NioProtocol      : Failed to start end point associated with ProtocolHandler ["http-nio-2222"]

java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method) ~[na:1.8.0_131]
	at sun.nio.ch.Net.bind(Net.java:433) ~[na:1.8.0_131]
	at sun.nio.ch.Net.bind(Net.java:425) ~[na:1.8.0_131]
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223) ~[na:1.8.0_131]
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74) ~[na:1.8.0_131]
	at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:210) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:990) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:635) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1022) [tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.core.StandardService.addConnector(StandardService.java:225) [tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.addPreviouslyRemovedConnectors(TomcatEmbeddedServletContainer.java:250) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.start(TomcatEmbeddedServletContainer.java:193) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:297) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:145) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]

2018-05-01 16:38:31.385 ERROR 18064 --- [restartedMain] o.apache.catalina.core.StandardService   : Failed to start connector [Connector[HTTP/1.1-2222]]

org.apache.catalina.LifecycleException: Failed to start component [Connector[HTTP/1.1-2222]]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:167) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.core.StandardService.addConnector(StandardService.java:225) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.addPreviouslyRemovedConnectors(TomcatEmbeddedServletContainer.java:250) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.start(TomcatEmbeddedServletContainer.java:193) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:297) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:145) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546) [spring-context-4.3.13.RELEASE.jar:4.3.13.RELEASE]
	at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:693) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:360) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) [spring-boot-1.5.9.RELEASE.jar:1.5.9.RELEASE]
	at com.jcombat.profile.ProfileMicroserviceServerApplication.main(ProfileMicroserviceServerApplication.java:12) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49) [spring-boot-devtools-1.5.9.RELEASE.jar:1.5.9.RELEASE]
Caused by: org.apache.catalina.LifecycleException: service.getName(): "Tomcat";  Protocol handler start failed
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1031) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	... 18 common frames omitted
Caused by: java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method) ~[na:1.8.0_131]
	at sun.nio.ch.Net.bind(Net.java:433) ~[na:1.8.0_131]
	at sun.nio.ch.Net.bind(Net.java:425) ~[na:1.8.0_131]
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223) ~[na:1.8.0_131]
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74) ~[na:1.8.0_131]
	at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:210) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.tomcat.util.net.AbstractEndpoint.start(AbstractEndpoint.java:990) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.coyote.AbstractProtocol.start(AbstractProtocol.java:635) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	at org.apache.catalina.connector.Connector.startInternal(Connector.java:1022) ~[tomcat-embed-core-8.5.23.jar:8.5.23]
	... 19 common frames omitted

2018-05-01 16:38:31.392  INFO 18064 --- [restartedMain] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2018-05-01 16:38:31.401  INFO 18064 --- [restartedMain] utoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2018-05-01 16:38:31.407 ERROR 18064 --- [restartedMain] o.s.b.d.LoggingFailureAnalysisReporter   : 

***************************
APPLICATION FAILED TO START
***************************

Description:

The Tomcat connector configured to listen on port 2222 failed to start. The port may already be in use or the connector may be misconfigured.

Action:

Verify the connector's configuration, identify and stop any process that's listening on port 2222, or configure this application to listen on another port.

2018-05-01 16:38:31.408  INFO 18064 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Closing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6b05d6e4: startup date [Tue May 01 16:38:20 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@54b0b8c1
2018-05-01 16:38:31.408  INFO 18064 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Unregistering application qqqqqqq with eureka with status DOWN
2018-05-01 16:38:31.408  WARN 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525181911408, current=DOWN, previous=UP]
2018-05-01 16:38:31.410  INFO 18064 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222: registering service...
2018-05-01 16:38:31.410  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
2018-05-01 16:38:31.410  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Unregistering ...
2018-05-01 16:38:31.415  INFO 18064 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222 - registration status: 204
2018-05-01 16:38:31.416  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_QQQQQQQ/ari:qqqqqqq:2222 - deregister  status: 200
2018-05-01 16:38:31.420  INFO 18064 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Completed shut down of DiscoveryClient
2018-05-01 16:38:31.422  INFO 18064 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 2147483647
2018-05-01 16:38:31.423  INFO 18064 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Stopping beans in phase 0
2018-05-01 16:38:31.427  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown
2018-05-01 16:38:31.427  INFO 18064 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans
2018-05-01 16:38:31.435  INFO 18064 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Stopped Spark@f42a1a3{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2018-05-01 16:38:31.437  INFO 18064 --- [restartedMain] org.apache.spark.ui.SparkUI              : Stopped Spark web UI at http://172.21.241.193:4041
2018-05-01 16:38:31.445  INFO 18064 --- [dispatcher-event-loop-7] o.a.s.MapOutputTrackerMasterEndpoint     : MapOutputTrackerMasterEndpoint stopped!
2018-05-01 16:38:31.452  INFO 18064 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore cleared
2018-05-01 16:38:31.452  INFO 18064 --- [restartedMain] org.apache.spark.storage.BlockManager    : BlockManager stopped
2018-05-01 16:38:31.457  INFO 18064 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : BlockManagerMaster stopped
2018-05-01 16:38:31.460  INFO 18064 --- [dispatcher-event-loop-4] rdinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2018-05-01 16:38:31.463  INFO 18064 --- [restartedMain] org.apache.spark.SparkContext            : Successfully stopped SparkContext
2018-05-01 16:38:31.466  INFO 18064 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:31.475  INFO 18064 --- [pool-7-thread-1] o.apache.spark.util.ShutdownHookManager  : Shutdown hook called
2018-05-01 16:38:31.476  INFO 18064 --- [pool-7-thread-1] o.apache.spark.util.ShutdownHookManager  : Deleting directory C:\Users\memojja\AppData\Local\Temp\spark-f27db239-928a-40c4-a8cc-9072d99b0e7e
2018-05-01 16:38:50.243  INFO 7440 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 16:38:50.254  INFO 7440 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@19cf7a59: startup date [Tue May 01 16:38:50 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@62d09928
2018-05-01 16:38:51.776  INFO 7440 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 16:38:51.800  INFO 7440 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 16:38:51.808  INFO 7440 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 16:38:52.044  INFO 7440 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 16:38:52.075  INFO 7440 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 16:38:52.209  INFO 7440 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$e1d47911] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 16:38:52.249  INFO 7440 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$fdee7c0e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 16:38:52.714  INFO 7440 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 16:38:52.723  INFO 7440 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 16:38:52.724  INFO 7440 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 16:38:52.778  INFO 7440 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 16:38:52.778  INFO 7440 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2524 ms
2018-05-01 16:38:53.059  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 16:38:53.061  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 16:38:53.066  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 16:38:53.067  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 16:38:53.067  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 16:38:53.067  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 16:38:53.068  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 16:38:53.068  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 16:38:53.068  INFO 7440 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 16:38:53.426  INFO 7440 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:53.998  INFO 7440 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 16:38:54.587  INFO 7440 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 16:38:54.588  INFO 7440 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 16:38:54.728  INFO 7440 --- [cluster-ClusterId{value='5ae86deeb11f8e1d10c3be6e', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:61}] to localhost:27017
2018-05-01 16:38:54.732  INFO 7440 --- [cluster-ClusterId{value='5ae86deeb11f8e1d10c3be6e', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=953679}
2018-05-01 16:38:54.734  INFO 7440 --- [cluster-ClusterId{value='5ae86deeb11f8e1d10c3be6e', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 16:38:55.323  INFO 7440 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 16:38:55.502  WARN 7440 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 16:38:55.637  INFO 7440 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 16:38:55.650  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 16:38:55.651  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 16:38:55.651  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 16:38:55.653  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 16:38:55.653  INFO 7440 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 16:38:55.994  INFO 7440 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 57024.
2018-05-01 16:38:56.027  INFO 7440 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 16:38:56.042  INFO 7440 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 16:38:56.045  INFO 7440 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 16:38:56.045  INFO 7440 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 16:38:56.052  INFO 7440 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-7ed48ef5-05ab-487c-af86-f377fb3fb66b
2018-05-01 16:38:56.072  INFO 7440 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 16:38:56.122  INFO 7440 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 16:38:56.184  INFO 7440 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8621ms
2018-05-01 16:38:56.232  INFO 7440 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 16:38:56.243  INFO 7440 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8680ms
2018-05-01 16:38:56.253  WARN 7440 --- [restartedMain] org.apache.spark.util.Utils              : Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-05-01 16:38:56.260  INFO 7440 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@4340a009{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2018-05-01 16:38:56.260  INFO 7440 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4041.
2018-05-01 16:38:56.279  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@21d7bcb2{/jobs,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.280  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2f9ecd44{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.280  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5dfe92c1{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.282  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1874ba5c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.283  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@502bb12c{/stages,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.283  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3d26a894{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.284  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2b7fb60d{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.285  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3f066941{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.285  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@64221815{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.285  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7ac268bd{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.286  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@585a1015{/storage,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.286  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@558860c1{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.287  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1361f19d{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.288  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@a1313d9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.288  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@115466cd{/environment,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.288  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4034fabf{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.289  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@537f5349{/executors,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.289  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3beacb88{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.290  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@a0ccfab{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.290  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5a1be74a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.294  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@14c8d493{/static,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.295  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3326ecd9{/,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.296  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@132c0ef5{/api,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.297  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@c32a5d7{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.297  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@389cff32{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.299  INFO 7440 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4041
2018-05-01 16:38:56.398  INFO 7440 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 16:38:56.432  INFO 7440 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57037.
2018-05-01 16:38:56.433  INFO 7440 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:57037
2018-05-01 16:38:56.434  INFO 7440 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 16:38:56.436  INFO 7440 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 57037, None)
2018-05-01 16:38:56.439  INFO 7440 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:57037 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 57037, None)
2018-05-01 16:38:56.444  INFO 7440 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 57037, None)
2018-05-01 16:38:56.445  INFO 7440 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 57037, None)
2018-05-01 16:38:56.455  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3da98e35{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.501  INFO 7440 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 16:38:56.501  INFO 7440 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 16:38:56.506  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@157c9b9d{/SQL,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.507  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@54b54f93{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.509  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2e3957c9{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.510  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@72a99a5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 16:38:56.513  INFO 7440 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1e9d5397{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 16:38:57.021  WARN 7440 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 16:38:57.228  INFO 7440 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 16:38:57.865  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 16:38:57.866  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 16:38:57.869  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 16:38:57.871  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 16:38:57.872  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 16:38:57.874  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 16:38:57.874  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 16:38:58.704  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.706  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 16:38:58.706  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 16:38:58.706  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.707  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.707  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:58.708  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.708  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.709  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.710  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:58.711  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.711  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 16:38:58.712  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 16:38:58.712  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.713  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 16:38:58.714  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 16:38:58.714  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.715  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 16:38:58.715  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.716  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 16:38:58.716  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 16:38:58.716  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 16:38:58.716  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.717  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 16:38:58.717  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 16:38:58.719  INFO 7440 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 16:38:59.135  INFO 7440 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@19cf7a59: startup date [Tue May 01 16:38:50 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@62d09928
2018-05-01 16:38:59.194  INFO 7440 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:59.194  INFO 7440 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:59.215  INFO 7440 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 16:38:59.243  INFO 7440 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 16:38:59.708  WARN 7440 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 16:38:59.793  WARN 7440 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 16:38:59.793  INFO 7440 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 16:38:59.799  WARN 7440 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 16:38:59.799  INFO 7440 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 16:38:59.886  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 16:38:59.895  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 16:38:59.896  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 16:38:59.899  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 16:38:59.899  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 16:38:59.900  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 16:38:59.904  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 16:38:59.919  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 16:38:59.930  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 16:38:59.944  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=19cf7a59,type=ConfigurationPropertiesRebinder]
2018-05-01 16:38:59.952  INFO 7440 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 16:39:00.260  INFO 7440 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 16:39:00.267  INFO 7440 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 16:39:00.358  INFO 7440 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 16:39:00.358  INFO 7440 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 16:39:00.473  INFO 7440 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 16:39:00.473  INFO 7440 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 16:39:00.820  INFO 7440 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:39:00.934  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 16:39:00.934  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 16:39:00.934  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 16:39:00.935  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 16:39:00.935  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 16:39:00.935  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 16:39:00.935  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 16:39:01.097  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 16:39:01.098  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 16:39:01.100  INFO 7440 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 16:39:01.104  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525181941103 with initial instances count: 1
2018-05-01 16:39:01.125  INFO 7440 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service with eureka with status UP
2018-05-01 16:39:01.126  INFO 7440 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525181941126, current=UP, previous=STARTING]
2018-05-01 16:39:01.128  INFO 7440 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE/ari:recomendation-service:3333: registering service...
2018-05-01 16:39:01.170  INFO 7440 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE/ari:recomendation-service:3333 - registration status: 204
2018-05-01 16:39:01.182  INFO 7440 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 16:39:01.183  INFO 7440 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 16:39:01.197  INFO 7440 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 16:39:01.211  INFO 7440 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 16:39:01.268  INFO 7440 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 16:39:01.268  INFO 7440 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 16:39:01.273  INFO 7440 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.515 seconds (JVM running for 13.71)
2018-05-01 16:39:01.637  INFO 7440 --- [RMI TCP Connection(12)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:62}] to localhost:27017
2018-05-01 16:44:00.938  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:49:00.940  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:54:00.942  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 16:59:00.943  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:04:00.944  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:09:00.946  INFO 7440 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:13:01.027  INFO 12612 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:13:01.045  INFO 12612 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@31ac79e9: startup date [Tue May 01 17:13:01 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@335bc18b
2018-05-01 17:13:03.544  INFO 12612 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:13:03.572  INFO 12612 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:13:03.583  INFO 12612 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:13:03.910  INFO 12612 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:13:03.954  INFO 12612 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:13:04.138  INFO 12612 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$6662db67] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:13:04.206  INFO 12612 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$827cde64] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:13:04.901  INFO 12612 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:13:04.916  INFO 12612 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:13:04.917  INFO 12612 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:13:05.022  INFO 12612 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:13:05.024  INFO 12612 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3979 ms
2018-05-01 17:13:05.522  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:13:05.524  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:13:05.574  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:13:05.575  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:13:05.575  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:13:05.575  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:13:05.597  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:13:05.598  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:13:05.598  INFO 12612 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:13:06.138  INFO 12612 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:13:07.197  INFO 12612 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:13:07.988  INFO 12612 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:13:07.989  INFO 12612 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:13:08.096  INFO 12612 --- [cluster-ClusterId{value='5ae875f3b11f8e31441c7ade', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:68}] to localhost:27017
2018-05-01 17:13:08.100  INFO 12612 --- [cluster-ClusterId{value='5ae875f3b11f8e31441c7ade', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=778667}
2018-05-01 17:13:08.102  INFO 12612 --- [cluster-ClusterId{value='5ae875f3b11f8e31441c7ade', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:13:08.669  INFO 12612 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:13:08.978  WARN 12612 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:13:09.173  INFO 12612 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:13:09.199  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:13:09.203  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:13:09.206  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:13:09.209  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:13:09.211  INFO 12612 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:13:09.743  INFO 12612 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 57604.
2018-05-01 17:13:09.756  INFO 12612 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:13:09.780  INFO 12612 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:13:09.784  INFO 12612 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:13:09.784  INFO 12612 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:13:09.792  INFO 12612 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-645967dd-9191-465f-8d56-6102977d9347
2018-05-01 17:13:09.820  INFO 12612 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:13:09.862  INFO 12612 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:13:09.929  INFO 12612 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @13732ms
2018-05-01 17:13:10.025  INFO 12612 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:13:10.041  INFO 12612 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @13843ms
2018-05-01 17:13:10.084  INFO 12612 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@17e5e4a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:13:10.084  INFO 12612 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:13:10.110  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@53bac889{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.111  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4f8a86a0{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.111  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@71c1ae71{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.112  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74937371{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.112  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@48782d79{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.113  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5d99fab8{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.114  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@33f4d927{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.115  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3da7b1b3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.116  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5c5d6fc9{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.116  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@fe8e20c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.117  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5bfe5da5{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.117  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@b9775ce{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.118  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1cdf3c72{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.120  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@573336d6{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.120  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2d708cc9{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.121  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@548142c2{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.122  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7dbf94c8{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.123  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b629e1b{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.123  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3c4e5f60{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.124  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2c8e694b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.129  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b044f29{/static,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.130  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@f567d33{/,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.131  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7f5ae08d{/api,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.131  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@13eb647b{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.132  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@daea1a9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.134  INFO 12612 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:13:10.240  INFO 12612 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:13:10.271  INFO 12612 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57619.
2018-05-01 17:13:10.272  INFO 12612 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:57619
2018-05-01 17:13:10.274  INFO 12612 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:13:10.276  INFO 12612 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 57619, None)
2018-05-01 17:13:10.279  INFO 12612 --- [dispatcher-event-loop-6] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:57619 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 57619, None)
2018-05-01 17:13:10.284  INFO 12612 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 57619, None)
2018-05-01 17:13:10.285  INFO 12612 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 57619, None)
2018-05-01 17:13:10.303  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@201b2252{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.360  INFO 12612 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:13:10.360  INFO 12612 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:13:10.368  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1f88243a{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.368  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4197fe1{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.369  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b8d216b{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.369  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@38183466{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.372  INFO 12612 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@281e5c6b{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:13:10.975  WARN 12612 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:13:11.288  INFO 12612 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:13:12.236  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:13:12.240  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:13:12.245  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:13:12.246  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:13:12.248  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:13:12.251  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:13:12.251  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:13:13.452  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:13:13.453  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.456  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:13:13.457  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:13:13.458  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.459  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.462  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.462  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.463  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.464  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:13:13.467  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:13:13.468  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.470  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:13:13.473  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:13:13.474  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.476  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:13:13.479  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:13:13.480  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.481  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:13:13.492  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:13:13.500  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:13:13.501  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:13:13.501  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.502  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:13:13.502  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:13.503  INFO 12612 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:13:14.239  INFO 12612 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@31ac79e9: startup date [Tue May 01 17:13:01 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@335bc18b
2018-05-01 17:13:14.343  INFO 12612 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:13:14.344  INFO 12612 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:13:14.368  INFO 12612 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:13:14.407  INFO 12612 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:13:14.955  INFO 12612 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2018-05-01 17:13:15.046  WARN 12612 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:13:15.046  INFO 12612 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:13:15.055  WARN 12612 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:13:15.055  INFO 12612 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:13:15.160  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:13:15.173  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:13:15.175  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:13:15.180  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:13:15.181  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:13:15.181  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:13:15.186  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:13:15.203  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:13:15.218  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:13:15.235  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=31ac79e9,type=ConfigurationPropertiesRebinder]
2018-05-01 17:13:15.244  INFO 12612 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:13:15.596  INFO 12612 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:13:15.606  INFO 12612 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:13:15.718  INFO 12612 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:13:15.719  INFO 12612 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:13:15.867  INFO 12612 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:13:15.868  INFO 12612 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:13:16.240  INFO 12612 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:13:16.402  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:13:16.402  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:13:16.402  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:13:16.402  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:13:16.403  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:13:16.403  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:13:16.403  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:13:16.621  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:13:16.625  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:13:16.628  INFO 12612 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:13:16.631  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525183996630 with initial instances count: 3
2018-05-01 17:13:16.654  INFO 12612 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service with eureka with status UP
2018-05-01 17:13:16.655  INFO 12612 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525183996655, current=UP, previous=STARTING]
2018-05-01 17:13:16.657  INFO 12612 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE/ari:recomendation-service:3333: registering service...
2018-05-01 17:13:16.720  INFO 12612 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE/ari:recomendation-service:3333 - registration status: 204
2018-05-01 17:13:16.735  INFO 12612 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:13:16.735  INFO 12612 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:13:16.753  INFO 12612 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:13:16.776  INFO 12612 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:13:16.850  INFO 12612 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:13:16.852  INFO 12612 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:13:16.859  INFO 12612 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 18.795 seconds (JVM running for 20.662)
2018-05-01 17:13:17.004  INFO 12612 --- [RMI TCP Connection(16)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:70}] to localhost:27017
2018-05-01 17:13:25.063  INFO 12612 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-01 17:13:25.063  INFO 12612 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-01 17:13:25.094  INFO 12612 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 31 ms
2018-05-01 17:13:56.823  INFO 8764 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:13:56.838  INFO 8764 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@63c0092a: startup date [Tue May 01 17:13:56 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@38ad47a
2018-05-01 17:13:58.774  INFO 8764 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:13:58.802  INFO 8764 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:13:58.812  INFO 8764 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:13:59.110  INFO 8764 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:13:59.144  INFO 8764 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:13:59.299  INFO 8764 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d890893e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:13:59.345  INFO 8764 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$f4aa8c3b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:13:59.903  INFO 8764 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:13:59.912  INFO 8764 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:13:59.913  INFO 8764 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:13:59.999  INFO 8764 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:13:59.999  INFO 8764 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3161 ms
2018-05-01 17:14:00.390  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:14:00.391  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:14:00.396  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:14:00.396  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:14:00.396  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:14:00.396  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:14:00.397  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:14:00.398  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:14:00.398  INFO 8764 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:14:00.790  INFO 8764 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:14:01.482  INFO 8764 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:14:02.137  INFO 8764 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:14:02.138  INFO 8764 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:14:02.201  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:73}] to localhost:27017
2018-05-01 17:14:02.206  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=672395}
2018-05-01 17:14:02.208  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:14:02.661  INFO 8764 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:14:02.898  WARN 8764 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:14:03.012  INFO 8764 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:14:03.025  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:14:03.026  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:14:03.026  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:14:03.028  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:14:03.029  INFO 8764 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:14:03.370  INFO 8764 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 57743.
2018-05-01 17:14:03.383  INFO 8764 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:14:03.400  INFO 8764 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:14:03.403  INFO 8764 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:14:03.404  INFO 8764 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:14:03.410  INFO 8764 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-5f8cf114-0c47-4095-ba57-d9ab5316b369
2018-05-01 17:14:03.438  INFO 8764 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:14:03.477  INFO 8764 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:14:03.536  INFO 8764 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @9796ms
2018-05-01 17:14:03.587  INFO 8764 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:14:03.600  INFO 8764 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @9860ms
2018-05-01 17:14:03.618  INFO 8764 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@d726fe2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:14:03.619  INFO 8764 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:14:03.641  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2fd3fade{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.642  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2d46da4e{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.643  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@66cbec08{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.644  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@67726af3{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.645  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2fed91fb{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.646  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4878900c{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.647  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@56e96418{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.648  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@66e55da3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.649  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4ada8456{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.649  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74a6eaf9{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.650  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@44a17250{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.650  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2adcfe09{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.651  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@22bba45{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.652  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@57bb9253{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.653  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7eaeb805{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.654  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3fc13601{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.654  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@53f4bc42{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.654  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@49e2b800{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.655  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6d8f261b{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.655  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6142f5de{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.659  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@121df492{/static,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.660  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6a95c00c{/,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.662  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@357f6e60{/api,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.662  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5c1b4f42{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.663  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@14b54d2{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.664  INFO 8764 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:14:03.748  INFO 8764 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:14:03.776  INFO 8764 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57756.
2018-05-01 17:14:03.777  INFO 8764 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:57756
2018-05-01 17:14:03.778  INFO 8764 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:14:03.780  INFO 8764 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 57756, None)
2018-05-01 17:14:03.783  INFO 8764 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:57756 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 57756, None)
2018-05-01 17:14:03.789  INFO 8764 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 57756, None)
2018-05-01 17:14:03.789  INFO 8764 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 57756, None)
2018-05-01 17:14:03.807  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7d68b8e1{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.857  INFO 8764 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:14:03.858  INFO 8764 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:14:03.863  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@bc3bab8{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.863  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@667cb762{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.864  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@79da3990{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.864  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3e108e56{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:14:03.866  INFO 8764 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@364afa97{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:14:04.480  WARN 8764 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:14:04.759  INFO 8764 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:14:05.642  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:14:05.645  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:14:05.649  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:14:05.650  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:14:05.651  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:14:05.654  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:14:05.654  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:14:06.631  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:14:06.632  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:14:06.634  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:14:06.634  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:14:06.634  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:14:06.636  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:14:06.638  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.638  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.639  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:14:06.639  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.640  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.641  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.641  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:14:06.642  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:14:06.642  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.643  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.644  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:14:06.645  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:14:06.645  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.645  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:14:06.645  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.646  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:14:06.646  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:14:06.646  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.647  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:06.647  INFO 8764 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:14:07.098  INFO 8764 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@63c0092a: startup date [Tue May 01 17:13:56 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@38ad47a
2018-05-01 17:14:07.179  INFO 8764 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:14:07.179  INFO 8764 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:14:07.221  INFO 8764 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:14:07.257  INFO 8764 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:14:07.745  WARN 8764 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:14:07.866  WARN 8764 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:14:07.867  INFO 8764 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:14:07.880  WARN 8764 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:14:07.880  INFO 8764 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:14:08.001  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:14:08.012  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:14:08.012  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:14:08.016  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:14:08.017  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:14:08.017  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:14:08.023  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:14:08.045  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:14:08.058  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:14:08.072  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=63c0092a,type=ConfigurationPropertiesRebinder]
2018-05-01 17:14:08.077  INFO 8764 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:14:08.398  INFO 8764 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:14:08.405  INFO 8764 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:14:08.501  INFO 8764 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:14:08.502  INFO 8764 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:14:08.602  INFO 8764 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:14:08.603  INFO 8764 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:14:08.881  INFO 8764 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:14:08.995  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:14:08.996  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:14:08.996  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:14:08.996  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:14:08.997  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:14:08.997  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:14:08.997  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:14:09.174  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:14:09.176  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:14:09.178  INFO 8764 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:14:09.181  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525184049181 with initial instances count: 3
2018-05-01 17:14:09.201  INFO 8764 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:14:09.204  INFO 8764 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525184049203, current=UP, previous=STARTING]
2018-05-01 17:14:09.205  INFO 8764 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:14:09.243  INFO 8764 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:14:09.258  INFO 8764 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:14:09.258  INFO 8764 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:14:09.273  INFO 8764 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:14:09.287  INFO 8764 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:14:09.344  INFO 8764 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:14:09.345  INFO 8764 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:14:09.350  INFO 8764 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 14.386 seconds (JVM running for 15.61)
2018-05-01 17:14:09.639  INFO 8764 --- [RMI TCP Connection(10)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:75}] to localhost:27017
2018-05-01 17:14:12.447  INFO 8764 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-01 17:14:12.448  INFO 8764 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-01 17:14:12.482  INFO 8764 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 33 ms
2018-05-01 17:15:53.236  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Exception in monitor thread while connecting to server localhost:27017

com.mongodb.MongoSocketOpenException: Exception opening socket
	at com.mongodb.connection.SocketStream.open(SocketStream.java:63) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.InternalStreamConnection.open(InternalStreamConnection.java:115) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:127) ~[mongodb-driver-core-3.4.3.jar:na]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_131]
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at com.mongodb.connection.SocketStreamHelper.initialize(SocketStreamHelper.java:57) ~[mongodb-driver-core-3.4.3.jar:na]
	at com.mongodb.connection.SocketStream.open(SocketStream.java:58) ~[mongodb-driver-core-3.4.3.jar:na]
	... 3 common frames omitted

2018-05-01 17:16:03.239  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:2}] to localhost:27017
2018-05-01 17:16:03.241  INFO 8764 --- [cluster-ClusterId{value='5ae8762ab11f8e223ccecfac', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=465778}
2018-05-01 17:19:09.000  INFO 8764 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:24:09.001  INFO 8764 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:25:55.290  INFO 15012 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:25:55.302  INFO 15012 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@63c0092a: startup date [Tue May 01 17:25:55 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@38ad47a
2018-05-01 17:25:56.907  INFO 15012 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:25:56.930  INFO 15012 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:25:56.938  INFO 15012 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:25:57.172  INFO 15012 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:25:57.201  INFO 15012 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:25:57.328  INFO 15012 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$d890893e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:25:57.374  INFO 15012 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$f4aa8c3b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:25:57.890  INFO 15012 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:25:57.902  INFO 15012 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:25:57.903  INFO 15012 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:25:57.963  INFO 15012 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:25:57.964  INFO 15012 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2662 ms
2018-05-01 17:25:58.280  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:25:58.282  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:25:58.288  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:25:58.288  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:25:58.288  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:25:58.288  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:25:58.289  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:25:58.290  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:25:58.290  INFO 15012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:25:58.655  INFO 15012 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:25:59.252  INFO 15012 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:25:59.825  INFO 15012 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:25:59.825  INFO 15012 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:25:59.874  INFO 15012 --- [cluster-ClusterId{value='5ae878f7b11f8e3aa467c390', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:6}] to localhost:27017
2018-05-01 17:25:59.877  INFO 15012 --- [cluster-ClusterId{value='5ae878f7b11f8e3aa467c390', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=625778}
2018-05-01 17:25:59.878  INFO 15012 --- [cluster-ClusterId{value='5ae878f7b11f8e3aa467c390', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:26:00.246  INFO 15012 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:26:00.395  WARN 15012 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:26:00.514  INFO 15012 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:26:00.528  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:26:00.529  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:26:00.530  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:26:00.532  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:26:00.532  INFO 15012 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:26:00.838  INFO 15012 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 58040.
2018-05-01 17:26:00.851  INFO 15012 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:26:00.867  INFO 15012 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:26:00.869  INFO 15012 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:26:00.870  INFO 15012 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:26:00.876  INFO 15012 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-190dc532-83c2-4e0f-ad47-2a5a388db107
2018-05-01 17:26:00.898  INFO 15012 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:26:00.932  INFO 15012 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:26:00.998  INFO 15012 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8185ms
2018-05-01 17:26:01.052  INFO 15012 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:26:01.065  INFO 15012 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8252ms
2018-05-01 17:26:01.081  INFO 15012 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@7bcca24{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:26:01.082  INFO 15012 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:26:01.102  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1ae7cf7a{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.103  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2032c3cd{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.103  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7bb13f69{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.104  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4ada8456{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.104  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74a6eaf9{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.105  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@44a17250{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.106  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2adcfe09{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.107  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@57bb9253{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.107  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7eaeb805{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.108  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3fc13601{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.108  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@53f4bc42{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.109  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@49e2b800{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.109  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6d8f261b{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.111  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6142f5de{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.112  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@121df492{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.112  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3a231cbc{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.112  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@74cf71a3{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.113  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@55f67994{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.113  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@e8f35a1{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.114  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@d4dcc04{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.118  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b396769{/static,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.118  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2b9ecfae{/,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.119  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6de1fe2d{/api,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.119  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@17b822c3{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.119  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@61d345fa{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.121  INFO 15012 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:26:01.197  INFO 15012 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:26:01.221  INFO 15012 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58053.
2018-05-01 17:26:01.222  INFO 15012 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:58053
2018-05-01 17:26:01.223  INFO 15012 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:26:01.225  INFO 15012 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 58053, None)
2018-05-01 17:26:01.228  INFO 15012 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:58053 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 58053, None)
2018-05-01 17:26:01.231  INFO 15012 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 58053, None)
2018-05-01 17:26:01.232  INFO 15012 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 58053, None)
2018-05-01 17:26:01.245  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@566ff32c{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.312  INFO 15012 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:26:01.312  INFO 15012 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:26:01.316  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@51b313c5{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.317  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@73f54035{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.317  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@760a646e{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.317  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7550714e{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.318  INFO 15012 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6d12c6f3{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:26:01.803  WARN 15012 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:26:01.997  INFO 15012 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:26:02.589  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:26:02.591  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:26:02.594  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:26:02.595  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:26:02.596  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:26:02.598  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:26:02.598  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:26:03.416  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:26:03.418  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.420  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:26:03.421  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:26:03.421  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.422  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.423  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.424  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.424  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:26:03.425  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.426  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:26:03.426  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:26:03.427  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:26:03.427  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.428  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:26:03.428  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.429  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:26:03.429  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:26:03.430  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.431  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:26:03.431  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:26:03.431  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.431  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.432  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:26:03.432  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:26:03.433  INFO 15012 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:26:03.856  INFO 15012 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@63c0092a: startup date [Tue May 01 17:25:55 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@38ad47a
2018-05-01 17:26:03.927  INFO 15012 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:26:03.927  INFO 15012 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:26:03.964  INFO 15012 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:26:03.994  INFO 15012 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:26:04.437  WARN 15012 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:26:04.512  WARN 15012 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:26:04.512  INFO 15012 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:26:04.518  WARN 15012 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:26:04.518  INFO 15012 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:26:04.606  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:26:04.618  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:26:04.618  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:26:04.622  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:26:04.623  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:26:04.623  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:26:04.627  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:26:04.642  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:26:04.653  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:26:04.669  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=63c0092a,type=ConfigurationPropertiesRebinder]
2018-05-01 17:26:04.676  INFO 15012 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:26:05.006  INFO 15012 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:26:05.015  INFO 15012 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:26:05.107  INFO 15012 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:26:05.108  INFO 15012 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:26:05.227  INFO 15012 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:26:05.227  INFO 15012 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:26:05.500  INFO 15012 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:26:05.607  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:26:05.607  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:26:05.607  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:26:05.607  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:26:05.609  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:26:05.609  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:26:05.609  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:26:05.770  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:26:05.773  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:26:05.776  INFO 15012 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:26:05.779  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525184765779 with initial instances count: 6
2018-05-01 17:26:05.799  INFO 15012 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:26:05.800  INFO 15012 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525184765800, current=UP, previous=STARTING]
2018-05-01 17:26:05.802  INFO 15012 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:26:05.844  INFO 15012 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:26:05.859  INFO 15012 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:26:05.859  INFO 15012 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:26:05.875  INFO 15012 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:26:05.892  INFO 15012 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:26:05.952  INFO 15012 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:26:05.953  INFO 15012 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:26:05.958  INFO 15012 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.026 seconds (JVM running for 13.145)
2018-05-01 17:26:06.351  INFO 15012 --- [RMI TCP Connection(8)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:7}] to localhost:27017
2018-05-01 17:31:05.611  INFO 15012 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:32:42.459  INFO 6088 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:32:42.492  INFO 6088 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@33caa67f: startup date [Tue May 01 17:32:42 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@7e14480a
2018-05-01 17:32:44.075  INFO 6088 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:32:44.099  INFO 6088 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:32:44.106  INFO 6088 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:32:44.323  INFO 6088 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:32:44.353  INFO 6088 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:32:44.462  INFO 6088 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$b3783e11] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:32:44.505  INFO 6088 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$cf92410e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:32:44.953  INFO 6088 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:32:44.963  INFO 6088 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:32:44.964  INFO 6088 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:32:45.018  INFO 6088 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:32:45.018  INFO 6088 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2527 ms
2018-05-01 17:32:45.294  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:32:45.296  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:32:45.301  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:32:45.301  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:32:45.301  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:32:45.301  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:32:45.302  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:32:45.303  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:32:45.303  INFO 6088 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:32:45.639  INFO 6088 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:32:46.284  INFO 6088 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:32:46.963  INFO 6088 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:32:46.964  INFO 6088 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:32:47.025  INFO 6088 --- [cluster-ClusterId{value='5ae87a8eb11f8e17c808bb2c', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:10}] to localhost:27017
2018-05-01 17:32:47.028  INFO 6088 --- [cluster-ClusterId{value='5ae87a8eb11f8e17c808bb2c', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=571655}
2018-05-01 17:32:47.030  INFO 6088 --- [cluster-ClusterId{value='5ae87a8eb11f8e17c808bb2c', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:32:47.383  INFO 6088 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:32:47.540  WARN 6088 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:32:47.640  INFO 6088 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:32:47.654  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:32:47.655  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:32:47.656  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:32:47.657  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:32:47.658  INFO 6088 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:32:47.957  INFO 6088 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 58220.
2018-05-01 17:32:47.970  INFO 6088 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:32:47.988  INFO 6088 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:32:47.991  INFO 6088 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:32:47.991  INFO 6088 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:32:47.998  INFO 6088 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-2f0f458b-6edf-494e-a9f1-91a65a53d8bf
2018-05-01 17:32:48.022  INFO 6088 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:32:48.053  INFO 6088 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:32:48.109  INFO 6088 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8136ms
2018-05-01 17:32:48.156  INFO 6088 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:32:48.168  INFO 6088 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8195ms
2018-05-01 17:32:48.187  INFO 6088 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@2d702d9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:32:48.188  INFO 6088 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:32:48.205  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@754a0ed{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.205  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4f11dc0e{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.206  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1990727b{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.206  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4dad37d0{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.207  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2656ef73{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.208  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@30239e5e{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.208  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@52e5e4a6{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.210  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@38a0e878{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.210  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@79023539{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.211  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6cccefbe{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.211  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7b653709{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.212  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@22e929ac{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.212  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@50fd9fdb{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.213  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@ec59c1d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.214  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@21747226{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.214  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3525f069{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.215  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@73e511a7{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.215  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b66b1d6{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.216  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5474199f{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.216  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2e35f62b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.220  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6f44301a{/static,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.221  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2b764cc{/,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.222  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1d9d214b{/api,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.222  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@333228c8{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.222  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@58717e98{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.224  INFO 6088 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:32:48.298  INFO 6088 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:32:48.321  INFO 6088 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58233.
2018-05-01 17:32:48.321  INFO 6088 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:58233
2018-05-01 17:32:48.323  INFO 6088 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:32:48.324  INFO 6088 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 58233, None)
2018-05-01 17:32:48.327  INFO 6088 --- [dispatcher-event-loop-1] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:58233 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 58233, None)
2018-05-01 17:32:48.330  INFO 6088 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 58233, None)
2018-05-01 17:32:48.330  INFO 6088 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 58233, None)
2018-05-01 17:32:48.341  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1f3d0894{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.406  INFO 6088 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:32:48.406  INFO 6088 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:32:48.413  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4bc05f1d{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.414  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5467a4c4{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.415  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@533b8586{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.415  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@590658fe{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.416  INFO 6088 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5d51a7a4{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:32:48.905  WARN 6088 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:32:49.104  INFO 6088 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:32:49.695  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.List<com.jcombat.profile.model.Movie> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:32:49.698  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:32:49.702  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:32:49.703  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:32:49.703  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:32:49.705  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:32:49.706  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:32:50.525  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.526  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.528  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.528  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:32:50.529  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:32:50.529  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.531  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:32:50.531  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:32:50.532  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:32:50.532  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.534  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:32:50.535  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:32:50.536  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:32:50.536  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.536  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.537  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:32:50.538  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:32:50.538  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.539  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:32:50.539  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:32:50.539  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:32:50.540  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.540  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.540  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:32:50.540  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.541  INFO 6088 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:32:50.964  INFO 6088 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@33caa67f: startup date [Tue May 01 17:32:42 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@7e14480a
2018-05-01 17:32:51.033  INFO 6088 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:32:51.033  INFO 6088 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:32:51.055  INFO 6088 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:32:51.098  INFO 6088 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:32:51.542  WARN 6088 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:32:51.617  WARN 6088 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:32:51.617  INFO 6088 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:32:51.622  WARN 6088 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:32:51.622  INFO 6088 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:32:51.703  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:32:51.712  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:32:51.712  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:32:51.715  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:32:51.716  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:32:51.716  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:32:51.719  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:32:51.733  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:32:51.744  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:32:51.758  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=33caa67f,type=ConfigurationPropertiesRebinder]
2018-05-01 17:32:51.765  INFO 6088 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:32:52.110  INFO 6088 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:32:52.117  INFO 6088 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:32:52.226  INFO 6088 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:32:52.226  INFO 6088 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:32:52.388  INFO 6088 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:32:52.389  INFO 6088 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:32:52.693  INFO 6088 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:32:52.821  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:32:52.821  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:32:52.821  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:32:52.821  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:32:52.822  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:32:52.822  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:32:52.822  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:32:53.007  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:32:53.009  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:32:53.013  INFO 6088 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:32:53.017  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525185173017 with initial instances count: 6
2018-05-01 17:32:53.043  INFO 6088 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:32:53.045  INFO 6088 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525185173045, current=UP, previous=STARTING]
2018-05-01 17:32:53.047  INFO 6088 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:32:53.093  INFO 6088 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:32:53.107  INFO 6088 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:32:53.108  INFO 6088 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:32:53.126  INFO 6088 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:32:53.144  INFO 6088 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:32:53.207  INFO 6088 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:32:53.209  INFO 6088 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:32:53.215  INFO 6088 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.287 seconds (JVM running for 13.242)
2018-05-01 17:32:53.447  INFO 6088 --- [RMI TCP Connection(10)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:11}] to localhost:27017
2018-05-01 17:35:33.537  INFO 17168 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:35:33.548  INFO 17168 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3187c937: startup date [Tue May 01 17:35:33 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@dadaa75
2018-05-01 17:35:34.969  INFO 17168 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:35:34.995  INFO 17168 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:35:35.005  INFO 17168 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:35:35.250  INFO 17168 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:35:35.279  INFO 17168 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:35:35.384  INFO 17168 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$4bb8b089] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:35:35.420  INFO 17168 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$67d2b386] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:35:35.865  INFO 17168 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:35:35.874  INFO 17168 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:35:35.875  INFO 17168 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:35:35.932  INFO 17168 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:35:35.932  INFO 17168 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2384 ms
2018-05-01 17:35:36.227  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:35:36.229  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:35:36.233  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:35:36.233  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:35:36.233  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:35:36.233  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:35:36.234  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:35:36.235  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:35:36.235  INFO 17168 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:35:36.553  INFO 17168 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:35:37.126  INFO 17168 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:35:37.612  INFO 17168 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:35:37.613  INFO 17168 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:35:37.661  INFO 17168 --- [cluster-ClusterId{value='5ae87b39b11f8e431050e167', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:14}] to localhost:27017
2018-05-01 17:35:37.664  INFO 17168 --- [cluster-ClusterId{value='5ae87b39b11f8e431050e167', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=614321}
2018-05-01 17:35:37.666  INFO 17168 --- [cluster-ClusterId{value='5ae87b39b11f8e431050e167', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:35:38.023  INFO 17168 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:35:38.188  WARN 17168 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:35:38.284  INFO 17168 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:35:38.295  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:35:38.296  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:35:38.297  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:35:38.298  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:35:38.298  INFO 17168 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:35:38.586  INFO 17168 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 58350.
2018-05-01 17:35:38.598  INFO 17168 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:35:38.613  INFO 17168 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:35:38.616  INFO 17168 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:35:38.616  INFO 17168 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:35:38.622  INFO 17168 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-c509552c-c791-43f2-9f74-21dc8e870480
2018-05-01 17:35:38.642  INFO 17168 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:35:38.676  INFO 17168 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:35:38.726  INFO 17168 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @7544ms
2018-05-01 17:35:38.769  INFO 17168 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:35:38.780  INFO 17168 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @7598ms
2018-05-01 17:35:38.797  INFO 17168 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@733bbcb1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:35:38.798  INFO 17168 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:35:38.825  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7f9b16b7{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.825  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@22e929ac{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.826  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@50fd9fdb{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.826  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1dcb3503{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.827  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@17a2a3f4{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.829  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7102a8e3{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.829  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@715ab12c{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.831  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@708311ec{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.831  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1b087a05{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.832  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@720406f{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.833  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5e25f09d{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.833  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1589c6e1{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.834  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@498105cb{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.837  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7c58ed47{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.837  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@80899b9{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.838  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@78bbf7b2{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.838  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4e3ee072{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.839  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3a3c432d{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.840  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3a909cd2{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.841  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@168e626a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.846  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@d7a5470{/static,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.846  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@27b66b5e{/,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.847  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1d17cb79{/api,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.848  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@51dc0f6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.848  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5c21f9cc{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:35:38.850  INFO 17168 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:35:38.936  INFO 17168 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:35:38.958  INFO 17168 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58363.
2018-05-01 17:35:38.959  INFO 17168 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:58363
2018-05-01 17:35:38.960  INFO 17168 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:35:38.961  INFO 17168 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 58363, None)
2018-05-01 17:35:38.964  INFO 17168 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:58363 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 58363, None)
2018-05-01 17:35:38.967  INFO 17168 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 58363, None)
2018-05-01 17:35:38.967  INFO 17168 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 58363, None)
2018-05-01 17:35:38.978  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1b40a5ff{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.022  INFO 17168 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:35:39.023  INFO 17168 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:35:39.028  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3c9ff59a{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.029  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@b7b7041{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.029  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@548b8f96{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.030  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3faa751f{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.031  INFO 17168 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@62150053{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:35:39.556  WARN 17168 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:35:39.740  INFO 17168 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:35:40.327  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.List<com.jcombat.profile.model.Movie> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:35:40.329  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[GET]}" onto public com.jcombat.profile.model.Movie com.jcombat.profile.controller.RecomendationController.asdsa() throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:35:40.330  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:35:40.333  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:35:40.334  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:35:40.334  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:35:40.336  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:35:40.336  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:35:41.112  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:35:41.112  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.113  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.113  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.114  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:35:41.114  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.115  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.115  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:35:41.116  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.117  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:35:41.119  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:35:41.119  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:35:41.119  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.120  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:35:41.120  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:35:41.121  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.121  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.121  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.122  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:35:41.123  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:35:41.123  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:35:41.123  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:35:41.124  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.124  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:35:41.124  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:35:41.126  INFO 17168 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:35:41.555  INFO 17168 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3187c937: startup date [Tue May 01 17:35:33 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@dadaa75
2018-05-01 17:35:41.618  INFO 17168 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:35:41.619  INFO 17168 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:35:41.640  INFO 17168 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:35:41.681  INFO 17168 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:35:42.112  WARN 17168 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:35:42.185  WARN 17168 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:35:42.186  INFO 17168 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:35:42.191  WARN 17168 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:35:42.191  INFO 17168 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:35:42.277  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:35:42.287  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:35:42.287  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:35:42.290  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:35:42.290  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:35:42.292  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:35:42.294  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:35:42.307  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:35:42.317  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:35:42.330  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=3187c937,type=ConfigurationPropertiesRebinder]
2018-05-01 17:35:42.338  INFO 17168 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:35:42.671  INFO 17168 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:35:42.678  INFO 17168 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:35:42.776  INFO 17168 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:35:42.776  INFO 17168 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:35:42.875  INFO 17168 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:35:42.876  INFO 17168 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:35:43.165  INFO 17168 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:35:43.275  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:35:43.275  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:35:43.275  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:35:43.276  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:35:43.276  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:35:43.277  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:35:43.277  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:35:43.452  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:35:43.456  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:35:43.458  INFO 17168 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:35:43.461  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525185343461 with initial instances count: 6
2018-05-01 17:35:43.485  INFO 17168 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:35:43.485  INFO 17168 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525185343485, current=UP, previous=STARTING]
2018-05-01 17:35:43.487  INFO 17168 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:35:43.529  INFO 17168 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:35:43.543  INFO 17168 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:35:43.544  INFO 17168 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:35:43.560  INFO 17168 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:35:43.574  INFO 17168 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:35:43.629  INFO 17168 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:35:43.630  INFO 17168 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:35:43.634  INFO 17168 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 11.433 seconds (JVM running for 12.452)
2018-05-01 17:35:44.114  INFO 17168 --- [RMI TCP Connection(2)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:15}] to localhost:27017
2018-05-01 17:37:55.062  INFO 17168 --- [http-nio-3333-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-01 17:37:55.062  INFO 17168 --- [http-nio-3333-exec-2] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-01 17:37:55.088  INFO 17168 --- [http-nio-3333-exec-2] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 25 ms
2018-05-01 17:40:43.280  INFO 17168 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:42:02.425  WARN 17168 --- [http-nio-3333-exec-2] o.apache.spark.sql.SparkSession$Builder  : Using an existing SparkSession; some configuration may not take effect.
2018-05-01 17:42:02.541  INFO 17168 --- [http-nio-3333-exec-2] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0 stored as values in memory (estimated size 248.0 B, free 1990.8 MB)
2018-05-01 17:42:02.662  INFO 17168 --- [http-nio-3333-exec-2] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0_piece0 stored as bytes in memory (estimated size 419.0 B, free 1990.8 MB)
2018-05-01 17:42:02.665  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_0_piece0 in memory on 172.21.241.193:58363 (size: 419.0 B, free: 1990.8 MB)
2018-05-01 17:42:02.671  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Created broadcast 0 from broadcast at MongoSpark.scala:536
2018-05-01 17:42:02.879  INFO 17168 --- [http-nio-3333-exec-2] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:42:02.887  INFO 17168 --- [http-nio-3333-exec-2] org.mongodb.driver.cluster               : Cluster description not yet available. Waiting for 30000 ms before timing out
2018-05-01 17:42:02.890  INFO 17168 --- [cluster-ClusterId{value='5ae87cbab11f8e431050e168', description='null'}-127.0.0.1:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:20}] to 127.0.0.1:27017
2018-05-01 17:42:02.892  INFO 17168 --- [cluster-ClusterId{value='5ae87cbab11f8e431050e168', description='null'}-127.0.0.1:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=259950}
2018-05-01 17:42:02.893  INFO 17168 --- [http-nio-3333-exec-2] c.m.spark.connection.MongoClientCache    : Creating MongoClient: [127.0.0.1:27017]
2018-05-01 17:42:02.906  INFO 17168 --- [http-nio-3333-exec-2] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:21}] to 127.0.0.1:27017
2018-05-01 17:42:04.059  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: collect at RecomendationServiceImpl.java:86
2018-05-01 17:42:04.076  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 0 (collect at RecomendationServiceImpl.java:86) with 66 output partitions
2018-05-01 17:42:04.077  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 0 (collect at RecomendationServiceImpl.java:86)
2018-05-01 17:42:04.077  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:42:04.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:42:04.088  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 0 (MapPartitionsRDD[1] at map at RecomendationServiceImpl.java:83), which has no missing parents
2018-05-01 17:42:04.115  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 1990.8 MB)
2018-05-01 17:42:04.118  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1990.8 MB)
2018-05-01 17:42:04.119  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_1_piece0 in memory on 172.21.241.193:58363 (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 17:42:04.121  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:04.133  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 66 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at RecomendationServiceImpl.java:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-05-01 17:42:04.134  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 0.0 with 66 tasks
2018-05-01 17:42:04.184  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 4987 bytes)
2018-05-01 17:42:04.195  INFO 17168 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Running task 0.0 in stage 0.0 (TID 0)
2018-05-01 17:42:04.270  INFO 17168 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 0.0 (TID 0). 708 bytes result sent to driver
2018-05-01 17:42:04.273  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 4999 bytes)
2018-05-01 17:42:04.273  INFO 17168 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Running task 1.0 in stage 0.0 (TID 1)
2018-05-01 17:42:04.280  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 0.0 (TID 0) in 112 ms on localhost (executor driver) (1/66)
2018-05-01 17:42:04.947  INFO 17168 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 0.0 (TID 1). 429884 bytes result sent to driver
2018-05-01 17:42:04.948  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 5005 bytes)
2018-05-01 17:42:04.948  INFO 17168 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Running task 2.0 in stage 0.0 (TID 2)
2018-05-01 17:42:04.966  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 0.0 (TID 1) in 694 ms on localhost (executor driver) (2/66)
2018-05-01 17:42:05.695  INFO 17168 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 0.0 (TID 2). 432580 bytes result sent to driver
2018-05-01 17:42:05.696  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 5004 bytes)
2018-05-01 17:42:05.696  INFO 17168 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Running task 3.0 in stage 0.0 (TID 3)
2018-05-01 17:42:05.712  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 0.0 (TID 2) in 764 ms on localhost (executor driver) (3/66)
2018-05-01 17:42:06.345  INFO 17168 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 0.0 (TID 3). 433940 bytes result sent to driver
2018-05-01 17:42:06.346  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 5003 bytes)
2018-05-01 17:42:06.346  INFO 17168 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Running task 4.0 in stage 0.0 (TID 4)
2018-05-01 17:42:06.370  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 0.0 (TID 3) in 674 ms on localhost (executor driver) (4/66)
2018-05-01 17:42:07.000  INFO 17168 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Finished task 4.0 in stage 0.0 (TID 4). 423957 bytes result sent to driver
2018-05-01 17:42:07.000  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 5003 bytes)
2018-05-01 17:42:07.001  INFO 17168 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Running task 5.0 in stage 0.0 (TID 5)
2018-05-01 17:42:07.019  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 4.0 in stage 0.0 (TID 4) in 673 ms on localhost (executor driver) (5/66)
2018-05-01 17:42:07.722  INFO 17168 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Finished task 5.0 in stage 0.0 (TID 5). 418098 bytes result sent to driver
2018-05-01 17:42:07.723  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 5003 bytes)
2018-05-01 17:42:07.723  INFO 17168 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Running task 6.0 in stage 0.0 (TID 6)
2018-05-01 17:42:07.738  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 5.0 in stage 0.0 (TID 5) in 738 ms on localhost (executor driver) (6/66)
2018-05-01 17:42:08.348  INFO 17168 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Finished task 6.0 in stage 0.0 (TID 6). 416945 bytes result sent to driver
2018-05-01 17:42:08.348  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 5003 bytes)
2018-05-01 17:42:08.349  INFO 17168 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Running task 7.0 in stage 0.0 (TID 7)
2018-05-01 17:42:08.366  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 6.0 in stage 0.0 (TID 6) in 644 ms on localhost (executor driver) (7/66)
2018-05-01 17:42:08.986  INFO 17168 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Finished task 7.0 in stage 0.0 (TID 7). 426842 bytes result sent to driver
2018-05-01 17:42:08.987  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 5003 bytes)
2018-05-01 17:42:08.988  INFO 17168 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Running task 8.0 in stage 0.0 (TID 8)
2018-05-01 17:42:09.003  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 7.0 in stage 0.0 (TID 7) in 655 ms on localhost (executor driver) (8/66)
2018-05-01 17:42:09.573  INFO 17168 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Finished task 8.0 in stage 0.0 (TID 8). 430736 bytes result sent to driver
2018-05-01 17:42:09.574  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 5003 bytes)
2018-05-01 17:42:09.574  INFO 17168 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Running task 9.0 in stage 0.0 (TID 9)
2018-05-01 17:42:09.591  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 8.0 in stage 0.0 (TID 8) in 603 ms on localhost (executor driver) (9/66)
2018-05-01 17:42:10.161  INFO 17168 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Finished task 9.0 in stage 0.0 (TID 9). 432112 bytes result sent to driver
2018-05-01 17:42:10.162  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 5003 bytes)
2018-05-01 17:42:10.162  INFO 17168 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Running task 10.0 in stage 0.0 (TID 10)
2018-05-01 17:42:10.182  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 9.0 in stage 0.0 (TID 9) in 608 ms on localhost (executor driver) (10/66)
2018-05-01 17:42:10.734  INFO 17168 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Finished task 10.0 in stage 0.0 (TID 10). 428533 bytes result sent to driver
2018-05-01 17:42:10.735  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 5003 bytes)
2018-05-01 17:42:10.735  INFO 17168 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Running task 11.0 in stage 0.0 (TID 11)
2018-05-01 17:42:10.750  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 10.0 in stage 0.0 (TID 10) in 588 ms on localhost (executor driver) (11/66)
2018-05-01 17:42:11.355  INFO 17168 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Finished task 11.0 in stage 0.0 (TID 11). 432916 bytes result sent to driver
2018-05-01 17:42:11.357  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 5003 bytes)
2018-05-01 17:42:11.357  INFO 17168 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Running task 12.0 in stage 0.0 (TID 12)
2018-05-01 17:42:11.374  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 11.0 in stage 0.0 (TID 11) in 639 ms on localhost (executor driver) (12/66)
2018-05-01 17:42:11.936  INFO 17168 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Finished task 12.0 in stage 0.0 (TID 12). 431975 bytes result sent to driver
2018-05-01 17:42:11.936  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 5003 bytes)
2018-05-01 17:42:11.937  INFO 17168 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Running task 13.0 in stage 0.0 (TID 13)
2018-05-01 17:42:11.951  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 12.0 in stage 0.0 (TID 12) in 596 ms on localhost (executor driver) (13/66)
2018-05-01 17:42:12.547  INFO 17168 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Finished task 13.0 in stage 0.0 (TID 13). 430518 bytes result sent to driver
2018-05-01 17:42:12.548  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 5003 bytes)
2018-05-01 17:42:12.548  INFO 17168 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Running task 14.0 in stage 0.0 (TID 14)
2018-05-01 17:42:12.569  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 13.0 in stage 0.0 (TID 13) in 633 ms on localhost (executor driver) (14/66)
2018-05-01 17:42:13.126  INFO 17168 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Finished task 14.0 in stage 0.0 (TID 14). 433458 bytes result sent to driver
2018-05-01 17:42:13.127  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 5003 bytes)
2018-05-01 17:42:13.127  INFO 17168 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Running task 15.0 in stage 0.0 (TID 15)
2018-05-01 17:42:13.142  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 14.0 in stage 0.0 (TID 14) in 594 ms on localhost (executor driver) (15/66)
2018-05-01 17:42:13.683  INFO 17168 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Finished task 15.0 in stage 0.0 (TID 15). 433639 bytes result sent to driver
2018-05-01 17:42:13.684  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 5003 bytes)
2018-05-01 17:42:13.684  INFO 17168 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Running task 16.0 in stage 0.0 (TID 16)
2018-05-01 17:42:13.701  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 15.0 in stage 0.0 (TID 15) in 574 ms on localhost (executor driver) (16/66)
2018-05-01 17:42:14.236  INFO 17168 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Finished task 16.0 in stage 0.0 (TID 16). 429584 bytes result sent to driver
2018-05-01 17:42:14.237  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 5002 bytes)
2018-05-01 17:42:14.237  INFO 17168 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Running task 17.0 in stage 0.0 (TID 17)
2018-05-01 17:42:14.255  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 16.0 in stage 0.0 (TID 16) in 571 ms on localhost (executor driver) (17/66)
2018-05-01 17:42:14.805  INFO 17168 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Finished task 17.0 in stage 0.0 (TID 17). 434264 bytes result sent to driver
2018-05-01 17:42:14.806  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 5002 bytes)
2018-05-01 17:42:14.806  INFO 17168 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Running task 18.0 in stage 0.0 (TID 18)
2018-05-01 17:42:14.821  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 17.0 in stage 0.0 (TID 17) in 585 ms on localhost (executor driver) (18/66)
2018-05-01 17:42:15.381  INFO 17168 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Finished task 18.0 in stage 0.0 (TID 18). 431426 bytes result sent to driver
2018-05-01 17:42:15.382  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 5003 bytes)
2018-05-01 17:42:15.382  INFO 17168 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Running task 19.0 in stage 0.0 (TID 19)
2018-05-01 17:42:15.398  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 18.0 in stage 0.0 (TID 18) in 592 ms on localhost (executor driver) (19/66)
2018-05-01 17:42:15.959  INFO 17168 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Finished task 19.0 in stage 0.0 (TID 19). 435226 bytes result sent to driver
2018-05-01 17:42:15.960  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 5003 bytes)
2018-05-01 17:42:15.960  INFO 17168 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Running task 20.0 in stage 0.0 (TID 20)
2018-05-01 17:42:15.975  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 19.0 in stage 0.0 (TID 19) in 593 ms on localhost (executor driver) (20/66)
2018-05-01 17:42:16.500  INFO 17168 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Finished task 20.0 in stage 0.0 (TID 20). 434347 bytes result sent to driver
2018-05-01 17:42:16.500  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 5003 bytes)
2018-05-01 17:42:16.500  INFO 17168 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Running task 21.0 in stage 0.0 (TID 21)
2018-05-01 17:42:16.515  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 20.0 in stage 0.0 (TID 20) in 555 ms on localhost (executor driver) (21/66)
2018-05-01 17:42:17.091  INFO 17168 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Finished task 21.0 in stage 0.0 (TID 21). 428428 bytes result sent to driver
2018-05-01 17:42:17.091  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 22.0 in stage 0.0 (TID 22, localhost, executor driver, partition 22, ANY, 5003 bytes)
2018-05-01 17:42:17.092  INFO 17168 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Running task 22.0 in stage 0.0 (TID 22)
2018-05-01 17:42:17.107  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 21.0 in stage 0.0 (TID 21) in 607 ms on localhost (executor driver) (22/66)
2018-05-01 17:42:17.627  INFO 17168 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Finished task 22.0 in stage 0.0 (TID 22). 434997 bytes result sent to driver
2018-05-01 17:42:17.628  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 23.0 in stage 0.0 (TID 23, localhost, executor driver, partition 23, ANY, 5003 bytes)
2018-05-01 17:42:17.628  INFO 17168 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Running task 23.0 in stage 0.0 (TID 23)
2018-05-01 17:42:17.647  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 22.0 in stage 0.0 (TID 22) in 556 ms on localhost (executor driver) (23/66)
2018-05-01 17:42:18.205  INFO 17168 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Finished task 23.0 in stage 0.0 (TID 23). 430843 bytes result sent to driver
2018-05-01 17:42:18.206  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 24.0 in stage 0.0 (TID 24, localhost, executor driver, partition 24, ANY, 5003 bytes)
2018-05-01 17:42:18.206  INFO 17168 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Running task 24.0 in stage 0.0 (TID 24)
2018-05-01 17:42:18.224  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 23.0 in stage 0.0 (TID 23) in 596 ms on localhost (executor driver) (24/66)
2018-05-01 17:42:18.743  INFO 17168 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Finished task 24.0 in stage 0.0 (TID 24). 429256 bytes result sent to driver
2018-05-01 17:42:18.744  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 25.0 in stage 0.0 (TID 25, localhost, executor driver, partition 25, ANY, 5003 bytes)
2018-05-01 17:42:18.744  INFO 17168 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Running task 25.0 in stage 0.0 (TID 25)
2018-05-01 17:42:18.759  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 24.0 in stage 0.0 (TID 24) in 553 ms on localhost (executor driver) (25/66)
2018-05-01 17:42:19.330  INFO 17168 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Finished task 25.0 in stage 0.0 (TID 25). 432294 bytes result sent to driver
2018-05-01 17:42:19.330  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 26.0 in stage 0.0 (TID 26, localhost, executor driver, partition 26, ANY, 5003 bytes)
2018-05-01 17:42:19.331  INFO 17168 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Running task 26.0 in stage 0.0 (TID 26)
2018-05-01 17:42:19.345  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 25.0 in stage 0.0 (TID 25) in 601 ms on localhost (executor driver) (26/66)
2018-05-01 17:42:19.875  INFO 17168 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Finished task 26.0 in stage 0.0 (TID 26). 433194 bytes result sent to driver
2018-05-01 17:42:19.875  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 27.0 in stage 0.0 (TID 27, localhost, executor driver, partition 27, ANY, 5003 bytes)
2018-05-01 17:42:19.875  INFO 17168 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Running task 27.0 in stage 0.0 (TID 27)
2018-05-01 17:42:19.895  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 26.0 in stage 0.0 (TID 26) in 565 ms on localhost (executor driver) (27/66)
2018-05-01 17:42:20.443  INFO 17168 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Finished task 27.0 in stage 0.0 (TID 27). 433416 bytes result sent to driver
2018-05-01 17:42:20.443  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 28.0 in stage 0.0 (TID 28, localhost, executor driver, partition 28, ANY, 5003 bytes)
2018-05-01 17:42:20.443  INFO 17168 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Running task 28.0 in stage 0.0 (TID 28)
2018-05-01 17:42:20.459  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 27.0 in stage 0.0 (TID 27) in 584 ms on localhost (executor driver) (28/66)
2018-05-01 17:42:20.997  INFO 17168 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Finished task 28.0 in stage 0.0 (TID 28). 431277 bytes result sent to driver
2018-05-01 17:42:20.998  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 29.0 in stage 0.0 (TID 29, localhost, executor driver, partition 29, ANY, 5003 bytes)
2018-05-01 17:42:20.998  INFO 17168 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Running task 29.0 in stage 0.0 (TID 29)
2018-05-01 17:42:21.012  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 28.0 in stage 0.0 (TID 28) in 569 ms on localhost (executor driver) (29/66)
2018-05-01 17:42:21.550  INFO 17168 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Finished task 29.0 in stage 0.0 (TID 29). 432490 bytes result sent to driver
2018-05-01 17:42:21.551  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 30.0 in stage 0.0 (TID 30, localhost, executor driver, partition 30, ANY, 5003 bytes)
2018-05-01 17:42:21.551  INFO 17168 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Running task 30.0 in stage 0.0 (TID 30)
2018-05-01 17:42:21.597  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 29.0 in stage 0.0 (TID 29) in 600 ms on localhost (executor driver) (30/66)
2018-05-01 17:42:22.127  INFO 17168 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Finished task 30.0 in stage 0.0 (TID 30). 431401 bytes result sent to driver
2018-05-01 17:42:22.129  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 31.0 in stage 0.0 (TID 31, localhost, executor driver, partition 31, ANY, 5003 bytes)
2018-05-01 17:42:22.129  INFO 17168 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Running task 31.0 in stage 0.0 (TID 31)
2018-05-01 17:42:22.145  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 30.0 in stage 0.0 (TID 30) in 595 ms on localhost (executor driver) (31/66)
2018-05-01 17:42:22.683  INFO 17168 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Finished task 31.0 in stage 0.0 (TID 31). 434098 bytes result sent to driver
2018-05-01 17:42:22.684  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 32.0 in stage 0.0 (TID 32, localhost, executor driver, partition 32, ANY, 5002 bytes)
2018-05-01 17:42:22.684  INFO 17168 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Running task 32.0 in stage 0.0 (TID 32)
2018-05-01 17:42:22.699  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 31.0 in stage 0.0 (TID 31) in 571 ms on localhost (executor driver) (32/66)
2018-05-01 17:42:23.231  INFO 17168 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Finished task 32.0 in stage 0.0 (TID 32). 432096 bytes result sent to driver
2018-05-01 17:42:23.231  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 33.0 in stage 0.0 (TID 33, localhost, executor driver, partition 33, ANY, 5002 bytes)
2018-05-01 17:42:23.232  INFO 17168 --- [Executor task launch worker for task 33] org.apache.spark.executor.Executor       : Running task 33.0 in stage 0.0 (TID 33)
2018-05-01 17:42:23.247  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 32.0 in stage 0.0 (TID 32) in 563 ms on localhost (executor driver) (33/66)
2018-05-01 17:42:23.778  INFO 17168 --- [Executor task launch worker for task 33] org.apache.spark.executor.Executor       : Finished task 33.0 in stage 0.0 (TID 33). 433257 bytes result sent to driver
2018-05-01 17:42:23.779  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 34.0 in stage 0.0 (TID 34, localhost, executor driver, partition 34, ANY, 5002 bytes)
2018-05-01 17:42:23.779  INFO 17168 --- [Executor task launch worker for task 34] org.apache.spark.executor.Executor       : Running task 34.0 in stage 0.0 (TID 34)
2018-05-01 17:42:23.795  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 33.0 in stage 0.0 (TID 33) in 564 ms on localhost (executor driver) (34/66)
2018-05-01 17:42:24.365  INFO 17168 --- [Executor task launch worker for task 34] org.apache.spark.executor.Executor       : Finished task 34.0 in stage 0.0 (TID 34). 433019 bytes result sent to driver
2018-05-01 17:42:24.365  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 35.0 in stage 0.0 (TID 35, localhost, executor driver, partition 35, ANY, 5002 bytes)
2018-05-01 17:42:24.366  INFO 17168 --- [Executor task launch worker for task 35] org.apache.spark.executor.Executor       : Running task 35.0 in stage 0.0 (TID 35)
2018-05-01 17:42:24.382  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 34.0 in stage 0.0 (TID 34) in 604 ms on localhost (executor driver) (35/66)
2018-05-01 17:42:24.903  INFO 17168 --- [Executor task launch worker for task 35] org.apache.spark.executor.Executor       : Finished task 35.0 in stage 0.0 (TID 35). 431659 bytes result sent to driver
2018-05-01 17:42:24.904  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 36.0 in stage 0.0 (TID 36, localhost, executor driver, partition 36, ANY, 5002 bytes)
2018-05-01 17:42:24.904  INFO 17168 --- [Executor task launch worker for task 36] org.apache.spark.executor.Executor       : Running task 36.0 in stage 0.0 (TID 36)
2018-05-01 17:42:24.919  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 35.0 in stage 0.0 (TID 35) in 554 ms on localhost (executor driver) (36/66)
2018-05-01 17:42:25.455  INFO 17168 --- [Executor task launch worker for task 36] org.apache.spark.executor.Executor       : Finished task 36.0 in stage 0.0 (TID 36). 435545 bytes result sent to driver
2018-05-01 17:42:25.456  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 37.0 in stage 0.0 (TID 37, localhost, executor driver, partition 37, ANY, 5002 bytes)
2018-05-01 17:42:25.456  INFO 17168 --- [Executor task launch worker for task 37] org.apache.spark.executor.Executor       : Running task 37.0 in stage 0.0 (TID 37)
2018-05-01 17:42:25.472  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 36.0 in stage 0.0 (TID 36) in 569 ms on localhost (executor driver) (37/66)
2018-05-01 17:42:25.999  INFO 17168 --- [Executor task launch worker for task 37] org.apache.spark.executor.Executor       : Finished task 37.0 in stage 0.0 (TID 37). 432635 bytes result sent to driver
2018-05-01 17:42:26.000  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 38.0 in stage 0.0 (TID 38, localhost, executor driver, partition 38, ANY, 5003 bytes)
2018-05-01 17:42:26.000  INFO 17168 --- [Executor task launch worker for task 38] org.apache.spark.executor.Executor       : Running task 38.0 in stage 0.0 (TID 38)
2018-05-01 17:42:26.015  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 37.0 in stage 0.0 (TID 37) in 559 ms on localhost (executor driver) (38/66)
2018-05-01 17:42:26.558  INFO 17168 --- [Executor task launch worker for task 38] org.apache.spark.executor.Executor       : Finished task 38.0 in stage 0.0 (TID 38). 433731 bytes result sent to driver
2018-05-01 17:42:26.559  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 39.0 in stage 0.0 (TID 39, localhost, executor driver, partition 39, ANY, 5003 bytes)
2018-05-01 17:42:26.559  INFO 17168 --- [Executor task launch worker for task 39] org.apache.spark.executor.Executor       : Running task 39.0 in stage 0.0 (TID 39)
2018-05-01 17:42:26.574  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 38.0 in stage 0.0 (TID 38) in 574 ms on localhost (executor driver) (39/66)
2018-05-01 17:42:27.155  INFO 17168 --- [Executor task launch worker for task 39] org.apache.spark.executor.Executor       : Finished task 39.0 in stage 0.0 (TID 39). 430075 bytes result sent to driver
2018-05-01 17:42:27.157  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 40.0 in stage 0.0 (TID 40, localhost, executor driver, partition 40, ANY, 5003 bytes)
2018-05-01 17:42:27.157  INFO 17168 --- [Executor task launch worker for task 40] org.apache.spark.executor.Executor       : Running task 40.0 in stage 0.0 (TID 40)
2018-05-01 17:42:27.172  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 39.0 in stage 0.0 (TID 39) in 614 ms on localhost (executor driver) (40/66)
2018-05-01 17:42:27.707  INFO 17168 --- [Executor task launch worker for task 40] org.apache.spark.executor.Executor       : Finished task 40.0 in stage 0.0 (TID 40). 432889 bytes result sent to driver
2018-05-01 17:42:27.707  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 41.0 in stage 0.0 (TID 41, localhost, executor driver, partition 41, ANY, 5003 bytes)
2018-05-01 17:42:27.708  INFO 17168 --- [Executor task launch worker for task 41] org.apache.spark.executor.Executor       : Running task 41.0 in stage 0.0 (TID 41)
2018-05-01 17:42:27.723  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 40.0 in stage 0.0 (TID 40) in 567 ms on localhost (executor driver) (41/66)
2018-05-01 17:42:28.250  INFO 17168 --- [Executor task launch worker for task 41] org.apache.spark.executor.Executor       : Finished task 41.0 in stage 0.0 (TID 41). 431707 bytes result sent to driver
2018-05-01 17:42:28.250  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 42.0 in stage 0.0 (TID 42, localhost, executor driver, partition 42, ANY, 5003 bytes)
2018-05-01 17:42:28.250  INFO 17168 --- [Executor task launch worker for task 42] org.apache.spark.executor.Executor       : Running task 42.0 in stage 0.0 (TID 42)
2018-05-01 17:42:28.266  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 41.0 in stage 0.0 (TID 41) in 559 ms on localhost (executor driver) (42/66)
2018-05-01 17:42:28.805  INFO 17168 --- [Executor task launch worker for task 42] org.apache.spark.executor.Executor       : Finished task 42.0 in stage 0.0 (TID 42). 432035 bytes result sent to driver
2018-05-01 17:42:28.806  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 43.0 in stage 0.0 (TID 43, localhost, executor driver, partition 43, ANY, 5003 bytes)
2018-05-01 17:42:28.806  INFO 17168 --- [Executor task launch worker for task 43] org.apache.spark.executor.Executor       : Running task 43.0 in stage 0.0 (TID 43)
2018-05-01 17:42:28.822  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 42.0 in stage 0.0 (TID 42) in 572 ms on localhost (executor driver) (43/66)
2018-05-01 17:42:29.341  INFO 17168 --- [Executor task launch worker for task 43] org.apache.spark.executor.Executor       : Finished task 43.0 in stage 0.0 (TID 43). 428969 bytes result sent to driver
2018-05-01 17:42:29.341  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 44.0 in stage 0.0 (TID 44, localhost, executor driver, partition 44, ANY, 5003 bytes)
2018-05-01 17:42:29.342  INFO 17168 --- [Executor task launch worker for task 44] org.apache.spark.executor.Executor       : Running task 44.0 in stage 0.0 (TID 44)
2018-05-01 17:42:29.358  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 43.0 in stage 0.0 (TID 43) in 552 ms on localhost (executor driver) (44/66)
2018-05-01 17:42:29.948  INFO 17168 --- [Executor task launch worker for task 44] org.apache.spark.executor.Executor       : Finished task 44.0 in stage 0.0 (TID 44). 432725 bytes result sent to driver
2018-05-01 17:42:29.949  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 45.0 in stage 0.0 (TID 45, localhost, executor driver, partition 45, ANY, 5003 bytes)
2018-05-01 17:42:29.949  INFO 17168 --- [Executor task launch worker for task 45] org.apache.spark.executor.Executor       : Running task 45.0 in stage 0.0 (TID 45)
2018-05-01 17:42:29.967  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 44.0 in stage 0.0 (TID 44) in 626 ms on localhost (executor driver) (45/66)
2018-05-01 17:42:30.484  INFO 17168 --- [Executor task launch worker for task 45] org.apache.spark.executor.Executor       : Finished task 45.0 in stage 0.0 (TID 45). 430122 bytes result sent to driver
2018-05-01 17:42:30.485  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 46.0 in stage 0.0 (TID 46, localhost, executor driver, partition 46, ANY, 5003 bytes)
2018-05-01 17:42:30.485  INFO 17168 --- [Executor task launch worker for task 46] org.apache.spark.executor.Executor       : Running task 46.0 in stage 0.0 (TID 46)
2018-05-01 17:42:30.500  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 45.0 in stage 0.0 (TID 45) in 551 ms on localhost (executor driver) (46/66)
2018-05-01 17:42:31.042  INFO 17168 --- [Executor task launch worker for task 46] org.apache.spark.executor.Executor       : Finished task 46.0 in stage 0.0 (TID 46). 430137 bytes result sent to driver
2018-05-01 17:42:31.043  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 47.0 in stage 0.0 (TID 47, localhost, executor driver, partition 47, ANY, 5003 bytes)
2018-05-01 17:42:31.043  INFO 17168 --- [Executor task launch worker for task 47] org.apache.spark.executor.Executor       : Running task 47.0 in stage 0.0 (TID 47)
2018-05-01 17:42:31.058  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 46.0 in stage 0.0 (TID 46) in 573 ms on localhost (executor driver) (47/66)
2018-05-01 17:42:31.572  INFO 17168 --- [Executor task launch worker for task 47] org.apache.spark.executor.Executor       : Finished task 47.0 in stage 0.0 (TID 47). 433553 bytes result sent to driver
2018-05-01 17:42:31.573  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 48.0 in stage 0.0 (TID 48, localhost, executor driver, partition 48, ANY, 5003 bytes)
2018-05-01 17:42:31.573  INFO 17168 --- [Executor task launch worker for task 48] org.apache.spark.executor.Executor       : Running task 48.0 in stage 0.0 (TID 48)
2018-05-01 17:42:31.588  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 47.0 in stage 0.0 (TID 47) in 545 ms on localhost (executor driver) (48/66)
2018-05-01 17:42:32.141  INFO 17168 --- [Executor task launch worker for task 48] org.apache.spark.executor.Executor       : Finished task 48.0 in stage 0.0 (TID 48). 431478 bytes result sent to driver
2018-05-01 17:42:32.142  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 49.0 in stage 0.0 (TID 49, localhost, executor driver, partition 49, ANY, 5003 bytes)
2018-05-01 17:42:32.142  INFO 17168 --- [Executor task launch worker for task 49] org.apache.spark.executor.Executor       : Running task 49.0 in stage 0.0 (TID 49)
2018-05-01 17:42:32.157  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 48.0 in stage 0.0 (TID 48) in 584 ms on localhost (executor driver) (49/66)
2018-05-01 17:42:32.726  INFO 17168 --- [Executor task launch worker for task 49] org.apache.spark.executor.Executor       : Finished task 49.0 in stage 0.0 (TID 49). 432786 bytes result sent to driver
2018-05-01 17:42:32.727  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 50.0 in stage 0.0 (TID 50, localhost, executor driver, partition 50, ANY, 5003 bytes)
2018-05-01 17:42:32.727  INFO 17168 --- [Executor task launch worker for task 50] org.apache.spark.executor.Executor       : Running task 50.0 in stage 0.0 (TID 50)
2018-05-01 17:42:32.743  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 49.0 in stage 0.0 (TID 49) in 601 ms on localhost (executor driver) (50/66)
2018-05-01 17:42:33.276  INFO 17168 --- [Executor task launch worker for task 50] org.apache.spark.executor.Executor       : Finished task 50.0 in stage 0.0 (TID 50). 430368 bytes result sent to driver
2018-05-01 17:42:33.276  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 51.0 in stage 0.0 (TID 51, localhost, executor driver, partition 51, ANY, 5002 bytes)
2018-05-01 17:42:33.277  INFO 17168 --- [Executor task launch worker for task 51] org.apache.spark.executor.Executor       : Running task 51.0 in stage 0.0 (TID 51)
2018-05-01 17:42:33.292  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 50.0 in stage 0.0 (TID 50) in 565 ms on localhost (executor driver) (51/66)
2018-05-01 17:42:33.846  INFO 17168 --- [Executor task launch worker for task 51] org.apache.spark.executor.Executor       : Finished task 51.0 in stage 0.0 (TID 51). 435039 bytes result sent to driver
2018-05-01 17:42:33.846  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 52.0 in stage 0.0 (TID 52, localhost, executor driver, partition 52, ANY, 5002 bytes)
2018-05-01 17:42:33.846  INFO 17168 --- [Executor task launch worker for task 52] org.apache.spark.executor.Executor       : Running task 52.0 in stage 0.0 (TID 52)
2018-05-01 17:42:33.861  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 51.0 in stage 0.0 (TID 51) in 585 ms on localhost (executor driver) (52/66)
2018-05-01 17:42:34.392  INFO 17168 --- [Executor task launch worker for task 52] org.apache.spark.executor.Executor       : Finished task 52.0 in stage 0.0 (TID 52). 431702 bytes result sent to driver
2018-05-01 17:42:34.392  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 53.0 in stage 0.0 (TID 53, localhost, executor driver, partition 53, ANY, 5002 bytes)
2018-05-01 17:42:34.393  INFO 17168 --- [Executor task launch worker for task 53] org.apache.spark.executor.Executor       : Running task 53.0 in stage 0.0 (TID 53)
2018-05-01 17:42:34.409  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 52.0 in stage 0.0 (TID 52) in 563 ms on localhost (executor driver) (53/66)
2018-05-01 17:42:34.994  INFO 17168 --- [Executor task launch worker for task 53] org.apache.spark.executor.Executor       : Finished task 53.0 in stage 0.0 (TID 53). 431628 bytes result sent to driver
2018-05-01 17:42:34.995  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 54.0 in stage 0.0 (TID 54, localhost, executor driver, partition 54, ANY, 5002 bytes)
2018-05-01 17:42:34.995  INFO 17168 --- [Executor task launch worker for task 54] org.apache.spark.executor.Executor       : Running task 54.0 in stage 0.0 (TID 54)
2018-05-01 17:42:35.011  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 53.0 in stage 0.0 (TID 53) in 619 ms on localhost (executor driver) (54/66)
2018-05-01 17:42:35.541  INFO 17168 --- [Executor task launch worker for task 54] org.apache.spark.executor.Executor       : Finished task 54.0 in stage 0.0 (TID 54). 428857 bytes result sent to driver
2018-05-01 17:42:35.542  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 55.0 in stage 0.0 (TID 55, localhost, executor driver, partition 55, ANY, 5003 bytes)
2018-05-01 17:42:35.542  INFO 17168 --- [Executor task launch worker for task 55] org.apache.spark.executor.Executor       : Running task 55.0 in stage 0.0 (TID 55)
2018-05-01 17:42:35.556  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 54.0 in stage 0.0 (TID 54) in 561 ms on localhost (executor driver) (55/66)
2018-05-01 17:42:36.101  INFO 17168 --- [Executor task launch worker for task 55] org.apache.spark.executor.Executor       : Finished task 55.0 in stage 0.0 (TID 55). 431970 bytes result sent to driver
2018-05-01 17:42:36.102  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 56.0 in stage 0.0 (TID 56, localhost, executor driver, partition 56, ANY, 5003 bytes)
2018-05-01 17:42:36.102  INFO 17168 --- [Executor task launch worker for task 56] org.apache.spark.executor.Executor       : Running task 56.0 in stage 0.0 (TID 56)
2018-05-01 17:42:36.119  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 55.0 in stage 0.0 (TID 55) in 577 ms on localhost (executor driver) (56/66)
2018-05-01 17:42:36.638  INFO 17168 --- [Executor task launch worker for task 56] org.apache.spark.executor.Executor       : Finished task 56.0 in stage 0.0 (TID 56). 431035 bytes result sent to driver
2018-05-01 17:42:36.639  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 57.0 in stage 0.0 (TID 57, localhost, executor driver, partition 57, ANY, 5003 bytes)
2018-05-01 17:42:36.639  INFO 17168 --- [Executor task launch worker for task 57] org.apache.spark.executor.Executor       : Running task 57.0 in stage 0.0 (TID 57)
2018-05-01 17:42:36.654  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 56.0 in stage 0.0 (TID 56) in 552 ms on localhost (executor driver) (57/66)
2018-05-01 17:42:37.199  INFO 17168 --- [Executor task launch worker for task 57] org.apache.spark.executor.Executor       : Finished task 57.0 in stage 0.0 (TID 57). 433983 bytes result sent to driver
2018-05-01 17:42:37.200  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 58.0 in stage 0.0 (TID 58, localhost, executor driver, partition 58, ANY, 5003 bytes)
2018-05-01 17:42:37.200  INFO 17168 --- [Executor task launch worker for task 58] org.apache.spark.executor.Executor       : Running task 58.0 in stage 0.0 (TID 58)
2018-05-01 17:42:37.215  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 57.0 in stage 0.0 (TID 57) in 577 ms on localhost (executor driver) (58/66)
2018-05-01 17:42:37.789  INFO 17168 --- [Executor task launch worker for task 58] org.apache.spark.executor.Executor       : Finished task 58.0 in stage 0.0 (TID 58). 431075 bytes result sent to driver
2018-05-01 17:42:37.790  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 59.0 in stage 0.0 (TID 59, localhost, executor driver, partition 59, ANY, 5003 bytes)
2018-05-01 17:42:37.790  INFO 17168 --- [Executor task launch worker for task 59] org.apache.spark.executor.Executor       : Running task 59.0 in stage 0.0 (TID 59)
2018-05-01 17:42:37.806  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 58.0 in stage 0.0 (TID 58) in 607 ms on localhost (executor driver) (59/66)
2018-05-01 17:42:38.350  INFO 17168 --- [Executor task launch worker for task 59] org.apache.spark.executor.Executor       : Finished task 59.0 in stage 0.0 (TID 59). 433207 bytes result sent to driver
2018-05-01 17:42:38.350  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 60.0 in stage 0.0 (TID 60, localhost, executor driver, partition 60, ANY, 5003 bytes)
2018-05-01 17:42:38.351  INFO 17168 --- [Executor task launch worker for task 60] org.apache.spark.executor.Executor       : Running task 60.0 in stage 0.0 (TID 60)
2018-05-01 17:42:38.367  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 59.0 in stage 0.0 (TID 59) in 577 ms on localhost (executor driver) (60/66)
2018-05-01 17:42:38.886  INFO 17168 --- [Executor task launch worker for task 60] org.apache.spark.executor.Executor       : Finished task 60.0 in stage 0.0 (TID 60). 432171 bytes result sent to driver
2018-05-01 17:42:38.887  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 61.0 in stage 0.0 (TID 61, localhost, executor driver, partition 61, ANY, 5003 bytes)
2018-05-01 17:42:38.887  INFO 17168 --- [Executor task launch worker for task 61] org.apache.spark.executor.Executor       : Running task 61.0 in stage 0.0 (TID 61)
2018-05-01 17:42:38.903  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 60.0 in stage 0.0 (TID 60) in 553 ms on localhost (executor driver) (61/66)
2018-05-01 17:42:39.443  INFO 17168 --- [Executor task launch worker for task 61] org.apache.spark.executor.Executor       : Finished task 61.0 in stage 0.0 (TID 61). 432524 bytes result sent to driver
2018-05-01 17:42:39.443  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 62.0 in stage 0.0 (TID 62, localhost, executor driver, partition 62, ANY, 5003 bytes)
2018-05-01 17:42:39.443  INFO 17168 --- [Executor task launch worker for task 62] org.apache.spark.executor.Executor       : Running task 62.0 in stage 0.0 (TID 62)
2018-05-01 17:42:39.458  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 61.0 in stage 0.0 (TID 61) in 571 ms on localhost (executor driver) (62/66)
2018-05-01 17:42:40.034  INFO 17168 --- [Executor task launch worker for task 62] org.apache.spark.executor.Executor       : Finished task 62.0 in stage 0.0 (TID 62). 431615 bytes result sent to driver
2018-05-01 17:42:40.034  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 63.0 in stage 0.0 (TID 63, localhost, executor driver, partition 63, ANY, 5003 bytes)
2018-05-01 17:42:40.035  INFO 17168 --- [Executor task launch worker for task 63] org.apache.spark.executor.Executor       : Running task 63.0 in stage 0.0 (TID 63)
2018-05-01 17:42:40.052  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 62.0 in stage 0.0 (TID 62) in 609 ms on localhost (executor driver) (63/66)
2018-05-01 17:42:40.598  INFO 17168 --- [Executor task launch worker for task 63] org.apache.spark.executor.Executor       : Finished task 63.0 in stage 0.0 (TID 63). 429910 bytes result sent to driver
2018-05-01 17:42:40.599  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 64.0 in stage 0.0 (TID 64, localhost, executor driver, partition 64, ANY, 5003 bytes)
2018-05-01 17:42:40.599  INFO 17168 --- [Executor task launch worker for task 64] org.apache.spark.executor.Executor       : Running task 64.0 in stage 0.0 (TID 64)
2018-05-01 17:42:40.614  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 63.0 in stage 0.0 (TID 63) in 580 ms on localhost (executor driver) (64/66)
2018-05-01 17:42:41.136  INFO 17168 --- [Executor task launch worker for task 64] org.apache.spark.executor.Executor       : Finished task 64.0 in stage 0.0 (TID 64). 434975 bytes result sent to driver
2018-05-01 17:42:41.137  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 65.0 in stage 0.0 (TID 65, localhost, executor driver, partition 65, ANY, 4992 bytes)
2018-05-01 17:42:41.137  INFO 17168 --- [Executor task launch worker for task 65] org.apache.spark.executor.Executor       : Running task 65.0 in stage 0.0 (TID 65)
2018-05-01 17:42:41.141  INFO 17168 --- [Executor task launch worker for task 65] org.apache.spark.executor.Executor       : Finished task 65.0 in stage 0.0 (TID 65). 777 bytes result sent to driver
2018-05-01 17:42:41.142  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 65.0 in stage 0.0 (TID 65) in 6 ms on localhost (executor driver) (65/66)
2018-05-01 17:42:41.151  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 64.0 in stage 0.0 (TID 64) in 552 ms on localhost (executor driver) (66/66)
2018-05-01 17:42:41.152  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-05-01 17:42:41.153  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 0 (collect at RecomendationServiceImpl.java:86) finished in 36.998 s
2018-05-01 17:42:41.159  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 0 finished: collect at RecomendationServiceImpl.java:86, took 37.099721 s
2018-05-01 17:42:41.344  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:240
2018-05-01 17:42:41.346  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 1 (isEmpty at ALS.scala:240) with 1 output partitions
2018-05-01 17:42:41.346  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1 (isEmpty at ALS.scala:240)
2018-05-01 17:42:41.346  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:42:41.349  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:42:41.349  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1 (UnionRDD[5] at union at RecomendationServiceImpl.java:77), which has no missing parents
2018-05-01 17:42:41.353  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.8 MB)
2018-05-01 17:42:41.355  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.8 MB)
2018-05-01 17:42:41.357  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_2_piece0 in memory on 172.21.241.193:58363 (size: 2.1 KB, free: 1990.8 MB)
2018-05-01 17:42:41.357  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:41.358  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1 (UnionRDD[5] at union at RecomendationServiceImpl.java:77) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:41.358  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1.0 with 1 tasks
2018-05-01 17:42:44.286  WARN 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Stage 1 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:42:44.286  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:42:44.287  INFO 17168 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1.0 (TID 66)
2018-05-01 17:42:45.889  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_1_piece0 on 172.21.241.193:58363 in memory (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 17:42:45.894  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_0_piece0 on 172.21.241.193:58363 in memory (size: 419.0 B, free: 1990.8 MB)
2018-05-01 17:42:46.188  INFO 17168 --- [pool-25-thread-1] c.m.spark.connection.MongoClientCache    : Closing MongoClient: [127.0.0.1:27017]
2018-05-01 17:42:46.190  INFO 17168 --- [pool-25-thread-1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:21}] to 127.0.0.1:27017 because the pool has been closed.
2018-05-01 17:42:47.028  INFO 17168 --- [Executor task launch worker for task 66] o.a.spark.storage.memory.MemoryStore     : Block rdd_3_0 stored as values in memory (estimated size 36.0 MB, free 1954.8 MB)
2018-05-01 17:42:47.029  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_3_0 in memory on 172.21.241.193:58363 (size: 36.0 MB, free: 1954.8 MB)
2018-05-01 17:42:47.037  INFO 17168 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 66:
[rdd_3_0]
2018-05-01 17:42:47.040  INFO 17168 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1.0 (TID 66). 1551 bytes result sent to driver
2018-05-01 17:42:47.042  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1.0 (TID 66) in 5683 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:47.042  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-05-01 17:42:47.043  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1 (isEmpty at ALS.scala:240) finished in 5.684 s
2018-05-01 17:42:47.044  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 1 finished: isEmpty at ALS.scala:240, took 5.700280 s
2018-05-01 17:42:47.059  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:843
2018-05-01 17:42:47.060  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 2 (isEmpty at ALS.scala:843) with 1 output partitions
2018-05-01 17:42:47.060  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 2 (isEmpty at ALS.scala:843)
2018-05-01 17:42:47.061  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:42:47.061  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:42:47.061  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 2 (MapPartitionsRDD[6] at map at ALS.scala:256), which has no missing parents
2018-05-01 17:42:47.063  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1954.8 MB)
2018-05-01 17:42:47.065  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1954.8 MB)
2018-05-01 17:42:47.066  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_3_piece0 in memory on 172.21.241.193:58363 (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 17:42:47.066  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:47.066  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:47.067  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 2.0 with 1 tasks
2018-05-01 17:42:51.196  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_2_piece0 on 172.21.241.193:58363 in memory (size: 2.1 KB, free: 1954.8 MB)
2018-05-01 17:42:51.520  WARN 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 2 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:42:51.520  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 2.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:42:51.520  INFO 17168 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : Running task 0.0 in stage 2.0 (TID 67)
2018-05-01 17:42:52.509  INFO 17168 --- [Executor task launch worker for task 67] org.apache.spark.storage.BlockManager    : Found block rdd_3_0 locally
2018-05-01 17:42:52.512  INFO 17168 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 67:
[rdd_3_0]
2018-05-01 17:42:52.513  INFO 17168 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 2.0 (TID 67). 1089 bytes result sent to driver
2018-05-01 17:42:52.516  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 2.0 (TID 67) in 5447 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:52.516  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-05-01 17:42:52.516  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 2 (isEmpty at ALS.scala:843) finished in 5.448 s
2018-05-01 17:42:52.516  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 2 finished: isEmpty at ALS.scala:843, took 5.456916 s
2018-05-01 17:42:52.591  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:857
2018-05-01 17:42:52.596  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 7 (mapPartitions at ALS.scala:1101)
2018-05-01 17:42:52.596  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 10 (map at ALS.scala:1344)
2018-05-01 17:42:52.597  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 3 (count at ALS.scala:857) with 1 output partitions
2018-05-01 17:42:52.598  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 5 (count at ALS.scala:857)
2018-05-01 17:42:52.598  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 4)
2018-05-01 17:42:52.598  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 4)
2018-05-01 17:42:52.600  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 3 (MapPartitionsRDD[7] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-05-01 17:42:52.604  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 1954.8 MB)
2018-05-01 17:42:52.606  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1954.8 MB)
2018-05-01 17:42:52.607  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_4_piece0 in memory on 172.21.241.193:58363 (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 17:42:52.608  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:52.610  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[7] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:42:52.610  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 3.0 with 2 tasks
2018-05-01 17:42:55.529  WARN 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 3 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:42:55.530  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 3.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427802 bytes)
2018-05-01 17:42:55.530  INFO 17168 --- [Executor task launch worker for task 68] org.apache.spark.executor.Executor       : Running task 0.0 in stage 3.0 (TID 68)
2018-05-01 17:42:56.644  INFO 17168 --- [Executor task launch worker for task 68] org.apache.spark.storage.BlockManager    : Found block rdd_3_0 locally
2018-05-01 17:42:56.981  INFO 17168 --- [Executor task launch worker for task 68] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 3.0 (TID 68). 1070 bytes result sent to driver
2018-05-01 17:42:56.982  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 3.0 (TID 69, localhost, executor driver, partition 1, PROCESS_LOCAL, 5072 bytes)
2018-05-01 17:42:56.983  INFO 17168 --- [Executor task launch worker for task 69] org.apache.spark.executor.Executor       : Running task 1.0 in stage 3.0 (TID 69)
2018-05-01 17:42:56.985  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 3.0 (TID 68) in 4375 ms on localhost (executor driver) (1/2)
2018-05-01 17:42:57.004  INFO 17168 --- [Executor task launch worker for task 69] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 3.0 (TID 69). 812 bytes result sent to driver
2018-05-01 17:42:57.005  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 3.0 (TID 69) in 24 ms on localhost (executor driver) (2/2)
2018-05-01 17:42:57.006  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-05-01 17:42:57.006  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 3 (mapPartitions at ALS.scala:1101) finished in 4.396 s
2018-05-01 17:42:57.006  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:57.007  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:57.009  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 5, ShuffleMapStage 4)
2018-05-01 17:42:57.009  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:57.014  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:42:57.018  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 1954.8 MB)
2018-05-01 17:42:57.020  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1954.8 MB)
2018-05-01 17:42:57.021  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_5_piece0 in memory on 172.21.241.193:58363 (size: 3.7 KB, free: 1954.8 MB)
2018-05-01 17:42:57.022  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:57.022  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:42:57.023  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 4.0 with 2 tasks
2018-05-01 17:42:57.024  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 4.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:42:57.024  INFO 17168 --- [Executor task launch worker for task 70] org.apache.spark.executor.Executor       : Running task 0.0 in stage 4.0 (TID 70)
2018-05-01 17:42:57.036  INFO 17168 --- [Executor task launch worker for task 70] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 2 blocks
2018-05-01 17:42:57.037  INFO 17168 --- [Executor task launch worker for task 70] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 3 ms
2018-05-01 17:42:57.048  INFO 17168 --- [Executor task launch worker for task 70] o.a.spark.storage.memory.MemoryStore     : Block rdd_9_0 stored as values in memory (estimated size 16.0 B, free 1954.8 MB)
2018-05-01 17:42:57.049  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_9_0 in memory on 172.21.241.193:58363 (size: 16.0 B, free: 1954.8 MB)
2018-05-01 17:42:57.056  INFO 17168 --- [Executor task launch worker for task 70] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 4.0 (TID 70). 1852 bytes result sent to driver
2018-05-01 17:42:57.057  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 4.0 (TID 71, localhost, executor driver, partition 1, ANY, 4610 bytes)
2018-05-01 17:42:57.057  INFO 17168 --- [Executor task launch worker for task 71] org.apache.spark.executor.Executor       : Running task 1.0 in stage 4.0 (TID 71)
2018-05-01 17:42:57.057  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 4.0 (TID 70) in 34 ms on localhost (executor driver) (1/2)
2018-05-01 17:42:57.059  INFO 17168 --- [Executor task launch worker for task 71] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 2 non-empty blocks out of 2 blocks
2018-05-01 17:42:57.059  INFO 17168 --- [Executor task launch worker for task 71] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:42:57.205  INFO 17168 --- [Executor task launch worker for task 71] o.a.spark.storage.memory.MemoryStore     : Block rdd_9_1 stored as values in memory (estimated size 12.0 MB, free 1942.8 MB)
2018-05-01 17:42:57.206  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_9_1 in memory on 172.21.241.193:58363 (size: 12.0 MB, free: 1942.8 MB)
2018-05-01 17:42:57.409  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_4_piece0 on 172.21.241.193:58363 in memory (size: 3.2 KB, free: 1942.8 MB)
2018-05-01 17:42:57.588  INFO 17168 --- [Executor task launch worker for task 71] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 4.0 (TID 71). 1938 bytes result sent to driver
2018-05-01 17:42:57.588  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 4.0 (TID 71) in 531 ms on localhost (executor driver) (2/2)
2018-05-01 17:42:57.588  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 4 (map at ALS.scala:1344) finished in 0.565 s
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 5)
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:57.589  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 5 (userOutBlocks MapPartitionsRDD[13] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:42:57.590  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6 stored as values in memory (estimated size 7.7 KB, free 1942.8 MB)
2018-05-01 17:42:57.591  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1942.8 MB)
2018-05-01 17:42:57.592  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_6_piece0 in memory on 172.21.241.193:58363 (size: 3.9 KB, free: 1942.8 MB)
2018-05-01 17:42:57.592  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:57.593  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 5 (userOutBlocks MapPartitionsRDD[13] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:57.593  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 5.0 with 1 tasks
2018-05-01 17:42:57.593  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 5.0 (TID 72, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:42:57.593  INFO 17168 --- [Executor task launch worker for task 72] org.apache.spark.executor.Executor       : Running task 0.0 in stage 5.0 (TID 72)
2018-05-01 17:42:57.595  INFO 17168 --- [Executor task launch worker for task 72] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:42:57.595  INFO 17168 --- [Executor task launch worker for task 72] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:42:58.031  INFO 17168 --- [Executor task launch worker for task 72] o.a.spark.storage.memory.MemoryStore     : Block rdd_12_0 stored as values in memory (estimated size 8.1 MB, free 1934.7 MB)
2018-05-01 17:42:58.032  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_12_0 in memory on 172.21.241.193:58363 (size: 8.1 MB, free: 1934.7 MB)
2018-05-01 17:42:58.041  INFO 17168 --- [Executor task launch worker for task 72] o.a.spark.storage.memory.MemoryStore     : Block rdd_13_0 stored as values in memory (estimated size 27.9 KB, free 1934.7 MB)
2018-05-01 17:42:58.042  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_13_0 in memory on 172.21.241.193:58363 (size: 27.9 KB, free: 1934.7 MB)
2018-05-01 17:42:58.043  INFO 17168 --- [Executor task launch worker for task 72] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 5.0 (TID 72). 1834 bytes result sent to driver
2018-05-01 17:42:58.043  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 5.0 (TID 72) in 450 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:58.043  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-05-01 17:42:58.044  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 5 (count at ALS.scala:857) finished in 0.450 s
2018-05-01 17:42:58.044  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 3 finished: count at ALS.scala:857, took 5.452494 s
2018-05-01 17:42:58.063  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:865
2018-05-01 17:42:58.067  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:42:58.068  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 15 (map at ALS.scala:1344)
2018-05-01 17:42:58.068  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 4 (count at ALS.scala:865) with 1 output partitions
2018-05-01 17:42:58.069  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 8 (count at ALS.scala:865)
2018-05-01 17:42:58.069  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 7)
2018-05-01 17:42:58.070  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 7)
2018-05-01 17:42:58.070  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 7 (MapPartitionsRDD[15] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:42:58.071  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7 stored as values in memory (estimated size 7.3 KB, free 1934.7 MB)
2018-05-01 17:42:58.073  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1934.7 MB)
2018-05-01 17:42:58.074  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_7_piece0 in memory on 172.21.241.193:58363 (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:42:58.074  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:58.075  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[15] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:42:58.075  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 7.0 with 2 tasks
2018-05-01 17:42:58.075  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 7.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:42:58.075  INFO 17168 --- [Executor task launch worker for task 73] org.apache.spark.executor.Executor       : Running task 0.0 in stage 7.0 (TID 73)
2018-05-01 17:42:58.077  INFO 17168 --- [Executor task launch worker for task 73] org.apache.spark.storage.BlockManager    : Found block rdd_9_0 locally
2018-05-01 17:42:58.082  INFO 17168 --- [Executor task launch worker for task 73] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 7.0 (TID 73). 725 bytes result sent to driver
2018-05-01 17:42:58.082  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 7.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:42:58.082  INFO 17168 --- [Executor task launch worker for task 74] org.apache.spark.executor.Executor       : Running task 1.0 in stage 7.0 (TID 74)
2018-05-01 17:42:58.083  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 7.0 (TID 73) in 7 ms on localhost (executor driver) (1/2)
2018-05-01 17:42:58.084  INFO 17168 --- [Executor task launch worker for task 74] org.apache.spark.storage.BlockManager    : Found block rdd_9_1 locally
2018-05-01 17:42:58.343  INFO 17168 --- [Executor task launch worker for task 74] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 7.0 (TID 74). 940 bytes result sent to driver
2018-05-01 17:42:58.343  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 7.0 (TID 74) in 261 ms on localhost (executor driver) (2/2)
2018-05-01 17:42:58.344  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 7 (map at ALS.scala:1344) finished in 0.269 s
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2018-05-01 17:42:58.344  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:58.345  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 8 (itemOutBlocks MapPartitionsRDD[18] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:42:58.346  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8 stored as values in memory (estimated size 7.9 KB, free 1934.7 MB)
2018-05-01 17:42:58.348  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1934.7 MB)
2018-05-01 17:42:58.349  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_8_piece0 in memory on 172.21.241.193:58363 (size: 4.0 KB, free: 1934.7 MB)
2018-05-01 17:42:58.349  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:58.351  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 8 (itemOutBlocks MapPartitionsRDD[18] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:58.352  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 8.0 with 1 tasks
2018-05-01 17:42:58.353  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 8.0 (TID 75, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:42:58.353  INFO 17168 --- [Executor task launch worker for task 75] org.apache.spark.executor.Executor       : Running task 0.0 in stage 8.0 (TID 75)
2018-05-01 17:42:58.356  INFO 17168 --- [Executor task launch worker for task 75] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:42:58.356  INFO 17168 --- [Executor task launch worker for task 75] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:42:58.480  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_5_piece0 on 172.21.241.193:58363 in memory (size: 3.7 KB, free: 1934.7 MB)
2018-05-01 17:42:58.481  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_6_piece0 on 172.21.241.193:58363 in memory (size: 3.9 KB, free: 1934.7 MB)
2018-05-01 17:42:58.482  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_7_piece0 on 172.21.241.193:58363 in memory (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:42:59.639  INFO 17168 --- [Executor task launch worker for task 75] o.a.spark.storage.memory.MemoryStore     : Block rdd_17_0 stored as values in memory (estimated size 8.1 MB, free 1926.6 MB)
2018-05-01 17:42:59.640  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_17_0 in memory on 172.21.241.193:58363 (size: 8.1 MB, free: 1926.6 MB)
2018-05-01 17:42:59.645  INFO 17168 --- [Executor task launch worker for task 75] o.a.spark.storage.memory.MemoryStore     : Block rdd_18_0 stored as values in memory (estimated size 54.9 KB, free 1926.5 MB)
2018-05-01 17:42:59.646  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_18_0 in memory on 172.21.241.193:58363 (size: 54.9 KB, free: 1926.6 MB)
2018-05-01 17:42:59.646  INFO 17168 --- [Executor task launch worker for task 75] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 8.0 (TID 75). 1920 bytes result sent to driver
2018-05-01 17:42:59.647  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 8.0 (TID 75) in 1294 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:59.647  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-05-01 17:42:59.648  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 8 (count at ALS.scala:865) finished in 1.295 s
2018-05-01 17:42:59.649  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 4 finished: count at ALS.scala:865, took 1.585610 s
2018-05-01 17:42:59.675  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:42:59.676  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:42:59.677  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:42:59.677  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 5 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:42:59.677  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 11 (aggregate at ALS.scala:1491)
2018-05-01 17:42:59.677  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 10)
2018-05-01 17:42:59.678  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:42:59.678  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 11 (MapPartitionsRDD[21] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:42:59.679  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9 stored as values in memory (estimated size 9.1 KB, free 1926.5 MB)
2018-05-01 17:42:59.680  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.5 MB)
2018-05-01 17:42:59.681  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_9_piece0 in memory on 172.21.241.193:58363 (size: 4.3 KB, free: 1926.5 MB)
2018-05-01 17:42:59.682  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:59.682  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:59.682  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 11.0 with 1 tasks
2018-05-01 17:42:59.682  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 11.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
2018-05-01 17:42:59.684  INFO 17168 --- [Executor task launch worker for task 76] org.apache.spark.executor.Executor       : Running task 0.0 in stage 11.0 (TID 76)
2018-05-01 17:42:59.689  INFO 17168 --- [Executor task launch worker for task 76] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:42:59.692  WARN 17168 --- [Executor task launch worker for task 76] com.github.fommil.netlib.BLAS            : Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-05-01 17:42:59.692  WARN 17168 --- [Executor task launch worker for task 76] com.github.fommil.netlib.BLAS            : Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-05-01 17:42:59.709  INFO 17168 --- [Executor task launch worker for task 76] o.a.spark.storage.memory.MemoryStore     : Block rdd_19_0 stored as values in memory (estimated size 416.2 KB, free 1926.1 MB)
2018-05-01 17:42:59.709  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_19_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1926.1 MB)
2018-05-01 17:42:59.716  INFO 17168 --- [Executor task launch worker for task 76] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 11.0 (TID 76). 2208 bytes result sent to driver
2018-05-01 17:42:59.717  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 11.0 (TID 76) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:59.717  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-05-01 17:42:59.717  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 11 (aggregate at ALS.scala:1491) finished in 0.035 s
2018-05-01 17:42:59.718  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 5 finished: aggregate at ALS.scala:1491, took 0.043108 s
2018-05-01 17:42:59.750  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 20 from persistence list
2018-05-01 17:42:59.755  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 20
2018-05-01 17:42:59.764  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:42:59.766  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 19 (map at ALS.scala:1017)
2018-05-01 17:42:59.766  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 25 (flatMap at ALS.scala:1433)
2018-05-01 17:42:59.766  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:42:59.767  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 6 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:42:59.767  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 17 (aggregate at ALS.scala:1491)
2018-05-01 17:42:59.767  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 16)
2018-05-01 17:42:59.767  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 15)
2018-05-01 17:42:59.768  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[19] at map at ALS.scala:1017), which has no missing parents
2018-05-01 17:42:59.769  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10 stored as values in memory (estimated size 7.7 KB, free 1926.1 MB)
2018-05-01 17:42:59.770  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1926.1 MB)
2018-05-01 17:42:59.771  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_10_piece0 in memory on 172.21.241.193:58363 (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:42:59.771  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:59.772  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[19] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:59.772  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 14.0 with 1 tasks
2018-05-01 17:42:59.773  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 14.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:42:59.773  INFO 17168 --- [Executor task launch worker for task 77] org.apache.spark.executor.Executor       : Running task 0.0 in stage 14.0 (TID 77)
2018-05-01 17:42:59.774  INFO 17168 --- [Executor task launch worker for task 77] org.apache.spark.storage.BlockManager    : Found block rdd_19_0 locally
2018-05-01 17:42:59.800  INFO 17168 --- [Executor task launch worker for task 77] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 14.0 (TID 77). 940 bytes result sent to driver
2018-05-01 17:42:59.801  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 14.0 (TID 77) in 29 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:59.802  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 14 (map at ALS.scala:1017) finished in 0.030 s
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 15, ResultStage 17)
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:59.802  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 15 (MapPartitionsRDD[25] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:42:59.803  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11 stored as values in memory (estimated size 8.8 KB, free 1926.1 MB)
2018-05-01 17:42:59.805  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.1 MB)
2018-05-01 17:42:59.805  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_11_piece0 in memory on 172.21.241.193:58363 (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 17:42:59.805  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:59.806  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[25] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:59.806  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 15.0 with 1 tasks
2018-05-01 17:42:59.808  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 15.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-05-01 17:42:59.808  INFO 17168 --- [Executor task launch worker for task 78] org.apache.spark.executor.Executor       : Running task 0.0 in stage 15.0 (TID 78)
2018-05-01 17:42:59.812  INFO 17168 --- [Executor task launch worker for task 78] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:42:59.812  INFO 17168 --- [Executor task launch worker for task 78] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:42:59.812  INFO 17168 --- [Executor task launch worker for task 78] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:42:59.849  INFO 17168 --- [Executor task launch worker for task 78] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 15.0 (TID 78). 1327 bytes result sent to driver
2018-05-01 17:42:59.849  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 15.0 (TID 78) in 42 ms on localhost (executor driver) (1/1)
2018-05-01 17:42:59.850  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 15 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 17)
2018-05-01 17:42:59.850  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:42:59.851  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 17 (MapPartitionsRDD[31] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:42:59.854  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12 stored as values in memory (estimated size 12.6 KB, free 1926.1 MB)
2018-05-01 17:42:59.855  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1926.1 MB)
2018-05-01 17:42:59.856  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_12_piece0 in memory on 172.21.241.193:58363 (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 17:42:59.857  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:42:59.859  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[31] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:42:59.859  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 17.0 with 1 tasks
2018-05-01 17:42:59.859  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 17.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:42:59.859  INFO 17168 --- [Executor task launch worker for task 79] org.apache.spark.executor.Executor       : Running task 0.0 in stage 17.0 (TID 79)
2018-05-01 17:42:59.863  INFO 17168 --- [Executor task launch worker for task 79] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:42:59.863  INFO 17168 --- [Executor task launch worker for task 79] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:42:59.863  INFO 17168 --- [Executor task launch worker for task 79] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:42:59.879  WARN 17168 --- [Executor task launch worker for task 79] com.github.fommil.netlib.LAPACK          : Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-05-01 17:42:59.879  WARN 17168 --- [Executor task launch worker for task 79] com.github.fommil.netlib.LAPACK          : Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-05-01 17:43:00.222  INFO 17168 --- [Executor task launch worker for task 79] o.a.spark.storage.memory.MemoryStore     : Block rdd_30_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:43:00.223  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_30_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:43:00.226  INFO 17168 --- [Executor task launch worker for task 79] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 17.0 (TID 79). 2595 bytes result sent to driver
2018-05-01 17:43:00.226  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 17.0 (TID 79) in 367 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.226  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.227  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 17 (aggregate at ALS.scala:1491) finished in 0.368 s
2018-05-01 17:43:00.227  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 6 finished: aggregate at ALS.scala:1491, took 0.463461 s
2018-05-01 17:43:00.246  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 19 from persistence list
2018-05-01 17:43:00.247  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 19
2018-05-01 17:43:00.257  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:00.258  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:00.258  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:00.259  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:00.259  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:00.259  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 35 (flatMap at ALS.scala:1433)
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 7 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 24 (aggregate at ALS.scala:1491)
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 19, ShuffleMapStage 23)
2018-05-01 17:43:00.260  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 23)
2018-05-01 17:43:00.261  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 23 (MapPartitionsRDD[35] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:00.262  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13 stored as values in memory (estimated size 11.8 KB, free 1925.7 MB)
2018-05-01 17:43:00.263  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.6 KB, free 1925.7 MB)
2018-05-01 17:43:00.265  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_13_piece0 in memory on 172.21.241.193:58363 (size: 5.6 KB, free: 1925.7 MB)
2018-05-01 17:43:00.266  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.266  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[35] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.266  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 23.0 with 1 tasks
2018-05-01 17:43:00.266  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 23.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:00.267  INFO 17168 --- [Executor task launch worker for task 80] org.apache.spark.executor.Executor       : Running task 0.0 in stage 23.0 (TID 80)
2018-05-01 17:43:00.269  INFO 17168 --- [Executor task launch worker for task 80] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:00.269  INFO 17168 --- [Executor task launch worker for task 80] org.apache.spark.storage.BlockManager    : Found block rdd_30_0 locally
2018-05-01 17:43:00.300  INFO 17168 --- [Executor task launch worker for task 80] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 23.0 (TID 80). 1069 bytes result sent to driver
2018-05-01 17:43:00.301  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 23.0 (TID 80) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.301  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 23 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 24)
2018-05-01 17:43:00.301  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:00.302  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 24 (MapPartitionsRDD[41] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:00.303  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_14 stored as values in memory (estimated size 14.3 KB, free 1925.7 MB)
2018-05-01 17:43:00.305  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1925.6 MB)
2018-05-01 17:43:00.306  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_14_piece0 in memory on 172.21.241.193:58363 (size: 6.6 KB, free: 1925.7 MB)
2018-05-01 17:43:00.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[41] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.306  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 24.0 with 1 tasks
2018-05-01 17:43:00.307  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 24.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:00.307  INFO 17168 --- [Executor task launch worker for task 81] org.apache.spark.executor.Executor       : Running task 0.0 in stage 24.0 (TID 81)
2018-05-01 17:43:00.309  INFO 17168 --- [Executor task launch worker for task 81] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:00.309  INFO 17168 --- [Executor task launch worker for task 81] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:00.309  INFO 17168 --- [Executor task launch worker for task 81] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:00.587  INFO 17168 --- [Executor task launch worker for task 81] o.a.spark.storage.memory.MemoryStore     : Block rdd_40_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:43:00.588  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_40_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:43:00.590  INFO 17168 --- [Executor task launch worker for task 81] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 24.0 (TID 81). 2638 bytes result sent to driver
2018-05-01 17:43:00.591  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 24.0 (TID 81) in 284 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.591  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 24.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.591  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 24 (aggregate at ALS.scala:1491) finished in 0.285 s
2018-05-01 17:43:00.592  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 7 finished: aggregate at ALS.scala:1491, took 0.334248 s
2018-05-01 17:43:00.610  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 30 from persistence list
2018-05-01 17:43:00.610  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 30
2018-05-01 17:43:00.615  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:00.616  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:00.616  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:00.617  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:00.617  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:00.618  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:00.619  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:00.619  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 45 (flatMap at ALS.scala:1433)
2018-05-01 17:43:00.619  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 8 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:00.620  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 32 (aggregate at ALS.scala:1491)
2018-05-01 17:43:00.620  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 31, ShuffleMapStage 28)
2018-05-01 17:43:00.620  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 31)
2018-05-01 17:43:00.621  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 31 (MapPartitionsRDD[45] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:00.623  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_15 stored as values in memory (estimated size 13.4 KB, free 1926.0 MB)
2018-05-01 17:43:00.624  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1926.0 MB)
2018-05-01 17:43:00.624  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_15_piece0 in memory on 172.21.241.193:58363 (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:43:00.624  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.625  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[45] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.625  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 31.0 with 1 tasks
2018-05-01 17:43:00.625  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 31.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:00.625  INFO 17168 --- [Executor task launch worker for task 82] org.apache.spark.executor.Executor       : Running task 0.0 in stage 31.0 (TID 82)
2018-05-01 17:43:00.627  INFO 17168 --- [Executor task launch worker for task 82] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:00.627  INFO 17168 --- [Executor task launch worker for task 82] org.apache.spark.storage.BlockManager    : Found block rdd_40_0 locally
2018-05-01 17:43:00.656  INFO 17168 --- [Executor task launch worker for task 82] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 31.0 (TID 82). 1069 bytes result sent to driver
2018-05-01 17:43:00.657  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 31.0 (TID 82) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.657  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 31.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.657  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 31 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:43:00.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:00.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:00.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 32)
2018-05-01 17:43:00.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:00.659  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 32 (MapPartitionsRDD[51] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:00.660  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_16 stored as values in memory (estimated size 15.8 KB, free 1926.0 MB)
2018-05-01 17:43:00.661  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1926.0 MB)
2018-05-01 17:43:00.661  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_16_piece0 in memory on 172.21.241.193:58363 (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 17:43:00.662  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.662  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[51] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.662  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 32.0 with 1 tasks
2018-05-01 17:43:00.662  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 32.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:00.663  INFO 17168 --- [Executor task launch worker for task 83] org.apache.spark.executor.Executor       : Running task 0.0 in stage 32.0 (TID 83)
2018-05-01 17:43:00.665  INFO 17168 --- [Executor task launch worker for task 83] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:00.666  INFO 17168 --- [Executor task launch worker for task 83] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:00.666  INFO 17168 --- [Executor task launch worker for task 83] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:00.943  INFO 17168 --- [Executor task launch worker for task 83] o.a.spark.storage.memory.MemoryStore     : Block rdd_50_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 17:43:00.944  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_50_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:43:00.947  INFO 17168 --- [Executor task launch worker for task 83] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 32.0 (TID 83). 2595 bytes result sent to driver
2018-05-01 17:43:00.948  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 32.0 (TID 83) in 286 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:00.948  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 32.0, whose tasks have all completed, from pool 
2018-05-01 17:43:00.948  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 32 (aggregate at ALS.scala:1491) finished in 0.286 s
2018-05-01 17:43:00.948  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 8 finished: aggregate at ALS.scala:1491, took 0.332756 s
2018-05-01 17:43:00.969  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 40 from persistence list
2018-05-01 17:43:00.970  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 40
2018-05-01 17:43:00.976  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:00.976  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:00.977  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:00.977  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:00.978  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:00.978  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:00.979  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:00.979  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:00.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 55 (flatMap at ALS.scala:1433)
2018-05-01 17:43:00.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 9 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:00.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 41 (aggregate at ALS.scala:1491)
2018-05-01 17:43:00.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 40)
2018-05-01 17:43:00.981  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 40)
2018-05-01 17:43:00.981  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 40 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:00.983  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_17 stored as values in memory (estimated size 14.9 KB, free 1925.6 MB)
2018-05-01 17:43:00.984  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1925.6 MB)
2018-05-01 17:43:00.985  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_17_piece0 in memory on 172.21.241.193:58363 (size: 7.0 KB, free: 1925.7 MB)
2018-05-01 17:43:00.985  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:00.986  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:00.986  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 40.0 with 1 tasks
2018-05-01 17:43:00.987  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 40.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:00.987  INFO 17168 --- [Executor task launch worker for task 84] org.apache.spark.executor.Executor       : Running task 0.0 in stage 40.0 (TID 84)
2018-05-01 17:43:00.989  INFO 17168 --- [Executor task launch worker for task 84] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:00.989  INFO 17168 --- [Executor task launch worker for task 84] org.apache.spark.storage.BlockManager    : Found block rdd_50_0 locally
2018-05-01 17:43:01.026  INFO 17168 --- [Executor task launch worker for task 84] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 40.0 (TID 84). 1069 bytes result sent to driver
2018-05-01 17:43:01.026  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 40.0 (TID 84) in 40 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.026  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 40.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.026  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 40 (flatMap at ALS.scala:1433) finished in 0.040 s
2018-05-01 17:43:01.026  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:01.027  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:01.027  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 41)
2018-05-01 17:43:01.027  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:01.027  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 41 (MapPartitionsRDD[61] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:01.028  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_18 stored as values in memory (estimated size 17.4 KB, free 1925.6 MB)
2018-05-01 17:43:01.030  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_18_piece0 stored as bytes in memory (estimated size 7.9 KB, free 1925.6 MB)
2018-05-01 17:43:01.030  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_18_piece0 in memory on 172.21.241.193:58363 (size: 7.9 KB, free: 1925.7 MB)
2018-05-01 17:43:01.031  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.031  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[61] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.031  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 41.0 with 1 tasks
2018-05-01 17:43:01.032  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 41.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:01.033  INFO 17168 --- [Executor task launch worker for task 85] org.apache.spark.executor.Executor       : Running task 0.0 in stage 41.0 (TID 85)
2018-05-01 17:43:01.035  INFO 17168 --- [Executor task launch worker for task 85] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:01.035  INFO 17168 --- [Executor task launch worker for task 85] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:01.035  INFO 17168 --- [Executor task launch worker for task 85] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:01.299  INFO 17168 --- [Executor task launch worker for task 85] o.a.spark.storage.memory.MemoryStore     : Block rdd_60_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:43:01.301  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_60_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:43:01.305  INFO 17168 --- [Executor task launch worker for task 85] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 41.0 (TID 85). 2595 bytes result sent to driver
2018-05-01 17:43:01.305  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 41.0 (TID 85) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.305  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 41.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 41 (aggregate at ALS.scala:1491) finished in 0.274 s
2018-05-01 17:43:01.306  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 9 finished: aggregate at ALS.scala:1491, took 0.330251 s
2018-05-01 17:43:01.324  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 50 from persistence list
2018-05-01 17:43:01.324  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 50
2018-05-01 17:43:01.330  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:01.330  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:01.331  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:01.331  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:01.331  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:01.332  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:01.332  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:01.332  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 65 (flatMap at ALS.scala:1433)
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 10 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 51 (aggregate at ALS.scala:1491)
2018-05-01 17:43:01.333  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 45, ShuffleMapStage 50)
2018-05-01 17:43:01.334  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 50)
2018-05-01 17:43:01.334  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 50 (MapPartitionsRDD[65] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:01.336  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_19 stored as values in memory (estimated size 16.5 KB, free 1925.9 MB)
2018-05-01 17:43:01.337  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.8 KB, free 1925.9 MB)
2018-05-01 17:43:01.337  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_19_piece0 in memory on 172.21.241.193:58363 (size: 7.8 KB, free: 1926.1 MB)
2018-05-01 17:43:01.338  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.338  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[65] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.338  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 50.0 with 1 tasks
2018-05-01 17:43:01.338  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 50.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:01.339  INFO 17168 --- [Executor task launch worker for task 86] org.apache.spark.executor.Executor       : Running task 0.0 in stage 50.0 (TID 86)
2018-05-01 17:43:01.340  INFO 17168 --- [Executor task launch worker for task 86] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:01.340  INFO 17168 --- [Executor task launch worker for task 86] org.apache.spark.storage.BlockManager    : Found block rdd_60_0 locally
2018-05-01 17:43:01.366  INFO 17168 --- [Executor task launch worker for task 86] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 50.0 (TID 86). 1026 bytes result sent to driver
2018-05-01 17:43:01.366  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 50.0 (TID 86) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.366  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 50.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 50 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 51)
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:01.367  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 51 (MapPartitionsRDD[71] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:01.369  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_20 stored as values in memory (estimated size 18.9 KB, free 1925.9 MB)
2018-05-01 17:43:01.370  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1925.9 MB)
2018-05-01 17:43:01.370  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_20_piece0 in memory on 172.21.241.193:58363 (size: 8.6 KB, free: 1926.1 MB)
2018-05-01 17:43:01.370  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.370  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[71] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.370  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 51.0 with 1 tasks
2018-05-01 17:43:01.371  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 51.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:01.371  INFO 17168 --- [Executor task launch worker for task 87] org.apache.spark.executor.Executor       : Running task 0.0 in stage 51.0 (TID 87)
2018-05-01 17:43:01.373  INFO 17168 --- [Executor task launch worker for task 87] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:01.373  INFO 17168 --- [Executor task launch worker for task 87] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:01.373  INFO 17168 --- [Executor task launch worker for task 87] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:01.654  INFO 17168 --- [Executor task launch worker for task 87] o.a.spark.storage.memory.MemoryStore     : Block rdd_70_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 17:43:01.654  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_70_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:43:01.657  INFO 17168 --- [Executor task launch worker for task 87] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 51.0 (TID 87). 2595 bytes result sent to driver
2018-05-01 17:43:01.658  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 51.0 (TID 87) in 287 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.658  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 51.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.658  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 51 (aggregate at ALS.scala:1491) finished in 0.287 s
2018-05-01 17:43:01.659  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 10 finished: aggregate at ALS.scala:1491, took 0.329520 s
2018-05-01 17:43:01.678  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 60 from persistence list
2018-05-01 17:43:01.678  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 60
2018-05-01 17:43:01.684  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:01.685  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:01.685  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:01.686  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:01.686  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:01.686  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:01.687  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:01.687  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:01.687  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:01.687  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 75 (flatMap at ALS.scala:1433)
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 11 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 62 (aggregate at ALS.scala:1491)
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 53, ShuffleMapStage 61)
2018-05-01 17:43:01.688  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 61)
2018-05-01 17:43:01.689  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 61 (MapPartitionsRDD[75] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:01.691  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_21 stored as values in memory (estimated size 18.0 KB, free 1925.5 MB)
2018-05-01 17:43:01.692  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1925.5 MB)
2018-05-01 17:43:01.693  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_21_piece0 in memory on 172.21.241.193:58363 (size: 8.4 KB, free: 1925.7 MB)
2018-05-01 17:43:01.693  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.693  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[75] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.694  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 61.0 with 1 tasks
2018-05-01 17:43:01.694  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 61.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:01.694  INFO 17168 --- [Executor task launch worker for task 88] org.apache.spark.executor.Executor       : Running task 0.0 in stage 61.0 (TID 88)
2018-05-01 17:43:01.696  INFO 17168 --- [Executor task launch worker for task 88] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:01.696  INFO 17168 --- [Executor task launch worker for task 88] org.apache.spark.storage.BlockManager    : Found block rdd_70_0 locally
2018-05-01 17:43:01.732  INFO 17168 --- [Executor task launch worker for task 88] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 61.0 (TID 88). 1069 bytes result sent to driver
2018-05-01 17:43:01.733  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 61.0 (TID 88) in 39 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:01.733  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 61.0, whose tasks have all completed, from pool 
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 61 (flatMap at ALS.scala:1433) finished in 0.039 s
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 62)
2018-05-01 17:43:01.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:01.734  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 62 (MapPartitionsRDD[81] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:01.735  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_22 stored as values in memory (estimated size 20.5 KB, free 1925.5 MB)
2018-05-01 17:43:01.737  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.2 KB, free 1925.5 MB)
2018-05-01 17:43:01.737  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_22_piece0 in memory on 172.21.241.193:58363 (size: 9.2 KB, free: 1925.7 MB)
2018-05-01 17:43:01.738  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:01.738  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[81] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:01.738  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 62.0 with 1 tasks
2018-05-01 17:43:01.738  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 62.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:01.739  INFO 17168 --- [Executor task launch worker for task 89] org.apache.spark.executor.Executor       : Running task 0.0 in stage 62.0 (TID 89)
2018-05-01 17:43:01.741  INFO 17168 --- [Executor task launch worker for task 89] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:01.741  INFO 17168 --- [Executor task launch worker for task 89] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:01.741  INFO 17168 --- [Executor task launch worker for task 89] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:02.008  INFO 17168 --- [Executor task launch worker for task 89] o.a.spark.storage.memory.MemoryStore     : Block rdd_80_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 17:43:02.009  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_80_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:43:02.011  INFO 17168 --- [Executor task launch worker for task 89] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 62.0 (TID 89). 2595 bytes result sent to driver
2018-05-01 17:43:02.011  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 62.0 (TID 89) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.011  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 62.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.012  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 62 (aggregate at ALS.scala:1491) finished in 0.274 s
2018-05-01 17:43:02.012  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 11 finished: aggregate at ALS.scala:1491, took 0.328132 s
2018-05-01 17:43:02.033  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 70 from persistence list
2018-05-01 17:43:02.034  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 70
2018-05-01 17:43:02.040  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:02.041  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:02.041  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:02.042  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:02.042  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:02.043  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:02.044  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:02.044  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:02.045  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:02.045  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:02.045  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:02.045  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 85 (flatMap at ALS.scala:1433)
2018-05-01 17:43:02.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 12 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:02.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 74 (aggregate at ALS.scala:1491)
2018-05-01 17:43:02.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 66, ShuffleMapStage 73)
2018-05-01 17:43:02.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 73)
2018-05-01 17:43:02.047  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 73 (MapPartitionsRDD[85] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:02.048  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_23 stored as values in memory (estimated size 19.6 KB, free 1925.8 MB)
2018-05-01 17:43:02.049  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.1 KB, free 1925.8 MB)
2018-05-01 17:43:02.051  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_23_piece0 in memory on 172.21.241.193:58363 (size: 9.1 KB, free: 1926.0 MB)
2018-05-01 17:43:02.051  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.051  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[85] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.051  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 73.0 with 1 tasks
2018-05-01 17:43:02.052  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 73.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:02.052  INFO 17168 --- [Executor task launch worker for task 90] org.apache.spark.executor.Executor       : Running task 0.0 in stage 73.0 (TID 90)
2018-05-01 17:43:02.054  INFO 17168 --- [Executor task launch worker for task 90] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:02.054  INFO 17168 --- [Executor task launch worker for task 90] org.apache.spark.storage.BlockManager    : Found block rdd_80_0 locally
2018-05-01 17:43:02.080  INFO 17168 --- [Executor task launch worker for task 90] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 73.0 (TID 90). 1069 bytes result sent to driver
2018-05-01 17:43:02.080  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 73.0 (TID 90) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.080  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 73.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 73 (flatMap at ALS.scala:1433) finished in 0.028 s
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 74)
2018-05-01 17:43:02.080  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:02.081  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 74 (MapPartitionsRDD[91] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:02.082  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_24 stored as values in memory (estimated size 22.0 KB, free 1925.8 MB)
2018-05-01 17:43:02.083  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.9 KB, free 1925.8 MB)
2018-05-01 17:43:02.083  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_24_piece0 in memory on 172.21.241.193:58363 (size: 9.9 KB, free: 1926.0 MB)
2018-05-01 17:43:02.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[91] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.085  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 74.0 with 1 tasks
2018-05-01 17:43:02.085  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 74.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:02.085  INFO 17168 --- [Executor task launch worker for task 91] org.apache.spark.executor.Executor       : Running task 0.0 in stage 74.0 (TID 91)
2018-05-01 17:43:02.088  INFO 17168 --- [Executor task launch worker for task 91] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:02.088  INFO 17168 --- [Executor task launch worker for task 91] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:02.088  INFO 17168 --- [Executor task launch worker for task 91] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:02.382  INFO 17168 --- [Executor task launch worker for task 91] o.a.spark.storage.memory.MemoryStore     : Block rdd_90_0 stored as values in memory (estimated size 820.5 KB, free 1925.0 MB)
2018-05-01 17:43:02.382  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_90_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:43:02.386  INFO 17168 --- [Executor task launch worker for task 91] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 74.0 (TID 91). 2595 bytes result sent to driver
2018-05-01 17:43:02.387  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 74.0 (TID 91) in 302 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.387  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 74.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.387  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 74 (aggregate at ALS.scala:1491) finished in 0.302 s
2018-05-01 17:43:02.388  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 12 finished: aggregate at ALS.scala:1491, took 0.347280 s
2018-05-01 17:43:02.404  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 80 from persistence list
2018-05-01 17:43:02.405  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 80
2018-05-01 17:43:02.409  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:02.410  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:02.411  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:02.411  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:02.411  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:02.411  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:02.412  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:02.413  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:02.413  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 95 (flatMap at ALS.scala:1433)
2018-05-01 17:43:02.414  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 13 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:02.414  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 87 (aggregate at ALS.scala:1491)
2018-05-01 17:43:02.414  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 86, ShuffleMapStage 76)
2018-05-01 17:43:02.415  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 86)
2018-05-01 17:43:02.415  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 86 (MapPartitionsRDD[95] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:02.417  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_25 stored as values in memory (estimated size 21.1 KB, free 1925.4 MB)
2018-05-01 17:43:02.419  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1925.4 MB)
2018-05-01 17:43:02.419  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_25_piece0 in memory on 172.21.241.193:58363 (size: 9.7 KB, free: 1925.6 MB)
2018-05-01 17:43:02.419  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.420  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[95] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.420  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 86.0 with 1 tasks
2018-05-01 17:43:02.421  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 86.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:02.421  INFO 17168 --- [Executor task launch worker for task 92] org.apache.spark.executor.Executor       : Running task 0.0 in stage 86.0 (TID 92)
2018-05-01 17:43:02.423  INFO 17168 --- [Executor task launch worker for task 92] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:02.423  INFO 17168 --- [Executor task launch worker for task 92] org.apache.spark.storage.BlockManager    : Found block rdd_90_0 locally
2018-05-01 17:43:02.452  INFO 17168 --- [Executor task launch worker for task 92] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 86.0 (TID 92). 1069 bytes result sent to driver
2018-05-01 17:43:02.453  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 86.0 (TID 92) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.453  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 86.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 86 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 87)
2018-05-01 17:43:02.453  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:02.454  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 87 (MapPartitionsRDD[101] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:02.456  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_26 stored as values in memory (estimated size 23.6 KB, free 1925.3 MB)
2018-05-01 17:43:02.457  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_26_piece0 stored as bytes in memory (estimated size 10.6 KB, free 1925.3 MB)
2018-05-01 17:43:02.457  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_26_piece0 in memory on 172.21.241.193:58363 (size: 10.6 KB, free: 1925.6 MB)
2018-05-01 17:43:02.458  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.458  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[101] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.458  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 87.0 with 1 tasks
2018-05-01 17:43:02.458  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 87.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:02.458  INFO 17168 --- [Executor task launch worker for task 93] org.apache.spark.executor.Executor       : Running task 0.0 in stage 87.0 (TID 93)
2018-05-01 17:43:02.460  INFO 17168 --- [Executor task launch worker for task 93] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:02.460  INFO 17168 --- [Executor task launch worker for task 93] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:02.461  INFO 17168 --- [Executor task launch worker for task 93] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:43:02.730  INFO 17168 --- [Executor task launch worker for task 93] o.a.spark.storage.memory.MemoryStore     : Block rdd_100_0 stored as values in memory (estimated size 416.2 KB, free 1924.9 MB)
2018-05-01 17:43:02.731  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_100_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:43:02.733  INFO 17168 --- [Executor task launch worker for task 93] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 87.0 (TID 93). 2595 bytes result sent to driver
2018-05-01 17:43:02.733  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 87.0 (TID 93) in 275 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.733  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 87.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.733  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 87 (aggregate at ALS.scala:1491) finished in 0.275 s
2018-05-01 17:43:02.734  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 13 finished: aggregate at ALS.scala:1491, took 0.324174 s
2018-05-01 17:43:02.752  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 90 from persistence list
2018-05-01 17:43:02.752  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 90
2018-05-01 17:43:02.758  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:02.759  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:02.759  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:02.759  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:02.760  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:02.760  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:02.760  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:02.760  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:02.761  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:02.761  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:02.761  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 105 (flatMap at ALS.scala:1433)
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 14 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 101 (aggregate at ALS.scala:1491)
2018-05-01 17:43:02.762  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 100, ShuffleMapStage 91)
2018-05-01 17:43:02.763  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 100)
2018-05-01 17:43:02.763  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 100 (MapPartitionsRDD[105] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:02.765  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_27 stored as values in memory (estimated size 22.7 KB, free 1925.7 MB)
2018-05-01 17:43:02.769  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_27_piece0 stored as bytes in memory (estimated size 10.5 KB, free 1925.7 MB)
2018-05-01 17:43:02.770  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_27_piece0 in memory on 172.21.241.193:58363 (size: 10.5 KB, free: 1926.0 MB)
2018-05-01 17:43:02.770  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.770  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[105] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.770  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 100.0 with 1 tasks
2018-05-01 17:43:02.771  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 100.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:02.771  INFO 17168 --- [Executor task launch worker for task 94] org.apache.spark.executor.Executor       : Running task 0.0 in stage 100.0 (TID 94)
2018-05-01 17:43:02.773  INFO 17168 --- [Executor task launch worker for task 94] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:02.773  INFO 17168 --- [Executor task launch worker for task 94] org.apache.spark.storage.BlockManager    : Found block rdd_100_0 locally
2018-05-01 17:43:02.818  INFO 17168 --- [Executor task launch worker for task 94] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 100.0 (TID 94). 1069 bytes result sent to driver
2018-05-01 17:43:02.819  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 100.0 (TID 94) in 48 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:02.819  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 100.0, whose tasks have all completed, from pool 
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 100 (flatMap at ALS.scala:1433) finished in 0.049 s
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 101)
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:02.820  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 101 (MapPartitionsRDD[111] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:02.822  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_28 stored as values in memory (estimated size 25.1 KB, free 1925.7 MB)
2018-05-01 17:43:02.823  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.2 KB, free 1925.7 MB)
2018-05-01 17:43:02.823  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_28_piece0 in memory on 172.21.241.193:58363 (size: 11.2 KB, free: 1926.0 MB)
2018-05-01 17:43:02.823  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:02.823  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[111] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:02.823  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 101.0 with 1 tasks
2018-05-01 17:43:02.824  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 101.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:02.824  INFO 17168 --- [Executor task launch worker for task 95] org.apache.spark.executor.Executor       : Running task 0.0 in stage 101.0 (TID 95)
2018-05-01 17:43:02.826  INFO 17168 --- [Executor task launch worker for task 95] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:02.826  INFO 17168 --- [Executor task launch worker for task 95] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:02.826  INFO 17168 --- [Executor task launch worker for task 95] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:03.112  INFO 17168 --- [Executor task launch worker for task 95] o.a.spark.storage.memory.MemoryStore     : Block rdd_110_0 stored as values in memory (estimated size 820.5 KB, free 1924.9 MB)
2018-05-01 17:43:03.112  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_110_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:43:03.115  INFO 17168 --- [Executor task launch worker for task 95] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 101.0 (TID 95). 2595 bytes result sent to driver
2018-05-01 17:43:03.116  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 101.0 (TID 95) in 292 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.116  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 101.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.116  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 101 (aggregate at ALS.scala:1491) finished in 0.292 s
2018-05-01 17:43:03.117  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 14 finished: aggregate at ALS.scala:1491, took 0.358523 s
2018-05-01 17:43:03.133  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 100 from persistence list
2018-05-01 17:43:03.134  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 100
2018-05-01 17:43:03.139  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:03.140  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:03.140  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:03.141  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:03.141  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:03.141  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:03.141  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:03.142  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 115 (flatMap at ALS.scala:1433)
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 15 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 116 (aggregate at ALS.scala:1491)
2018-05-01 17:43:03.143  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 103, ShuffleMapStage 115)
2018-05-01 17:43:03.144  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 115)
2018-05-01 17:43:03.144  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 115 (MapPartitionsRDD[115] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:03.146  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_29 stored as values in memory (estimated size 24.2 KB, free 1925.2 MB)
2018-05-01 17:43:03.147  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.1 KB, free 1925.2 MB)
2018-05-01 17:43:03.147  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_29_piece0 in memory on 172.21.241.193:58363 (size: 11.1 KB, free: 1925.6 MB)
2018-05-01 17:43:03.147  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.148  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[115] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.148  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 115.0 with 1 tasks
2018-05-01 17:43:03.149  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 115.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:03.149  INFO 17168 --- [Executor task launch worker for task 96] org.apache.spark.executor.Executor       : Running task 0.0 in stage 115.0 (TID 96)
2018-05-01 17:43:03.152  INFO 17168 --- [Executor task launch worker for task 96] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:03.152  INFO 17168 --- [Executor task launch worker for task 96] org.apache.spark.storage.BlockManager    : Found block rdd_110_0 locally
2018-05-01 17:43:03.187  INFO 17168 --- [Executor task launch worker for task 96] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 115.0 (TID 96). 1155 bytes result sent to driver
2018-05-01 17:43:03.187  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 115.0 (TID 96) in 38 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.187  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 115.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 115 (flatMap at ALS.scala:1433) finished in 0.039 s
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 116)
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:03.188  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 116 (MapPartitionsRDD[121] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:03.190  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_30 stored as values in memory (estimated size 26.7 KB, free 1925.2 MB)
2018-05-01 17:43:03.191  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1925.2 MB)
2018-05-01 17:43:03.192  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_30_piece0 in memory on 172.21.241.193:58363 (size: 11.9 KB, free: 1925.6 MB)
2018-05-01 17:43:03.192  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.192  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[121] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.192  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 116.0 with 1 tasks
2018-05-01 17:43:03.193  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 116.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:03.193  INFO 17168 --- [Executor task launch worker for task 97] org.apache.spark.executor.Executor       : Running task 0.0 in stage 116.0 (TID 97)
2018-05-01 17:43:03.196  INFO 17168 --- [Executor task launch worker for task 97] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:03.197  INFO 17168 --- [Executor task launch worker for task 97] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:03.197  INFO 17168 --- [Executor task launch worker for task 97] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:03.470  INFO 17168 --- [Executor task launch worker for task 97] o.a.spark.storage.memory.MemoryStore     : Block rdd_120_0 stored as values in memory (estimated size 416.2 KB, free 1924.8 MB)
2018-05-01 17:43:03.471  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_120_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:43:03.472  INFO 17168 --- [Executor task launch worker for task 97] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 116.0 (TID 97). 2595 bytes result sent to driver
2018-05-01 17:43:03.473  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 116.0 (TID 97) in 280 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.473  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 116.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.473  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 116 (aggregate at ALS.scala:1491) finished in 0.281 s
2018-05-01 17:43:03.474  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 15 finished: aggregate at ALS.scala:1491, took 0.334581 s
2018-05-01 17:43:03.492  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 110 from persistence list
2018-05-01 17:43:03.492  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 110
2018-05-01 17:43:03.497  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:03.498  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:03.499  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:03.500  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:03.500  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:03.500  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:03.501  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:03.502  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:03.502  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:03.502  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 125 (flatMap at ALS.scala:1433)
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 16 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 132 (aggregate at ALS.scala:1491)
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 120, ShuffleMapStage 131)
2018-05-01 17:43:03.503  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 131)
2018-05-01 17:43:03.504  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 131 (MapPartitionsRDD[125] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:03.507  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_31 stored as values in memory (estimated size 25.8 KB, free 1925.6 MB)
2018-05-01 17:43:03.508  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_31_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1925.6 MB)
2018-05-01 17:43:03.509  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_31_piece0 in memory on 172.21.241.193:58363 (size: 11.7 KB, free: 1926.0 MB)
2018-05-01 17:43:03.509  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.509  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[125] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.509  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 131.0 with 1 tasks
2018-05-01 17:43:03.510  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 131.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:03.510  INFO 17168 --- [Executor task launch worker for task 98] org.apache.spark.executor.Executor       : Running task 0.0 in stage 131.0 (TID 98)
2018-05-01 17:43:03.512  INFO 17168 --- [Executor task launch worker for task 98] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:03.512  INFO 17168 --- [Executor task launch worker for task 98] org.apache.spark.storage.BlockManager    : Found block rdd_120_0 locally
2018-05-01 17:43:03.538  INFO 17168 --- [Executor task launch worker for task 98] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 131.0 (TID 98). 1112 bytes result sent to driver
2018-05-01 17:43:03.539  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 131.0 (TID 98) in 29 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.539  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 131.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 131 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 132)
2018-05-01 17:43:03.539  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:03.540  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 132 (MapPartitionsRDD[131] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:03.541  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_32 stored as values in memory (estimated size 28.2 KB, free 1925.5 MB)
2018-05-01 17:43:03.542  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_32_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1925.5 MB)
2018-05-01 17:43:03.543  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_32_piece0 in memory on 172.21.241.193:58363 (size: 12.5 KB, free: 1926.0 MB)
2018-05-01 17:43:03.543  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.543  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[131] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.543  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 132.0 with 1 tasks
2018-05-01 17:43:03.544  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 132.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:03.544  INFO 17168 --- [Executor task launch worker for task 99] org.apache.spark.executor.Executor       : Running task 0.0 in stage 132.0 (TID 99)
2018-05-01 17:43:03.546  INFO 17168 --- [Executor task launch worker for task 99] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:03.546  INFO 17168 --- [Executor task launch worker for task 99] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:03.546  INFO 17168 --- [Executor task launch worker for task 99] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:03.833  INFO 17168 --- [Executor task launch worker for task 99] o.a.spark.storage.memory.MemoryStore     : Block rdd_130_0 stored as values in memory (estimated size 820.5 KB, free 1924.7 MB)
2018-05-01 17:43:03.834  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_130_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:43:03.840  INFO 17168 --- [Executor task launch worker for task 99] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 132.0 (TID 99). 2595 bytes result sent to driver
2018-05-01 17:43:03.840  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 132.0 (TID 99) in 296 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.840  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 132.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.841  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 132 (aggregate at ALS.scala:1491) finished in 0.298 s
2018-05-01 17:43:03.841  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 16 finished: aggregate at ALS.scala:1491, took 0.343726 s
2018-05-01 17:43:03.861  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 120 from persistence list
2018-05-01 17:43:03.862  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 120
2018-05-01 17:43:03.866  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:03.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:03.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:03.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:03.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:03.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:03.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:03.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:03.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:03.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 135 (flatMap at ALS.scala:1433)
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 17 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 149 (aggregate at ALS.scala:1491)
2018-05-01 17:43:03.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 148, ShuffleMapStage 134)
2018-05-01 17:43:03.871  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 148)
2018-05-01 17:43:03.871  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 148 (MapPartitionsRDD[135] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:03.873  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_33 stored as values in memory (estimated size 27.3 KB, free 1925.1 MB)
2018-05-01 17:43:03.874  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_33_piece0 stored as bytes in memory (estimated size 12.4 KB, free 1925.1 MB)
2018-05-01 17:43:03.874  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_33_piece0 in memory on 172.21.241.193:58363 (size: 12.4 KB, free: 1925.5 MB)
2018-05-01 17:43:03.875  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.875  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[135] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.875  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 148.0 with 1 tasks
2018-05-01 17:43:03.875  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 148.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:03.875  INFO 17168 --- [Executor task launch worker for task 100] org.apache.spark.executor.Executor       : Running task 0.0 in stage 148.0 (TID 100)
2018-05-01 17:43:03.877  INFO 17168 --- [Executor task launch worker for task 100] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:03.877  INFO 17168 --- [Executor task launch worker for task 100] org.apache.spark.storage.BlockManager    : Found block rdd_130_0 locally
2018-05-01 17:43:03.909  INFO 17168 --- [Executor task launch worker for task 100] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 148.0 (TID 100). 1069 bytes result sent to driver
2018-05-01 17:43:03.909  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 148.0 (TID 100) in 34 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:03.910  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 148.0, whose tasks have all completed, from pool 
2018-05-01 17:43:03.910  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 148 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:43:03.910  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:03.911  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:03.911  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 149)
2018-05-01 17:43:03.911  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:03.911  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 149 (MapPartitionsRDD[141] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:03.913  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_34 stored as values in memory (estimated size 29.8 KB, free 1925.0 MB)
2018-05-01 17:43:03.913  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_34_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1925.0 MB)
2018-05-01 17:43:03.914  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_34_piece0 in memory on 172.21.241.193:58363 (size: 13.3 KB, free: 1925.5 MB)
2018-05-01 17:43:03.914  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:03.914  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[141] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:03.914  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 149.0 with 1 tasks
2018-05-01 17:43:03.915  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 149.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:03.915  INFO 17168 --- [Executor task launch worker for task 101] org.apache.spark.executor.Executor       : Running task 0.0 in stage 149.0 (TID 101)
2018-05-01 17:43:03.917  INFO 17168 --- [Executor task launch worker for task 101] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:03.917  INFO 17168 --- [Executor task launch worker for task 101] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:03.917  INFO 17168 --- [Executor task launch worker for task 101] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:04.193  INFO 17168 --- [Executor task launch worker for task 101] o.a.spark.storage.memory.MemoryStore     : Block rdd_140_0 stored as values in memory (estimated size 416.2 KB, free 1924.6 MB)
2018-05-01 17:43:04.193  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_140_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 17:43:04.195  INFO 17168 --- [Executor task launch worker for task 101] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 149.0 (TID 101). 2638 bytes result sent to driver
2018-05-01 17:43:04.196  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 149.0 (TID 101) in 281 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.196  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 149.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.196  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 149 (aggregate at ALS.scala:1491) finished in 0.282 s
2018-05-01 17:43:04.197  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 17 finished: aggregate at ALS.scala:1491, took 0.330489 s
2018-05-01 17:43:04.212  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 130 from persistence list
2018-05-01 17:43:04.213  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 130
2018-05-01 17:43:04.218  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:04.218  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:04.219  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:04.219  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:04.219  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:04.220  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:04.220  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:04.220  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:04.220  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:04.221  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:04.221  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:04.221  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:04.221  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 145 (flatMap at ALS.scala:1433)
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 18 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:04.222  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 167 (aggregate at ALS.scala:1491)
2018-05-01 17:43:04.223  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 153, ShuffleMapStage 166)
2018-05-01 17:43:04.223  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 166)
2018-05-01 17:43:04.223  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 166 (MapPartitionsRDD[145] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:04.225  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_35 stored as values in memory (estimated size 28.9 KB, free 1925.4 MB)
2018-05-01 17:43:04.226  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_35_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1925.4 MB)
2018-05-01 17:43:04.226  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_35_piece0 in memory on 172.21.241.193:58363 (size: 13.0 KB, free: 1925.9 MB)
2018-05-01 17:43:04.226  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.227  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[145] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.227  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 166.0 with 1 tasks
2018-05-01 17:43:04.227  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 166.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:04.227  INFO 17168 --- [Executor task launch worker for task 102] org.apache.spark.executor.Executor       : Running task 0.0 in stage 166.0 (TID 102)
2018-05-01 17:43:04.229  INFO 17168 --- [Executor task launch worker for task 102] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:04.229  INFO 17168 --- [Executor task launch worker for task 102] org.apache.spark.storage.BlockManager    : Found block rdd_140_0 locally
2018-05-01 17:43:04.255  INFO 17168 --- [Executor task launch worker for task 102] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 166.0 (TID 102). 1069 bytes result sent to driver
2018-05-01 17:43:04.255  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 166.0 (TID 102) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.256  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 166.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.256  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 166 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:43:04.256  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:04.257  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:04.257  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 167)
2018-05-01 17:43:04.257  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:04.257  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 167 (MapPartitionsRDD[151] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:04.259  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_36 stored as values in memory (estimated size 31.3 KB, free 1925.4 MB)
2018-05-01 17:43:04.260  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_36_piece0 stored as bytes in memory (estimated size 13.8 KB, free 1925.3 MB)
2018-05-01 17:43:04.260  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_36_piece0 in memory on 172.21.241.193:58363 (size: 13.8 KB, free: 1925.9 MB)
2018-05-01 17:43:04.261  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.261  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[151] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.261  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 167.0 with 1 tasks
2018-05-01 17:43:04.261  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 167.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:04.262  INFO 17168 --- [Executor task launch worker for task 103] org.apache.spark.executor.Executor       : Running task 0.0 in stage 167.0 (TID 103)
2018-05-01 17:43:04.264  INFO 17168 --- [Executor task launch worker for task 103] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:04.264  INFO 17168 --- [Executor task launch worker for task 103] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:04.264  INFO 17168 --- [Executor task launch worker for task 103] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:04.540  INFO 17168 --- [Executor task launch worker for task 103] o.a.spark.storage.memory.MemoryStore     : Block rdd_150_0 stored as values in memory (estimated size 820.5 KB, free 1924.5 MB)
2018-05-01 17:43:04.540  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_150_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:43:04.544  INFO 17168 --- [Executor task launch worker for task 103] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 167.0 (TID 103). 2595 bytes result sent to driver
2018-05-01 17:43:04.545  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 167.0 (TID 103) in 284 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.545  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 167.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.545  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 167 (aggregate at ALS.scala:1491) finished in 0.284 s
2018-05-01 17:43:04.545  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 18 finished: aggregate at ALS.scala:1491, took 0.327285 s
2018-05-01 17:43:04.562  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 140 from persistence list
2018-05-01 17:43:04.563  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 140
2018-05-01 17:43:04.567  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:04.568  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:04.568  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:04.569  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:04.569  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:04.569  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:04.569  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:04.570  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:04.571  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 155 (flatMap at ALS.scala:1433)
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 19 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 186 (aggregate at ALS.scala:1491)
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 169, ShuffleMapStage 185)
2018-05-01 17:43:04.572  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 185)
2018-05-01 17:43:04.573  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 185 (MapPartitionsRDD[155] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:04.575  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_37 stored as values in memory (estimated size 30.4 KB, free 1924.9 MB)
2018-05-01 17:43:04.576  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_37_piece0 stored as bytes in memory (estimated size 13.7 KB, free 1924.9 MB)
2018-05-01 17:43:04.576  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_37_piece0 in memory on 172.21.241.193:58363 (size: 13.7 KB, free: 1925.5 MB)
2018-05-01 17:43:04.576  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.577  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 185 (MapPartitionsRDD[155] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.577  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 185.0 with 1 tasks
2018-05-01 17:43:04.577  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 185.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:04.577  INFO 17168 --- [Executor task launch worker for task 104] org.apache.spark.executor.Executor       : Running task 0.0 in stage 185.0 (TID 104)
2018-05-01 17:43:04.579  INFO 17168 --- [Executor task launch worker for task 104] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:04.579  INFO 17168 --- [Executor task launch worker for task 104] org.apache.spark.storage.BlockManager    : Found block rdd_150_0 locally
2018-05-01 17:43:04.610  INFO 17168 --- [Executor task launch worker for task 104] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 185.0 (TID 104). 1069 bytes result sent to driver
2018-05-01 17:43:04.610  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 185.0 (TID 104) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.610  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 185.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.610  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 185 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 17:43:04.610  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:04.610  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:04.611  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 186)
2018-05-01 17:43:04.611  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:04.612  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 186 (MapPartitionsRDD[161] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:04.613  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_38 stored as values in memory (estimated size 32.9 KB, free 1924.9 MB)
2018-05-01 17:43:04.614  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_38_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1924.9 MB)
2018-05-01 17:43:04.615  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_38_piece0 in memory on 172.21.241.193:58363 (size: 14.6 KB, free: 1925.5 MB)
2018-05-01 17:43:04.615  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.615  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[161] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.615  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 186.0 with 1 tasks
2018-05-01 17:43:04.616  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 186.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:04.616  INFO 17168 --- [Executor task launch worker for task 105] org.apache.spark.executor.Executor       : Running task 0.0 in stage 186.0 (TID 105)
2018-05-01 17:43:04.618  INFO 17168 --- [Executor task launch worker for task 105] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:04.618  INFO 17168 --- [Executor task launch worker for task 105] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:04.618  INFO 17168 --- [Executor task launch worker for task 105] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:04.893  INFO 17168 --- [Executor task launch worker for task 105] o.a.spark.storage.memory.MemoryStore     : Block rdd_160_0 stored as values in memory (estimated size 416.2 KB, free 1924.5 MB)
2018-05-01 17:43:04.893  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_160_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 17:43:04.895  INFO 17168 --- [Executor task launch worker for task 105] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 186.0 (TID 105). 2595 bytes result sent to driver
2018-05-01 17:43:04.896  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 186.0 (TID 105) in 280 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.896  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 186.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.896  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 186 (aggregate at ALS.scala:1491) finished in 0.281 s
2018-05-01 17:43:04.897  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 19 finished: aggregate at ALS.scala:1491, took 0.329117 s
2018-05-01 17:43:04.919  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 150 from persistence list
2018-05-01 17:43:04.920  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 150
2018-05-01 17:43:04.925  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:04.925  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:04.925  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:04.926  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:04.927  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:04.928  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:04.928  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:04.928  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:04.928  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 165 (flatMap at ALS.scala:1433)
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 20 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 206 (aggregate at ALS.scala:1491)
2018-05-01 17:43:04.929  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 190, ShuffleMapStage 205)
2018-05-01 17:43:04.930  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 205)
2018-05-01 17:43:04.930  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 205 (MapPartitionsRDD[165] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:04.932  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_39 stored as values in memory (estimated size 32.0 KB, free 1925.2 MB)
2018-05-01 17:43:04.933  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_39_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1925.2 MB)
2018-05-01 17:43:04.933  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_39_piece0 in memory on 172.21.241.193:58363 (size: 14.3 KB, free: 1925.9 MB)
2018-05-01 17:43:04.933  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.934  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 205 (MapPartitionsRDD[165] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.934  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 205.0 with 1 tasks
2018-05-01 17:43:04.934  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 205.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:04.934  INFO 17168 --- [Executor task launch worker for task 106] org.apache.spark.executor.Executor       : Running task 0.0 in stage 205.0 (TID 106)
2018-05-01 17:43:04.937  INFO 17168 --- [Executor task launch worker for task 106] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:04.937  INFO 17168 --- [Executor task launch worker for task 106] org.apache.spark.storage.BlockManager    : Found block rdd_160_0 locally
2018-05-01 17:43:04.979  INFO 17168 --- [Executor task launch worker for task 106] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 205.0 (TID 106). 1069 bytes result sent to driver
2018-05-01 17:43:04.980  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 205.0 (TID 106) in 46 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:04.980  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 205.0, whose tasks have all completed, from pool 
2018-05-01 17:43:04.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 205 (flatMap at ALS.scala:1433) finished in 0.046 s
2018-05-01 17:43:04.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:04.980  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:04.981  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 206)
2018-05-01 17:43:04.981  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:04.982  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 206 (MapPartitionsRDD[171] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:04.984  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_40 stored as values in memory (estimated size 34.4 KB, free 1925.2 MB)
2018-05-01 17:43:04.986  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_40_piece0 stored as bytes in memory (estimated size 15.5 KB, free 1925.2 MB)
2018-05-01 17:43:04.986  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_40_piece0 in memory on 172.21.241.193:58363 (size: 15.5 KB, free: 1925.8 MB)
2018-05-01 17:43:04.987  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:04.987  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 206 (MapPartitionsRDD[171] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:04.987  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 206.0 with 1 tasks
2018-05-01 17:43:04.988  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 206.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:04.988  INFO 17168 --- [Executor task launch worker for task 107] org.apache.spark.executor.Executor       : Running task 0.0 in stage 206.0 (TID 107)
2018-05-01 17:43:04.990  INFO 17168 --- [Executor task launch worker for task 107] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:04.990  INFO 17168 --- [Executor task launch worker for task 107] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:04.990  INFO 17168 --- [Executor task launch worker for task 107] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:05.273  INFO 17168 --- [Executor task launch worker for task 107] o.a.spark.storage.memory.MemoryStore     : Block rdd_170_0 stored as values in memory (estimated size 820.5 KB, free 1924.4 MB)
2018-05-01 17:43:05.274  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_170_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.0 MB)
2018-05-01 17:43:05.277  INFO 17168 --- [Executor task launch worker for task 107] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 206.0 (TID 107). 2595 bytes result sent to driver
2018-05-01 17:43:05.278  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 206.0 (TID 107) in 290 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:05.278  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 206.0, whose tasks have all completed, from pool 
2018-05-01 17:43:05.278  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 206 (aggregate at ALS.scala:1491) finished in 0.291 s
2018-05-01 17:43:05.279  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 20 finished: aggregate at ALS.scala:1491, took 0.354083 s
2018-05-01 17:43:05.297  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 160 from persistence list
2018-05-01 17:43:05.297  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 160
2018-05-01 17:43:05.302  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:05.303  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:05.303  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:05.303  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:05.303  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:05.304  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:05.305  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:05.305  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:05.305  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:05.305  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:05.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:05.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:05.306  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:05.307  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:05.307  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 175 (flatMap at ALS.scala:1433)
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 21 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 227 (aggregate at ALS.scala:1491)
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 208, ShuffleMapStage 226)
2018-05-01 17:43:05.308  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 226)
2018-05-01 17:43:05.309  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 226 (MapPartitionsRDD[175] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:05.311  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_41 stored as values in memory (estimated size 33.5 KB, free 1924.7 MB)
2018-05-01 17:43:05.312  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_41_piece0 stored as bytes in memory (estimated size 15.2 KB, free 1924.7 MB)
2018-05-01 17:43:05.312  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_41_piece0 in memory on 172.21.241.193:58363 (size: 15.2 KB, free: 1925.4 MB)
2018-05-01 17:43:05.312  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:05.313  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 226 (MapPartitionsRDD[175] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:05.313  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 226.0 with 1 tasks
2018-05-01 17:43:05.313  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 226.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:05.313  INFO 17168 --- [Executor task launch worker for task 108] org.apache.spark.executor.Executor       : Running task 0.0 in stage 226.0 (TID 108)
2018-05-01 17:43:05.315  INFO 17168 --- [Executor task launch worker for task 108] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:05.315  INFO 17168 --- [Executor task launch worker for task 108] org.apache.spark.storage.BlockManager    : Found block rdd_170_0 locally
2018-05-01 17:43:05.346  INFO 17168 --- [Executor task launch worker for task 108] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 226.0 (TID 108). 1069 bytes result sent to driver
2018-05-01 17:43:05.346  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 226.0 (TID 108) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:05.346  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 226.0, whose tasks have all completed, from pool 
2018-05-01 17:43:05.346  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 226 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 17:43:05.347  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:05.348  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:05.348  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 227)
2018-05-01 17:43:05.348  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:05.348  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 227 (MapPartitionsRDD[181] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:05.350  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_42 stored as values in memory (estimated size 36.0 KB, free 1924.7 MB)
2018-05-01 17:43:05.351  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_42_piece0 stored as bytes in memory (estimated size 16.3 KB, free 1924.7 MB)
2018-05-01 17:43:05.351  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_42_piece0 in memory on 172.21.241.193:58363 (size: 16.3 KB, free: 1925.4 MB)
2018-05-01 17:43:05.352  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:05.352  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[181] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:05.352  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 227.0 with 1 tasks
2018-05-01 17:43:05.353  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 227.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:05.353  INFO 17168 --- [Executor task launch worker for task 109] org.apache.spark.executor.Executor       : Running task 0.0 in stage 227.0 (TID 109)
2018-05-01 17:43:05.356  INFO 17168 --- [Executor task launch worker for task 109] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:05.356  INFO 17168 --- [Executor task launch worker for task 109] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:05.356  INFO 17168 --- [Executor task launch worker for task 109] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:05.632  INFO 17168 --- [Executor task launch worker for task 109] o.a.spark.storage.memory.MemoryStore     : Block rdd_180_0 stored as values in memory (estimated size 416.2 KB, free 1924.3 MB)
2018-05-01 17:43:05.632  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_180_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1925.0 MB)
2018-05-01 17:43:05.635  INFO 17168 --- [Executor task launch worker for task 109] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 227.0 (TID 109). 2638 bytes result sent to driver
2018-05-01 17:43:05.636  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 227.0 (TID 109) in 283 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:05.636  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 227.0, whose tasks have all completed, from pool 
2018-05-01 17:43:05.636  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 227 (aggregate at ALS.scala:1491) finished in 0.284 s
2018-05-01 17:43:05.637  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 21 finished: aggregate at ALS.scala:1491, took 0.334334 s
2018-05-01 17:43:05.656  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 170 from persistence list
2018-05-01 17:43:05.657  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 170
2018-05-01 17:43:05.662  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:05.662  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:05.662  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:05.663  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:05.663  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:05.663  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:05.663  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:05.664  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:05.664  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:05.664  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:05.664  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:05.665  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:05.666  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 185 (flatMap at ALS.scala:1433)
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 22 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 249 (aggregate at ALS.scala:1491)
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 248, ShuffleMapStage 229)
2018-05-01 17:43:05.667  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 248)
2018-05-01 17:43:05.668  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 248 (MapPartitionsRDD[185] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:05.670  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_43 stored as values in memory (estimated size 35.1 KB, free 1925.0 MB)
2018-05-01 17:43:05.671  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_43_piece0 stored as bytes in memory (estimated size 15.9 KB, free 1925.0 MB)
2018-05-01 17:43:05.671  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_43_piece0 in memory on 172.21.241.193:58363 (size: 15.9 KB, free: 1925.8 MB)
2018-05-01 17:43:05.671  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:05.671  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 248 (MapPartitionsRDD[185] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:05.672  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 248.0 with 1 tasks
2018-05-01 17:43:05.672  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 248.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:05.672  INFO 17168 --- [Executor task launch worker for task 110] org.apache.spark.executor.Executor       : Running task 0.0 in stage 248.0 (TID 110)
2018-05-01 17:43:05.674  INFO 17168 --- [Executor task launch worker for task 110] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:05.674  INFO 17168 --- [Executor task launch worker for task 110] org.apache.spark.storage.BlockManager    : Found block rdd_180_0 locally
2018-05-01 17:43:05.704  INFO 17168 --- [Executor task launch worker for task 110] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 248.0 (TID 110). 1069 bytes result sent to driver
2018-05-01 17:43:05.705  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 248.0 (TID 110) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:05.705  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 248.0, whose tasks have all completed, from pool 
2018-05-01 17:43:05.705  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 248 (flatMap at ALS.scala:1433) finished in 0.033 s
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 249)
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:05.706  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 249 (MapPartitionsRDD[191] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:05.708  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_44 stored as values in memory (estimated size 37.5 KB, free 1925.0 MB)
2018-05-01 17:43:05.709  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.8 KB, free 1925.0 MB)
2018-05-01 17:43:05.710  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_44_piece0 in memory on 172.21.241.193:58363 (size: 16.8 KB, free: 1925.8 MB)
2018-05-01 17:43:05.710  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:05.710  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 249 (MapPartitionsRDD[191] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:05.710  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 249.0 with 1 tasks
2018-05-01 17:43:05.711  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 249.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:05.711  INFO 17168 --- [Executor task launch worker for task 111] org.apache.spark.executor.Executor       : Running task 0.0 in stage 249.0 (TID 111)
2018-05-01 17:43:05.714  INFO 17168 --- [Executor task launch worker for task 111] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:05.714  INFO 17168 --- [Executor task launch worker for task 111] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:05.714  INFO 17168 --- [Executor task launch worker for task 111] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:06.008  INFO 17168 --- [Executor task launch worker for task 111] o.a.spark.storage.memory.MemoryStore     : Block rdd_190_0 stored as values in memory (estimated size 820.5 KB, free 1924.2 MB)
2018-05-01 17:43:06.009  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_190_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.0 MB)
2018-05-01 17:43:06.012  INFO 17168 --- [Executor task launch worker for task 111] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 249.0 (TID 111). 2638 bytes result sent to driver
2018-05-01 17:43:06.013  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 249.0 (TID 111) in 303 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.013  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 249.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.013  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 249 (aggregate at ALS.scala:1491) finished in 0.303 s
2018-05-01 17:43:06.014  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 22 finished: aggregate at ALS.scala:1491, took 0.351830 s
2018-05-01 17:43:06.031  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 180 from persistence list
2018-05-01 17:43:06.031  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 180
2018-05-01 17:43:06.036  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:06.036  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:06.036  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:06.037  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:06.037  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:06.037  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:06.037  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:06.038  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:06.039  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 195 (flatMap at ALS.scala:1433)
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 23 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 272 (aggregate at ALS.scala:1491)
2018-05-01 17:43:06.040  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 251, ShuffleMapStage 271)
2018-05-01 17:43:06.041  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 271)
2018-05-01 17:43:06.041  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 271 (MapPartitionsRDD[195] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:06.044  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_45 stored as values in memory (estimated size 36.6 KB, free 1924.5 MB)
2018-05-01 17:43:06.045  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_45_piece0 stored as bytes in memory (estimated size 16.5 KB, free 1924.5 MB)
2018-05-01 17:43:06.045  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_45_piece0 in memory on 172.21.241.193:58363 (size: 16.5 KB, free: 1925.4 MB)
2018-05-01 17:43:06.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.046  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 271 (MapPartitionsRDD[195] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.046  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 271.0 with 1 tasks
2018-05-01 17:43:06.047  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 271.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:06.047  INFO 17168 --- [Executor task launch worker for task 112] org.apache.spark.executor.Executor       : Running task 0.0 in stage 271.0 (TID 112)
2018-05-01 17:43:06.049  INFO 17168 --- [Executor task launch worker for task 112] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:06.049  INFO 17168 --- [Executor task launch worker for task 112] org.apache.spark.storage.BlockManager    : Found block rdd_190_0 locally
2018-05-01 17:43:06.084  INFO 17168 --- [Executor task launch worker for task 112] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 271.0 (TID 112). 1069 bytes result sent to driver
2018-05-01 17:43:06.084  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 271.0 (TID 112) in 38 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.084  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 271.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 271 (flatMap at ALS.scala:1433) finished in 0.038 s
2018-05-01 17:43:06.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:06.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:06.084  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 272)
2018-05-01 17:43:06.085  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:06.085  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 272 (MapPartitionsRDD[201] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:06.088  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_46 stored as values in memory (estimated size 39.1 KB, free 1924.5 MB)
2018-05-01 17:43:06.089  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_46_piece0 stored as bytes in memory (estimated size 17.6 KB, free 1924.5 MB)
2018-05-01 17:43:06.089  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_46_piece0 in memory on 172.21.241.193:58363 (size: 17.6 KB, free: 1925.4 MB)
2018-05-01 17:43:06.090  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.090  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[201] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.090  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 272.0 with 1 tasks
2018-05-01 17:43:06.090  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 272.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:06.091  INFO 17168 --- [Executor task launch worker for task 113] org.apache.spark.executor.Executor       : Running task 0.0 in stage 272.0 (TID 113)
2018-05-01 17:43:06.093  INFO 17168 --- [Executor task launch worker for task 113] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:06.093  INFO 17168 --- [Executor task launch worker for task 113] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:06.093  INFO 17168 --- [Executor task launch worker for task 113] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:06.363  INFO 17168 --- [Executor task launch worker for task 113] o.a.spark.storage.memory.MemoryStore     : Block rdd_200_0 stored as values in memory (estimated size 416.2 KB, free 1924.1 MB)
2018-05-01 17:43:06.363  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_200_0 in memory on 172.21.241.193:58363 (size: 416.2 KB, free: 1924.9 MB)
2018-05-01 17:43:06.365  INFO 17168 --- [Executor task launch worker for task 113] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 272.0 (TID 113). 2595 bytes result sent to driver
2018-05-01 17:43:06.365  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 272.0 (TID 113) in 275 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.365  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 272.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.366  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 272 (aggregate at ALS.scala:1491) finished in 0.276 s
2018-05-01 17:43:06.366  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 23 finished: aggregate at ALS.scala:1491, took 0.330080 s
2018-05-01 17:43:06.382  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 190 from persistence list
2018-05-01 17:43:06.382  INFO 17168 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 190
2018-05-01 17:43:06.387  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:43:06.388  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:06.388  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:06.389  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:06.389  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:06.389  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:06.389  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:06.390  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:06.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:06.392  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 205 (flatMap at ALS.scala:1433)
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 24 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 296 (aggregate at ALS.scala:1491)
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 276, ShuffleMapStage 295)
2018-05-01 17:43:06.393  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 295)
2018-05-01 17:43:06.394  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 295 (MapPartitionsRDD[205] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:06.396  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_47 stored as values in memory (estimated size 38.2 KB, free 1924.8 MB)
2018-05-01 17:43:06.397  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_47_piece0 stored as bytes in memory (estimated size 17.3 KB, free 1924.8 MB)
2018-05-01 17:43:06.397  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_47_piece0 in memory on 172.21.241.193:58363 (size: 17.3 KB, free: 1925.7 MB)
2018-05-01 17:43:06.397  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.398  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 295 (MapPartitionsRDD[205] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.398  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 295.0 with 1 tasks
2018-05-01 17:43:06.399  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 295.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:06.399  INFO 17168 --- [Executor task launch worker for task 114] org.apache.spark.executor.Executor       : Running task 0.0 in stage 295.0 (TID 114)
2018-05-01 17:43:06.402  INFO 17168 --- [Executor task launch worker for task 114] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:43:06.402  INFO 17168 --- [Executor task launch worker for task 114] org.apache.spark.storage.BlockManager    : Found block rdd_200_0 locally
2018-05-01 17:43:06.434  INFO 17168 --- [Executor task launch worker for task 114] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 295.0 (TID 114). 1112 bytes result sent to driver
2018-05-01 17:43:06.435  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 295.0 (TID 114) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.435  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 295.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 295 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 296)
2018-05-01 17:43:06.435  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:06.436  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 296 (MapPartitionsRDD[211] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:43:06.438  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_48 stored as values in memory (estimated size 40.6 KB, free 1924.8 MB)
2018-05-01 17:43:06.521  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_48_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1924.7 MB)
2018-05-01 17:43:06.523  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_48_piece0 in memory on 172.21.241.193:58363 (size: 18.2 KB, free: 1925.7 MB)
2018-05-01 17:43:06.527  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.528  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 296 (MapPartitionsRDD[211] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.528  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 296.0 with 1 tasks
2018-05-01 17:43:06.528  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_9_piece0 on 172.21.241.193:58363 in memory (size: 4.3 KB, free: 1925.7 MB)
2018-05-01 17:43:06.528  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 296.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:43:06.528  INFO 17168 --- [Executor task launch worker for task 115] org.apache.spark.executor.Executor       : Running task 0.0 in stage 296.0 (TID 115)
2018-05-01 17:43:06.529  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_18_piece0 on 172.21.241.193:58363 in memory (size: 7.9 KB, free: 1925.7 MB)
2018-05-01 17:43:06.529  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_26_piece0 on 172.21.241.193:58363 in memory (size: 10.6 KB, free: 1925.7 MB)
2018-05-01 17:43:06.530  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_17_piece0 on 172.21.241.193:58363 in memory (size: 7.0 KB, free: 1925.7 MB)
2018-05-01 17:43:06.531  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_29_piece0 on 172.21.241.193:58363 in memory (size: 11.1 KB, free: 1925.8 MB)
2018-05-01 17:43:06.531  INFO 17168 --- [Executor task launch worker for task 115] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:06.532  INFO 17168 --- [Executor task launch worker for task 115] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:06.532  INFO 17168 --- [Executor task launch worker for task 115] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:06.532  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_36_piece0 on 172.21.241.193:58363 in memory (size: 13.8 KB, free: 1925.8 MB)
2018-05-01 17:43:06.532  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_31_piece0 on 172.21.241.193:58363 in memory (size: 11.7 KB, free: 1925.8 MB)
2018-05-01 17:43:06.533  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_8_piece0 on 172.21.241.193:58363 in memory (size: 4.0 KB, free: 1925.8 MB)
2018-05-01 17:43:06.534  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_41_piece0 on 172.21.241.193:58363 in memory (size: 15.2 KB, free: 1925.8 MB)
2018-05-01 17:43:06.535  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_44_piece0 on 172.21.241.193:58363 in memory (size: 16.8 KB, free: 1925.8 MB)
2018-05-01 17:43:06.536  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_14_piece0 on 172.21.241.193:58363 in memory (size: 6.6 KB, free: 1925.8 MB)
2018-05-01 17:43:06.537  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_30_piece0 on 172.21.241.193:58363 in memory (size: 11.9 KB, free: 1925.8 MB)
2018-05-01 17:43:06.537  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_11_piece0 on 172.21.241.193:58363 in memory (size: 4.3 KB, free: 1925.8 MB)
2018-05-01 17:43:06.538  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_28_piece0 on 172.21.241.193:58363 in memory (size: 11.2 KB, free: 1925.8 MB)
2018-05-01 17:43:06.539  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_38_piece0 on 172.21.241.193:58363 in memory (size: 14.6 KB, free: 1925.9 MB)
2018-05-01 17:43:06.539  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_16_piece0 on 172.21.241.193:58363 in memory (size: 7.3 KB, free: 1925.9 MB)
2018-05-01 17:43:06.540  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_20_piece0 on 172.21.241.193:58363 in memory (size: 8.6 KB, free: 1925.9 MB)
2018-05-01 17:43:06.541  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_35_piece0 on 172.21.241.193:58363 in memory (size: 13.0 KB, free: 1925.9 MB)
2018-05-01 17:43:06.542  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_10_piece0 on 172.21.241.193:58363 in memory (size: 4.0 KB, free: 1925.9 MB)
2018-05-01 17:43:06.542  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_27_piece0 on 172.21.241.193:58363 in memory (size: 10.5 KB, free: 1925.9 MB)
2018-05-01 17:43:06.543  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_21_piece0 on 172.21.241.193:58363 in memory (size: 8.4 KB, free: 1925.9 MB)
2018-05-01 17:43:06.544  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_23_piece0 on 172.21.241.193:58363 in memory (size: 9.1 KB, free: 1925.9 MB)
2018-05-01 17:43:06.544  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_34_piece0 on 172.21.241.193:58363 in memory (size: 13.3 KB, free: 1925.9 MB)
2018-05-01 17:43:06.545  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_24_piece0 on 172.21.241.193:58363 in memory (size: 9.9 KB, free: 1925.9 MB)
2018-05-01 17:43:06.545  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_33_piece0 on 172.21.241.193:58363 in memory (size: 12.4 KB, free: 1926.0 MB)
2018-05-01 17:43:06.546  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_46_piece0 on 172.21.241.193:58363 in memory (size: 17.6 KB, free: 1926.0 MB)
2018-05-01 17:43:06.547  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_12_piece0 on 172.21.241.193:58363 in memory (size: 5.8 KB, free: 1926.0 MB)
2018-05-01 17:43:06.547  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_13_piece0 on 172.21.241.193:58363 in memory (size: 5.6 KB, free: 1926.0 MB)
2018-05-01 17:43:06.548  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_42_piece0 on 172.21.241.193:58363 in memory (size: 16.3 KB, free: 1926.0 MB)
2018-05-01 17:43:06.548  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_25_piece0 on 172.21.241.193:58363 in memory (size: 9.7 KB, free: 1926.0 MB)
2018-05-01 17:43:06.549  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_19_piece0 on 172.21.241.193:58363 in memory (size: 7.8 KB, free: 1926.0 MB)
2018-05-01 17:43:06.549  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_45_piece0 on 172.21.241.193:58363 in memory (size: 16.5 KB, free: 1926.0 MB)
2018-05-01 17:43:06.550  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_43_piece0 on 172.21.241.193:58363 in memory (size: 15.9 KB, free: 1926.0 MB)
2018-05-01 17:43:06.551  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_32_piece0 on 172.21.241.193:58363 in memory (size: 12.5 KB, free: 1926.1 MB)
2018-05-01 17:43:06.551  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_22_piece0 on 172.21.241.193:58363 in memory (size: 9.2 KB, free: 1926.1 MB)
2018-05-01 17:43:06.552  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_37_piece0 on 172.21.241.193:58363 in memory (size: 13.7 KB, free: 1926.1 MB)
2018-05-01 17:43:06.553  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_39_piece0 on 172.21.241.193:58363 in memory (size: 14.3 KB, free: 1926.1 MB)
2018-05-01 17:43:06.554  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_15_piece0 on 172.21.241.193:58363 in memory (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:43:06.554  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_40_piece0 on 172.21.241.193:58363 in memory (size: 15.5 KB, free: 1926.1 MB)
2018-05-01 17:43:06.808  INFO 17168 --- [Executor task launch worker for task 115] o.a.spark.storage.memory.MemoryStore     : Block rdd_210_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 17:43:06.809  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_210_0 in memory on 172.21.241.193:58363 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:43:06.813  INFO 17168 --- [Executor task launch worker for task 115] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 296.0 (TID 115). 2595 bytes result sent to driver
2018-05-01 17:43:06.813  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 296.0 (TID 115) in 285 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.813  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 296.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.814  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 296 (aggregate at ALS.scala:1491) finished in 0.285 s
2018-05-01 17:43:06.814  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 24 finished: aggregate at ALS.scala:1491, took 0.426876 s
2018-05-01 17:43:06.834  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 200 from persistence list
2018-05-01 17:43:06.835  INFO 17168 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 200
2018-05-01 17:43:06.864  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:279
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:06.865  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:06.866  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:06.867  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:06.868  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:06.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:43:06.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:43:06.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 22 is 150 bytes
2018-05-01 17:43:06.869  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 215 (flatMap at ALS.scala:1433)
2018-05-01 17:43:06.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 25 (count at ALS.scala:279) with 1 output partitions
2018-05-01 17:43:06.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 321 (count at ALS.scala:279)
2018-05-01 17:43:06.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 320, ShuffleMapStage 298)
2018-05-01 17:43:06.870  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 320)
2018-05-01 17:43:06.871  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 320 (MapPartitionsRDD[215] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:43:06.873  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_49 stored as values in memory (estimated size 39.7 KB, free 1925.6 MB)
2018-05-01 17:43:06.874  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_49_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1925.6 MB)
2018-05-01 17:43:06.874  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_49_piece0 in memory on 172.21.241.193:58363 (size: 18.0 KB, free: 1925.7 MB)
2018-05-01 17:43:06.874  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.874  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 320 (MapPartitionsRDD[215] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.874  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 320.0 with 1 tasks
2018-05-01 17:43:06.875  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 320.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:43:06.875  INFO 17168 --- [Executor task launch worker for task 116] org.apache.spark.executor.Executor       : Running task 0.0 in stage 320.0 (TID 116)
2018-05-01 17:43:06.877  INFO 17168 --- [Executor task launch worker for task 116] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:43:06.877  INFO 17168 --- [Executor task launch worker for task 116] org.apache.spark.storage.BlockManager    : Found block rdd_210_0 locally
2018-05-01 17:43:06.906  INFO 17168 --- [Executor task launch worker for task 116] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 320.0 (TID 116). 1069 bytes result sent to driver
2018-05-01 17:43:06.907  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 320.0 (TID 116) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:06.907  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 320.0, whose tasks have all completed, from pool 
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 320 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 321)
2018-05-01 17:43:06.907  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:43:06.908  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 321 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:43:06.910  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_50 stored as values in memory (estimated size 41.6 KB, free 1925.5 MB)
2018-05-01 17:43:06.910  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_50_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1925.5 MB)
2018-05-01 17:43:06.911  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_50_piece0 in memory on 172.21.241.193:58363 (size: 18.7 KB, free: 1925.7 MB)
2018-05-01 17:43:06.912  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:06.912  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 321 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:06.912  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 321.0 with 1 tasks
2018-05-01 17:43:06.912  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 321.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:06.913  INFO 17168 --- [Executor task launch worker for task 117] org.apache.spark.executor.Executor       : Running task 0.0 in stage 321.0 (TID 117)
2018-05-01 17:43:06.916  INFO 17168 --- [Executor task launch worker for task 117] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:06.917  INFO 17168 --- [Executor task launch worker for task 117] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:43:06.917  INFO 17168 --- [Executor task launch worker for task 117] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:43:06.917  INFO 17168 --- [Executor task launch worker for task 117] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:43:07.275  INFO 17168 --- [Executor task launch worker for task 117] o.a.spark.storage.memory.MemoryStore     : Block rdd_231_0 stored as values in memory (estimated size 970.8 KB, free 1924.6 MB)
2018-05-01 17:43:07.275  INFO 17168 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_231_0 in memory on 172.21.241.193:58363 (size: 970.8 KB, free: 1924.7 MB)
2018-05-01 17:43:07.276  INFO 17168 --- [Executor task launch worker for task 117] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 321.0 (TID 117). 1873 bytes result sent to driver
2018-05-01 17:43:07.276  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 321.0 (TID 117) in 364 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.276  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 321.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.277  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 321 (count at ALS.scala:279) finished in 0.365 s
2018-05-01 17:43:07.277  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 25 finished: count at ALS.scala:279, took 0.413265 s
2018-05-01 17:43:07.280  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:280
2018-05-01 17:43:07.280  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:43:07.280  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:43:07.281  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:43:07.282  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:43:07.283  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:43:07.283  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:43:07.283  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:43:07.283  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:43:07.284  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:43:07.285  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:43:07.285  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 22 is 150 bytes
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 26 (count at ALS.scala:280) with 1 output partitions
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 345 (count at ALS.scala:280)
2018-05-01 17:43:07.286  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 325, ShuffleMapStage 344)
2018-05-01 17:43:07.287  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.287  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 345 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:43:07.289  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_51 stored as values in memory (estimated size 40.1 KB, free 1924.5 MB)
2018-05-01 17:43:07.290  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1924.5 MB)
2018-05-01 17:43:07.290  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_51_piece0 in memory on 172.21.241.193:58363 (size: 18.0 KB, free: 1924.7 MB)
2018-05-01 17:43:07.290  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.290  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 345 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.291  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 345.0 with 1 tasks
2018-05-01 17:43:07.291  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 345.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.291  INFO 17168 --- [Executor task launch worker for task 118] org.apache.spark.executor.Executor       : Running task 0.0 in stage 345.0 (TID 118)
2018-05-01 17:43:07.294  INFO 17168 --- [Executor task launch worker for task 118] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:43:07.294  INFO 17168 --- [Executor task launch worker for task 118] org.apache.spark.storage.BlockManager    : Found block rdd_210_0 locally
2018-05-01 17:43:07.375  INFO 17168 --- [Executor task launch worker for task 118] o.a.spark.storage.memory.MemoryStore     : Block rdd_232_0 stored as values in memory (estimated size 1914.2 KB, free 1922.7 MB)
2018-05-01 17:43:07.375  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_232_0 in memory on 172.21.241.193:58363 (size: 1914.2 KB, free: 1922.9 MB)
2018-05-01 17:43:07.376  INFO 17168 --- [Executor task launch worker for task 118] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 345.0 (TID 118). 1658 bytes result sent to driver
2018-05-01 17:43:07.377  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 345.0 (TID 118) in 86 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.377  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 345.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.377  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 345 (count at ALS.scala:280) finished in 0.086 s
2018-05-01 17:43:07.377  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 26 finished: count at ALS.scala:280, took 0.097097 s
2018-05-01 17:43:07.383  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 23 is 150 bytes
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 27 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 370 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 369, ShuffleMapStage 347)
2018-05-01 17:43:07.386  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.387  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 370 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:43:07.389  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_52 stored as values in memory (estimated size 41.8 KB, free 1922.6 MB)
2018-05-01 17:43:07.390  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_52_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1922.6 MB)
2018-05-01 17:43:07.391  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_52_piece0 in memory on 172.21.241.193:58363 (size: 18.8 KB, free: 1922.8 MB)
2018-05-01 17:43:07.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.391  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 370 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.392  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 370.0 with 1 tasks
2018-05-01 17:43:07.392  INFO 17168 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 370.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.392  INFO 17168 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : Running task 0.0 in stage 370.0 (TID 119)
2018-05-01 17:43:07.395  INFO 17168 --- [Executor task launch worker for task 119] org.apache.spark.storage.BlockManager    : Found block rdd_231_0 locally
2018-05-01 17:43:07.395  INFO 17168 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 119:
[rdd_231_0]
2018-05-01 17:43:07.395  INFO 17168 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 370.0 (TID 119). 909 bytes result sent to driver
2018-05-01 17:43:07.396  INFO 17168 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 370.0 (TID 119) in 3 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.396  INFO 17168 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 370.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.396  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 370 (first at MatrixFactorizationModel.scala:67) finished in 0.004 s
2018-05-01 17:43:07.396  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 27 finished: first at MatrixFactorizationModel.scala:67, took 0.012869 s
2018-05-01 17:43:07.404  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:43:07.406  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 28 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:43:07.406  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 394 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:43:07.406  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 393)
2018-05-01 17:43:07.406  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.407  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 394 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:43:07.408  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_53 stored as values in memory (estimated size 40.2 KB, free 1922.6 MB)
2018-05-01 17:43:07.409  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_53_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1922.5 MB)
2018-05-01 17:43:07.410  INFO 17168 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_53_piece0 in memory on 172.21.241.193:58363 (size: 18.1 KB, free: 1922.8 MB)
2018-05-01 17:43:07.410  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.410  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 394 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.410  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 394.0 with 1 tasks
2018-05-01 17:43:07.411  INFO 17168 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 394.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.411  INFO 17168 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : Running task 0.0 in stage 394.0 (TID 120)
2018-05-01 17:43:07.413  INFO 17168 --- [Executor task launch worker for task 120] org.apache.spark.storage.BlockManager    : Found block rdd_232_0 locally
2018-05-01 17:43:07.413  INFO 17168 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 120:
[rdd_232_0]
2018-05-01 17:43:07.413  INFO 17168 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 394.0 (TID 120). 909 bytes result sent to driver
2018-05-01 17:43:07.413  INFO 17168 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 394.0 (TID 120) in 3 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.413  INFO 17168 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 394.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.414  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 394 (first at MatrixFactorizationModel.scala:67) finished in 0.004 s
2018-05-01 17:43:07.414  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 28 finished: first at MatrixFactorizationModel.scala:67, took 0.010330 s
2018-05-01 17:43:07.423  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: lookup at MatrixFactorizationModel.scala:168
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 29 (lookup at MatrixFactorizationModel.scala:168) with 1 output partitions
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 419 (lookup at MatrixFactorizationModel.scala:168)
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 396, ShuffleMapStage 418)
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.426  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 419 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:43:07.428  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_54 stored as values in memory (estimated size 41.9 KB, free 1922.5 MB)
2018-05-01 17:43:07.429  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_54_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1922.5 MB)
2018-05-01 17:43:07.429  INFO 17168 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_54_piece0 in memory on 172.21.241.193:58363 (size: 18.8 KB, free: 1922.8 MB)
2018-05-01 17:43:07.430  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.430  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 419 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.430  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 419.0 with 1 tasks
2018-05-01 17:43:07.430  INFO 17168 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 419.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.430  INFO 17168 --- [Executor task launch worker for task 121] org.apache.spark.executor.Executor       : Running task 0.0 in stage 419.0 (TID 121)
2018-05-01 17:43:07.433  INFO 17168 --- [Executor task launch worker for task 121] org.apache.spark.storage.BlockManager    : Found block rdd_231_0 locally
2018-05-01 17:43:07.435  INFO 17168 --- [Executor task launch worker for task 121] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 419.0 (TID 121). 985 bytes result sent to driver
2018-05-01 17:43:07.435  INFO 17168 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 419.0 (TID 121) in 5 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.435  INFO 17168 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 419.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.436  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 419 (lookup at MatrixFactorizationModel.scala:168) finished in 0.005 s
2018-05-01 17:43:07.436  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 29 finished: lookup at MatrixFactorizationModel.scala:168, took 0.012811 s
2018-05-01 17:43:07.453  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.SparkContext            : Starting job: top at MatrixFactorizationModel.scala:259
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 30 (top at MatrixFactorizationModel.scala:259) with 1 output partitions
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 443 (top at MatrixFactorizationModel.scala:259)
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 423, ShuffleMapStage 442)
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:43:07.457  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 443 (MapPartitionsRDD[234] at top at MatrixFactorizationModel.scala:259), which has no missing parents
2018-05-01 17:43:07.460  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_55 stored as values in memory (estimated size 41.2 KB, free 1922.4 MB)
2018-05-01 17:43:07.462  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_55_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1922.4 MB)
2018-05-01 17:43:07.462  INFO 17168 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_55_piece0 in memory on 172.21.241.193:58363 (size: 18.7 KB, free: 1922.8 MB)
2018-05-01 17:43:07.463  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:43:07.463  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 443 (MapPartitionsRDD[234] at top at MatrixFactorizationModel.scala:259) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:43:07.463  INFO 17168 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 443.0 with 1 tasks
2018-05-01 17:43:07.463  INFO 17168 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 443.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:43:07.463  INFO 17168 --- [Executor task launch worker for task 122] org.apache.spark.executor.Executor       : Running task 0.0 in stage 443.0 (TID 122)
2018-05-01 17:43:07.466  INFO 17168 --- [Executor task launch worker for task 122] org.apache.spark.storage.BlockManager    : Found block rdd_232_0 locally
2018-05-01 17:43:07.478  INFO 17168 --- [Executor task launch worker for task 122] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 443.0 (TID 122). 1652 bytes result sent to driver
2018-05-01 17:43:07.479  INFO 17168 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 443.0 (TID 122) in 15 ms on localhost (executor driver) (1/1)
2018-05-01 17:43:07.479  INFO 17168 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 443.0, whose tasks have all completed, from pool 
2018-05-01 17:43:07.479  INFO 17168 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 443 (top at MatrixFactorizationModel.scala:259) finished in 0.016 s
2018-05-01 17:43:07.479  INFO 17168 --- [http-nio-3333-exec-2] org.apache.spark.scheduler.DAGScheduler  : Job 30 finished: top at MatrixFactorizationModel.scala:259, took 0.025885 s
2018-05-01 17:43:07.481  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Recommendations for1
2018-05-01 17:43:07.482  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1214-- Rating : 0.996791517895507
2018-05-01 17:43:07.513  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1200-- Rating : 0.9640660249450387
2018-05-01 17:43:07.516  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 541-- Rating : 0.928069625916408
2018-05-01 17:43:07.518  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 924-- Rating : 0.9245498636950754
2018-05-01 17:43:07.522  INFO 17168 --- [http-nio-3333-exec-2] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1206-- Rating : 0.9212852243141509
2018-05-01 17:45:43.281  INFO 17168 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:45:57.859  INFO 16044 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : The following profiles are active: mongo
2018-05-01 17:45:57.875  INFO 16044 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7a027ff0: startup date [Tue May 01 17:45:57 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3bc6718a
2018-05-01 17:45:59.419  INFO 16044 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:45:59.442  INFO 16044 --- [restartedMain] .RepositoryConfigurationExtensionSupport : Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.jcombat.profile.repository.MovieRepository.
2018-05-01 17:45:59.450  INFO 16044 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2018-05-01 17:45:59.717  INFO 16044 --- [restartedMain] o.s.cloud.context.scope.GenericScope     : BeanFactory id=38240428-1a64-306b-94a6-a520528c22e6
2018-05-01 17:45:59.761  INFO 16044 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-05-01 17:45:59.877  INFO 16044 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$c11eba2b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:45:59.921  INFO 16044 --- [restartedMain] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$dd38bd28] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-05-01 17:46:00.413  INFO 16044 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 3333 (http)
2018-05-01 17:46:00.423  INFO 16044 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2018-05-01 17:46:00.423  INFO 16044 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.23
2018-05-01 17:46:00.481  INFO 16044 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2018-05-01 17:46:00.481  INFO 16044 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2607 ms
2018-05-01 17:46:00.781  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2018-05-01 17:46:00.784  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'webServlet' to [/h2-console/*]
2018-05-01 17:46:00.789  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2018-05-01 17:46:00.789  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2018-05-01 17:46:00.789  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-05-01 17:46:00.789  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-05-01 17:46:00.790  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2018-05-01 17:46:00.791  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2018-05-01 17:46:00.791  INFO 16044 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2018-05-01 17:46:01.259  INFO 16044 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Building JPA container EntityManagerFactory for persistence unit 'default'
2018-05-01 17:46:01.957  INFO 16044 --- [restartedMain] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2018-05-01 17:46:02.500  INFO 16044 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=MULTIPLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:46:02.501  INFO 16044 --- [restartedMain] org.mongodb.driver.cluster               : Adding discovered server localhost:27017 to client view of cluster
2018-05-01 17:46:02.550  INFO 16044 --- [cluster-ClusterId{value='5ae87daab11f8e3eac338e32', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:22}] to localhost:27017
2018-05-01 17:46:02.553  INFO 16044 --- [cluster-ClusterId{value='5ae87daab11f8e3eac338e32', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=576791}
2018-05-01 17:46:02.554  INFO 16044 --- [cluster-ClusterId{value='5ae87daab11f8e3eac338e32', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Discovered cluster type of STANDALONE
2018-05-01 17:46:02.923  INFO 16044 --- [restartedMain] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2018-05-01 17:46:03.077  WARN 16044 --- [restartedMain] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-01 17:46:03.179  INFO 16044 --- [restartedMain] org.apache.spark.SparkContext            : Submitted application: MongoSparkConnectorIntro
2018-05-01 17:46:03.190  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls to: memojja
2018-05-01 17:46:03.190  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls to: memojja
2018-05-01 17:46:03.191  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2018-05-01 17:46:03.192  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2018-05-01 17:46:03.193  INFO 16044 --- [restartedMain] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(memojja); groups with view permissions: Set(); users  with modify permissions: Set(memojja); groups with modify permissions: Set()
2018-05-01 17:46:03.519  INFO 16044 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 58607.
2018-05-01 17:46:03.534  INFO 16044 --- [restartedMain] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2018-05-01 17:46:03.550  INFO 16044 --- [restartedMain] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2018-05-01 17:46:03.552  INFO 16044 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-01 17:46:03.552  INFO 16044 --- [restartedMain] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2018-05-01 17:46:03.558  INFO 16044 --- [restartedMain] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Users\memojja\AppData\Local\Temp\blockmgr-791e8dc9-b201-4054-8118-4169f2f7545e
2018-05-01 17:46:03.581  INFO 16044 --- [restartedMain] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1990.8 MB
2018-05-01 17:46:03.618  INFO 16044 --- [restartedMain] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2018-05-01 17:46:03.669  INFO 16044 --- [restartedMain] org.spark_project.jetty.util.log         : Logging initialized @8439ms
2018-05-01 17:46:03.714  INFO 16044 --- [restartedMain] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2018-05-01 17:46:03.725  INFO 16044 --- [restartedMain] org.spark_project.jetty.server.Server    : Started @8496ms
2018-05-01 17:46:03.746  INFO 16044 --- [restartedMain] o.s.jetty.server.AbstractConnector       : Started ServerConnector@71ae6b79{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-01 17:46:03.747  INFO 16044 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2018-05-01 17:46:03.767  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5859388b{/jobs,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.768  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1328ce00{/jobs/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.768  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6281d4b3{/jobs/job,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.769  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2a15bc7e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.769  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@c86d4a7{/stages,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.771  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@78c0e38f{/stages/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.772  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6a2223c1{/stages/stage,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.773  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1430f0b7{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.773  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@71d15733{/stages/pool,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.773  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3205e013{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.774  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@63a2d760{/storage,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.775  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@476e99b0{/storage/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.775  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@213ccb49{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.777  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7fcba19e{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.777  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6c155a00{/environment,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.778  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5a2a629a{/environment/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.778  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1246d77b{/executors,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.779  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1c63d566{/executors/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.780  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4694f264{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.781  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7362399f{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.786  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@182186e0{/static,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.787  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@37a2b8e1{/,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.788  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@d08c792{/api,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.788  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@144b723b{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.789  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2459beff{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.790  INFO 16044 --- [restartedMain] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://172.21.241.193:4040
2018-05-01 17:46:03.875  INFO 16044 --- [restartedMain] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2018-05-01 17:46:03.900  INFO 16044 --- [restartedMain] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58620.
2018-05-01 17:46:03.901  INFO 16044 --- [restartedMain] o.a.s.n.netty.NettyBlockTransferService  : Server created on 172.21.241.193:58620
2018-05-01 17:46:03.902  INFO 16044 --- [restartedMain] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-01 17:46:03.903  INFO 16044 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 172.21.241.193, 58620, None)
2018-05-01 17:46:03.906  INFO 16044 --- [dispatcher-event-loop-3] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 172.21.241.193:58620 with 1990.8 MB RAM, BlockManagerId(driver, 172.21.241.193, 58620, None)
2018-05-01 17:46:03.910  INFO 16044 --- [restartedMain] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 172.21.241.193, 58620, None)
2018-05-01 17:46:03.910  INFO 16044 --- [restartedMain] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 172.21.241.193, 58620, None)
2018-05-01 17:46:03.921  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@235b1574{/metrics/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.970  INFO 16044 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/').
2018-05-01 17:46:03.971  INFO 16044 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : Warehouse path is 'file:/C:/Users/memojja/Desktop/thesis-microservice/recomendation-service/spark-warehouse/'.
2018-05-01 17:46:03.976  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5fa69481{/SQL,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.977  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5e8813a0{/SQL/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.978  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4e9a94a4{/SQL/execution,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.978  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6306825e{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-05-01 17:46:03.980  INFO 16044 --- [restartedMain] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2a94ad38{/static/sql,null,AVAILABLE,@Spark}
2018-05-01 17:46:04.507  WARN 16044 --- [restartedMain] o.apache.spark.sql.internal.SharedState  : URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
2018-05-01 17:46:04.718  INFO 16044 --- [restartedMain] o.a.s.s.e.s.s.StateStoreCoordinatorRef   : Registered StateStoreCoordinator endpoint
2018-05-01 17:46:05.352  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/recomendations],methods=[POST]}" onto public java.util.concurrent.Future<java.util.List<com.jcombat.profile.model.Movie>> com.jcombat.profile.controller.RecomendationController.handleRatings(java.util.List<com.jcombat.profile.model.Rating>) throws java.util.concurrent.ExecutionException,java.lang.InterruptedException
2018-05-01 17:46:05.355  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/v2/api-docs],methods=[GET],produces=[application/json || application/hal+json]}" onto public org.springframework.http.ResponseEntity<springfox.documentation.spring.web.json.Json> springfox.documentation.swagger2.web.Swagger2Controller.getDocumentation(java.lang.String,javax.servlet.http.HttpServletRequest)
2018-05-01 17:46:05.358  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/security]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.SecurityConfiguration> springfox.documentation.swagger.web.ApiResourceController.securityConfiguration()
2018-05-01 17:46:05.359  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources/configuration/ui]}" onto org.springframework.http.ResponseEntity<springfox.documentation.swagger.web.UiConfiguration> springfox.documentation.swagger.web.ApiResourceController.uiConfiguration()
2018-05-01 17:46:05.359  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/swagger-resources]}" onto org.springframework.http.ResponseEntity<java.util.List<springfox.documentation.swagger.web.SwaggerResource>> springfox.documentation.swagger.web.ApiResourceController.swaggerResources()
2018-05-01 17:46:05.361  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-05-01 17:46:05.361  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-05-01 17:46:06.242  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.value(java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:46:06.244  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/reset],methods=[POST]}" onto public java.util.Map<java.lang.String, java.lang.Object> org.springframework.cloud.context.environment.EnvironmentManagerMvcEndpoint.reset()
2018-05-01 17:46:06.245  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.246  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/archaius || /archaius.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.247  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2018-05-01 17:46:06.247  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.248  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2018-05-01 17:46:06.250  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2018-05-01 17:46:06.250  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2018-05-01 17:46:06.250  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.252  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2018-05-01 17:46:06.252  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.253  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2018-05-01 17:46:06.253  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.253  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/features || /features.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.254  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.254  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.255  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2018-05-01 17:46:06.255  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/pause || /pause.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:46:06.256  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/resume || /resume.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:46:06.256  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.257  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/refresh || /refresh.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.endpoint.GenericPostableMvcEndpoint.invoke()
2018-05-01 17:46:06.257  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.258  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2018-05-01 17:46:06.259  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2018-05-01 17:46:06.259  INFO 16044 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/restart || /restart.json],methods=[POST]}" onto public java.lang.Object org.springframework.cloud.context.restart.RestartMvcEndpoint.invoke()
2018-05-01 17:46:06.709  INFO 16044 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7a027ff0: startup date [Tue May 01 17:45:57 EET 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@3bc6718a
2018-05-01 17:46:06.787  INFO 16044 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:46:06.787  INFO 16044 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:46:06.808  INFO 16044 --- [restartedMain] .m.m.a.ExceptionHandlerExceptionResolver : Detected @ExceptionHandler methods in exceptionHandlerAdvice
2018-05-01 17:46:06.838  INFO 16044 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-05-01 17:46:07.347  WARN 16044 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : Unable to start LiveReload server
2018-05-01 17:46:07.436  WARN 16044 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:46:07.436  INFO 16044 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:46:07.442  WARN 16044 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2018-05-01 17:46:07.442  INFO 16044 --- [restartedMain] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-05-01 17:46:07.539  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2018-05-01 17:46:07.551  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-05-01 17:46:07.551  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-05-01 17:46:07.555  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-05-01 17:46:07.555  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'refreshEndpoint' has been autodetected for JMX exposure
2018-05-01 17:46:07.556  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Bean with name 'restartEndpoint' has been autodetected for JMX exposure
2018-05-01 17:46:07.560  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-05-01 17:46:07.577  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'restartEndpoint': registering with JMX server as MBean [org.springframework.cloud.context.restart:name=restartEndpoint,type=RestartEndpoint]
2018-05-01 17:46:07.590  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-05-01 17:46:07.605  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=7a027ff0,type=ConfigurationPropertiesRebinder]
2018-05-01 17:46:07.612  INFO 16044 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Located managed bean 'refreshEndpoint': registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]
2018-05-01 17:46:07.977  INFO 16044 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2018-05-01 17:46:07.987  INFO 16044 --- [restartedMain] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2018-05-01 17:46:08.096  INFO 16044 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2018-05-01 17:46:08.096  INFO 16044 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2018-05-01 17:46:08.216  INFO 16044 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2018-05-01 17:46:08.216  INFO 16044 --- [restartedMain] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2018-05-01 17:46:08.532  INFO 16044 --- [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2018-05-01 17:46:08.652  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2018-05-01 17:46:08.652  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2018-05-01 17:46:08.652  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2018-05-01 17:46:08.652  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application is null : false
2018-05-01 17:46:08.654  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2018-05-01 17:46:08.654  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2018-05-01 17:46:08.654  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2018-05-01 17:46:08.842  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : The response status is 200
2018-05-01 17:46:08.846  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2018-05-01 17:46:08.848  INFO 16044 --- [restartedMain] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2018-05-01 17:46:08.852  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1525185968852 with initial instances count: 6
2018-05-01 17:46:08.871  INFO 16044 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Registering application recomendation-service2 with eureka with status UP
2018-05-01 17:46:08.872  INFO 16044 --- [restartedMain] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1525185968872, current=UP, previous=STARTING]
2018-05-01 17:46:08.874  INFO 16044 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333: registering service...
2018-05-01 17:46:08.917  INFO 16044 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_RECOMENDATION-SERVICE2/ari:recomendation-service2:3333 - registration status: 204
2018-05-01 17:46:08.931  INFO 16044 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 2147483647
2018-05-01 17:46:08.931  INFO 16044 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Context refreshed
2018-05-01 17:46:08.949  INFO 16044 --- [restartedMain] d.s.w.p.DocumentationPluginsBootstrapper : Found 1 custom documentation plugin(s)
2018-05-01 17:46:08.963  INFO 16044 --- [restartedMain] s.d.s.w.s.ApiListingReferenceScanner     : Scanning for api listing references
2018-05-01 17:46:09.025  INFO 16044 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 3333 (http)
2018-05-01 17:46:09.027  INFO 16044 --- [restartedMain] c.n.e.EurekaDiscoveryClientConfiguration : Updating port to 3333
2018-05-01 17:46:09.031  INFO 16044 --- [restartedMain] j.p.ProfileMicroserviceServerApplication : Started ProfileMicroserviceServerApplication in 12.658 seconds (JVM running for 13.802)
2018-05-01 17:46:09.612  INFO 16044 --- [RMI TCP Connection(11)-172.21.241.193] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:23}] to localhost:27017
2018-05-01 17:47:27.670  INFO 16044 --- [http-nio-3333-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-05-01 17:47:27.670  INFO 16044 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2018-05-01 17:47:27.700  INFO 16044 --- [http-nio-3333-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 30 ms
2018-05-01 17:47:27.720  WARN 16044 --- [http-nio-3333-exec-1] o.s.web.servlet.PageNotFound             : Request method 'GET' not supported
2018-05-01 17:47:27.721  WARN 16044 --- [http-nio-3333-exec-1] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved exception caused by Handler execution: org.springframework.web.HttpRequestMethodNotSupportedException: Request method 'GET' not supported
2018-05-01 17:48:03.882  WARN 16044 --- [http-nio-3333-exec-3] o.apache.spark.sql.SparkSession$Builder  : Using an existing SparkSession; some configuration may not take effect.
2018-05-01 17:48:03.965  INFO 16044 --- [http-nio-3333-exec-3] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0 stored as values in memory (estimated size 248.0 B, free 1990.8 MB)
2018-05-01 17:48:04.037  INFO 16044 --- [http-nio-3333-exec-3] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0_piece0 stored as bytes in memory (estimated size 419.0 B, free 1990.8 MB)
2018-05-01 17:48:04.039  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_0_piece0 in memory on 172.21.241.193:58620 (size: 419.0 B, free: 1990.8 MB)
2018-05-01 17:48:04.043  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Created broadcast 0 from broadcast at MongoSpark.scala:536
2018-05-01 17:48:04.252  INFO 16044 --- [http-nio-3333-exec-3] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:48:04.258  INFO 16044 --- [http-nio-3333-exec-3] org.mongodb.driver.cluster               : Cluster description not yet available. Waiting for 30000 ms before timing out
2018-05-01 17:48:04.261  INFO 16044 --- [cluster-ClusterId{value='5ae87e24b11f8e3eac338e33', description='null'}-127.0.0.1:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:28}] to 127.0.0.1:27017
2018-05-01 17:48:04.263  INFO 16044 --- [cluster-ClusterId{value='5ae87e24b11f8e3eac338e33', description='null'}-127.0.0.1:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=934321}
2018-05-01 17:48:04.265  INFO 16044 --- [http-nio-3333-exec-3] c.m.spark.connection.MongoClientCache    : Creating MongoClient: [127.0.0.1:27017]
2018-05-01 17:48:04.276  INFO 16044 --- [http-nio-3333-exec-3] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:29}] to 127.0.0.1:27017
2018-05-01 17:48:05.508  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: collect at RecomendationServiceImpl.java:86
2018-05-01 17:48:05.520  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 0 (collect at RecomendationServiceImpl.java:86) with 66 output partitions
2018-05-01 17:48:05.520  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 0 (collect at RecomendationServiceImpl.java:86)
2018-05-01 17:48:05.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:48:05.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:48:05.529  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 0 (MapPartitionsRDD[1] at map at RecomendationServiceImpl.java:83), which has no missing parents
2018-05-01 17:48:05.549  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 1990.8 MB)
2018-05-01 17:48:05.553  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1990.8 MB)
2018-05-01 17:48:05.553  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_1_piece0 in memory on 172.21.241.193:58620 (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 17:48:05.554  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:48:05.564  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 66 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at RecomendationServiceImpl.java:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-05-01 17:48:05.565  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 0.0 with 66 tasks
2018-05-01 17:48:05.606  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 4987 bytes)
2018-05-01 17:48:05.613  INFO 16044 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Running task 0.0 in stage 0.0 (TID 0)
2018-05-01 17:48:05.672  INFO 16044 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 0.0 (TID 0). 751 bytes result sent to driver
2018-05-01 17:48:05.675  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 4999 bytes)
2018-05-01 17:48:05.675  INFO 16044 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Running task 1.0 in stage 0.0 (TID 1)
2018-05-01 17:48:05.680  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 0.0 (TID 0) in 88 ms on localhost (executor driver) (1/66)
2018-05-01 17:48:06.346  INFO 16044 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 0.0 (TID 1). 429841 bytes result sent to driver
2018-05-01 17:48:06.347  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 5005 bytes)
2018-05-01 17:48:06.347  INFO 16044 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Running task 2.0 in stage 0.0 (TID 2)
2018-05-01 17:48:06.368  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 0.0 (TID 1) in 694 ms on localhost (executor driver) (2/66)
2018-05-01 17:48:06.920  INFO 16044 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 0.0 (TID 2). 432580 bytes result sent to driver
2018-05-01 17:48:06.922  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 5004 bytes)
2018-05-01 17:48:06.922  INFO 16044 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Running task 3.0 in stage 0.0 (TID 3)
2018-05-01 17:48:06.940  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 0.0 (TID 2) in 593 ms on localhost (executor driver) (3/66)
2018-05-01 17:48:07.584  INFO 16044 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 0.0 (TID 3). 433940 bytes result sent to driver
2018-05-01 17:48:07.585  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, ANY, 5003 bytes)
2018-05-01 17:48:07.585  INFO 16044 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Running task 4.0 in stage 0.0 (TID 4)
2018-05-01 17:48:07.601  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 0.0 (TID 3) in 679 ms on localhost (executor driver) (4/66)
2018-05-01 17:48:08.136  INFO 16044 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Finished task 4.0 in stage 0.0 (TID 4). 423957 bytes result sent to driver
2018-05-01 17:48:08.137  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, ANY, 5003 bytes)
2018-05-01 17:48:08.137  INFO 16044 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Running task 5.0 in stage 0.0 (TID 5)
2018-05-01 17:48:08.153  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 4.0 in stage 0.0 (TID 4) in 567 ms on localhost (executor driver) (5/66)
2018-05-01 17:48:08.708  INFO 16044 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Finished task 5.0 in stage 0.0 (TID 5). 418098 bytes result sent to driver
2018-05-01 17:48:08.710  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, ANY, 5003 bytes)
2018-05-01 17:48:08.710  INFO 16044 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Running task 6.0 in stage 0.0 (TID 6)
2018-05-01 17:48:08.735  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 5.0 in stage 0.0 (TID 5) in 598 ms on localhost (executor driver) (6/66)
2018-05-01 17:48:09.336  INFO 16044 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Finished task 6.0 in stage 0.0 (TID 6). 416988 bytes result sent to driver
2018-05-01 17:48:09.337  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, ANY, 5003 bytes)
2018-05-01 17:48:09.337  INFO 16044 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Running task 7.0 in stage 0.0 (TID 7)
2018-05-01 17:48:09.353  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 6.0 in stage 0.0 (TID 6) in 644 ms on localhost (executor driver) (7/66)
2018-05-01 17:48:09.889  INFO 16044 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Finished task 7.0 in stage 0.0 (TID 7). 426842 bytes result sent to driver
2018-05-01 17:48:09.889  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, ANY, 5003 bytes)
2018-05-01 17:48:09.889  INFO 16044 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Running task 8.0 in stage 0.0 (TID 8)
2018-05-01 17:48:09.907  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 7.0 in stage 0.0 (TID 7) in 570 ms on localhost (executor driver) (8/66)
2018-05-01 17:48:10.447  INFO 16044 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Finished task 8.0 in stage 0.0 (TID 8). 430736 bytes result sent to driver
2018-05-01 17:48:10.448  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, ANY, 5003 bytes)
2018-05-01 17:48:10.449  INFO 16044 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Running task 9.0 in stage 0.0 (TID 9)
2018-05-01 17:48:10.464  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 8.0 in stage 0.0 (TID 8) in 575 ms on localhost (executor driver) (9/66)
2018-05-01 17:48:11.021  INFO 16044 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Finished task 9.0 in stage 0.0 (TID 9). 432112 bytes result sent to driver
2018-05-01 17:48:11.022  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 10.0 in stage 0.0 (TID 10, localhost, executor driver, partition 10, ANY, 5003 bytes)
2018-05-01 17:48:11.022  INFO 16044 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Running task 10.0 in stage 0.0 (TID 10)
2018-05-01 17:48:11.040  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 9.0 in stage 0.0 (TID 9) in 592 ms on localhost (executor driver) (10/66)
2018-05-01 17:48:11.642  INFO 16044 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Finished task 10.0 in stage 0.0 (TID 10). 428533 bytes result sent to driver
2018-05-01 17:48:11.643  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 11.0 in stage 0.0 (TID 11, localhost, executor driver, partition 11, ANY, 5003 bytes)
2018-05-01 17:48:11.643  INFO 16044 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Running task 11.0 in stage 0.0 (TID 11)
2018-05-01 17:48:11.660  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 10.0 in stage 0.0 (TID 10) in 638 ms on localhost (executor driver) (11/66)
2018-05-01 17:48:12.276  INFO 16044 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Finished task 11.0 in stage 0.0 (TID 11). 432916 bytes result sent to driver
2018-05-01 17:48:12.277  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 12.0 in stage 0.0 (TID 12, localhost, executor driver, partition 12, ANY, 5003 bytes)
2018-05-01 17:48:12.278  INFO 16044 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Running task 12.0 in stage 0.0 (TID 12)
2018-05-01 17:48:12.296  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 11.0 in stage 0.0 (TID 11) in 653 ms on localhost (executor driver) (12/66)
2018-05-01 17:48:12.849  INFO 16044 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Finished task 12.0 in stage 0.0 (TID 12). 431975 bytes result sent to driver
2018-05-01 17:48:12.850  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 13.0 in stage 0.0 (TID 13, localhost, executor driver, partition 13, ANY, 5003 bytes)
2018-05-01 17:48:12.850  INFO 16044 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Running task 13.0 in stage 0.0 (TID 13)
2018-05-01 17:48:12.868  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 12.0 in stage 0.0 (TID 12) in 591 ms on localhost (executor driver) (13/66)
2018-05-01 17:48:13.480  INFO 16044 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Finished task 13.0 in stage 0.0 (TID 13). 430518 bytes result sent to driver
2018-05-01 17:48:13.480  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 14.0 in stage 0.0 (TID 14, localhost, executor driver, partition 14, ANY, 5003 bytes)
2018-05-01 17:48:13.481  INFO 16044 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Running task 14.0 in stage 0.0 (TID 14)
2018-05-01 17:48:13.497  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 13.0 in stage 0.0 (TID 13) in 647 ms on localhost (executor driver) (14/66)
2018-05-01 17:48:14.119  INFO 16044 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Finished task 14.0 in stage 0.0 (TID 14). 433458 bytes result sent to driver
2018-05-01 17:48:14.120  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 15.0 in stage 0.0 (TID 15, localhost, executor driver, partition 15, ANY, 5003 bytes)
2018-05-01 17:48:14.121  INFO 16044 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Running task 15.0 in stage 0.0 (TID 15)
2018-05-01 17:48:14.140  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 14.0 in stage 0.0 (TID 14) in 660 ms on localhost (executor driver) (15/66)
2018-05-01 17:48:14.705  INFO 16044 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Finished task 15.0 in stage 0.0 (TID 15). 433639 bytes result sent to driver
2018-05-01 17:48:14.706  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 16.0 in stage 0.0 (TID 16, localhost, executor driver, partition 16, ANY, 5003 bytes)
2018-05-01 17:48:14.706  INFO 16044 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Running task 16.0 in stage 0.0 (TID 16)
2018-05-01 17:48:14.729  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 15.0 in stage 0.0 (TID 15) in 609 ms on localhost (executor driver) (16/66)
2018-05-01 17:48:15.284  INFO 16044 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Finished task 16.0 in stage 0.0 (TID 16). 429584 bytes result sent to driver
2018-05-01 17:48:15.285  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 17.0 in stage 0.0 (TID 17, localhost, executor driver, partition 17, ANY, 5002 bytes)
2018-05-01 17:48:15.285  INFO 16044 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Running task 17.0 in stage 0.0 (TID 17)
2018-05-01 17:48:15.302  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 16.0 in stage 0.0 (TID 16) in 596 ms on localhost (executor driver) (17/66)
2018-05-01 17:48:15.887  INFO 16044 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Finished task 17.0 in stage 0.0 (TID 17). 434264 bytes result sent to driver
2018-05-01 17:48:15.887  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 18.0 in stage 0.0 (TID 18, localhost, executor driver, partition 18, ANY, 5002 bytes)
2018-05-01 17:48:15.888  INFO 16044 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Running task 18.0 in stage 0.0 (TID 18)
2018-05-01 17:48:15.903  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 17.0 in stage 0.0 (TID 17) in 618 ms on localhost (executor driver) (18/66)
2018-05-01 17:48:16.437  INFO 16044 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Finished task 18.0 in stage 0.0 (TID 18). 431383 bytes result sent to driver
2018-05-01 17:48:16.438  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 19.0 in stage 0.0 (TID 19, localhost, executor driver, partition 19, ANY, 5003 bytes)
2018-05-01 17:48:16.438  INFO 16044 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Running task 19.0 in stage 0.0 (TID 19)
2018-05-01 17:48:16.453  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 18.0 in stage 0.0 (TID 18) in 566 ms on localhost (executor driver) (19/66)
2018-05-01 17:48:17.020  INFO 16044 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Finished task 19.0 in stage 0.0 (TID 19). 435226 bytes result sent to driver
2018-05-01 17:48:17.021  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 20.0 in stage 0.0 (TID 20, localhost, executor driver, partition 20, ANY, 5003 bytes)
2018-05-01 17:48:17.021  INFO 16044 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Running task 20.0 in stage 0.0 (TID 20)
2018-05-01 17:48:17.042  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 19.0 in stage 0.0 (TID 19) in 605 ms on localhost (executor driver) (20/66)
2018-05-01 17:48:17.584  INFO 16044 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Finished task 20.0 in stage 0.0 (TID 20). 434347 bytes result sent to driver
2018-05-01 17:48:17.584  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 21.0 in stage 0.0 (TID 21, localhost, executor driver, partition 21, ANY, 5003 bytes)
2018-05-01 17:48:17.585  INFO 16044 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Running task 21.0 in stage 0.0 (TID 21)
2018-05-01 17:48:17.602  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 20.0 in stage 0.0 (TID 20) in 581 ms on localhost (executor driver) (21/66)
2018-05-01 17:48:18.231  INFO 16044 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Finished task 21.0 in stage 0.0 (TID 21). 428428 bytes result sent to driver
2018-05-01 17:48:18.231  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 22.0 in stage 0.0 (TID 22, localhost, executor driver, partition 22, ANY, 5003 bytes)
2018-05-01 17:48:18.232  INFO 16044 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Running task 22.0 in stage 0.0 (TID 22)
2018-05-01 17:48:18.249  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 21.0 in stage 0.0 (TID 21) in 664 ms on localhost (executor driver) (22/66)
2018-05-01 17:48:18.811  INFO 16044 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Finished task 22.0 in stage 0.0 (TID 22). 434997 bytes result sent to driver
2018-05-01 17:48:18.811  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 23.0 in stage 0.0 (TID 23, localhost, executor driver, partition 23, ANY, 5003 bytes)
2018-05-01 17:48:18.811  INFO 16044 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Running task 23.0 in stage 0.0 (TID 23)
2018-05-01 17:48:18.829  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 22.0 in stage 0.0 (TID 22) in 598 ms on localhost (executor driver) (23/66)
2018-05-01 17:48:19.381  INFO 16044 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Finished task 23.0 in stage 0.0 (TID 23). 430843 bytes result sent to driver
2018-05-01 17:48:19.381  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 24.0 in stage 0.0 (TID 24, localhost, executor driver, partition 24, ANY, 5003 bytes)
2018-05-01 17:48:19.382  INFO 16044 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Running task 24.0 in stage 0.0 (TID 24)
2018-05-01 17:48:19.397  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 23.0 in stage 0.0 (TID 23) in 586 ms on localhost (executor driver) (24/66)
2018-05-01 17:48:19.987  INFO 16044 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Finished task 24.0 in stage 0.0 (TID 24). 429256 bytes result sent to driver
2018-05-01 17:48:19.988  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 25.0 in stage 0.0 (TID 25, localhost, executor driver, partition 25, ANY, 5003 bytes)
2018-05-01 17:48:19.988  INFO 16044 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Running task 25.0 in stage 0.0 (TID 25)
2018-05-01 17:48:20.006  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 24.0 in stage 0.0 (TID 24) in 625 ms on localhost (executor driver) (25/66)
2018-05-01 17:48:20.630  INFO 16044 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Finished task 25.0 in stage 0.0 (TID 25). 432251 bytes result sent to driver
2018-05-01 17:48:20.631  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 26.0 in stage 0.0 (TID 26, localhost, executor driver, partition 26, ANY, 5003 bytes)
2018-05-01 17:48:20.631  INFO 16044 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Running task 26.0 in stage 0.0 (TID 26)
2018-05-01 17:48:20.649  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 25.0 in stage 0.0 (TID 25) in 662 ms on localhost (executor driver) (26/66)
2018-05-01 17:48:21.205  INFO 16044 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Finished task 26.0 in stage 0.0 (TID 26). 433194 bytes result sent to driver
2018-05-01 17:48:21.206  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 27.0 in stage 0.0 (TID 27, localhost, executor driver, partition 27, ANY, 5003 bytes)
2018-05-01 17:48:21.206  INFO 16044 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Running task 27.0 in stage 0.0 (TID 27)
2018-05-01 17:48:21.221  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 26.0 in stage 0.0 (TID 26) in 590 ms on localhost (executor driver) (27/66)
2018-05-01 17:48:21.759  INFO 16044 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Finished task 27.0 in stage 0.0 (TID 27). 433416 bytes result sent to driver
2018-05-01 17:48:21.759  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 28.0 in stage 0.0 (TID 28, localhost, executor driver, partition 28, ANY, 5003 bytes)
2018-05-01 17:48:21.760  INFO 16044 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Running task 28.0 in stage 0.0 (TID 28)
2018-05-01 17:48:21.776  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 27.0 in stage 0.0 (TID 27) in 571 ms on localhost (executor driver) (28/66)
2018-05-01 17:48:22.376  INFO 16044 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Finished task 28.0 in stage 0.0 (TID 28). 431320 bytes result sent to driver
2018-05-01 17:48:22.377  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 29.0 in stage 0.0 (TID 29, localhost, executor driver, partition 29, ANY, 5003 bytes)
2018-05-01 17:48:22.377  INFO 16044 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Running task 29.0 in stage 0.0 (TID 29)
2018-05-01 17:48:22.396  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 28.0 in stage 0.0 (TID 28) in 637 ms on localhost (executor driver) (29/66)
2018-05-01 17:48:23.032  INFO 16044 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Finished task 29.0 in stage 0.0 (TID 29). 432533 bytes result sent to driver
2018-05-01 17:48:23.033  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 30.0 in stage 0.0 (TID 30, localhost, executor driver, partition 30, ANY, 5003 bytes)
2018-05-01 17:48:23.033  INFO 16044 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Running task 30.0 in stage 0.0 (TID 30)
2018-05-01 17:48:23.049  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 29.0 in stage 0.0 (TID 29) in 672 ms on localhost (executor driver) (30/66)
2018-05-01 17:48:23.680  INFO 16044 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Finished task 30.0 in stage 0.0 (TID 30). 431358 bytes result sent to driver
2018-05-01 17:48:23.681  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 31.0 in stage 0.0 (TID 31, localhost, executor driver, partition 31, ANY, 5003 bytes)
2018-05-01 17:48:23.681  INFO 16044 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Running task 31.0 in stage 0.0 (TID 31)
2018-05-01 17:48:23.697  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 30.0 in stage 0.0 (TID 30) in 665 ms on localhost (executor driver) (31/66)
2018-05-01 17:48:24.311  INFO 16044 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Finished task 31.0 in stage 0.0 (TID 31). 434098 bytes result sent to driver
2018-05-01 17:48:24.312  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 32.0 in stage 0.0 (TID 32, localhost, executor driver, partition 32, ANY, 5002 bytes)
2018-05-01 17:48:24.312  INFO 16044 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Running task 32.0 in stage 0.0 (TID 32)
2018-05-01 17:48:24.335  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 31.0 in stage 0.0 (TID 31) in 654 ms on localhost (executor driver) (32/66)
2018-05-01 17:48:24.915  INFO 16044 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Finished task 32.0 in stage 0.0 (TID 32). 432096 bytes result sent to driver
2018-05-01 17:48:24.915  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 33.0 in stage 0.0 (TID 33, localhost, executor driver, partition 33, ANY, 5002 bytes)
2018-05-01 17:48:24.915  INFO 16044 --- [Executor task launch worker for task 33] org.apache.spark.executor.Executor       : Running task 33.0 in stage 0.0 (TID 33)
2018-05-01 17:48:24.939  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 32.0 in stage 0.0 (TID 32) in 627 ms on localhost (executor driver) (33/66)
2018-05-01 17:48:25.491  INFO 16044 --- [Executor task launch worker for task 33] org.apache.spark.executor.Executor       : Finished task 33.0 in stage 0.0 (TID 33). 433300 bytes result sent to driver
2018-05-01 17:48:25.491  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 34.0 in stage 0.0 (TID 34, localhost, executor driver, partition 34, ANY, 5002 bytes)
2018-05-01 17:48:25.492  INFO 16044 --- [Executor task launch worker for task 34] org.apache.spark.executor.Executor       : Running task 34.0 in stage 0.0 (TID 34)
2018-05-01 17:48:25.510  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 33.0 in stage 0.0 (TID 33) in 595 ms on localhost (executor driver) (34/66)
2018-05-01 17:48:26.097  INFO 16044 --- [Executor task launch worker for task 34] org.apache.spark.executor.Executor       : Finished task 34.0 in stage 0.0 (TID 34). 433019 bytes result sent to driver
2018-05-01 17:48:26.098  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 35.0 in stage 0.0 (TID 35, localhost, executor driver, partition 35, ANY, 5002 bytes)
2018-05-01 17:48:26.098  INFO 16044 --- [Executor task launch worker for task 35] org.apache.spark.executor.Executor       : Running task 35.0 in stage 0.0 (TID 35)
2018-05-01 17:48:26.120  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 34.0 in stage 0.0 (TID 34) in 628 ms on localhost (executor driver) (35/66)
2018-05-01 17:48:26.698  INFO 16044 --- [Executor task launch worker for task 35] org.apache.spark.executor.Executor       : Finished task 35.0 in stage 0.0 (TID 35). 431659 bytes result sent to driver
2018-05-01 17:48:26.699  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 36.0 in stage 0.0 (TID 36, localhost, executor driver, partition 36, ANY, 5002 bytes)
2018-05-01 17:48:26.699  INFO 16044 --- [Executor task launch worker for task 36] org.apache.spark.executor.Executor       : Running task 36.0 in stage 0.0 (TID 36)
2018-05-01 17:48:26.714  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 35.0 in stage 0.0 (TID 35) in 616 ms on localhost (executor driver) (36/66)
2018-05-01 17:48:27.446  INFO 16044 --- [Executor task launch worker for task 36] org.apache.spark.executor.Executor       : Finished task 36.0 in stage 0.0 (TID 36). 435545 bytes result sent to driver
2018-05-01 17:48:27.447  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 37.0 in stage 0.0 (TID 37, localhost, executor driver, partition 37, ANY, 5002 bytes)
2018-05-01 17:48:27.447  INFO 16044 --- [Executor task launch worker for task 37] org.apache.spark.executor.Executor       : Running task 37.0 in stage 0.0 (TID 37)
2018-05-01 17:48:27.465  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 36.0 in stage 0.0 (TID 36) in 766 ms on localhost (executor driver) (37/66)
2018-05-01 17:48:28.021  INFO 16044 --- [Executor task launch worker for task 37] org.apache.spark.executor.Executor       : Finished task 37.0 in stage 0.0 (TID 37). 432678 bytes result sent to driver
2018-05-01 17:48:28.021  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 38.0 in stage 0.0 (TID 38, localhost, executor driver, partition 38, ANY, 5003 bytes)
2018-05-01 17:48:28.022  INFO 16044 --- [Executor task launch worker for task 38] org.apache.spark.executor.Executor       : Running task 38.0 in stage 0.0 (TID 38)
2018-05-01 17:48:28.046  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 37.0 in stage 0.0 (TID 37) in 599 ms on localhost (executor driver) (38/66)
2018-05-01 17:48:28.596  INFO 16044 --- [Executor task launch worker for task 38] org.apache.spark.executor.Executor       : Finished task 38.0 in stage 0.0 (TID 38). 433731 bytes result sent to driver
2018-05-01 17:48:28.596  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 39.0 in stage 0.0 (TID 39, localhost, executor driver, partition 39, ANY, 5003 bytes)
2018-05-01 17:48:28.597  INFO 16044 --- [Executor task launch worker for task 39] org.apache.spark.executor.Executor       : Running task 39.0 in stage 0.0 (TID 39)
2018-05-01 17:48:28.655  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 38.0 in stage 0.0 (TID 38) in 634 ms on localhost (executor driver) (39/66)
2018-05-01 17:48:29.190  INFO 16044 --- [Executor task launch worker for task 39] org.apache.spark.executor.Executor       : Finished task 39.0 in stage 0.0 (TID 39). 430075 bytes result sent to driver
2018-05-01 17:48:29.191  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 40.0 in stage 0.0 (TID 40, localhost, executor driver, partition 40, ANY, 5003 bytes)
2018-05-01 17:48:29.191  INFO 16044 --- [Executor task launch worker for task 40] org.apache.spark.executor.Executor       : Running task 40.0 in stage 0.0 (TID 40)
2018-05-01 17:48:29.208  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 39.0 in stage 0.0 (TID 39) in 611 ms on localhost (executor driver) (40/66)
2018-05-01 17:48:29.775  INFO 16044 --- [Executor task launch worker for task 40] org.apache.spark.executor.Executor       : Finished task 40.0 in stage 0.0 (TID 40). 432889 bytes result sent to driver
2018-05-01 17:48:29.775  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 41.0 in stage 0.0 (TID 41, localhost, executor driver, partition 41, ANY, 5003 bytes)
2018-05-01 17:48:29.775  INFO 16044 --- [Executor task launch worker for task 41] org.apache.spark.executor.Executor       : Running task 41.0 in stage 0.0 (TID 41)
2018-05-01 17:48:29.800  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 40.0 in stage 0.0 (TID 40) in 609 ms on localhost (executor driver) (41/66)
2018-05-01 17:48:30.374  INFO 16044 --- [Executor task launch worker for task 41] org.apache.spark.executor.Executor       : Finished task 41.0 in stage 0.0 (TID 41). 431750 bytes result sent to driver
2018-05-01 17:48:30.374  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 42.0 in stage 0.0 (TID 42, localhost, executor driver, partition 42, ANY, 5003 bytes)
2018-05-01 17:48:30.374  INFO 16044 --- [Executor task launch worker for task 42] org.apache.spark.executor.Executor       : Running task 42.0 in stage 0.0 (TID 42)
2018-05-01 17:48:30.390  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 41.0 in stage 0.0 (TID 41) in 615 ms on localhost (executor driver) (42/66)
2018-05-01 17:48:30.971  INFO 16044 --- [Executor task launch worker for task 42] org.apache.spark.executor.Executor       : Finished task 42.0 in stage 0.0 (TID 42). 432035 bytes result sent to driver
2018-05-01 17:48:30.971  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 43.0 in stage 0.0 (TID 43, localhost, executor driver, partition 43, ANY, 5003 bytes)
2018-05-01 17:48:30.971  INFO 16044 --- [Executor task launch worker for task 43] org.apache.spark.executor.Executor       : Running task 43.0 in stage 0.0 (TID 43)
2018-05-01 17:48:30.990  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 42.0 in stage 0.0 (TID 42) in 616 ms on localhost (executor driver) (43/66)
2018-05-01 17:48:31.613  INFO 16044 --- [Executor task launch worker for task 43] org.apache.spark.executor.Executor       : Finished task 43.0 in stage 0.0 (TID 43). 428969 bytes result sent to driver
2018-05-01 17:48:31.613  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 44.0 in stage 0.0 (TID 44, localhost, executor driver, partition 44, ANY, 5003 bytes)
2018-05-01 17:48:31.613  INFO 16044 --- [Executor task launch worker for task 44] org.apache.spark.executor.Executor       : Running task 44.0 in stage 0.0 (TID 44)
2018-05-01 17:48:31.635  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 43.0 in stage 0.0 (TID 43) in 664 ms on localhost (executor driver) (44/66)
2018-05-01 17:48:32.366  INFO 16044 --- [Executor task launch worker for task 44] org.apache.spark.executor.Executor       : Finished task 44.0 in stage 0.0 (TID 44). 432682 bytes result sent to driver
2018-05-01 17:48:32.367  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 45.0 in stage 0.0 (TID 45, localhost, executor driver, partition 45, ANY, 5003 bytes)
2018-05-01 17:48:32.367  INFO 16044 --- [Executor task launch worker for task 45] org.apache.spark.executor.Executor       : Running task 45.0 in stage 0.0 (TID 45)
2018-05-01 17:48:32.384  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 44.0 in stage 0.0 (TID 44) in 771 ms on localhost (executor driver) (45/66)
2018-05-01 17:48:33.008  INFO 16044 --- [Executor task launch worker for task 45] org.apache.spark.executor.Executor       : Finished task 45.0 in stage 0.0 (TID 45). 430122 bytes result sent to driver
2018-05-01 17:48:33.009  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 46.0 in stage 0.0 (TID 46, localhost, executor driver, partition 46, ANY, 5003 bytes)
2018-05-01 17:48:33.009  INFO 16044 --- [Executor task launch worker for task 46] org.apache.spark.executor.Executor       : Running task 46.0 in stage 0.0 (TID 46)
2018-05-01 17:48:33.032  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 45.0 in stage 0.0 (TID 45) in 665 ms on localhost (executor driver) (46/66)
2018-05-01 17:48:33.549  INFO 16044 --- [Executor task launch worker for task 46] org.apache.spark.executor.Executor       : Finished task 46.0 in stage 0.0 (TID 46). 430180 bytes result sent to driver
2018-05-01 17:48:33.549  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 47.0 in stage 0.0 (TID 47, localhost, executor driver, partition 47, ANY, 5003 bytes)
2018-05-01 17:48:33.549  INFO 16044 --- [Executor task launch worker for task 47] org.apache.spark.executor.Executor       : Running task 47.0 in stage 0.0 (TID 47)
2018-05-01 17:48:33.565  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 46.0 in stage 0.0 (TID 46) in 557 ms on localhost (executor driver) (47/66)
2018-05-01 17:48:34.149  INFO 16044 --- [Executor task launch worker for task 47] org.apache.spark.executor.Executor       : Finished task 47.0 in stage 0.0 (TID 47). 433553 bytes result sent to driver
2018-05-01 17:48:34.149  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 48.0 in stage 0.0 (TID 48, localhost, executor driver, partition 48, ANY, 5003 bytes)
2018-05-01 17:48:34.149  INFO 16044 --- [Executor task launch worker for task 48] org.apache.spark.executor.Executor       : Running task 48.0 in stage 0.0 (TID 48)
2018-05-01 17:48:34.166  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 47.0 in stage 0.0 (TID 47) in 617 ms on localhost (executor driver) (48/66)
2018-05-01 17:48:34.765  INFO 16044 --- [Executor task launch worker for task 48] org.apache.spark.executor.Executor       : Finished task 48.0 in stage 0.0 (TID 48). 431564 bytes result sent to driver
2018-05-01 17:48:34.765  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 49.0 in stage 0.0 (TID 49, localhost, executor driver, partition 49, ANY, 5003 bytes)
2018-05-01 17:48:34.766  INFO 16044 --- [Executor task launch worker for task 49] org.apache.spark.executor.Executor       : Running task 49.0 in stage 0.0 (TID 49)
2018-05-01 17:48:34.783  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 48.0 in stage 0.0 (TID 48) in 634 ms on localhost (executor driver) (49/66)
2018-05-01 17:48:35.327  INFO 16044 --- [Executor task launch worker for task 49] org.apache.spark.executor.Executor       : Finished task 49.0 in stage 0.0 (TID 49). 432743 bytes result sent to driver
2018-05-01 17:48:35.327  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 50.0 in stage 0.0 (TID 50, localhost, executor driver, partition 50, ANY, 5003 bytes)
2018-05-01 17:48:35.328  INFO 16044 --- [Executor task launch worker for task 50] org.apache.spark.executor.Executor       : Running task 50.0 in stage 0.0 (TID 50)
2018-05-01 17:48:35.347  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 49.0 in stage 0.0 (TID 49) in 582 ms on localhost (executor driver) (50/66)
2018-05-01 17:48:35.880  INFO 16044 --- [Executor task launch worker for task 50] org.apache.spark.executor.Executor       : Finished task 50.0 in stage 0.0 (TID 50). 430368 bytes result sent to driver
2018-05-01 17:48:35.881  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 51.0 in stage 0.0 (TID 51, localhost, executor driver, partition 51, ANY, 5002 bytes)
2018-05-01 17:48:35.881  INFO 16044 --- [Executor task launch worker for task 51] org.apache.spark.executor.Executor       : Running task 51.0 in stage 0.0 (TID 51)
2018-05-01 17:48:35.904  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 50.0 in stage 0.0 (TID 50) in 577 ms on localhost (executor driver) (51/66)
2018-05-01 17:48:36.440  INFO 16044 --- [Executor task launch worker for task 51] org.apache.spark.executor.Executor       : Finished task 51.0 in stage 0.0 (TID 51). 435039 bytes result sent to driver
2018-05-01 17:48:36.440  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 52.0 in stage 0.0 (TID 52, localhost, executor driver, partition 52, ANY, 5002 bytes)
2018-05-01 17:48:36.441  INFO 16044 --- [Executor task launch worker for task 52] org.apache.spark.executor.Executor       : Running task 52.0 in stage 0.0 (TID 52)
2018-05-01 17:48:36.457  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 51.0 in stage 0.0 (TID 51) in 576 ms on localhost (executor driver) (52/66)
2018-05-01 17:48:36.987  INFO 16044 --- [Executor task launch worker for task 52] org.apache.spark.executor.Executor       : Finished task 52.0 in stage 0.0 (TID 52). 431702 bytes result sent to driver
2018-05-01 17:48:36.987  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 53.0 in stage 0.0 (TID 53, localhost, executor driver, partition 53, ANY, 5002 bytes)
2018-05-01 17:48:36.987  INFO 16044 --- [Executor task launch worker for task 53] org.apache.spark.executor.Executor       : Running task 53.0 in stage 0.0 (TID 53)
2018-05-01 17:48:37.005  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 52.0 in stage 0.0 (TID 52) in 565 ms on localhost (executor driver) (53/66)
2018-05-01 17:48:37.622  INFO 16044 --- [Executor task launch worker for task 53] org.apache.spark.executor.Executor       : Finished task 53.0 in stage 0.0 (TID 53). 431628 bytes result sent to driver
2018-05-01 17:48:37.623  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 54.0 in stage 0.0 (TID 54, localhost, executor driver, partition 54, ANY, 5002 bytes)
2018-05-01 17:48:37.623  INFO 16044 --- [Executor task launch worker for task 54] org.apache.spark.executor.Executor       : Running task 54.0 in stage 0.0 (TID 54)
2018-05-01 17:48:37.641  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 53.0 in stage 0.0 (TID 53) in 654 ms on localhost (executor driver) (54/66)
2018-05-01 17:48:38.190  INFO 16044 --- [Executor task launch worker for task 54] org.apache.spark.executor.Executor       : Finished task 54.0 in stage 0.0 (TID 54). 428857 bytes result sent to driver
2018-05-01 17:48:38.191  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 55.0 in stage 0.0 (TID 55, localhost, executor driver, partition 55, ANY, 5003 bytes)
2018-05-01 17:48:38.191  INFO 16044 --- [Executor task launch worker for task 55] org.apache.spark.executor.Executor       : Running task 55.0 in stage 0.0 (TID 55)
2018-05-01 17:48:38.209  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 54.0 in stage 0.0 (TID 54) in 586 ms on localhost (executor driver) (55/66)
2018-05-01 17:48:38.735  INFO 16044 --- [Executor task launch worker for task 55] org.apache.spark.executor.Executor       : Finished task 55.0 in stage 0.0 (TID 55). 431970 bytes result sent to driver
2018-05-01 17:48:38.735  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 56.0 in stage 0.0 (TID 56, localhost, executor driver, partition 56, ANY, 5003 bytes)
2018-05-01 17:48:38.736  INFO 16044 --- [Executor task launch worker for task 56] org.apache.spark.executor.Executor       : Running task 56.0 in stage 0.0 (TID 56)
2018-05-01 17:48:38.753  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 55.0 in stage 0.0 (TID 55) in 563 ms on localhost (executor driver) (56/66)
2018-05-01 17:48:39.284  INFO 16044 --- [Executor task launch worker for task 56] org.apache.spark.executor.Executor       : Finished task 56.0 in stage 0.0 (TID 56). 430992 bytes result sent to driver
2018-05-01 17:48:39.285  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 57.0 in stage 0.0 (TID 57, localhost, executor driver, partition 57, ANY, 5003 bytes)
2018-05-01 17:48:39.285  INFO 16044 --- [Executor task launch worker for task 57] org.apache.spark.executor.Executor       : Running task 57.0 in stage 0.0 (TID 57)
2018-05-01 17:48:39.303  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 56.0 in stage 0.0 (TID 56) in 568 ms on localhost (executor driver) (57/66)
2018-05-01 17:48:39.886  INFO 16044 --- [Executor task launch worker for task 57] org.apache.spark.executor.Executor       : Finished task 57.0 in stage 0.0 (TID 57). 434026 bytes result sent to driver
2018-05-01 17:48:39.887  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 58.0 in stage 0.0 (TID 58, localhost, executor driver, partition 58, ANY, 5003 bytes)
2018-05-01 17:48:39.887  INFO 16044 --- [Executor task launch worker for task 58] org.apache.spark.executor.Executor       : Running task 58.0 in stage 0.0 (TID 58)
2018-05-01 17:48:39.910  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 57.0 in stage 0.0 (TID 57) in 626 ms on localhost (executor driver) (58/66)
2018-05-01 17:48:40.443  INFO 16044 --- [Executor task launch worker for task 58] org.apache.spark.executor.Executor       : Finished task 58.0 in stage 0.0 (TID 58). 431032 bytes result sent to driver
2018-05-01 17:48:40.444  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 59.0 in stage 0.0 (TID 59, localhost, executor driver, partition 59, ANY, 5003 bytes)
2018-05-01 17:48:40.445  INFO 16044 --- [Executor task launch worker for task 59] org.apache.spark.executor.Executor       : Running task 59.0 in stage 0.0 (TID 59)
2018-05-01 17:48:40.462  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 58.0 in stage 0.0 (TID 58) in 575 ms on localhost (executor driver) (59/66)
2018-05-01 17:48:41.014  INFO 16044 --- [Executor task launch worker for task 59] org.apache.spark.executor.Executor       : Finished task 59.0 in stage 0.0 (TID 59). 433164 bytes result sent to driver
2018-05-01 17:48:41.014  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 60.0 in stage 0.0 (TID 60, localhost, executor driver, partition 60, ANY, 5003 bytes)
2018-05-01 17:48:41.015  INFO 16044 --- [Executor task launch worker for task 60] org.apache.spark.executor.Executor       : Running task 60.0 in stage 0.0 (TID 60)
2018-05-01 17:48:41.030  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 59.0 in stage 0.0 (TID 59) in 586 ms on localhost (executor driver) (60/66)
2018-05-01 17:48:41.561  INFO 16044 --- [Executor task launch worker for task 60] org.apache.spark.executor.Executor       : Finished task 60.0 in stage 0.0 (TID 60). 432171 bytes result sent to driver
2018-05-01 17:48:41.562  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 61.0 in stage 0.0 (TID 61, localhost, executor driver, partition 61, ANY, 5003 bytes)
2018-05-01 17:48:41.562  INFO 16044 --- [Executor task launch worker for task 61] org.apache.spark.executor.Executor       : Running task 61.0 in stage 0.0 (TID 61)
2018-05-01 17:48:41.583  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 60.0 in stage 0.0 (TID 60) in 569 ms on localhost (executor driver) (61/66)
2018-05-01 17:48:42.103  INFO 16044 --- [Executor task launch worker for task 61] org.apache.spark.executor.Executor       : Finished task 61.0 in stage 0.0 (TID 61). 432524 bytes result sent to driver
2018-05-01 17:48:42.104  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 62.0 in stage 0.0 (TID 62, localhost, executor driver, partition 62, ANY, 5003 bytes)
2018-05-01 17:48:42.104  INFO 16044 --- [Executor task launch worker for task 62] org.apache.spark.executor.Executor       : Running task 62.0 in stage 0.0 (TID 62)
2018-05-01 17:48:42.119  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 61.0 in stage 0.0 (TID 61) in 557 ms on localhost (executor driver) (62/66)
2018-05-01 17:48:42.713  INFO 16044 --- [Executor task launch worker for task 62] org.apache.spark.executor.Executor       : Finished task 62.0 in stage 0.0 (TID 62). 431615 bytes result sent to driver
2018-05-01 17:48:42.714  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 63.0 in stage 0.0 (TID 63, localhost, executor driver, partition 63, ANY, 5003 bytes)
2018-05-01 17:48:42.714  INFO 16044 --- [Executor task launch worker for task 63] org.apache.spark.executor.Executor       : Running task 63.0 in stage 0.0 (TID 63)
2018-05-01 17:48:42.730  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 62.0 in stage 0.0 (TID 62) in 626 ms on localhost (executor driver) (63/66)
2018-05-01 17:48:43.294  INFO 16044 --- [Executor task launch worker for task 63] org.apache.spark.executor.Executor       : Finished task 63.0 in stage 0.0 (TID 63). 429910 bytes result sent to driver
2018-05-01 17:48:43.295  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 64.0 in stage 0.0 (TID 64, localhost, executor driver, partition 64, ANY, 5003 bytes)
2018-05-01 17:48:43.295  INFO 16044 --- [Executor task launch worker for task 64] org.apache.spark.executor.Executor       : Running task 64.0 in stage 0.0 (TID 64)
2018-05-01 17:48:43.311  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 63.0 in stage 0.0 (TID 63) in 598 ms on localhost (executor driver) (64/66)
2018-05-01 17:48:43.840  INFO 16044 --- [Executor task launch worker for task 64] org.apache.spark.executor.Executor       : Finished task 64.0 in stage 0.0 (TID 64). 434975 bytes result sent to driver
2018-05-01 17:48:43.840  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 65.0 in stage 0.0 (TID 65, localhost, executor driver, partition 65, ANY, 4992 bytes)
2018-05-01 17:48:43.841  INFO 16044 --- [Executor task launch worker for task 65] org.apache.spark.executor.Executor       : Running task 65.0 in stage 0.0 (TID 65)
2018-05-01 17:48:43.844  INFO 16044 --- [Executor task launch worker for task 65] org.apache.spark.executor.Executor       : Finished task 65.0 in stage 0.0 (TID 65). 777 bytes result sent to driver
2018-05-01 17:48:43.846  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 65.0 in stage 0.0 (TID 65) in 6 ms on localhost (executor driver) (65/66)
2018-05-01 17:48:43.856  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 64.0 in stage 0.0 (TID 64) in 562 ms on localhost (executor driver) (66/66)
2018-05-01 17:48:43.857  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-05-01 17:48:43.858  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 0 (collect at RecomendationServiceImpl.java:86) finished in 38.276 s
2018-05-01 17:48:43.863  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 0 finished: collect at RecomendationServiceImpl.java:86, took 38.355071 s
2018-05-01 17:48:44.034  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:240
2018-05-01 17:48:44.035  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 1 (isEmpty at ALS.scala:240) with 1 output partitions
2018-05-01 17:48:44.035  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1 (isEmpty at ALS.scala:240)
2018-05-01 17:48:44.035  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:48:44.037  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:48:44.037  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1 (UnionRDD[5] at union at RecomendationServiceImpl.java:77), which has no missing parents
2018-05-01 17:48:44.041  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 1990.8 MB)
2018-05-01 17:48:44.042  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.8 MB)
2018-05-01 17:48:44.044  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_2_piece0 in memory on 172.21.241.193:58620 (size: 2.1 KB, free: 1990.8 MB)
2018-05-01 17:48:44.044  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:48:44.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 1 (UnionRDD[5] at union at RecomendationServiceImpl.java:77) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:48:44.045  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1.0 with 1 tasks
2018-05-01 17:48:48.082  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_1_piece0 on 172.21.241.193:58620 in memory (size: 3.6 KB, free: 1990.8 MB)
2018-05-01 17:48:48.085  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_0_piece0 on 172.21.241.193:58620 in memory (size: 419.0 B, free: 1990.8 MB)
2018-05-01 17:48:48.795  WARN 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 1 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:48:48.795  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:48:48.795  INFO 16044 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1.0 (TID 66)
2018-05-01 17:48:48.921  INFO 16044 --- [pool-25-thread-1] c.m.spark.connection.MongoClientCache    : Closing MongoClient: [127.0.0.1:27017]
2018-05-01 17:48:48.923  INFO 16044 --- [pool-25-thread-1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:29}] to 127.0.0.1:27017 because the pool has been closed.
2018-05-01 17:48:50.195  INFO 16044 --- [Executor task launch worker for task 66] o.a.spark.storage.memory.MemoryStore     : Block rdd_3_0 stored as values in memory (estimated size 36.0 MB, free 1954.8 MB)
2018-05-01 17:48:50.196  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_3_0 in memory on 172.21.241.193:58620 (size: 36.0 MB, free: 1954.8 MB)
2018-05-01 17:48:50.205  INFO 16044 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 66:
[rdd_3_0]
2018-05-01 17:48:50.208  INFO 16044 --- [Executor task launch worker for task 66] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1.0 (TID 66). 1508 bytes result sent to driver
2018-05-01 17:48:50.210  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1.0 (TID 66) in 6165 ms on localhost (executor driver) (1/1)
2018-05-01 17:48:50.210  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-05-01 17:48:50.211  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1 (isEmpty at ALS.scala:240) finished in 6.165 s
2018-05-01 17:48:50.212  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 1 finished: isEmpty at ALS.scala:240, took 6.177699 s
2018-05-01 17:48:50.227  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:843
2018-05-01 17:48:50.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 2 (isEmpty at ALS.scala:843) with 1 output partitions
2018-05-01 17:48:50.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 2 (isEmpty at ALS.scala:843)
2018-05-01 17:48:50.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:48:50.229  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:48:50.230  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 2 (MapPartitionsRDD[6] at map at ALS.scala:256), which has no missing parents
2018-05-01 17:48:50.231  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 1954.8 MB)
2018-05-01 17:48:50.233  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1954.8 MB)
2018-05-01 17:48:50.233  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_3_piece0 in memory on 172.21.241.193:58620 (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 17:48:50.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:48:50.234  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:48:50.235  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 2.0 with 1 tasks
2018-05-01 17:48:53.029  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_2_piece0 on 172.21.241.193:58620 in memory (size: 2.1 KB, free: 1954.8 MB)
2018-05-01 17:48:54.790  WARN 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Stage 2 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:48:54.791  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 2.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:48:54.792  INFO 16044 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : Running task 0.0 in stage 2.0 (TID 67)
2018-05-01 17:48:55.956  INFO 16044 --- [Executor task launch worker for task 67] org.apache.spark.storage.BlockManager    : Found block rdd_3_0 locally
2018-05-01 17:48:55.959  INFO 16044 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 67:
[rdd_3_0]
2018-05-01 17:48:55.961  INFO 16044 --- [Executor task launch worker for task 67] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 2.0 (TID 67). 1089 bytes result sent to driver
2018-05-01 17:48:55.963  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 2.0 (TID 67) in 5727 ms on localhost (executor driver) (1/1)
2018-05-01 17:48:55.963  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-05-01 17:48:55.963  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 2 (isEmpty at ALS.scala:843) finished in 5.727 s
2018-05-01 17:48:55.964  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 2 finished: isEmpty at ALS.scala:843, took 5.735909 s
2018-05-01 17:48:56.071  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:857
2018-05-01 17:48:56.076  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 7 (mapPartitions at ALS.scala:1101)
2018-05-01 17:48:56.077  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 10 (map at ALS.scala:1344)
2018-05-01 17:48:56.077  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 3 (count at ALS.scala:857) with 1 output partitions
2018-05-01 17:48:56.078  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 5 (count at ALS.scala:857)
2018-05-01 17:48:56.078  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 4)
2018-05-01 17:48:56.079  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 4)
2018-05-01 17:48:56.080  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 3 (MapPartitionsRDD[7] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-05-01 17:48:56.084  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 1954.8 MB)
2018-05-01 17:48:56.086  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1954.8 MB)
2018-05-01 17:48:56.087  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_4_piece0 in memory on 172.21.241.193:58620 (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 17:48:56.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:48:56.090  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[7] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:48:56.090  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 3.0 with 2 tasks
2018-05-01 17:48:59.196  WARN 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Stage 3 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:48:59.196  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 3.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427802 bytes)
2018-05-01 17:48:59.197  INFO 16044 --- [Executor task launch worker for task 68] org.apache.spark.executor.Executor       : Running task 0.0 in stage 3.0 (TID 68)
2018-05-01 17:49:00.411  INFO 16044 --- [Executor task launch worker for task 68] org.apache.spark.storage.BlockManager    : Found block rdd_3_0 locally
2018-05-01 17:49:00.737  INFO 16044 --- [Executor task launch worker for task 68] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 3.0 (TID 68). 1070 bytes result sent to driver
2018-05-01 17:49:00.738  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 3.0 (TID 69, localhost, executor driver, partition 1, PROCESS_LOCAL, 5072 bytes)
2018-05-01 17:49:00.739  INFO 16044 --- [Executor task launch worker for task 69] org.apache.spark.executor.Executor       : Running task 1.0 in stage 3.0 (TID 69)
2018-05-01 17:49:00.740  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 3.0 (TID 68) in 4650 ms on localhost (executor driver) (1/2)
2018-05-01 17:49:00.756  INFO 16044 --- [Executor task launch worker for task 69] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 3.0 (TID 69). 855 bytes result sent to driver
2018-05-01 17:49:00.756  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 3.0 (TID 69) in 18 ms on localhost (executor driver) (2/2)
2018-05-01 17:49:00.757  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-05-01 17:49:00.757  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 3 (mapPartitions at ALS.scala:1101) finished in 4.667 s
2018-05-01 17:49:00.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:00.758  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:00.760  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 5, ShuffleMapStage 4)
2018-05-01 17:49:00.761  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:00.765  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:49:00.768  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 1954.8 MB)
2018-05-01 17:49:00.770  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1954.8 MB)
2018-05-01 17:49:00.771  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_5_piece0 in memory on 172.21.241.193:58620 (size: 3.7 KB, free: 1954.8 MB)
2018-05-01 17:49:00.772  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:00.772  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:49:00.773  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 4.0 with 2 tasks
2018-05-01 17:49:00.774  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 4.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:49:00.774  INFO 16044 --- [Executor task launch worker for task 70] org.apache.spark.executor.Executor       : Running task 0.0 in stage 4.0 (TID 70)
2018-05-01 17:49:00.785  INFO 16044 --- [Executor task launch worker for task 70] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 2 blocks
2018-05-01 17:49:00.787  INFO 16044 --- [Executor task launch worker for task 70] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 4 ms
2018-05-01 17:49:00.798  INFO 16044 --- [Executor task launch worker for task 70] o.a.spark.storage.memory.MemoryStore     : Block rdd_9_0 stored as values in memory (estimated size 16.0 B, free 1954.8 MB)
2018-05-01 17:49:00.798  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_9_0 in memory on 172.21.241.193:58620 (size: 16.0 B, free: 1954.8 MB)
2018-05-01 17:49:00.805  INFO 16044 --- [Executor task launch worker for task 70] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 4.0 (TID 70). 1852 bytes result sent to driver
2018-05-01 17:49:00.805  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 4.0 (TID 71, localhost, executor driver, partition 1, ANY, 4610 bytes)
2018-05-01 17:49:00.805  INFO 16044 --- [Executor task launch worker for task 71] org.apache.spark.executor.Executor       : Running task 1.0 in stage 4.0 (TID 71)
2018-05-01 17:49:00.805  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 4.0 (TID 70) in 31 ms on localhost (executor driver) (1/2)
2018-05-01 17:49:00.807  INFO 16044 --- [Executor task launch worker for task 71] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 2 non-empty blocks out of 2 blocks
2018-05-01 17:49:00.807  INFO 16044 --- [Executor task launch worker for task 71] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:00.962  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_4_piece0 on 172.21.241.193:58620 in memory (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 17:49:01.004  INFO 16044 --- [Executor task launch worker for task 71] o.a.spark.storage.memory.MemoryStore     : Block rdd_9_1 stored as values in memory (estimated size 12.0 MB, free 1942.8 MB)
2018-05-01 17:49:01.005  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_9_1 in memory on 172.21.241.193:58620 (size: 12.0 MB, free: 1942.8 MB)
2018-05-01 17:49:01.324  INFO 16044 --- [Executor task launch worker for task 71] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 4.0 (TID 71). 1981 bytes result sent to driver
2018-05-01 17:49:01.325  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 4.0 (TID 71) in 520 ms on localhost (executor driver) (2/2)
2018-05-01 17:49:01.325  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-05-01 17:49:01.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 4 (map at ALS.scala:1344) finished in 0.552 s
2018-05-01 17:49:01.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:01.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:01.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 5)
2018-05-01 17:49:01.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:01.332  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 5 (userOutBlocks MapPartitionsRDD[13] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:49:01.334  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6 stored as values in memory (estimated size 7.7 KB, free 1942.8 MB)
2018-05-01 17:49:01.336  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1942.8 MB)
2018-05-01 17:49:01.338  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_6_piece0 in memory on 172.21.241.193:58620 (size: 3.9 KB, free: 1942.8 MB)
2018-05-01 17:49:01.338  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:01.339  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 5 (userOutBlocks MapPartitionsRDD[13] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:01.339  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 5.0 with 1 tasks
2018-05-01 17:49:01.339  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 5.0 (TID 72, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:49:01.340  INFO 16044 --- [Executor task launch worker for task 72] org.apache.spark.executor.Executor       : Running task 0.0 in stage 5.0 (TID 72)
2018-05-01 17:49:01.342  INFO 16044 --- [Executor task launch worker for task 72] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:49:01.342  INFO 16044 --- [Executor task launch worker for task 72] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:01.784  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_5_piece0 on 172.21.241.193:58620 in memory (size: 3.7 KB, free: 1942.8 MB)
2018-05-01 17:49:01.844  INFO 16044 --- [Executor task launch worker for task 72] o.a.spark.storage.memory.MemoryStore     : Block rdd_12_0 stored as values in memory (estimated size 8.1 MB, free 1934.7 MB)
2018-05-01 17:49:01.847  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_12_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1934.7 MB)
2018-05-01 17:49:01.854  INFO 16044 --- [Executor task launch worker for task 72] o.a.spark.storage.memory.MemoryStore     : Block rdd_13_0 stored as values in memory (estimated size 27.9 KB, free 1934.7 MB)
2018-05-01 17:49:01.856  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_13_0 in memory on 172.21.241.193:58620 (size: 27.9 KB, free: 1934.7 MB)
2018-05-01 17:49:01.857  INFO 16044 --- [Executor task launch worker for task 72] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 5.0 (TID 72). 1877 bytes result sent to driver
2018-05-01 17:49:01.858  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 5.0 (TID 72) in 519 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:01.858  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-05-01 17:49:01.859  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 5 (count at ALS.scala:857) finished in 0.519 s
2018-05-01 17:49:01.859  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 3 finished: count at ALS.scala:857, took 5.787201 s
2018-05-01 17:49:01.880  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:865
2018-05-01 17:49:01.883  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:01.884  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 15 (map at ALS.scala:1344)
2018-05-01 17:49:01.885  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 4 (count at ALS.scala:865) with 1 output partitions
2018-05-01 17:49:01.885  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 8 (count at ALS.scala:865)
2018-05-01 17:49:01.885  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 7)
2018-05-01 17:49:01.886  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 7)
2018-05-01 17:49:01.887  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 7 (MapPartitionsRDD[15] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:49:01.888  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7 stored as values in memory (estimated size 7.3 KB, free 1934.7 MB)
2018-05-01 17:49:01.890  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1934.7 MB)
2018-05-01 17:49:01.891  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_7_piece0 in memory on 172.21.241.193:58620 (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:49:01.892  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:01.892  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[15] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:49:01.892  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 7.0 with 2 tasks
2018-05-01 17:49:01.892  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 7.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:49:01.892  INFO 16044 --- [Executor task launch worker for task 73] org.apache.spark.executor.Executor       : Running task 0.0 in stage 7.0 (TID 73)
2018-05-01 17:49:01.895  INFO 16044 --- [Executor task launch worker for task 73] org.apache.spark.storage.BlockManager    : Found block rdd_9_0 locally
2018-05-01 17:49:01.900  INFO 16044 --- [Executor task launch worker for task 73] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 7.0 (TID 73). 725 bytes result sent to driver
2018-05-01 17:49:01.901  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 7.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:49:01.901  INFO 16044 --- [Executor task launch worker for task 74] org.apache.spark.executor.Executor       : Running task 1.0 in stage 7.0 (TID 74)
2018-05-01 17:49:01.901  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 7.0 (TID 73) in 9 ms on localhost (executor driver) (1/2)
2018-05-01 17:49:01.902  INFO 16044 --- [Executor task launch worker for task 74] org.apache.spark.storage.BlockManager    : Found block rdd_9_1 locally
2018-05-01 17:49:02.168  INFO 16044 --- [Executor task launch worker for task 74] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 7.0 (TID 74). 983 bytes result sent to driver
2018-05-01 17:49:02.169  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 7.0 (TID 74) in 268 ms on localhost (executor driver) (2/2)
2018-05-01 17:49:02.169  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 7 (map at ALS.scala:1344) finished in 0.277 s
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2018-05-01 17:49:02.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:02.170  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 8 (itemOutBlocks MapPartitionsRDD[18] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:49:02.171  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8 stored as values in memory (estimated size 7.9 KB, free 1934.7 MB)
2018-05-01 17:49:02.173  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1934.7 MB)
2018-05-01 17:49:02.174  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_8_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1934.7 MB)
2018-05-01 17:49:02.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:02.176  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 8 (itemOutBlocks MapPartitionsRDD[18] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:02.176  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 8.0 with 1 tasks
2018-05-01 17:49:02.176  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 8.0 (TID 75, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:49:02.176  INFO 16044 --- [Executor task launch worker for task 75] org.apache.spark.executor.Executor       : Running task 0.0 in stage 8.0 (TID 75)
2018-05-01 17:49:02.179  INFO 16044 --- [Executor task launch worker for task 75] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:49:02.179  INFO 16044 --- [Executor task launch worker for task 75] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:02.645  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_7_piece0 on 172.21.241.193:58620 in memory (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:49:02.646  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_6_piece0 on 172.21.241.193:58620 in memory (size: 3.9 KB, free: 1934.7 MB)
2018-05-01 17:49:03.431  INFO 16044 --- [Executor task launch worker for task 75] o.a.spark.storage.memory.MemoryStore     : Block rdd_17_0 stored as values in memory (estimated size 8.1 MB, free 1926.6 MB)
2018-05-01 17:49:03.433  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_17_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1926.6 MB)
2018-05-01 17:49:03.439  INFO 16044 --- [Executor task launch worker for task 75] o.a.spark.storage.memory.MemoryStore     : Block rdd_18_0 stored as values in memory (estimated size 54.9 KB, free 1926.5 MB)
2018-05-01 17:49:03.441  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_18_0 in memory on 172.21.241.193:58620 (size: 54.9 KB, free: 1926.6 MB)
2018-05-01 17:49:03.442  INFO 16044 --- [Executor task launch worker for task 75] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 8.0 (TID 75). 1877 bytes result sent to driver
2018-05-01 17:49:03.442  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 8.0 (TID 75) in 1266 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:03.442  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-05-01 17:49:03.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 8 (count at ALS.scala:865) finished in 1.266 s
2018-05-01 17:49:03.445  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 4 finished: count at ALS.scala:865, took 1.564824 s
2018-05-01 17:49:03.480  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:03.481  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:03.481  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:03.481  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 5 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:03.481  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 11 (aggregate at ALS.scala:1491)
2018-05-01 17:49:03.482  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 10)
2018-05-01 17:49:03.482  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:03.482  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 11 (MapPartitionsRDD[21] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:03.483  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9 stored as values in memory (estimated size 9.1 KB, free 1926.5 MB)
2018-05-01 17:49:03.485  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.5 MB)
2018-05-01 17:49:03.486  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_9_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.5 MB)
2018-05-01 17:49:03.486  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:03.487  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[21] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:03.487  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 11.0 with 1 tasks
2018-05-01 17:49:03.487  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 11.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
2018-05-01 17:49:03.488  INFO 16044 --- [Executor task launch worker for task 76] org.apache.spark.executor.Executor       : Running task 0.0 in stage 11.0 (TID 76)
2018-05-01 17:49:03.494  INFO 16044 --- [Executor task launch worker for task 76] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:03.498  WARN 16044 --- [Executor task launch worker for task 76] com.github.fommil.netlib.BLAS            : Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-05-01 17:49:03.498  WARN 16044 --- [Executor task launch worker for task 76] com.github.fommil.netlib.BLAS            : Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-05-01 17:49:03.514  INFO 16044 --- [Executor task launch worker for task 76] o.a.spark.storage.memory.MemoryStore     : Block rdd_19_0 stored as values in memory (estimated size 416.2 KB, free 1926.1 MB)
2018-05-01 17:49:03.515  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_19_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1926.1 MB)
2018-05-01 17:49:03.521  INFO 16044 --- [Executor task launch worker for task 76] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 11.0 (TID 76). 2208 bytes result sent to driver
2018-05-01 17:49:03.522  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 11.0 (TID 76) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:03.522  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-05-01 17:49:03.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 11 (aggregate at ALS.scala:1491) finished in 0.035 s
2018-05-01 17:49:03.523  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 5 finished: aggregate at ALS.scala:1491, took 0.042372 s
2018-05-01 17:49:03.557  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 20 from persistence list
2018-05-01 17:49:03.561  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 20
2018-05-01 17:49:03.570  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:03.572  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 19 (map at ALS.scala:1017)
2018-05-01 17:49:03.572  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 25 (flatMap at ALS.scala:1433)
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 6 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 17 (aggregate at ALS.scala:1491)
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 16)
2018-05-01 17:49:03.573  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 15)
2018-05-01 17:49:03.574  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[19] at map at ALS.scala:1017), which has no missing parents
2018-05-01 17:49:03.575  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10 stored as values in memory (estimated size 7.7 KB, free 1926.1 MB)
2018-05-01 17:49:03.576  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1926.1 MB)
2018-05-01 17:49:03.577  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_10_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:49:03.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:03.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 14 (userFactors-1 MapPartitionsRDD[19] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:03.579  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 14.0 with 1 tasks
2018-05-01 17:49:03.580  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 14.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:49:03.580  INFO 16044 --- [Executor task launch worker for task 77] org.apache.spark.executor.Executor       : Running task 0.0 in stage 14.0 (TID 77)
2018-05-01 17:49:03.581  INFO 16044 --- [Executor task launch worker for task 77] org.apache.spark.storage.BlockManager    : Found block rdd_19_0 locally
2018-05-01 17:49:03.607  INFO 16044 --- [Executor task launch worker for task 77] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 14.0 (TID 77). 940 bytes result sent to driver
2018-05-01 17:49:03.608  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 14.0 (TID 77) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:03.608  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 14 (map at ALS.scala:1017) finished in 0.029 s
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 15, ResultStage 17)
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:03.609  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 15 (MapPartitionsRDD[25] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:03.610  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11 stored as values in memory (estimated size 8.8 KB, free 1926.1 MB)
2018-05-01 17:49:03.611  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.1 MB)
2018-05-01 17:49:03.612  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_11_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 17:49:03.612  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:03.613  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[25] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:03.613  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 15.0 with 1 tasks
2018-05-01 17:49:03.615  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 15.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-05-01 17:49:03.615  INFO 16044 --- [Executor task launch worker for task 78] org.apache.spark.executor.Executor       : Running task 0.0 in stage 15.0 (TID 78)
2018-05-01 17:49:03.618  INFO 16044 --- [Executor task launch worker for task 78] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:03.618  INFO 16044 --- [Executor task launch worker for task 78] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:03.618  INFO 16044 --- [Executor task launch worker for task 78] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:03.657  INFO 16044 --- [Executor task launch worker for task 78] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 15.0 (TID 78). 1327 bytes result sent to driver
2018-05-01 17:49:03.657  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 15.0 (TID 78) in 43 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:03.657  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 15 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 17)
2018-05-01 17:49:03.658  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:03.659  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 17 (MapPartitionsRDD[31] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:03.661  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12 stored as values in memory (estimated size 12.6 KB, free 1926.1 MB)
2018-05-01 17:49:03.664  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1926.1 MB)
2018-05-01 17:49:03.665  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_12_piece0 in memory on 172.21.241.193:58620 (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 17:49:03.665  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:03.667  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[31] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:03.667  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 17.0 with 1 tasks
2018-05-01 17:49:03.667  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 17.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:03.667  INFO 16044 --- [Executor task launch worker for task 79] org.apache.spark.executor.Executor       : Running task 0.0 in stage 17.0 (TID 79)
2018-05-01 17:49:03.670  INFO 16044 --- [Executor task launch worker for task 79] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:03.670  INFO 16044 --- [Executor task launch worker for task 79] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:03.670  INFO 16044 --- [Executor task launch worker for task 79] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:03.683  WARN 16044 --- [Executor task launch worker for task 79] com.github.fommil.netlib.LAPACK          : Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-05-01 17:49:03.684  WARN 16044 --- [Executor task launch worker for task 79] com.github.fommil.netlib.LAPACK          : Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-05-01 17:49:04.027  INFO 16044 --- [Executor task launch worker for task 79] o.a.spark.storage.memory.MemoryStore     : Block rdd_30_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:49:04.027  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_30_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:49:04.032  INFO 16044 --- [Executor task launch worker for task 79] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 17.0 (TID 79). 2595 bytes result sent to driver
2018-05-01 17:49:04.033  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 17.0 (TID 79) in 366 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.033  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.033  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 17 (aggregate at ALS.scala:1491) finished in 0.366 s
2018-05-01 17:49:04.033  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 6 finished: aggregate at ALS.scala:1491, took 0.462373 s
2018-05-01 17:49:04.052  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 19 from persistence list
2018-05-01 17:49:04.053  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 19
2018-05-01 17:49:04.062  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:04.063  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:04.063  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:04.063  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 35 (flatMap at ALS.scala:1433)
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 7 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 24 (aggregate at ALS.scala:1491)
2018-05-01 17:49:04.064  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 19, ShuffleMapStage 23)
2018-05-01 17:49:04.065  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 23)
2018-05-01 17:49:04.066  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 23 (MapPartitionsRDD[35] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:04.067  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13 stored as values in memory (estimated size 11.8 KB, free 1925.7 MB)
2018-05-01 17:49:04.069  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.6 KB, free 1925.7 MB)
2018-05-01 17:49:04.071  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_13_piece0 in memory on 172.21.241.193:58620 (size: 5.6 KB, free: 1925.7 MB)
2018-05-01 17:49:04.071  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.071  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[35] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.072  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 23.0 with 1 tasks
2018-05-01 17:49:04.072  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 23.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:04.072  INFO 16044 --- [Executor task launch worker for task 80] org.apache.spark.executor.Executor       : Running task 0.0 in stage 23.0 (TID 80)
2018-05-01 17:49:04.074  INFO 16044 --- [Executor task launch worker for task 80] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:04.074  INFO 16044 --- [Executor task launch worker for task 80] org.apache.spark.storage.BlockManager    : Found block rdd_30_0 locally
2018-05-01 17:49:04.107  INFO 16044 --- [Executor task launch worker for task 80] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 23.0 (TID 80). 1112 bytes result sent to driver
2018-05-01 17:49:04.107  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 23.0 (TID 80) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.107  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 23 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 24)
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:04.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 24 (MapPartitionsRDD[41] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:04.110  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_14 stored as values in memory (estimated size 14.3 KB, free 1925.7 MB)
2018-05-01 17:49:04.112  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1925.6 MB)
2018-05-01 17:49:04.112  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_14_piece0 in memory on 172.21.241.193:58620 (size: 6.6 KB, free: 1925.7 MB)
2018-05-01 17:49:04.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.113  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[41] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.113  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 24.0 with 1 tasks
2018-05-01 17:49:04.113  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 24.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:04.113  INFO 16044 --- [Executor task launch worker for task 81] org.apache.spark.executor.Executor       : Running task 0.0 in stage 24.0 (TID 81)
2018-05-01 17:49:04.115  INFO 16044 --- [Executor task launch worker for task 81] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:04.116  INFO 16044 --- [Executor task launch worker for task 81] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:04.116  INFO 16044 --- [Executor task launch worker for task 81] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:04.382  INFO 16044 --- [Executor task launch worker for task 81] o.a.spark.storage.memory.MemoryStore     : Block rdd_40_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:49:04.383  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_40_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:49:04.385  INFO 16044 --- [Executor task launch worker for task 81] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 24.0 (TID 81). 2595 bytes result sent to driver
2018-05-01 17:49:04.386  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 24.0 (TID 81) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.386  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 24.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.386  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 24 (aggregate at ALS.scala:1491) finished in 0.273 s
2018-05-01 17:49:04.387  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 7 finished: aggregate at ALS.scala:1491, took 0.324465 s
2018-05-01 17:49:04.409  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 30 from persistence list
2018-05-01 17:49:04.410  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 30
2018-05-01 17:49:04.464  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_8_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:49:04.465  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_13_piece0 on 172.21.241.193:58620 in memory (size: 5.6 KB, free: 1926.1 MB)
2018-05-01 17:49:04.466  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_12_piece0 on 172.21.241.193:58620 in memory (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 17:49:04.466  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_10_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:49:04.468  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_11_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 17:49:04.468  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_14_piece0 on 172.21.241.193:58620 in memory (size: 6.6 KB, free: 1926.1 MB)
2018-05-01 17:49:04.469  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_9_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1926.2 MB)
2018-05-01 17:49:04.470  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:04.470  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:04.471  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:04.472  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:04.472  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:04.473  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:04.473  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 45 (flatMap at ALS.scala:1433)
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 8 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 32 (aggregate at ALS.scala:1491)
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 31, ShuffleMapStage 28)
2018-05-01 17:49:04.474  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 31)
2018-05-01 17:49:04.475  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 31 (MapPartitionsRDD[45] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:04.477  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_15 stored as values in memory (estimated size 13.4 KB, free 1926.1 MB)
2018-05-01 17:49:04.479  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1926.1 MB)
2018-05-01 17:49:04.479  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_15_piece0 in memory on 172.21.241.193:58620 (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:49:04.480  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.480  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[45] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.480  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 31.0 with 1 tasks
2018-05-01 17:49:04.481  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 31.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:04.482  INFO 16044 --- [Executor task launch worker for task 82] org.apache.spark.executor.Executor       : Running task 0.0 in stage 31.0 (TID 82)
2018-05-01 17:49:04.484  INFO 16044 --- [Executor task launch worker for task 82] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:04.484  INFO 16044 --- [Executor task launch worker for task 82] org.apache.spark.storage.BlockManager    : Found block rdd_40_0 locally
2018-05-01 17:49:04.510  INFO 16044 --- [Executor task launch worker for task 82] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 31.0 (TID 82). 1026 bytes result sent to driver
2018-05-01 17:49:04.511  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 31.0 (TID 82) in 31 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.512  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 31.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 31 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 32)
2018-05-01 17:49:04.512  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:04.513  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 32 (MapPartitionsRDD[51] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:04.515  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_16 stored as values in memory (estimated size 15.8 KB, free 1926.1 MB)
2018-05-01 17:49:04.517  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1926.1 MB)
2018-05-01 17:49:04.517  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_16_piece0 in memory on 172.21.241.193:58620 (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 17:49:04.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[51] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.518  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 32.0 with 1 tasks
2018-05-01 17:49:04.518  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 32.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:04.518  INFO 16044 --- [Executor task launch worker for task 83] org.apache.spark.executor.Executor       : Running task 0.0 in stage 32.0 (TID 83)
2018-05-01 17:49:04.521  INFO 16044 --- [Executor task launch worker for task 83] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:04.521  INFO 16044 --- [Executor task launch worker for task 83] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:04.521  INFO 16044 --- [Executor task launch worker for task 83] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:04.800  INFO 16044 --- [Executor task launch worker for task 83] o.a.spark.storage.memory.MemoryStore     : Block rdd_50_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:49:04.800  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_50_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:49:04.803  INFO 16044 --- [Executor task launch worker for task 83] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 32.0 (TID 83). 2595 bytes result sent to driver
2018-05-01 17:49:04.804  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 32.0 (TID 83) in 286 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.804  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 32.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 32 (aggregate at ALS.scala:1491) finished in 0.286 s
2018-05-01 17:49:04.804  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 8 finished: aggregate at ALS.scala:1491, took 0.334600 s
2018-05-01 17:49:04.825  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 40 from persistence list
2018-05-01 17:49:04.825  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 40
2018-05-01 17:49:04.832  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:04.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:04.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:04.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:04.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:04.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:04.834  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 55 (flatMap at ALS.scala:1433)
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 9 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 41 (aggregate at ALS.scala:1491)
2018-05-01 17:49:04.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 40)
2018-05-01 17:49:04.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 40)
2018-05-01 17:49:04.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 40 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:04.838  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_17 stored as values in memory (estimated size 14.9 KB, free 1925.7 MB)
2018-05-01 17:49:04.840  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1925.7 MB)
2018-05-01 17:49:04.840  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_17_piece0 in memory on 172.21.241.193:58620 (size: 7.1 KB, free: 1925.7 MB)
2018-05-01 17:49:04.840  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.841  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.841  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 40.0 with 1 tasks
2018-05-01 17:49:04.842  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 40.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:04.842  INFO 16044 --- [Executor task launch worker for task 84] org.apache.spark.executor.Executor       : Running task 0.0 in stage 40.0 (TID 84)
2018-05-01 17:49:04.843  INFO 16044 --- [Executor task launch worker for task 84] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:04.844  INFO 16044 --- [Executor task launch worker for task 84] org.apache.spark.storage.BlockManager    : Found block rdd_50_0 locally
2018-05-01 17:49:04.877  INFO 16044 --- [Executor task launch worker for task 84] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 40.0 (TID 84). 1069 bytes result sent to driver
2018-05-01 17:49:04.878  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 40.0 (TID 84) in 37 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:04.878  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 40.0, whose tasks have all completed, from pool 
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 40 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 41)
2018-05-01 17:49:04.878  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:04.880  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 41 (MapPartitionsRDD[61] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:04.881  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_18 stored as values in memory (estimated size 17.4 KB, free 1925.7 MB)
2018-05-01 17:49:04.883  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 1925.7 MB)
2018-05-01 17:49:04.883  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_18_piece0 in memory on 172.21.241.193:58620 (size: 8.0 KB, free: 1925.7 MB)
2018-05-01 17:49:04.883  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:04.884  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[61] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:04.884  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 41.0 with 1 tasks
2018-05-01 17:49:04.885  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 41.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:04.885  INFO 16044 --- [Executor task launch worker for task 85] org.apache.spark.executor.Executor       : Running task 0.0 in stage 41.0 (TID 85)
2018-05-01 17:49:04.887  INFO 16044 --- [Executor task launch worker for task 85] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:04.887  INFO 16044 --- [Executor task launch worker for task 85] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:04.887  INFO 16044 --- [Executor task launch worker for task 85] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:05.160  INFO 16044 --- [Executor task launch worker for task 85] o.a.spark.storage.memory.MemoryStore     : Block rdd_60_0 stored as values in memory (estimated size 416.2 KB, free 1925.3 MB)
2018-05-01 17:49:05.162  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_60_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:49:05.164  INFO 16044 --- [Executor task launch worker for task 85] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 41.0 (TID 85). 2595 bytes result sent to driver
2018-05-01 17:49:05.165  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 41.0 (TID 85) in 281 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:05.165  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 41.0, whose tasks have all completed, from pool 
2018-05-01 17:49:05.166  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 41 (aggregate at ALS.scala:1491) finished in 0.281 s
2018-05-01 17:49:05.166  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 9 finished: aggregate at ALS.scala:1491, took 0.334084 s
2018-05-01 17:49:05.184  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 50 from persistence list
2018-05-01 17:49:05.185  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 50
2018-05-01 17:49:05.190  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:05.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:05.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:05.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:05.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:05.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:05.193  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:05.193  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:05.193  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 65 (flatMap at ALS.scala:1433)
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 10 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 51 (aggregate at ALS.scala:1491)
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 50, ShuffleMapStage 43)
2018-05-01 17:49:05.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 50)
2018-05-01 17:49:05.195  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 50 (MapPartitionsRDD[65] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:05.197  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_19 stored as values in memory (estimated size 16.5 KB, free 1926.0 MB)
2018-05-01 17:49:05.198  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.8 KB, free 1926.0 MB)
2018-05-01 17:49:05.198  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_19_piece0 in memory on 172.21.241.193:58620 (size: 7.8 KB, free: 1926.1 MB)
2018-05-01 17:49:05.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:05.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[65] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:05.199  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 50.0 with 1 tasks
2018-05-01 17:49:05.200  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 50.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:05.200  INFO 16044 --- [Executor task launch worker for task 86] org.apache.spark.executor.Executor       : Running task 0.0 in stage 50.0 (TID 86)
2018-05-01 17:49:05.201  INFO 16044 --- [Executor task launch worker for task 86] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:05.202  INFO 16044 --- [Executor task launch worker for task 86] org.apache.spark.storage.BlockManager    : Found block rdd_60_0 locally
2018-05-01 17:49:05.226  INFO 16044 --- [Executor task launch worker for task 86] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 50.0 (TID 86). 1069 bytes result sent to driver
2018-05-01 17:49:05.226  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 50.0 (TID 86) in 27 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:05.226  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 50.0, whose tasks have all completed, from pool 
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 50 (flatMap at ALS.scala:1433) finished in 0.027 s
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 51)
2018-05-01 17:49:05.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:05.228  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 51 (MapPartitionsRDD[71] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:05.229  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_20 stored as values in memory (estimated size 18.9 KB, free 1926.0 MB)
2018-05-01 17:49:05.230  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1926.0 MB)
2018-05-01 17:49:05.231  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_20_piece0 in memory on 172.21.241.193:58620 (size: 8.6 KB, free: 1926.1 MB)
2018-05-01 17:49:05.231  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:05.232  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[71] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:05.232  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 51.0 with 1 tasks
2018-05-01 17:49:05.232  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 51.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:05.232  INFO 16044 --- [Executor task launch worker for task 87] org.apache.spark.executor.Executor       : Running task 0.0 in stage 51.0 (TID 87)
2018-05-01 17:49:05.234  INFO 16044 --- [Executor task launch worker for task 87] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:05.235  INFO 16044 --- [Executor task launch worker for task 87] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:05.235  INFO 16044 --- [Executor task launch worker for task 87] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:05.524  INFO 16044 --- [Executor task launch worker for task 87] o.a.spark.storage.memory.MemoryStore     : Block rdd_70_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 17:49:05.524  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_70_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:49:05.528  INFO 16044 --- [Executor task launch worker for task 87] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 51.0 (TID 87). 2595 bytes result sent to driver
2018-05-01 17:49:05.528  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 51.0 (TID 87) in 296 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:05.529  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 51.0, whose tasks have all completed, from pool 
2018-05-01 17:49:05.529  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 51 (aggregate at ALS.scala:1491) finished in 0.297 s
2018-05-01 17:49:05.530  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 10 finished: aggregate at ALS.scala:1491, took 0.339306 s
2018-05-01 17:49:05.550  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 60 from persistence list
2018-05-01 17:49:05.550  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 60
2018-05-01 17:49:05.555  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:05.556  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:05.556  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:05.556  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:05.557  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:05.557  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:05.557  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:05.557  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 75 (flatMap at ALS.scala:1433)
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 11 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 62 (aggregate at ALS.scala:1491)
2018-05-01 17:49:05.558  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 53, ShuffleMapStage 61)
2018-05-01 17:49:05.559  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 61)
2018-05-01 17:49:05.559  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 61 (MapPartitionsRDD[75] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:05.561  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_21 stored as values in memory (estimated size 18.0 KB, free 1925.6 MB)
2018-05-01 17:49:05.563  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1925.6 MB)
2018-05-01 17:49:05.564  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_21_piece0 in memory on 172.21.241.193:58620 (size: 8.4 KB, free: 1925.7 MB)
2018-05-01 17:49:05.564  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:05.565  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[75] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:05.565  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 61.0 with 1 tasks
2018-05-01 17:49:05.565  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 61.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:05.565  INFO 16044 --- [Executor task launch worker for task 88] org.apache.spark.executor.Executor       : Running task 0.0 in stage 61.0 (TID 88)
2018-05-01 17:49:05.567  INFO 16044 --- [Executor task launch worker for task 88] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:05.567  INFO 16044 --- [Executor task launch worker for task 88] org.apache.spark.storage.BlockManager    : Found block rdd_70_0 locally
2018-05-01 17:49:05.599  INFO 16044 --- [Executor task launch worker for task 88] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 61.0 (TID 88). 1069 bytes result sent to driver
2018-05-01 17:49:05.599  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 61.0 (TID 88) in 34 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:05.599  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 61.0, whose tasks have all completed, from pool 
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 61 (flatMap at ALS.scala:1433) finished in 0.034 s
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 62)
2018-05-01 17:49:05.599  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:05.600  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 62 (MapPartitionsRDD[81] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:05.601  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_22 stored as values in memory (estimated size 20.5 KB, free 1925.6 MB)
2018-05-01 17:49:05.603  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1925.6 MB)
2018-05-01 17:49:05.603  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_22_piece0 in memory on 172.21.241.193:58620 (size: 9.3 KB, free: 1925.7 MB)
2018-05-01 17:49:05.603  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:05.604  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[81] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:05.604  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 62.0 with 1 tasks
2018-05-01 17:49:05.604  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 62.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:05.604  INFO 16044 --- [Executor task launch worker for task 89] org.apache.spark.executor.Executor       : Running task 0.0 in stage 62.0 (TID 89)
2018-05-01 17:49:05.607  INFO 16044 --- [Executor task launch worker for task 89] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:05.607  INFO 16044 --- [Executor task launch worker for task 89] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:05.607  INFO 16044 --- [Executor task launch worker for task 89] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:05.998  INFO 16044 --- [Executor task launch worker for task 89] o.a.spark.storage.memory.MemoryStore     : Block rdd_80_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:49:06.000  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_80_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:49:06.003  INFO 16044 --- [Executor task launch worker for task 89] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 62.0 (TID 89). 2595 bytes result sent to driver
2018-05-01 17:49:06.003  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 62.0 (TID 89) in 399 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.003  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 62.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.004  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 62 (aggregate at ALS.scala:1491) finished in 0.400 s
2018-05-01 17:49:06.005  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 11 finished: aggregate at ALS.scala:1491, took 0.449342 s
2018-05-01 17:49:06.035  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 70 from persistence list
2018-05-01 17:49:06.035  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 70
2018-05-01 17:49:06.042  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:06.043  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:06.043  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:06.044  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:06.044  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:06.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:06.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:06.046  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:06.046  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:06.046  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 85 (flatMap at ALS.scala:1433)
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 12 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 74 (aggregate at ALS.scala:1491)
2018-05-01 17:49:06.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 64, ShuffleMapStage 73)
2018-05-01 17:49:06.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 73)
2018-05-01 17:49:06.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 73 (MapPartitionsRDD[85] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:06.050  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_23 stored as values in memory (estimated size 19.6 KB, free 1925.9 MB)
2018-05-01 17:49:06.051  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.1 KB, free 1925.9 MB)
2018-05-01 17:49:06.053  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_23_piece0 in memory on 172.21.241.193:58620 (size: 9.1 KB, free: 1926.1 MB)
2018-05-01 17:49:06.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[85] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.053  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 73.0 with 1 tasks
2018-05-01 17:49:06.054  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 73.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:06.054  INFO 16044 --- [Executor task launch worker for task 90] org.apache.spark.executor.Executor       : Running task 0.0 in stage 73.0 (TID 90)
2018-05-01 17:49:06.057  INFO 16044 --- [Executor task launch worker for task 90] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:06.057  INFO 16044 --- [Executor task launch worker for task 90] org.apache.spark.storage.BlockManager    : Found block rdd_80_0 locally
2018-05-01 17:49:06.102  INFO 16044 --- [Executor task launch worker for task 90] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 73.0 (TID 90). 1069 bytes result sent to driver
2018-05-01 17:49:06.102  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 73.0 (TID 90) in 48 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.103  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 73.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 73 (flatMap at ALS.scala:1433) finished in 0.049 s
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 74)
2018-05-01 17:49:06.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:06.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 74 (MapPartitionsRDD[91] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:06.105  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_24 stored as values in memory (estimated size 22.0 KB, free 1925.9 MB)
2018-05-01 17:49:06.107  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.9 KB, free 1925.9 MB)
2018-05-01 17:49:06.107  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_24_piece0 in memory on 172.21.241.193:58620 (size: 9.9 KB, free: 1926.1 MB)
2018-05-01 17:49:06.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[91] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.108  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 74.0 with 1 tasks
2018-05-01 17:49:06.109  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 74.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:06.109  INFO 16044 --- [Executor task launch worker for task 91] org.apache.spark.executor.Executor       : Running task 0.0 in stage 74.0 (TID 91)
2018-05-01 17:49:06.112  INFO 16044 --- [Executor task launch worker for task 91] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:06.112  INFO 16044 --- [Executor task launch worker for task 91] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:06.112  INFO 16044 --- [Executor task launch worker for task 91] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:06.408  INFO 16044 --- [Executor task launch worker for task 91] o.a.spark.storage.memory.MemoryStore     : Block rdd_90_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 17:49:06.409  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_90_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:49:06.413  INFO 16044 --- [Executor task launch worker for task 91] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 74.0 (TID 91). 2595 bytes result sent to driver
2018-05-01 17:49:06.413  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 74.0 (TID 91) in 305 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.413  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 74.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.414  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 74 (aggregate at ALS.scala:1491) finished in 0.306 s
2018-05-01 17:49:06.414  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 12 finished: aggregate at ALS.scala:1491, took 0.372140 s
2018-05-01 17:49:06.434  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 80 from persistence list
2018-05-01 17:49:06.435  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 80
2018-05-01 17:49:06.440  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:06.441  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:06.441  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:06.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:06.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:06.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:06.444  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:06.444  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:06.445  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:06.445  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 95 (flatMap at ALS.scala:1433)
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 13 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 87 (aggregate at ALS.scala:1491)
2018-05-01 17:49:06.446  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 86, ShuffleMapStage 76)
2018-05-01 17:49:06.447  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 86)
2018-05-01 17:49:06.447  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 86 (MapPartitionsRDD[95] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:06.449  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_25 stored as values in memory (estimated size 21.1 KB, free 1925.5 MB)
2018-05-01 17:49:06.451  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1925.5 MB)
2018-05-01 17:49:06.451  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_25_piece0 in memory on 172.21.241.193:58620 (size: 9.7 KB, free: 1925.7 MB)
2018-05-01 17:49:06.451  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.452  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[95] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.452  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 86.0 with 1 tasks
2018-05-01 17:49:06.452  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 86.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:06.452  INFO 16044 --- [Executor task launch worker for task 92] org.apache.spark.executor.Executor       : Running task 0.0 in stage 86.0 (TID 92)
2018-05-01 17:49:06.454  INFO 16044 --- [Executor task launch worker for task 92] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:06.455  INFO 16044 --- [Executor task launch worker for task 92] org.apache.spark.storage.BlockManager    : Found block rdd_90_0 locally
2018-05-01 17:49:06.495  INFO 16044 --- [Executor task launch worker for task 92] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 86.0 (TID 92). 1069 bytes result sent to driver
2018-05-01 17:49:06.496  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 86.0 (TID 92) in 44 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.496  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 86.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 86 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 17:49:06.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:06.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:06.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 87)
2018-05-01 17:49:06.497  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:06.498  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 87 (MapPartitionsRDD[101] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:06.500  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_26 stored as values in memory (estimated size 23.6 KB, free 1925.4 MB)
2018-05-01 17:49:06.501  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_26_piece0 stored as bytes in memory (estimated size 10.6 KB, free 1925.4 MB)
2018-05-01 17:49:06.501  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_26_piece0 in memory on 172.21.241.193:58620 (size: 10.6 KB, free: 1925.7 MB)
2018-05-01 17:49:06.502  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.502  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[101] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.502  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 87.0 with 1 tasks
2018-05-01 17:49:06.502  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 87.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:06.503  INFO 16044 --- [Executor task launch worker for task 93] org.apache.spark.executor.Executor       : Running task 0.0 in stage 87.0 (TID 93)
2018-05-01 17:49:06.505  INFO 16044 --- [Executor task launch worker for task 93] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:06.505  INFO 16044 --- [Executor task launch worker for task 93] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:06.505  INFO 16044 --- [Executor task launch worker for task 93] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:06.775  INFO 16044 --- [Executor task launch worker for task 93] o.a.spark.storage.memory.MemoryStore     : Block rdd_100_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 17:49:06.775  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_100_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:49:06.777  INFO 16044 --- [Executor task launch worker for task 93] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 87.0 (TID 93). 2595 bytes result sent to driver
2018-05-01 17:49:06.778  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 87.0 (TID 93) in 276 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.778  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 87.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.778  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 87 (aggregate at ALS.scala:1491) finished in 0.276 s
2018-05-01 17:49:06.779  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 13 finished: aggregate at ALS.scala:1491, took 0.339223 s
2018-05-01 17:49:06.795  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 90 from persistence list
2018-05-01 17:49:06.795  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 90
2018-05-01 17:49:06.801  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:06.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:06.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:06.802  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:06.803  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:06.803  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:06.803  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:06.803  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:06.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:06.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:06.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:06.804  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:06.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:06.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 105 (flatMap at ALS.scala:1433)
2018-05-01 17:49:06.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 14 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:06.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 101 (aggregate at ALS.scala:1491)
2018-05-01 17:49:06.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 100, ShuffleMapStage 89)
2018-05-01 17:49:06.807  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 100)
2018-05-01 17:49:06.807  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 100 (MapPartitionsRDD[105] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:06.810  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_27 stored as values in memory (estimated size 22.7 KB, free 1925.8 MB)
2018-05-01 17:49:06.812  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_27_piece0 stored as bytes in memory (estimated size 10.4 KB, free 1925.8 MB)
2018-05-01 17:49:06.813  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_27_piece0 in memory on 172.21.241.193:58620 (size: 10.4 KB, free: 1926.0 MB)
2018-05-01 17:49:06.813  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.813  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[105] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.813  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 100.0 with 1 tasks
2018-05-01 17:49:06.814  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 100.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:06.814  INFO 16044 --- [Executor task launch worker for task 94] org.apache.spark.executor.Executor       : Running task 0.0 in stage 100.0 (TID 94)
2018-05-01 17:49:06.816  INFO 16044 --- [Executor task launch worker for task 94] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:06.816  INFO 16044 --- [Executor task launch worker for task 94] org.apache.spark.storage.BlockManager    : Found block rdd_100_0 locally
2018-05-01 17:49:06.860  INFO 16044 --- [Executor task launch worker for task 94] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 100.0 (TID 94). 1069 bytes result sent to driver
2018-05-01 17:49:06.860  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 100.0 (TID 94) in 46 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:06.860  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 100.0, whose tasks have all completed, from pool 
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 100 (flatMap at ALS.scala:1433) finished in 0.047 s
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 101)
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:06.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 101 (MapPartitionsRDD[111] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:06.863  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_28 stored as values in memory (estimated size 25.1 KB, free 1925.8 MB)
2018-05-01 17:49:06.865  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.2 KB, free 1925.8 MB)
2018-05-01 17:49:06.865  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_28_piece0 in memory on 172.21.241.193:58620 (size: 11.2 KB, free: 1926.0 MB)
2018-05-01 17:49:06.865  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:06.865  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[111] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:06.866  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 101.0 with 1 tasks
2018-05-01 17:49:06.866  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 101.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:06.866  INFO 16044 --- [Executor task launch worker for task 95] org.apache.spark.executor.Executor       : Running task 0.0 in stage 101.0 (TID 95)
2018-05-01 17:49:06.868  INFO 16044 --- [Executor task launch worker for task 95] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:06.868  INFO 16044 --- [Executor task launch worker for task 95] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:06.868  INFO 16044 --- [Executor task launch worker for task 95] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:07.171  INFO 16044 --- [Executor task launch worker for task 95] o.a.spark.storage.memory.MemoryStore     : Block rdd_110_0 stored as values in memory (estimated size 820.5 KB, free 1925.0 MB)
2018-05-01 17:49:07.171  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_110_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:49:07.175  INFO 16044 --- [Executor task launch worker for task 95] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 101.0 (TID 95). 2595 bytes result sent to driver
2018-05-01 17:49:07.175  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 101.0 (TID 95) in 309 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.175  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 101.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.176  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 101 (aggregate at ALS.scala:1491) finished in 0.310 s
2018-05-01 17:49:07.176  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 14 finished: aggregate at ALS.scala:1491, took 0.374871 s
2018-05-01 17:49:07.192  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 100 from persistence list
2018-05-01 17:49:07.192  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 100
2018-05-01 17:49:07.198  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:07.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:07.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:07.199  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:07.200  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:07.201  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:07.201  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:07.201  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:07.201  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 115 (flatMap at ALS.scala:1433)
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 15 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 116 (aggregate at ALS.scala:1491)
2018-05-01 17:49:07.202  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 103, ShuffleMapStage 115)
2018-05-01 17:49:07.203  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 115)
2018-05-01 17:49:07.204  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 115 (MapPartitionsRDD[115] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:07.205  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_29 stored as values in memory (estimated size 24.2 KB, free 1925.3 MB)
2018-05-01 17:49:07.206  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.0 KB, free 1925.3 MB)
2018-05-01 17:49:07.207  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_29_piece0 in memory on 172.21.241.193:58620 (size: 11.0 KB, free: 1925.6 MB)
2018-05-01 17:49:07.207  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[115] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.208  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 115.0 with 1 tasks
2018-05-01 17:49:07.208  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 115.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:07.208  INFO 16044 --- [Executor task launch worker for task 96] org.apache.spark.executor.Executor       : Running task 0.0 in stage 115.0 (TID 96)
2018-05-01 17:49:07.210  INFO 16044 --- [Executor task launch worker for task 96] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:07.210  INFO 16044 --- [Executor task launch worker for task 96] org.apache.spark.storage.BlockManager    : Found block rdd_110_0 locally
2018-05-01 17:49:07.248  INFO 16044 --- [Executor task launch worker for task 96] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 115.0 (TID 96). 1069 bytes result sent to driver
2018-05-01 17:49:07.248  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 115.0 (TID 96) in 40 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.248  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 115.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 115 (flatMap at ALS.scala:1433) finished in 0.040 s
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 116)
2018-05-01 17:49:07.248  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:07.249  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 116 (MapPartitionsRDD[121] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:07.250  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_30 stored as values in memory (estimated size 26.7 KB, free 1925.3 MB)
2018-05-01 17:49:07.251  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1925.3 MB)
2018-05-01 17:49:07.251  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_30_piece0 in memory on 172.21.241.193:58620 (size: 11.9 KB, free: 1925.6 MB)
2018-05-01 17:49:07.252  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.252  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[121] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.252  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 116.0 with 1 tasks
2018-05-01 17:49:07.253  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 116.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:07.253  INFO 16044 --- [Executor task launch worker for task 97] org.apache.spark.executor.Executor       : Running task 0.0 in stage 116.0 (TID 97)
2018-05-01 17:49:07.256  INFO 16044 --- [Executor task launch worker for task 97] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:07.256  INFO 16044 --- [Executor task launch worker for task 97] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:07.257  INFO 16044 --- [Executor task launch worker for task 97] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:49:07.546  INFO 16044 --- [Executor task launch worker for task 97] o.a.spark.storage.memory.MemoryStore     : Block rdd_120_0 stored as values in memory (estimated size 416.2 KB, free 1924.9 MB)
2018-05-01 17:49:07.547  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_120_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:49:07.548  INFO 16044 --- [Executor task launch worker for task 97] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 116.0 (TID 97). 2595 bytes result sent to driver
2018-05-01 17:49:07.549  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 116.0 (TID 97) in 296 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.549  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 116.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.549  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 116 (aggregate at ALS.scala:1491) finished in 0.297 s
2018-05-01 17:49:07.550  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 15 finished: aggregate at ALS.scala:1491, took 0.351506 s
2018-05-01 17:49:07.570  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 110 from persistence list
2018-05-01 17:49:07.570  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 110
2018-05-01 17:49:07.575  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:07.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:07.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:07.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:07.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:07.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:07.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:07.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 125 (flatMap at ALS.scala:1433)
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 16 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 132 (aggregate at ALS.scala:1491)
2018-05-01 17:49:07.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 118, ShuffleMapStage 131)
2018-05-01 17:49:07.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 131)
2018-05-01 17:49:07.582  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 131 (MapPartitionsRDD[125] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:07.584  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_31 stored as values in memory (estimated size 25.8 KB, free 1925.7 MB)
2018-05-01 17:49:07.586  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_31_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1925.7 MB)
2018-05-01 17:49:07.586  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_31_piece0 in memory on 172.21.241.193:58620 (size: 11.7 KB, free: 1926.0 MB)
2018-05-01 17:49:07.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[125] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.588  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 131.0 with 1 tasks
2018-05-01 17:49:07.588  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 131.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:07.588  INFO 16044 --- [Executor task launch worker for task 98] org.apache.spark.executor.Executor       : Running task 0.0 in stage 131.0 (TID 98)
2018-05-01 17:49:07.591  INFO 16044 --- [Executor task launch worker for task 98] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:07.591  INFO 16044 --- [Executor task launch worker for task 98] org.apache.spark.storage.BlockManager    : Found block rdd_120_0 locally
2018-05-01 17:49:07.618  INFO 16044 --- [Executor task launch worker for task 98] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 131.0 (TID 98). 1112 bytes result sent to driver
2018-05-01 17:49:07.619  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 131.0 (TID 98) in 31 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.619  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 131.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 131 (flatMap at ALS.scala:1433) finished in 0.031 s
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 132)
2018-05-01 17:49:07.619  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:07.620  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 132 (MapPartitionsRDD[131] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:07.622  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_32 stored as values in memory (estimated size 28.2 KB, free 1925.6 MB)
2018-05-01 17:49:07.623  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_32_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1925.6 MB)
2018-05-01 17:49:07.623  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_32_piece0 in memory on 172.21.241.193:58620 (size: 12.5 KB, free: 1926.0 MB)
2018-05-01 17:49:07.624  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.624  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[131] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.624  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 132.0 with 1 tasks
2018-05-01 17:49:07.624  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 132.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:07.625  INFO 16044 --- [Executor task launch worker for task 99] org.apache.spark.executor.Executor       : Running task 0.0 in stage 132.0 (TID 99)
2018-05-01 17:49:07.627  INFO 16044 --- [Executor task launch worker for task 99] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:07.627  INFO 16044 --- [Executor task launch worker for task 99] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:07.627  INFO 16044 --- [Executor task launch worker for task 99] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:07.918  INFO 16044 --- [Executor task launch worker for task 99] o.a.spark.storage.memory.MemoryStore     : Block rdd_130_0 stored as values in memory (estimated size 820.5 KB, free 1924.8 MB)
2018-05-01 17:49:07.918  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_130_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:49:07.922  INFO 16044 --- [Executor task launch worker for task 99] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 132.0 (TID 99). 2595 bytes result sent to driver
2018-05-01 17:49:07.922  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 132.0 (TID 99) in 298 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:07.922  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 132.0, whose tasks have all completed, from pool 
2018-05-01 17:49:07.923  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 132 (aggregate at ALS.scala:1491) finished in 0.299 s
2018-05-01 17:49:07.923  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 16 finished: aggregate at ALS.scala:1491, took 0.347837 s
2018-05-01 17:49:07.941  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 120 from persistence list
2018-05-01 17:49:07.941  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 120
2018-05-01 17:49:07.946  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:07.947  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:07.947  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:07.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:07.949  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:07.950  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 135 (flatMap at ALS.scala:1433)
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 17 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 149 (aggregate at ALS.scala:1491)
2018-05-01 17:49:07.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 148, ShuffleMapStage 134)
2018-05-01 17:49:07.952  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 148)
2018-05-01 17:49:07.952  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 148 (MapPartitionsRDD[135] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:07.954  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_33 stored as values in memory (estimated size 27.3 KB, free 1925.2 MB)
2018-05-01 17:49:07.955  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_33_piece0 stored as bytes in memory (estimated size 12.4 KB, free 1925.2 MB)
2018-05-01 17:49:07.956  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_33_piece0 in memory on 172.21.241.193:58620 (size: 12.4 KB, free: 1925.6 MB)
2018-05-01 17:49:07.956  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:07.957  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[135] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:07.957  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 148.0 with 1 tasks
2018-05-01 17:49:07.958  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 148.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:07.958  INFO 16044 --- [Executor task launch worker for task 100] org.apache.spark.executor.Executor       : Running task 0.0 in stage 148.0 (TID 100)
2018-05-01 17:49:07.960  INFO 16044 --- [Executor task launch worker for task 100] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:07.961  INFO 16044 --- [Executor task launch worker for task 100] org.apache.spark.storage.BlockManager    : Found block rdd_130_0 locally
2018-05-01 17:49:08.010  INFO 16044 --- [Executor task launch worker for task 100] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 148.0 (TID 100). 1069 bytes result sent to driver
2018-05-01 17:49:08.010  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 148.0 (TID 100) in 52 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.010  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 148.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 148 (flatMap at ALS.scala:1433) finished in 0.053 s
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 149)
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:08.011  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 149 (MapPartitionsRDD[141] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:08.014  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_34 stored as values in memory (estimated size 29.8 KB, free 1925.2 MB)
2018-05-01 17:49:08.015  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_34_piece0 stored as bytes in memory (estimated size 13.3 KB, free 1925.1 MB)
2018-05-01 17:49:08.016  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_34_piece0 in memory on 172.21.241.193:58620 (size: 13.3 KB, free: 1925.6 MB)
2018-05-01 17:49:08.016  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.016  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[141] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.016  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 149.0 with 1 tasks
2018-05-01 17:49:08.017  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 149.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:08.017  INFO 16044 --- [Executor task launch worker for task 101] org.apache.spark.executor.Executor       : Running task 0.0 in stage 149.0 (TID 101)
2018-05-01 17:49:08.020  INFO 16044 --- [Executor task launch worker for task 101] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:08.020  INFO 16044 --- [Executor task launch worker for task 101] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:08.020  INFO 16044 --- [Executor task launch worker for task 101] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:08.313  INFO 16044 --- [Executor task launch worker for task 101] o.a.spark.storage.memory.MemoryStore     : Block rdd_140_0 stored as values in memory (estimated size 416.2 KB, free 1924.7 MB)
2018-05-01 17:49:08.314  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_140_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:49:08.316  INFO 16044 --- [Executor task launch worker for task 101] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 149.0 (TID 101). 2595 bytes result sent to driver
2018-05-01 17:49:08.316  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 149.0 (TID 101) in 300 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.316  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 149.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.316  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 149 (aggregate at ALS.scala:1491) finished in 0.300 s
2018-05-01 17:49:08.317  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 17 finished: aggregate at ALS.scala:1491, took 0.370103 s
2018-05-01 17:49:08.335  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 130 from persistence list
2018-05-01 17:49:08.335  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 130
2018-05-01 17:49:08.341  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:08.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:08.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:08.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:08.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:08.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:08.344  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:08.344  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:08.344  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:08.345  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:08.345  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:08.345  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 145 (flatMap at ALS.scala:1433)
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 18 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 167 (aggregate at ALS.scala:1491)
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 151, ShuffleMapStage 166)
2018-05-01 17:49:08.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 166)
2018-05-01 17:49:08.347  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 166 (MapPartitionsRDD[145] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:08.349  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_35 stored as values in memory (estimated size 28.9 KB, free 1925.5 MB)
2018-05-01 17:49:08.349  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_35_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1925.5 MB)
2018-05-01 17:49:08.350  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_35_piece0 in memory on 172.21.241.193:58620 (size: 13.0 KB, free: 1925.9 MB)
2018-05-01 17:49:08.350  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.350  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[145] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.350  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 166.0 with 1 tasks
2018-05-01 17:49:08.351  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 166.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:08.351  INFO 16044 --- [Executor task launch worker for task 102] org.apache.spark.executor.Executor       : Running task 0.0 in stage 166.0 (TID 102)
2018-05-01 17:49:08.354  INFO 16044 --- [Executor task launch worker for task 102] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:08.354  INFO 16044 --- [Executor task launch worker for task 102] org.apache.spark.storage.BlockManager    : Found block rdd_140_0 locally
2018-05-01 17:49:08.383  INFO 16044 --- [Executor task launch worker for task 102] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 166.0 (TID 102). 1069 bytes result sent to driver
2018-05-01 17:49:08.383  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 166.0 (TID 102) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.383  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 166.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 166 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 167)
2018-05-01 17:49:08.383  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:08.384  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 167 (MapPartitionsRDD[151] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:08.386  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_36 stored as values in memory (estimated size 31.3 KB, free 1925.5 MB)
2018-05-01 17:49:08.387  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_36_piece0 stored as bytes in memory (estimated size 13.9 KB, free 1925.4 MB)
2018-05-01 17:49:08.387  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_36_piece0 in memory on 172.21.241.193:58620 (size: 13.9 KB, free: 1925.9 MB)
2018-05-01 17:49:08.388  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.388  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[151] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.388  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 167.0 with 1 tasks
2018-05-01 17:49:08.389  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 167.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:08.389  INFO 16044 --- [Executor task launch worker for task 103] org.apache.spark.executor.Executor       : Running task 0.0 in stage 167.0 (TID 103)
2018-05-01 17:49:08.391  INFO 16044 --- [Executor task launch worker for task 103] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:08.391  INFO 16044 --- [Executor task launch worker for task 103] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:08.391  INFO 16044 --- [Executor task launch worker for task 103] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:08.690  INFO 16044 --- [Executor task launch worker for task 103] o.a.spark.storage.memory.MemoryStore     : Block rdd_150_0 stored as values in memory (estimated size 820.5 KB, free 1924.6 MB)
2018-05-01 17:49:08.691  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_150_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:49:08.696  INFO 16044 --- [Executor task launch worker for task 103] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 167.0 (TID 103). 2595 bytes result sent to driver
2018-05-01 17:49:08.696  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 167.0 (TID 103) in 307 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.696  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 167.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.696  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 167 (aggregate at ALS.scala:1491) finished in 0.307 s
2018-05-01 17:49:08.697  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 18 finished: aggregate at ALS.scala:1491, took 0.355612 s
2018-05-01 17:49:08.718  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 140 from persistence list
2018-05-01 17:49:08.718  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 140
2018-05-01 17:49:08.724  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:08.725  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:08.725  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:08.725  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:08.726  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:08.726  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:08.726  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:08.726  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:08.727  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:08.728  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:08.728  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:08.728  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:08.728  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 155 (flatMap at ALS.scala:1433)
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 19 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 186 (aggregate at ALS.scala:1491)
2018-05-01 17:49:08.729  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 169, ShuffleMapStage 185)
2018-05-01 17:49:08.730  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 185)
2018-05-01 17:49:08.730  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 185 (MapPartitionsRDD[155] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:08.733  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_37 stored as values in memory (estimated size 30.4 KB, free 1925.0 MB)
2018-05-01 17:49:08.734  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_37_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1925.0 MB)
2018-05-01 17:49:08.734  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_37_piece0 in memory on 172.21.241.193:58620 (size: 13.6 KB, free: 1925.5 MB)
2018-05-01 17:49:08.735  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.735  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 185 (MapPartitionsRDD[155] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.735  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 185.0 with 1 tasks
2018-05-01 17:49:08.735  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 185.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:08.735  INFO 16044 --- [Executor task launch worker for task 104] org.apache.spark.executor.Executor       : Running task 0.0 in stage 185.0 (TID 104)
2018-05-01 17:49:08.737  INFO 16044 --- [Executor task launch worker for task 104] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:08.738  INFO 16044 --- [Executor task launch worker for task 104] org.apache.spark.storage.BlockManager    : Found block rdd_150_0 locally
2018-05-01 17:49:08.779  INFO 16044 --- [Executor task launch worker for task 104] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 185.0 (TID 104). 1069 bytes result sent to driver
2018-05-01 17:49:08.779  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 185.0 (TID 104) in 44 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:08.779  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 185.0, whose tasks have all completed, from pool 
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 185 (flatMap at ALS.scala:1433) finished in 0.044 s
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 186)
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:08.780  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 186 (MapPartitionsRDD[161] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:08.783  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_38 stored as values in memory (estimated size 32.9 KB, free 1925.0 MB)
2018-05-01 17:49:08.785  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_38_piece0 stored as bytes in memory (estimated size 14.7 KB, free 1925.0 MB)
2018-05-01 17:49:08.785  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_38_piece0 in memory on 172.21.241.193:58620 (size: 14.7 KB, free: 1925.5 MB)
2018-05-01 17:49:08.785  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:08.786  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[161] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:08.786  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 186.0 with 1 tasks
2018-05-01 17:49:08.786  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 186.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:08.786  INFO 16044 --- [Executor task launch worker for task 105] org.apache.spark.executor.Executor       : Running task 0.0 in stage 186.0 (TID 105)
2018-05-01 17:49:08.790  INFO 16044 --- [Executor task launch worker for task 105] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:08.790  INFO 16044 --- [Executor task launch worker for task 105] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:08.790  INFO 16044 --- [Executor task launch worker for task 105] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:09.085  INFO 16044 --- [Executor task launch worker for task 105] o.a.spark.storage.memory.MemoryStore     : Block rdd_160_0 stored as values in memory (estimated size 416.2 KB, free 1924.6 MB)
2018-05-01 17:49:09.085  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_160_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 17:49:09.087  INFO 16044 --- [Executor task launch worker for task 105] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 186.0 (TID 105). 2595 bytes result sent to driver
2018-05-01 17:49:09.088  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 186.0 (TID 105) in 302 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.088  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 186.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 186 (aggregate at ALS.scala:1491) finished in 0.302 s
2018-05-01 17:49:09.088  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 19 finished: aggregate at ALS.scala:1491, took 0.364357 s
2018-05-01 17:49:09.108  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 150 from persistence list
2018-05-01 17:49:09.109  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 150
2018-05-01 17:49:09.114  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:09.114  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:09.115  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:09.115  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:09.115  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:09.116  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:09.117  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:09.118  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:09.118  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:09.118  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 165 (flatMap at ALS.scala:1433)
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 20 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 206 (aggregate at ALS.scala:1491)
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 205, ShuffleMapStage 188)
2018-05-01 17:49:09.119  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 205)
2018-05-01 17:49:09.120  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 205 (MapPartitionsRDD[165] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:09.122  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_39 stored as values in memory (estimated size 32.0 KB, free 1925.3 MB)
2018-05-01 17:49:09.123  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_39_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1925.3 MB)
2018-05-01 17:49:09.123  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_39_piece0 in memory on 172.21.241.193:58620 (size: 14.4 KB, free: 1925.9 MB)
2018-05-01 17:49:09.123  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.123  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 205 (MapPartitionsRDD[165] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.123  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 205.0 with 1 tasks
2018-05-01 17:49:09.124  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 205.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:09.124  INFO 16044 --- [Executor task launch worker for task 106] org.apache.spark.executor.Executor       : Running task 0.0 in stage 205.0 (TID 106)
2018-05-01 17:49:09.127  INFO 16044 --- [Executor task launch worker for task 106] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:09.128  INFO 16044 --- [Executor task launch worker for task 106] org.apache.spark.storage.BlockManager    : Found block rdd_160_0 locally
2018-05-01 17:49:09.158  INFO 16044 --- [Executor task launch worker for task 106] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 205.0 (TID 106). 1069 bytes result sent to driver
2018-05-01 17:49:09.159  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 205.0 (TID 106) in 34 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.159  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 205.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 205 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 206)
2018-05-01 17:49:09.159  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:09.160  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 206 (MapPartitionsRDD[171] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:09.163  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_40 stored as values in memory (estimated size 34.4 KB, free 1925.3 MB)
2018-05-01 17:49:09.164  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_40_piece0 stored as bytes in memory (estimated size 15.5 KB, free 1925.3 MB)
2018-05-01 17:49:09.164  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_40_piece0 in memory on 172.21.241.193:58620 (size: 15.5 KB, free: 1925.9 MB)
2018-05-01 17:49:09.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 206 (MapPartitionsRDD[171] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.165  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 206.0 with 1 tasks
2018-05-01 17:49:09.166  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 206.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:09.166  INFO 16044 --- [Executor task launch worker for task 107] org.apache.spark.executor.Executor       : Running task 0.0 in stage 206.0 (TID 107)
2018-05-01 17:49:09.169  INFO 16044 --- [Executor task launch worker for task 107] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:09.170  INFO 16044 --- [Executor task launch worker for task 107] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:09.170  INFO 16044 --- [Executor task launch worker for task 107] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:49:09.483  INFO 16044 --- [Executor task launch worker for task 107] o.a.spark.storage.memory.MemoryStore     : Block rdd_170_0 stored as values in memory (estimated size 820.5 KB, free 1924.5 MB)
2018-05-01 17:49:09.484  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_170_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:49:09.487  INFO 16044 --- [Executor task launch worker for task 107] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 206.0 (TID 107). 2638 bytes result sent to driver
2018-05-01 17:49:09.487  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 206.0 (TID 107) in 322 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.488  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 206.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.488  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 206 (aggregate at ALS.scala:1491) finished in 0.323 s
2018-05-01 17:49:09.488  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 20 finished: aggregate at ALS.scala:1491, took 0.374356 s
2018-05-01 17:49:09.508  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 160 from persistence list
2018-05-01 17:49:09.509  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 160
2018-05-01 17:49:09.514  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:09.514  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:09.515  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:09.515  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:09.515  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:09.515  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:09.516  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:09.516  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:09.516  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:09.516  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:09.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:09.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:09.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:09.517  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:09.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:09.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:09.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:09.518  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 175 (flatMap at ALS.scala:1433)
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 21 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 227 (aggregate at ALS.scala:1491)
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 208, ShuffleMapStage 226)
2018-05-01 17:49:09.519  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 226)
2018-05-01 17:49:09.520  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 226 (MapPartitionsRDD[175] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:09.522  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_41 stored as values in memory (estimated size 33.5 KB, free 1924.8 MB)
2018-05-01 17:49:09.523  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_41_piece0 stored as bytes in memory (estimated size 15.2 KB, free 1924.8 MB)
2018-05-01 17:49:09.523  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_41_piece0 in memory on 172.21.241.193:58620 (size: 15.2 KB, free: 1925.5 MB)
2018-05-01 17:49:09.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 226 (MapPartitionsRDD[175] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.523  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 226.0 with 1 tasks
2018-05-01 17:49:09.524  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 226.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:09.524  INFO 16044 --- [Executor task launch worker for task 108] org.apache.spark.executor.Executor       : Running task 0.0 in stage 226.0 (TID 108)
2018-05-01 17:49:09.528  INFO 16044 --- [Executor task launch worker for task 108] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:09.528  INFO 16044 --- [Executor task launch worker for task 108] org.apache.spark.storage.BlockManager    : Found block rdd_170_0 locally
2018-05-01 17:49:09.565  INFO 16044 --- [Executor task launch worker for task 108] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 226.0 (TID 108). 1155 bytes result sent to driver
2018-05-01 17:49:09.565  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 226.0 (TID 108) in 41 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.565  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 226.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 226 (flatMap at ALS.scala:1433) finished in 0.041 s
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 227)
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:09.566  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 227 (MapPartitionsRDD[181] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:09.569  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_42 stored as values in memory (estimated size 36.0 KB, free 1924.8 MB)
2018-05-01 17:49:09.570  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_42_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1924.8 MB)
2018-05-01 17:49:09.571  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_42_piece0 in memory on 172.21.241.193:58620 (size: 16.4 KB, free: 1925.5 MB)
2018-05-01 17:49:09.571  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.571  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[181] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.571  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 227.0 with 1 tasks
2018-05-01 17:49:09.572  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 227.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:09.572  INFO 16044 --- [Executor task launch worker for task 109] org.apache.spark.executor.Executor       : Running task 0.0 in stage 227.0 (TID 109)
2018-05-01 17:49:09.576  INFO 16044 --- [Executor task launch worker for task 109] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:09.576  INFO 16044 --- [Executor task launch worker for task 109] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:09.576  INFO 16044 --- [Executor task launch worker for task 109] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:09.943  INFO 16044 --- [Executor task launch worker for task 109] o.a.spark.storage.memory.MemoryStore     : Block rdd_180_0 stored as values in memory (estimated size 416.2 KB, free 1924.4 MB)
2018-05-01 17:49:09.943  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_180_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.0 MB)
2018-05-01 17:49:09.947  INFO 16044 --- [Executor task launch worker for task 109] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 227.0 (TID 109). 2638 bytes result sent to driver
2018-05-01 17:49:09.947  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 227.0 (TID 109) in 375 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:09.947  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 227.0, whose tasks have all completed, from pool 
2018-05-01 17:49:09.948  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 227 (aggregate at ALS.scala:1491) finished in 0.377 s
2018-05-01 17:49:09.948  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 21 finished: aggregate at ALS.scala:1491, took 0.434254 s
2018-05-01 17:49:09.974  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 170 from persistence list
2018-05-01 17:49:09.974  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 170
2018-05-01 17:49:09.982  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:09.983  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:09.983  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:09.984  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:09.984  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:09.984  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:09.985  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:09.985  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:09.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:09.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:09.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:09.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:09.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:09.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:09.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:09.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:09.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:09.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:09.989  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:09.989  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:09.989  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 185 (flatMap at ALS.scala:1433)
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 22 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 249 (aggregate at ALS.scala:1491)
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 248, ShuffleMapStage 229)
2018-05-01 17:49:09.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 248)
2018-05-01 17:49:09.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 248 (MapPartitionsRDD[185] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:09.993  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_43 stored as values in memory (estimated size 35.1 KB, free 1925.1 MB)
2018-05-01 17:49:09.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_43_piece0 stored as bytes in memory (estimated size 16.0 KB, free 1925.1 MB)
2018-05-01 17:49:09.994  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_43_piece0 in memory on 172.21.241.193:58620 (size: 16.0 KB, free: 1925.8 MB)
2018-05-01 17:49:09.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:09.994  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 248 (MapPartitionsRDD[185] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:09.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 248.0 with 1 tasks
2018-05-01 17:49:09.996  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 248.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:09.996  INFO 16044 --- [Executor task launch worker for task 110] org.apache.spark.executor.Executor       : Running task 0.0 in stage 248.0 (TID 110)
2018-05-01 17:49:09.999  INFO 16044 --- [Executor task launch worker for task 110] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:09.999  INFO 16044 --- [Executor task launch worker for task 110] org.apache.spark.storage.BlockManager    : Found block rdd_180_0 locally
2018-05-01 17:49:10.031  INFO 16044 --- [Executor task launch worker for task 110] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 248.0 (TID 110). 1069 bytes result sent to driver
2018-05-01 17:49:10.032  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 248.0 (TID 110) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:10.032  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 248.0, whose tasks have all completed, from pool 
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 248 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 249)
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:10.032  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 249 (MapPartitionsRDD[191] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:10.035  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_44 stored as values in memory (estimated size 37.5 KB, free 1925.1 MB)
2018-05-01 17:49:10.037  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.8 KB, free 1925.1 MB)
2018-05-01 17:49:10.037  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_44_piece0 in memory on 172.21.241.193:58620 (size: 16.8 KB, free: 1925.8 MB)
2018-05-01 17:49:10.037  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:10.037  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 249 (MapPartitionsRDD[191] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:10.038  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 249.0 with 1 tasks
2018-05-01 17:49:10.038  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 249.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:10.038  INFO 16044 --- [Executor task launch worker for task 111] org.apache.spark.executor.Executor       : Running task 0.0 in stage 249.0 (TID 111)
2018-05-01 17:49:10.041  INFO 16044 --- [Executor task launch worker for task 111] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:10.041  INFO 16044 --- [Executor task launch worker for task 111] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:10.041  INFO 16044 --- [Executor task launch worker for task 111] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:10.440  INFO 16044 --- [Executor task launch worker for task 111] o.a.spark.storage.memory.MemoryStore     : Block rdd_190_0 stored as values in memory (estimated size 820.5 KB, free 1924.3 MB)
2018-05-01 17:49:10.441  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_190_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.0 MB)
2018-05-01 17:49:10.447  INFO 16044 --- [Executor task launch worker for task 111] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 249.0 (TID 111). 2595 bytes result sent to driver
2018-05-01 17:49:10.447  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 249.0 (TID 111) in 409 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:10.447  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 249.0, whose tasks have all completed, from pool 
2018-05-01 17:49:10.447  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 249 (aggregate at ALS.scala:1491) finished in 0.409 s
2018-05-01 17:49:10.448  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 22 finished: aggregate at ALS.scala:1491, took 0.465869 s
2018-05-01 17:49:10.470  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 180 from persistence list
2018-05-01 17:49:10.470  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 180
2018-05-01 17:49:10.476  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:10.477  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:10.477  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:10.477  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:10.478  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:10.478  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:10.478  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:10.478  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:10.479  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:10.576  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:10.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:10.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:10.577  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:10.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:10.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:10.578  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:10.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:10.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:10.579  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:10.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:10.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:10.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:49:10.580  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 195 (flatMap at ALS.scala:1433)
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 23 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 272 (aggregate at ALS.scala:1491)
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 251, ShuffleMapStage 271)
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 271)
2018-05-01 17:49:10.581  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 271 (MapPartitionsRDD[195] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:10.584  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_45 stored as values in memory (estimated size 36.6 KB, free 1924.6 MB)
2018-05-01 17:49:10.586  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_45_piece0 stored as bytes in memory (estimated size 16.5 KB, free 1924.6 MB)
2018-05-01 17:49:10.586  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_45_piece0 in memory on 172.21.241.193:58620 (size: 16.5 KB, free: 1925.4 MB)
2018-05-01 17:49:10.587  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:10.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 271 (MapPartitionsRDD[195] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:10.588  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 271.0 with 1 tasks
2018-05-01 17:49:10.588  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 271.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:10.588  INFO 16044 --- [Executor task launch worker for task 112] org.apache.spark.executor.Executor       : Running task 0.0 in stage 271.0 (TID 112)
2018-05-01 17:49:10.590  INFO 16044 --- [Executor task launch worker for task 112] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:10.590  INFO 16044 --- [Executor task launch worker for task 112] org.apache.spark.storage.BlockManager    : Found block rdd_190_0 locally
2018-05-01 17:49:10.639  INFO 16044 --- [Executor task launch worker for task 112] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 271.0 (TID 112). 1112 bytes result sent to driver
2018-05-01 17:49:10.643  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 271.0 (TID 112) in 55 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:10.644  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 271.0, whose tasks have all completed, from pool 
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 271 (flatMap at ALS.scala:1433) finished in 0.056 s
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 272)
2018-05-01 17:49:10.644  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:10.645  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 272 (MapPartitionsRDD[201] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:10.649  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_46 stored as values in memory (estimated size 39.1 KB, free 1924.6 MB)
2018-05-01 17:49:10.651  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_46_piece0 stored as bytes in memory (estimated size 17.6 KB, free 1924.6 MB)
2018-05-01 17:49:10.652  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_46_piece0 in memory on 172.21.241.193:58620 (size: 17.6 KB, free: 1925.4 MB)
2018-05-01 17:49:10.652  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:10.653  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[201] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:10.653  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 272.0 with 1 tasks
2018-05-01 17:49:10.654  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 272.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:10.655  INFO 16044 --- [Executor task launch worker for task 113] org.apache.spark.executor.Executor       : Running task 0.0 in stage 272.0 (TID 113)
2018-05-01 17:49:10.659  INFO 16044 --- [Executor task launch worker for task 113] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:10.659  INFO 16044 --- [Executor task launch worker for task 113] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:10.659  INFO 16044 --- [Executor task launch worker for task 113] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:11.052  INFO 16044 --- [Executor task launch worker for task 113] o.a.spark.storage.memory.MemoryStore     : Block rdd_200_0 stored as values in memory (estimated size 416.2 KB, free 1924.2 MB)
2018-05-01 17:49:11.053  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_200_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.0 MB)
2018-05-01 17:49:11.055  INFO 16044 --- [Executor task launch worker for task 113] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 272.0 (TID 113). 2595 bytes result sent to driver
2018-05-01 17:49:11.055  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 272.0 (TID 113) in 401 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:11.056  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 272.0, whose tasks have all completed, from pool 
2018-05-01 17:49:11.056  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 272 (aggregate at ALS.scala:1491) finished in 0.402 s
2018-05-01 17:49:11.056  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 23 finished: aggregate at ALS.scala:1491, took 0.580191 s
2018-05-01 17:49:11.079  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 190 from persistence list
2018-05-01 17:49:11.079  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 190
2018-05-01 17:49:11.085  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:49:11.086  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:11.086  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:11.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:11.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:11.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:11.087  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:11.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:11.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:11.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:11.088  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:11.089  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:11.090  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:11.090  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:11.090  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:11.091  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:11.091  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:11.091  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:49:11.091  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 205 (flatMap at ALS.scala:1433)
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 24 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 296 (aggregate at ALS.scala:1491)
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 274, ShuffleMapStage 295)
2018-05-01 17:49:11.092  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 295)
2018-05-01 17:49:11.094  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 295 (MapPartitionsRDD[205] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:11.096  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_47 stored as values in memory (estimated size 38.2 KB, free 1924.9 MB)
2018-05-01 17:49:11.098  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_47_piece0 stored as bytes in memory (estimated size 17.3 KB, free 1924.9 MB)
2018-05-01 17:49:11.098  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_47_piece0 in memory on 172.21.241.193:58620 (size: 17.3 KB, free: 1925.8 MB)
2018-05-01 17:49:11.098  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:11.099  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 295 (MapPartitionsRDD[205] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:11.099  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 295.0 with 1 tasks
2018-05-01 17:49:11.099  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 295.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:11.100  INFO 16044 --- [Executor task launch worker for task 114] org.apache.spark.executor.Executor       : Running task 0.0 in stage 295.0 (TID 114)
2018-05-01 17:49:11.102  INFO 16044 --- [Executor task launch worker for task 114] org.apache.spark.storage.BlockManager    : Found block rdd_13_0 locally
2018-05-01 17:49:11.103  INFO 16044 --- [Executor task launch worker for task 114] org.apache.spark.storage.BlockManager    : Found block rdd_200_0 locally
2018-05-01 17:49:11.134  INFO 16044 --- [Executor task launch worker for task 114] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 295.0 (TID 114). 1069 bytes result sent to driver
2018-05-01 17:49:11.135  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 295.0 (TID 114) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:11.135  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 295.0, whose tasks have all completed, from pool 
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 295 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 296)
2018-05-01 17:49:11.135  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:11.136  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 296 (MapPartitionsRDD[211] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:49:11.138  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_48 stored as values in memory (estimated size 40.6 KB, free 1924.9 MB)
2018-05-01 17:49:11.140  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_48_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1924.8 MB)
2018-05-01 17:49:11.140  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_48_piece0 in memory on 172.21.241.193:58620 (size: 18.2 KB, free: 1925.7 MB)
2018-05-01 17:49:11.140  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:11.140  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 296 (MapPartitionsRDD[211] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:11.140  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 296.0 with 1 tasks
2018-05-01 17:49:11.141  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 296.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:49:11.141  INFO 16044 --- [Executor task launch worker for task 115] org.apache.spark.executor.Executor       : Running task 0.0 in stage 296.0 (TID 115)
2018-05-01 17:49:11.144  INFO 16044 --- [Executor task launch worker for task 115] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:11.144  INFO 16044 --- [Executor task launch worker for task 115] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:11.144  INFO 16044 --- [Executor task launch worker for task 115] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:11.594  INFO 16044 --- [Executor task launch worker for task 115] o.a.spark.storage.memory.MemoryStore     : Block rdd_210_0 stored as values in memory (estimated size 820.5 KB, free 1924.0 MB)
2018-05-01 17:49:11.594  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_210_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1924.9 MB)
2018-05-01 17:49:11.600  INFO 16044 --- [Executor task launch worker for task 115] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 296.0 (TID 115). 2595 bytes result sent to driver
2018-05-01 17:49:11.601  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 296.0 (TID 115) in 459 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:11.601  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 296.0, whose tasks have all completed, from pool 
2018-05-01 17:49:11.601  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 296 (aggregate at ALS.scala:1491) finished in 0.460 s
2018-05-01 17:49:11.602  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 24 finished: aggregate at ALS.scala:1491, took 0.516182 s
2018-05-01 17:49:11.629  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 200 from persistence list
2018-05-01 17:49:11.630  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 200
2018-05-01 17:49:11.673  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:279
2018-05-01 17:49:11.674  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:11.674  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:11.675  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:11.675  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:11.675  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:11.676  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:11.676  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:11.676  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:11.677  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:11.677  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:11.677  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:11.678  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:11.678  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:11.679  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:11.679  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:11.680  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:11.681  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:11.682  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:11.682  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:11.682  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:11.682  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:49:11.683  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:49:11.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 22 is 150 bytes
2018-05-01 17:49:11.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 215 (flatMap at ALS.scala:1433)
2018-05-01 17:49:11.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 25 (count at ALS.scala:279) with 1 output partitions
2018-05-01 17:49:11.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 321 (count at ALS.scala:279)
2018-05-01 17:49:11.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 320, ShuffleMapStage 298)
2018-05-01 17:49:11.686  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 320)
2018-05-01 17:49:11.686  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 320 (MapPartitionsRDD[215] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:49:11.690  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_49 stored as values in memory (estimated size 39.7 KB, free 1924.4 MB)
2018-05-01 17:49:11.692  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_49_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1924.4 MB)
2018-05-01 17:49:11.692  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_49_piece0 in memory on 172.21.241.193:58620 (size: 18.0 KB, free: 1925.3 MB)
2018-05-01 17:49:11.692  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:11.693  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 320 (MapPartitionsRDD[215] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:11.693  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 320.0 with 1 tasks
2018-05-01 17:49:11.693  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 320.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:49:11.693  INFO 16044 --- [Executor task launch worker for task 116] org.apache.spark.executor.Executor       : Running task 0.0 in stage 320.0 (TID 116)
2018-05-01 17:49:11.698  INFO 16044 --- [Executor task launch worker for task 116] org.apache.spark.storage.BlockManager    : Found block rdd_18_0 locally
2018-05-01 17:49:11.699  INFO 16044 --- [Executor task launch worker for task 116] org.apache.spark.storage.BlockManager    : Found block rdd_210_0 locally
2018-05-01 17:49:11.739  INFO 16044 --- [Executor task launch worker for task 116] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 320.0 (TID 116). 1112 bytes result sent to driver
2018-05-01 17:49:11.739  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 320.0 (TID 116) in 46 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:11.740  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 320.0, whose tasks have all completed, from pool 
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 320 (flatMap at ALS.scala:1433) finished in 0.047 s
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 321)
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:49:11.740  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 321 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:49:11.743  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_50 stored as values in memory (estimated size 41.6 KB, free 1924.4 MB)
2018-05-01 17:49:11.745  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_50_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1924.3 MB)
2018-05-01 17:49:11.745  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_50_piece0 in memory on 172.21.241.193:58620 (size: 18.7 KB, free: 1925.3 MB)
2018-05-01 17:49:11.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:11.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 321 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:11.746  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 321.0 with 1 tasks
2018-05-01 17:49:11.747  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 321.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:11.747  INFO 16044 --- [Executor task launch worker for task 117] org.apache.spark.executor.Executor       : Running task 0.0 in stage 321.0 (TID 117)
2018-05-01 17:49:11.751  INFO 16044 --- [Executor task launch worker for task 117] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:11.751  INFO 16044 --- [Executor task launch worker for task 117] org.apache.spark.storage.BlockManager    : Found block rdd_12_0 locally
2018-05-01 17:49:11.751  INFO 16044 --- [Executor task launch worker for task 117] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:49:11.751  INFO 16044 --- [Executor task launch worker for task 117] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:49:12.282  INFO 16044 --- [Executor task launch worker for task 117] o.a.spark.storage.memory.MemoryStore     : Block rdd_231_0 stored as values in memory (estimated size 970.8 KB, free 1923.4 MB)
2018-05-01 17:49:12.283  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_231_0 in memory on 172.21.241.193:58620 (size: 970.8 KB, free: 1924.4 MB)
2018-05-01 17:49:12.284  INFO 16044 --- [Executor task launch worker for task 117] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 321.0 (TID 117). 1873 bytes result sent to driver
2018-05-01 17:49:12.285  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 321.0 (TID 117) in 539 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:12.285  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 321.0, whose tasks have all completed, from pool 
2018-05-01 17:49:12.285  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 321 (count at ALS.scala:279) finished in 0.539 s
2018-05-01 17:49:12.286  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 25 finished: count at ALS.scala:279, took 0.612536 s
2018-05-01 17:49:12.289  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:280
2018-05-01 17:49:12.290  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 161 bytes
2018-05-01 17:49:12.290  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 161 bytes
2018-05-01 17:49:12.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 161 bytes
2018-05-01 17:49:12.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 4 is 150 bytes
2018-05-01 17:49:12.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 150 bytes
2018-05-01 17:49:12.292  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 5 is 150 bytes
2018-05-01 17:49:12.292  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 6 is 150 bytes
2018-05-01 17:49:12.292  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 7 is 150 bytes
2018-05-01 17:49:12.292  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 8 is 150 bytes
2018-05-01 17:49:12.293  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 9 is 150 bytes
2018-05-01 17:49:12.293  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 10 is 150 bytes
2018-05-01 17:49:12.293  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 11 is 150 bytes
2018-05-01 17:49:12.293  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 12 is 150 bytes
2018-05-01 17:49:12.294  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 13 is 150 bytes
2018-05-01 17:49:12.294  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 14 is 150 bytes
2018-05-01 17:49:12.295  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 15 is 150 bytes
2018-05-01 17:49:12.295  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 16 is 150 bytes
2018-05-01 17:49:12.295  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 17 is 150 bytes
2018-05-01 17:49:12.295  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 18 is 150 bytes
2018-05-01 17:49:12.297  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 19 is 150 bytes
2018-05-01 17:49:12.298  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 20 is 150 bytes
2018-05-01 17:49:12.298  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 21 is 150 bytes
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 22 is 150 bytes
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 26 (count at ALS.scala:280) with 1 output partitions
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 345 (count at ALS.scala:280)
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 344, ShuffleMapStage 323)
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:12.299  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 345 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:49:12.303  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_51 stored as values in memory (estimated size 40.1 KB, free 1923.3 MB)
2018-05-01 17:49:12.304  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_51_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1923.3 MB)
2018-05-01 17:49:12.305  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_51_piece0 in memory on 172.21.241.193:58620 (size: 18.1 KB, free: 1924.3 MB)
2018-05-01 17:49:12.305  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:12.305  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 345 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:12.305  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 345.0 with 1 tasks
2018-05-01 17:49:12.306  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 345.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:12.306  INFO 16044 --- [Executor task launch worker for task 118] org.apache.spark.executor.Executor       : Running task 0.0 in stage 345.0 (TID 118)
2018-05-01 17:49:12.310  INFO 16044 --- [Executor task launch worker for task 118] org.apache.spark.storage.BlockManager    : Found block rdd_17_0 locally
2018-05-01 17:49:12.310  INFO 16044 --- [Executor task launch worker for task 118] org.apache.spark.storage.BlockManager    : Found block rdd_210_0 locally
2018-05-01 17:49:12.606  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_34_piece0 on 172.21.241.193:58620 in memory (size: 13.3 KB, free: 1924.4 MB)
2018-05-01 17:49:12.633  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_40_piece0 on 172.21.241.193:58620 in memory (size: 15.5 KB, free: 1924.4 MB)
2018-05-01 17:49:12.635  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_42_piece0 on 172.21.241.193:58620 in memory (size: 16.4 KB, free: 1924.4 MB)
2018-05-01 17:49:12.651  INFO 16044 --- [Executor task launch worker for task 118] o.a.spark.storage.memory.MemoryStore     : Block rdd_232_0 stored as values in memory (estimated size 1914.2 KB, free 1921.6 MB)
2018-05-01 17:49:12.670  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_232_0 in memory on 172.21.241.193:58620 (size: 1914.2 KB, free: 1922.5 MB)
2018-05-01 17:49:12.684  INFO 16044 --- [Executor task launch worker for task 118] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 345.0 (TID 118). 1701 bytes result sent to driver
2018-05-01 17:49:12.684  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_24_piece0 on 172.21.241.193:58620 in memory (size: 9.9 KB, free: 1922.5 MB)
2018-05-01 17:49:12.684  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 345.0 (TID 118) in 378 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:12.685  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 345.0, whose tasks have all completed, from pool 
2018-05-01 17:49:12.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 345 (count at ALS.scala:280) finished in 0.379 s
2018-05-01 17:49:12.686  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_35_piece0 on 172.21.241.193:58620 in memory (size: 13.0 KB, free: 1922.5 MB)
2018-05-01 17:49:12.686  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 26 finished: count at ALS.scala:280, took 0.395846 s
2018-05-01 17:49:12.716  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_39_piece0 on 172.21.241.193:58620 in memory (size: 14.4 KB, free: 1922.6 MB)
2018-05-01 17:49:12.732  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_27_piece0 on 172.21.241.193:58620 in memory (size: 10.4 KB, free: 1922.6 MB)
2018-05-01 17:49:12.738  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:49:12.799  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_16_piece0 on 172.21.241.193:58620 in memory (size: 7.3 KB, free: 1922.6 MB)
2018-05-01 17:49:12.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 23 is 150 bytes
2018-05-01 17:49:12.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 27 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:49:12.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 370 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:49:12.805  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 369, ShuffleMapStage 347)
2018-05-01 17:49:12.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:12.806  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 370 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:49:12.816  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_29_piece0 on 172.21.241.193:58620 in memory (size: 11.0 KB, free: 1922.6 MB)
2018-05-01 17:49:12.830  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_52 stored as values in memory (estimated size 41.8 KB, free 1921.8 MB)
2018-05-01 17:49:12.831  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_52_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1921.8 MB)
2018-05-01 17:49:12.832  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_52_piece0 in memory on 172.21.241.193:58620 (size: 18.8 KB, free: 1922.6 MB)
2018-05-01 17:49:12.832  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_20_piece0 on 172.21.241.193:58620 in memory (size: 8.6 KB, free: 1922.6 MB)
2018-05-01 17:49:12.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:12.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 370 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:12.833  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 370.0 with 1 tasks
2018-05-01 17:49:12.834  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 370.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:12.834  INFO 16044 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : Running task 0.0 in stage 370.0 (TID 119)
2018-05-01 17:49:12.839  INFO 16044 --- [Executor task launch worker for task 119] org.apache.spark.storage.BlockManager    : Found block rdd_231_0 locally
2018-05-01 17:49:12.840  INFO 16044 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 119:
[rdd_231_0]
2018-05-01 17:49:12.841  INFO 16044 --- [Executor task launch worker for task 119] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 370.0 (TID 119). 995 bytes result sent to driver
2018-05-01 17:49:12.841  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 370.0 (TID 119) in 7 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:12.841  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 370.0, whose tasks have all completed, from pool 
2018-05-01 17:49:12.841  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 370 (first at MatrixFactorizationModel.scala:67) finished in 0.008 s
2018-05-01 17:49:12.841  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_41_piece0 on 172.21.241.193:58620 in memory (size: 15.2 KB, free: 1922.6 MB)
2018-05-01 17:49:12.842  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 27 finished: first at MatrixFactorizationModel.scala:67, took 0.104570 s
2018-05-01 17:49:12.863  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_37_piece0 on 172.21.241.193:58620 in memory (size: 13.6 KB, free: 1922.6 MB)
2018-05-01 17:49:12.872  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_44_piece0 on 172.21.241.193:58620 in memory (size: 16.8 KB, free: 1922.6 MB)
2018-05-01 17:49:12.874  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_26_piece0 on 172.21.241.193:58620 in memory (size: 10.6 KB, free: 1922.6 MB)
2018-05-01 17:49:12.875  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_47_piece0 on 172.21.241.193:58620 in memory (size: 17.3 KB, free: 1922.6 MB)
2018-05-01 17:49:12.883  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:49:12.888  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_36_piece0 on 172.21.241.193:58620 in memory (size: 13.9 KB, free: 1922.7 MB)
2018-05-01 17:49:12.889  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_28_piece0 on 172.21.241.193:58620 in memory (size: 11.2 KB, free: 1922.7 MB)
2018-05-01 17:49:12.891  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 28 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:49:12.897  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 394 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:49:12.897  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 393, ShuffleMapStage 372)
2018-05-01 17:49:12.897  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:12.898  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 394 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:49:12.939  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_53 stored as values in memory (estimated size 40.2 KB, free 1922.1 MB)
2018-05-01 17:49:12.949  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_53_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1922.0 MB)
2018-05-01 17:49:12.950  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_49_piece0 on 172.21.241.193:58620 in memory (size: 18.0 KB, free: 1922.7 MB)
2018-05-01 17:49:12.951  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_53_piece0 in memory on 172.21.241.193:58620 (size: 18.2 KB, free: 1922.7 MB)
2018-05-01 17:49:12.952  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:12.952  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 394 (products MapPartitionsRDD[232] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:12.952  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 394.0 with 1 tasks
2018-05-01 17:49:12.975  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 394.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:12.977  INFO 16044 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : Running task 0.0 in stage 394.0 (TID 120)
2018-05-01 17:49:12.983  INFO 16044 --- [Executor task launch worker for task 120] org.apache.spark.storage.BlockManager    : Found block rdd_232_0 locally
2018-05-01 17:49:12.983  INFO 16044 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 120:
[rdd_232_0]
2018-05-01 17:49:12.984  INFO 16044 --- [Executor task launch worker for task 120] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 394.0 (TID 120). 995 bytes result sent to driver
2018-05-01 17:49:12.985  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 394.0 (TID 120) in 10 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:12.985  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 394.0, whose tasks have all completed, from pool 
2018-05-01 17:49:12.985  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_43_piece0 on 172.21.241.193:58620 in memory (size: 16.0 KB, free: 1922.7 MB)
2018-05-01 17:49:12.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 394 (first at MatrixFactorizationModel.scala:67) finished in 0.034 s
2018-05-01 17:49:12.988  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 28 finished: first at MatrixFactorizationModel.scala:67, took 0.102663 s
2018-05-01 17:49:12.988  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_38_piece0 on 172.21.241.193:58620 in memory (size: 14.7 KB, free: 1922.7 MB)
2018-05-01 17:49:12.990  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_45_piece0 on 172.21.241.193:58620 in memory (size: 16.5 KB, free: 1922.7 MB)
2018-05-01 17:49:12.991  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_33_piece0 on 172.21.241.193:58620 in memory (size: 12.4 KB, free: 1922.7 MB)
2018-05-01 17:49:12.992  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_22_piece0 on 172.21.241.193:58620 in memory (size: 9.3 KB, free: 1922.7 MB)
2018-05-01 17:49:12.993  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_30_piece0 on 172.21.241.193:58620 in memory (size: 11.9 KB, free: 1922.8 MB)
2018-05-01 17:49:12.994  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_19_piece0 on 172.21.241.193:58620 in memory (size: 7.8 KB, free: 1922.8 MB)
2018-05-01 17:49:12.997  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_32_piece0 on 172.21.241.193:58620 in memory (size: 12.5 KB, free: 1922.8 MB)
2018-05-01 17:49:12.998  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_31_piece0 on 172.21.241.193:58620 in memory (size: 11.7 KB, free: 1922.8 MB)
2018-05-01 17:49:13.000  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_50_piece0 on 172.21.241.193:58620 in memory (size: 18.7 KB, free: 1922.8 MB)
2018-05-01 17:49:13.003  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: lookup at MatrixFactorizationModel.scala:168
2018-05-01 17:49:13.004  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_21_piece0 on 172.21.241.193:58620 in memory (size: 8.4 KB, free: 1922.8 MB)
2018-05-01 17:49:13.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 29 (lookup at MatrixFactorizationModel.scala:168) with 1 output partitions
2018-05-01 17:49:13.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 419 (lookup at MatrixFactorizationModel.scala:168)
2018-05-01 17:49:13.045  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 396, ShuffleMapStage 418)
2018-05-01 17:49:13.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:13.047  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 419 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:49:13.050  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_54 stored as values in memory (estimated size 41.9 KB, free 1922.5 MB)
2018-05-01 17:49:13.051  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_54_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1922.5 MB)
2018-05-01 17:49:13.052  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_54_piece0 in memory on 172.21.241.193:58620 (size: 18.8 KB, free: 1922.8 MB)
2018-05-01 17:49:13.053  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_23_piece0 on 172.21.241.193:58620 in memory (size: 9.1 KB, free: 1922.8 MB)
2018-05-01 17:49:13.056  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:13.056  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 419 (users MapPartitionsRDD[231] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:13.057  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 419.0 with 1 tasks
2018-05-01 17:49:13.058  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 419.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:13.058  INFO 16044 --- [Executor task launch worker for task 121] org.apache.spark.executor.Executor       : Running task 0.0 in stage 419.0 (TID 121)
2018-05-01 17:49:13.062  INFO 16044 --- [Executor task launch worker for task 121] org.apache.spark.storage.BlockManager    : Found block rdd_231_0 locally
2018-05-01 17:49:13.063  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_17_piece0 on 172.21.241.193:58620 in memory (size: 7.1 KB, free: 1922.8 MB)
2018-05-01 17:49:13.067  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_48_piece0 on 172.21.241.193:58620 in memory (size: 18.2 KB, free: 1922.8 MB)
2018-05-01 17:49:13.068  INFO 16044 --- [Executor task launch worker for task 121] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 419.0 (TID 121). 942 bytes result sent to driver
2018-05-01 17:49:13.073  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 419.0 (TID 121) in 15 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:13.073  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 419.0, whose tasks have all completed, from pool 
2018-05-01 17:49:13.074  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 419 (lookup at MatrixFactorizationModel.scala:168) finished in 0.017 s
2018-05-01 17:49:13.075  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_15_piece0 on 172.21.241.193:58620 in memory (size: 6.4 KB, free: 1922.8 MB)
2018-05-01 17:49:13.075  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 29 finished: lookup at MatrixFactorizationModel.scala:168, took 0.071229 s
2018-05-01 17:49:13.084  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_46_piece0 on 172.21.241.193:58620 in memory (size: 17.6 KB, free: 1922.8 MB)
2018-05-01 17:49:13.087  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_18_piece0 on 172.21.241.193:58620 in memory (size: 8.0 KB, free: 1922.9 MB)
2018-05-01 17:49:13.097  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_25_piece0 on 172.21.241.193:58620 in memory (size: 9.7 KB, free: 1922.9 MB)
2018-05-01 17:49:13.105  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.SparkContext            : Starting job: top at MatrixFactorizationModel.scala:259
2018-05-01 17:49:13.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 30 (top at MatrixFactorizationModel.scala:259) with 1 output partitions
2018-05-01 17:49:13.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 443 (top at MatrixFactorizationModel.scala:259)
2018-05-01 17:49:13.120  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 442, ShuffleMapStage 421)
2018-05-01 17:49:13.121  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:13.121  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 443 (MapPartitionsRDD[234] at top at MatrixFactorizationModel.scala:259), which has no missing parents
2018-05-01 17:49:13.133  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_55 stored as values in memory (estimated size 41.2 KB, free 1922.7 MB)
2018-05-01 17:49:13.135  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_55_piece0 stored as bytes in memory (estimated size 18.6 KB, free 1922.6 MB)
2018-05-01 17:49:13.135  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_55_piece0 in memory on 172.21.241.193:58620 (size: 18.6 KB, free: 1922.8 MB)
2018-05-01 17:49:13.136  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:13.137  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 443 (MapPartitionsRDD[234] at top at MatrixFactorizationModel.scala:259) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:49:13.137  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 443.0 with 1 tasks
2018-05-01 17:49:13.137  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 443.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:49:13.138  INFO 16044 --- [Executor task launch worker for task 122] org.apache.spark.executor.Executor       : Running task 0.0 in stage 443.0 (TID 122)
2018-05-01 17:49:13.142  INFO 16044 --- [Executor task launch worker for task 122] org.apache.spark.storage.BlockManager    : Found block rdd_232_0 locally
2018-05-01 17:49:13.179  INFO 16044 --- [Executor task launch worker for task 122] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 443.0 (TID 122). 1652 bytes result sent to driver
2018-05-01 17:49:13.180  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 443.0 (TID 122) in 43 ms on localhost (executor driver) (1/1)
2018-05-01 17:49:13.180  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 443.0, whose tasks have all completed, from pool 
2018-05-01 17:49:13.181  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 443 (top at MatrixFactorizationModel.scala:259) finished in 0.044 s
2018-05-01 17:49:13.182  INFO 16044 --- [http-nio-3333-exec-3] org.apache.spark.scheduler.DAGScheduler  : Job 30 finished: top at MatrixFactorizationModel.scala:259, took 0.076463 s
2018-05-01 17:49:13.185  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Recommendations for1
2018-05-01 17:49:13.186  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1214-- Rating : 1.021264172885406
2018-05-01 17:49:13.248  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1200-- Rating : 0.9745515887700025
2018-05-01 17:49:13.253  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 541-- Rating : 0.9676810147435526
2018-05-01 17:49:13.257  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1196-- Rating : 0.9453526818611724
2018-05-01 17:49:13.261  INFO 16044 --- [http-nio-3333-exec-3] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 924-- Rating : 0.9439457908550074
2018-05-01 17:49:31.329  WARN 16044 --- [http-nio-3333-exec-4] o.apache.spark.sql.SparkSession$Builder  : Using an existing SparkSession; some configuration may not take effect.
2018-05-01 17:49:31.330  INFO 16044 --- [http-nio-3333-exec-4] o.a.spark.storage.memory.MemoryStore     : Block broadcast_56 stored as values in memory (estimated size 248.0 B, free 1922.6 MB)
2018-05-01 17:49:31.331  INFO 16044 --- [http-nio-3333-exec-4] o.a.spark.storage.memory.MemoryStore     : Block broadcast_56_piece0 stored as bytes in memory (estimated size 419.0 B, free 1922.6 MB)
2018-05-01 17:49:31.331  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_56_piece0 in memory on 172.21.241.193:58620 (size: 419.0 B, free: 1922.8 MB)
2018-05-01 17:49:31.332  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Created broadcast 56 from broadcast at MongoSpark.scala:536
2018-05-01 17:49:31.333  INFO 16044 --- [http-nio-3333-exec-4] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms', maxWaitQueueSize=500}
2018-05-01 17:49:31.335  INFO 16044 --- [http-nio-3333-exec-4] org.mongodb.driver.cluster               : Cluster description not yet available. Waiting for 30000 ms before timing out
2018-05-01 17:49:31.338  INFO 16044 --- [cluster-ClusterId{value='5ae87e7bb11f8e3eac338e34', description='null'}-127.0.0.1:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:5, serverValue:32}] to 127.0.0.1:27017
2018-05-01 17:49:31.339  INFO 16044 --- [cluster-ClusterId{value='5ae87e7bb11f8e3eac338e34', description='null'}-127.0.0.1:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:27017, type=STANDALONE, state=CONNECTED, ok=true, version=ServerVersion{versionList=[3, 6, 0]}, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, roundTripTimeNanos=305382}
2018-05-01 17:49:31.340  INFO 16044 --- [http-nio-3333-exec-4] c.m.spark.connection.MongoClientCache    : Creating MongoClient: [127.0.0.1:27017]
2018-05-01 17:49:31.343  INFO 16044 --- [http-nio-3333-exec-4] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:6, serverValue:33}] to 127.0.0.1:27017
2018-05-01 17:49:32.424  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: collect at RecomendationServiceImpl.java:86
2018-05-01 17:49:32.424  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 31 (collect at RecomendationServiceImpl.java:86) with 66 output partitions
2018-05-01 17:49:32.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 444 (collect at RecomendationServiceImpl.java:86)
2018-05-01 17:49:32.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:49:32.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:49:32.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 444 (MapPartitionsRDD[236] at map at RecomendationServiceImpl.java:83), which has no missing parents
2018-05-01 17:49:32.427  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_57 stored as values in memory (estimated size 7.0 KB, free 1922.6 MB)
2018-05-01 17:49:32.428  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_57_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1922.6 MB)
2018-05-01 17:49:32.428  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_57_piece0 in memory on 172.21.241.193:58620 (size: 3.6 KB, free: 1922.8 MB)
2018-05-01 17:49:32.429  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:49:32.429  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 66 missing tasks from ResultStage 444 (MapPartitionsRDD[236] at map at RecomendationServiceImpl.java:83) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-05-01 17:49:32.429  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 444.0 with 66 tasks
2018-05-01 17:49:32.430  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 444.0 (TID 123, localhost, executor driver, partition 0, ANY, 4987 bytes)
2018-05-01 17:49:32.430  INFO 16044 --- [Executor task launch worker for task 123] org.apache.spark.executor.Executor       : Running task 0.0 in stage 444.0 (TID 123)
2018-05-01 17:49:32.433  INFO 16044 --- [Executor task launch worker for task 123] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 444.0 (TID 123). 622 bytes result sent to driver
2018-05-01 17:49:32.434  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 444.0 (TID 124, localhost, executor driver, partition 1, ANY, 4999 bytes)
2018-05-01 17:49:32.434  INFO 16044 --- [Executor task launch worker for task 124] org.apache.spark.executor.Executor       : Running task 1.0 in stage 444.0 (TID 124)
2018-05-01 17:49:32.434  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 444.0 (TID 123) in 4 ms on localhost (executor driver) (1/66)
2018-05-01 17:49:33.053  INFO 16044 --- [Executor task launch worker for task 124] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 444.0 (TID 124). 429841 bytes result sent to driver
2018-05-01 17:49:33.054  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 444.0 (TID 125, localhost, executor driver, partition 2, ANY, 5005 bytes)
2018-05-01 17:49:33.054  INFO 16044 --- [Executor task launch worker for task 125] org.apache.spark.executor.Executor       : Running task 2.0 in stage 444.0 (TID 125)
2018-05-01 17:49:33.082  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 444.0 (TID 124) in 648 ms on localhost (executor driver) (2/66)
2018-05-01 17:49:33.511  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 232
2018-05-01 17:49:33.512  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 232
2018-05-01 17:49:33.514  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 13
2018-05-01 17:49:33.515  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 140
2018-05-01 17:49:33.515  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 140
2018-05-01 17:49:33.516  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 14
2018-05-01 17:49:33.516  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 190
2018-05-01 17:49:33.516  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 190
2018-05-01 17:49:33.518  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 110
2018-05-01 17:49:33.518  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 110
2018-05-01 17:49:33.519  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 15
2018-05-01 17:49:33.519  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_53_piece0 on 172.21.241.193:58620 in memory (size: 18.2 KB, free: 1924.7 MB)
2018-05-01 17:49:33.520  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 225
2018-05-01 17:49:33.520  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 225
2018-05-01 17:49:33.520  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 180
2018-05-01 17:49:33.520  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 180
2018-05-01 17:49:33.520  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 150
2018-05-01 17:49:33.520  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 150
2018-05-01 17:49:33.521  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_51_piece0 on 172.21.241.193:58620 in memory (size: 18.1 KB, free: 1924.7 MB)
2018-05-01 17:49:33.521  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 120
2018-05-01 17:49:33.522  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 120
2018-05-01 17:49:33.522  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 20
2018-05-01 17:49:33.522  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 22
2018-05-01 17:49:33.522  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 130
2018-05-01 17:49:33.523  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 130
2018-05-01 17:49:33.523  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 200
2018-05-01 17:49:33.523  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 200
2018-05-01 17:49:33.524  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_55_piece0 on 172.21.241.193:58620 in memory (size: 18.6 KB, free: 1924.8 MB)
2018-05-01 17:49:33.525  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_54_piece0 on 172.21.241.193:58620 in memory (size: 18.8 KB, free: 1924.8 MB)
2018-05-01 17:49:33.525  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 23
2018-05-01 17:49:33.525  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 170
2018-05-01 17:49:33.526  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 170
2018-05-01 17:49:33.526  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 17
2018-05-01 17:49:33.527  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_52_piece0 on 172.21.241.193:58620 in memory (size: 18.8 KB, free: 1924.8 MB)
2018-05-01 17:49:33.527  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 19
2018-05-01 17:49:33.527  INFO 16044 --- [block-manager-slave-async-thread-pool-1] org.apache.spark.storage.BlockManager    : Removing RDD 210
2018-05-01 17:49:33.528  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 210
2018-05-01 17:49:33.528  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 231
2018-05-01 17:49:33.528  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 231
2018-05-01 17:49:33.528  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 16
2018-05-01 17:49:33.530  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 21
2018-05-01 17:49:33.530  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 18
2018-05-01 17:49:33.530  INFO 16044 --- [block-manager-slave-async-thread-pool-6] org.apache.spark.storage.BlockManager    : Removing RDD 230
2018-05-01 17:49:33.530  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 230
2018-05-01 17:49:33.530  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 160
2018-05-01 17:49:33.530  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 160
2018-05-01 17:49:33.690  INFO 16044 --- [Executor task launch worker for task 125] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 444.0 (TID 125). 432623 bytes result sent to driver
2018-05-01 17:49:33.690  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 444.0 (TID 126, localhost, executor driver, partition 3, ANY, 5004 bytes)
2018-05-01 17:49:33.690  INFO 16044 --- [Executor task launch worker for task 126] org.apache.spark.executor.Executor       : Running task 3.0 in stage 444.0 (TID 126)
2018-05-01 17:49:33.718  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 444.0 (TID 125) in 665 ms on localhost (executor driver) (3/66)
2018-05-01 17:49:34.395  INFO 16044 --- [Executor task launch worker for task 126] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 444.0 (TID 126). 433897 bytes result sent to driver
2018-05-01 17:49:34.395  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 4.0 in stage 444.0 (TID 127, localhost, executor driver, partition 4, ANY, 5003 bytes)
2018-05-01 17:49:34.395  INFO 16044 --- [Executor task launch worker for task 127] org.apache.spark.executor.Executor       : Running task 4.0 in stage 444.0 (TID 127)
2018-05-01 17:49:34.410  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 444.0 (TID 126) in 720 ms on localhost (executor driver) (4/66)
2018-05-01 17:49:35.018  INFO 16044 --- [Executor task launch worker for task 127] org.apache.spark.executor.Executor       : Finished task 4.0 in stage 444.0 (TID 127). 424000 bytes result sent to driver
2018-05-01 17:49:35.018  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 5.0 in stage 444.0 (TID 128, localhost, executor driver, partition 5, ANY, 5003 bytes)
2018-05-01 17:49:35.019  INFO 16044 --- [Executor task launch worker for task 128] org.apache.spark.executor.Executor       : Running task 5.0 in stage 444.0 (TID 128)
2018-05-01 17:49:35.034  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 4.0 in stage 444.0 (TID 127) in 639 ms on localhost (executor driver) (5/66)
2018-05-01 17:49:35.574  INFO 16044 --- [Executor task launch worker for task 128] org.apache.spark.executor.Executor       : Finished task 5.0 in stage 444.0 (TID 128). 418098 bytes result sent to driver
2018-05-01 17:49:35.574  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 6.0 in stage 444.0 (TID 129, localhost, executor driver, partition 6, ANY, 5003 bytes)
2018-05-01 17:49:35.575  INFO 16044 --- [Executor task launch worker for task 129] org.apache.spark.executor.Executor       : Running task 6.0 in stage 444.0 (TID 129)
2018-05-01 17:49:35.591  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 5.0 in stage 444.0 (TID 128) in 573 ms on localhost (executor driver) (6/66)
2018-05-01 17:49:36.163  INFO 16044 --- [Executor task launch worker for task 129] org.apache.spark.executor.Executor       : Finished task 6.0 in stage 444.0 (TID 129). 416945 bytes result sent to driver
2018-05-01 17:49:36.164  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 7.0 in stage 444.0 (TID 130, localhost, executor driver, partition 7, ANY, 5003 bytes)
2018-05-01 17:49:36.165  INFO 16044 --- [Executor task launch worker for task 130] org.apache.spark.executor.Executor       : Running task 7.0 in stage 444.0 (TID 130)
2018-05-01 17:49:36.181  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 6.0 in stage 444.0 (TID 129) in 607 ms on localhost (executor driver) (7/66)
2018-05-01 17:49:36.710  INFO 16044 --- [Executor task launch worker for task 130] org.apache.spark.executor.Executor       : Finished task 7.0 in stage 444.0 (TID 130). 426885 bytes result sent to driver
2018-05-01 17:49:36.710  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 8.0 in stage 444.0 (TID 131, localhost, executor driver, partition 8, ANY, 5003 bytes)
2018-05-01 17:49:36.710  INFO 16044 --- [Executor task launch worker for task 131] org.apache.spark.executor.Executor       : Running task 8.0 in stage 444.0 (TID 131)
2018-05-01 17:49:36.725  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 7.0 in stage 444.0 (TID 130) in 561 ms on localhost (executor driver) (8/66)
2018-05-01 17:49:37.240  INFO 16044 --- [Executor task launch worker for task 131] org.apache.spark.executor.Executor       : Finished task 8.0 in stage 444.0 (TID 131). 430736 bytes result sent to driver
2018-05-01 17:49:37.241  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 9.0 in stage 444.0 (TID 132, localhost, executor driver, partition 9, ANY, 5003 bytes)
2018-05-01 17:49:37.242  INFO 16044 --- [Executor task launch worker for task 132] org.apache.spark.executor.Executor       : Running task 9.0 in stage 444.0 (TID 132)
2018-05-01 17:49:37.257  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 8.0 in stage 444.0 (TID 131) in 547 ms on localhost (executor driver) (9/66)
2018-05-01 17:49:37.846  INFO 16044 --- [Executor task launch worker for task 132] org.apache.spark.executor.Executor       : Finished task 9.0 in stage 444.0 (TID 132). 432112 bytes result sent to driver
2018-05-01 17:49:37.846  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 10.0 in stage 444.0 (TID 133, localhost, executor driver, partition 10, ANY, 5003 bytes)
2018-05-01 17:49:37.847  INFO 16044 --- [Executor task launch worker for task 133] org.apache.spark.executor.Executor       : Running task 10.0 in stage 444.0 (TID 133)
2018-05-01 17:49:37.862  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 9.0 in stage 444.0 (TID 132) in 621 ms on localhost (executor driver) (10/66)
2018-05-01 17:49:38.373  INFO 16044 --- [Executor task launch worker for task 133] org.apache.spark.executor.Executor       : Finished task 10.0 in stage 444.0 (TID 133). 428533 bytes result sent to driver
2018-05-01 17:49:38.373  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 11.0 in stage 444.0 (TID 134, localhost, executor driver, partition 11, ANY, 5003 bytes)
2018-05-01 17:49:38.374  INFO 16044 --- [Executor task launch worker for task 134] org.apache.spark.executor.Executor       : Running task 11.0 in stage 444.0 (TID 134)
2018-05-01 17:49:38.392  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 10.0 in stage 444.0 (TID 133) in 546 ms on localhost (executor driver) (11/66)
2018-05-01 17:49:38.978  INFO 16044 --- [Executor task launch worker for task 134] org.apache.spark.executor.Executor       : Finished task 11.0 in stage 444.0 (TID 134). 432959 bytes result sent to driver
2018-05-01 17:49:38.979  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 12.0 in stage 444.0 (TID 135, localhost, executor driver, partition 12, ANY, 5003 bytes)
2018-05-01 17:49:38.980  INFO 16044 --- [Executor task launch worker for task 135] org.apache.spark.executor.Executor       : Running task 12.0 in stage 444.0 (TID 135)
2018-05-01 17:49:38.995  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 11.0 in stage 444.0 (TID 134) in 622 ms on localhost (executor driver) (12/66)
2018-05-01 17:49:39.551  INFO 16044 --- [Executor task launch worker for task 135] org.apache.spark.executor.Executor       : Finished task 12.0 in stage 444.0 (TID 135). 431932 bytes result sent to driver
2018-05-01 17:49:39.552  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 13.0 in stage 444.0 (TID 136, localhost, executor driver, partition 13, ANY, 5003 bytes)
2018-05-01 17:49:39.553  INFO 16044 --- [Executor task launch worker for task 136] org.apache.spark.executor.Executor       : Running task 13.0 in stage 444.0 (TID 136)
2018-05-01 17:49:39.568  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 12.0 in stage 444.0 (TID 135) in 589 ms on localhost (executor driver) (13/66)
2018-05-01 17:49:40.159  INFO 16044 --- [Executor task launch worker for task 136] org.apache.spark.executor.Executor       : Finished task 13.0 in stage 444.0 (TID 136). 430475 bytes result sent to driver
2018-05-01 17:49:40.160  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 14.0 in stage 444.0 (TID 137, localhost, executor driver, partition 14, ANY, 5003 bytes)
2018-05-01 17:49:40.161  INFO 16044 --- [Executor task launch worker for task 137] org.apache.spark.executor.Executor       : Running task 14.0 in stage 444.0 (TID 137)
2018-05-01 17:49:40.176  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 13.0 in stage 444.0 (TID 136) in 624 ms on localhost (executor driver) (14/66)
2018-05-01 17:49:40.709  INFO 16044 --- [Executor task launch worker for task 137] org.apache.spark.executor.Executor       : Finished task 14.0 in stage 444.0 (TID 137). 433458 bytes result sent to driver
2018-05-01 17:49:40.710  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 15.0 in stage 444.0 (TID 138, localhost, executor driver, partition 15, ANY, 5003 bytes)
2018-05-01 17:49:40.711  INFO 16044 --- [Executor task launch worker for task 138] org.apache.spark.executor.Executor       : Running task 15.0 in stage 444.0 (TID 138)
2018-05-01 17:49:40.729  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 14.0 in stage 444.0 (TID 137) in 569 ms on localhost (executor driver) (15/66)
2018-05-01 17:49:41.242  INFO 16044 --- [Executor task launch worker for task 138] org.apache.spark.executor.Executor       : Finished task 15.0 in stage 444.0 (TID 138). 433596 bytes result sent to driver
2018-05-01 17:49:41.242  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 16.0 in stage 444.0 (TID 139, localhost, executor driver, partition 16, ANY, 5003 bytes)
2018-05-01 17:49:41.243  INFO 16044 --- [Executor task launch worker for task 139] org.apache.spark.executor.Executor       : Running task 16.0 in stage 444.0 (TID 139)
2018-05-01 17:49:41.258  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 15.0 in stage 444.0 (TID 138) in 548 ms on localhost (executor driver) (16/66)
2018-05-01 17:49:41.854  INFO 16044 --- [Executor task launch worker for task 139] org.apache.spark.executor.Executor       : Finished task 16.0 in stage 444.0 (TID 139). 429627 bytes result sent to driver
2018-05-01 17:49:41.855  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 17.0 in stage 444.0 (TID 140, localhost, executor driver, partition 17, ANY, 5002 bytes)
2018-05-01 17:49:41.856  INFO 16044 --- [Executor task launch worker for task 140] org.apache.spark.executor.Executor       : Running task 17.0 in stage 444.0 (TID 140)
2018-05-01 17:49:41.870  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 16.0 in stage 444.0 (TID 139) in 628 ms on localhost (executor driver) (17/66)
2018-05-01 17:49:42.380  INFO 16044 --- [Executor task launch worker for task 140] org.apache.spark.executor.Executor       : Finished task 17.0 in stage 444.0 (TID 140). 434178 bytes result sent to driver
2018-05-01 17:49:42.381  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 18.0 in stage 444.0 (TID 141, localhost, executor driver, partition 18, ANY, 5002 bytes)
2018-05-01 17:49:42.382  INFO 16044 --- [Executor task launch worker for task 141] org.apache.spark.executor.Executor       : Running task 18.0 in stage 444.0 (TID 141)
2018-05-01 17:49:42.398  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 17.0 in stage 444.0 (TID 140) in 544 ms on localhost (executor driver) (18/66)
2018-05-01 17:49:43.006  INFO 16044 --- [Executor task launch worker for task 141] org.apache.spark.executor.Executor       : Finished task 18.0 in stage 444.0 (TID 141). 431426 bytes result sent to driver
2018-05-01 17:49:43.007  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 19.0 in stage 444.0 (TID 142, localhost, executor driver, partition 19, ANY, 5003 bytes)
2018-05-01 17:49:43.008  INFO 16044 --- [Executor task launch worker for task 142] org.apache.spark.executor.Executor       : Running task 19.0 in stage 444.0 (TID 142)
2018-05-01 17:49:43.023  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 18.0 in stage 444.0 (TID 141) in 642 ms on localhost (executor driver) (19/66)
2018-05-01 17:49:43.540  INFO 16044 --- [Executor task launch worker for task 142] org.apache.spark.executor.Executor       : Finished task 19.0 in stage 444.0 (TID 142). 435226 bytes result sent to driver
2018-05-01 17:49:43.541  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 20.0 in stage 444.0 (TID 143, localhost, executor driver, partition 20, ANY, 5003 bytes)
2018-05-01 17:49:43.542  INFO 16044 --- [Executor task launch worker for task 143] org.apache.spark.executor.Executor       : Running task 20.0 in stage 444.0 (TID 143)
2018-05-01 17:49:43.557  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 19.0 in stage 444.0 (TID 142) in 550 ms on localhost (executor driver) (20/66)
2018-05-01 17:49:44.073  INFO 16044 --- [Executor task launch worker for task 143] org.apache.spark.executor.Executor       : Finished task 20.0 in stage 444.0 (TID 143). 434347 bytes result sent to driver
2018-05-01 17:49:44.073  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 21.0 in stage 444.0 (TID 144, localhost, executor driver, partition 21, ANY, 5003 bytes)
2018-05-01 17:49:44.075  INFO 16044 --- [Executor task launch worker for task 144] org.apache.spark.executor.Executor       : Running task 21.0 in stage 444.0 (TID 144)
2018-05-01 17:49:44.089  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 20.0 in stage 444.0 (TID 143) in 548 ms on localhost (executor driver) (21/66)
2018-05-01 17:49:44.931  INFO 16044 --- [block-manager-slave-async-thread-pool-6] org.apache.spark.storage.BlockManager    : Removing RDD 80
2018-05-01 17:49:44.933  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 80
2018-05-01 17:49:44.934  INFO 16044 --- [block-manager-slave-async-thread-pool-0] org.apache.spark.storage.BlockManager    : Removing RDD 13
2018-05-01 17:49:44.934  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 13
2018-05-01 17:49:44.935  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 1
2018-05-01 17:49:44.935  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 70
2018-05-01 17:49:44.936  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 70
2018-05-01 17:49:44.936  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 5
2018-05-01 17:49:44.937  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 2
2018-05-01 17:49:44.937  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 90
2018-05-01 17:49:44.937  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 90
2018-05-01 17:49:44.937  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 6
2018-05-01 17:49:44.937  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 3
2018-05-01 17:49:44.937  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 18
2018-05-01 17:49:44.940  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 18
2018-05-01 17:49:44.940  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 8
2018-05-01 17:49:44.940  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 30
2018-05-01 17:49:44.941  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 30
2018-05-01 17:49:44.941  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 50
2018-05-01 17:49:44.941  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 50
2018-05-01 17:49:44.942  INFO 16044 --- [block-manager-slave-async-thread-pool-3] org.apache.spark.storage.BlockManager    : Removing RDD 40
2018-05-01 17:49:44.942  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 40
2018-05-01 17:49:44.942  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 4
2018-05-01 17:49:44.942  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 12
2018-05-01 17:49:44.942  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 0
2018-05-01 17:49:44.942  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 3
2018-05-01 17:49:44.943  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 3
2018-05-01 17:49:44.943  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 19
2018-05-01 17:49:44.943  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 19
2018-05-01 17:49:44.943  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 12
2018-05-01 17:49:44.945  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 12
2018-05-01 17:49:44.946  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 100
2018-05-01 17:49:44.946  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 100
2018-05-01 17:49:44.946  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 9
2018-05-01 17:49:44.946  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 9
2018-05-01 17:49:44.946  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 11
2018-05-01 17:49:44.947  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 7
2018-05-01 17:49:44.947  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 17
2018-05-01 17:49:44.947  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 17
2018-05-01 17:49:44.947  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_3_piece0 on 172.21.241.193:58620 in memory (size: 2.2 KB, free: 1990.8 MB)
2018-05-01 17:49:44.948  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 9
2018-05-01 17:49:44.948  INFO 16044 --- [block-manager-slave-async-thread-pool-8] org.apache.spark.storage.BlockManager    : Removing RDD 60
2018-05-01 17:49:44.948  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned RDD 60
2018-05-01 17:49:44.948  INFO 16044 --- [Spark Context Cleaner] org.apache.spark.ContextCleaner          : Cleaned shuffle 10
2018-05-01 17:49:45.141  INFO 16044 --- [Executor task launch worker for task 144] org.apache.spark.executor.Executor       : Finished task 21.0 in stage 444.0 (TID 144). 428428 bytes result sent to driver
2018-05-01 17:49:45.141  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 22.0 in stage 444.0 (TID 145, localhost, executor driver, partition 22, ANY, 5003 bytes)
2018-05-01 17:49:45.142  INFO 16044 --- [Executor task launch worker for task 145] org.apache.spark.executor.Executor       : Running task 22.0 in stage 444.0 (TID 145)
2018-05-01 17:49:45.165  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 21.0 in stage 444.0 (TID 144) in 1092 ms on localhost (executor driver) (22/66)
2018-05-01 17:49:45.690  INFO 16044 --- [Executor task launch worker for task 145] org.apache.spark.executor.Executor       : Finished task 22.0 in stage 444.0 (TID 145). 434997 bytes result sent to driver
2018-05-01 17:49:45.690  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 23.0 in stage 444.0 (TID 146, localhost, executor driver, partition 23, ANY, 5003 bytes)
2018-05-01 17:49:45.690  INFO 16044 --- [Executor task launch worker for task 146] org.apache.spark.executor.Executor       : Running task 23.0 in stage 444.0 (TID 146)
2018-05-01 17:49:45.705  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 22.0 in stage 444.0 (TID 145) in 564 ms on localhost (executor driver) (23/66)
2018-05-01 17:49:46.244  INFO 16044 --- [Executor task launch worker for task 146] org.apache.spark.executor.Executor       : Finished task 23.0 in stage 444.0 (TID 146). 430843 bytes result sent to driver
2018-05-01 17:49:46.245  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 24.0 in stage 444.0 (TID 147, localhost, executor driver, partition 24, ANY, 5003 bytes)
2018-05-01 17:49:46.246  INFO 16044 --- [Executor task launch worker for task 147] org.apache.spark.executor.Executor       : Running task 24.0 in stage 444.0 (TID 147)
2018-05-01 17:49:46.261  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 23.0 in stage 444.0 (TID 146) in 571 ms on localhost (executor driver) (24/66)
2018-05-01 17:49:46.792  INFO 16044 --- [Executor task launch worker for task 147] org.apache.spark.executor.Executor       : Finished task 24.0 in stage 444.0 (TID 147). 429256 bytes result sent to driver
2018-05-01 17:49:46.793  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 25.0 in stage 444.0 (TID 148, localhost, executor driver, partition 25, ANY, 5003 bytes)
2018-05-01 17:49:46.793  INFO 16044 --- [Executor task launch worker for task 148] org.apache.spark.executor.Executor       : Running task 25.0 in stage 444.0 (TID 148)
2018-05-01 17:49:46.809  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 24.0 in stage 444.0 (TID 147) in 564 ms on localhost (executor driver) (25/66)
2018-05-01 17:49:47.338  INFO 16044 --- [Executor task launch worker for task 148] org.apache.spark.executor.Executor       : Finished task 25.0 in stage 444.0 (TID 148). 432165 bytes result sent to driver
2018-05-01 17:49:47.339  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 26.0 in stage 444.0 (TID 149, localhost, executor driver, partition 26, ANY, 5003 bytes)
2018-05-01 17:49:47.341  INFO 16044 --- [Executor task launch worker for task 149] org.apache.spark.executor.Executor       : Running task 26.0 in stage 444.0 (TID 149)
2018-05-01 17:49:47.356  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 25.0 in stage 444.0 (TID 148) in 563 ms on localhost (executor driver) (26/66)
2018-05-01 17:49:47.877  INFO 16044 --- [Executor task launch worker for task 149] org.apache.spark.executor.Executor       : Finished task 26.0 in stage 444.0 (TID 149). 433237 bytes result sent to driver
2018-05-01 17:49:47.877  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 27.0 in stage 444.0 (TID 150, localhost, executor driver, partition 27, ANY, 5003 bytes)
2018-05-01 17:49:47.877  INFO 16044 --- [Executor task launch worker for task 150] org.apache.spark.executor.Executor       : Running task 27.0 in stage 444.0 (TID 150)
2018-05-01 17:49:47.892  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 26.0 in stage 444.0 (TID 149) in 553 ms on localhost (executor driver) (27/66)
2018-05-01 17:49:48.421  INFO 16044 --- [Executor task launch worker for task 150] org.apache.spark.executor.Executor       : Finished task 27.0 in stage 444.0 (TID 150). 433416 bytes result sent to driver
2018-05-01 17:49:48.422  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 28.0 in stage 444.0 (TID 151, localhost, executor driver, partition 28, ANY, 5003 bytes)
2018-05-01 17:49:48.424  INFO 16044 --- [Executor task launch worker for task 151] org.apache.spark.executor.Executor       : Running task 28.0 in stage 444.0 (TID 151)
2018-05-01 17:49:48.438  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 27.0 in stage 444.0 (TID 150) in 561 ms on localhost (executor driver) (28/66)
2018-05-01 17:49:48.949  INFO 16044 --- [Executor task launch worker for task 151] org.apache.spark.executor.Executor       : Finished task 28.0 in stage 444.0 (TID 151). 431277 bytes result sent to driver
2018-05-01 17:49:48.950  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 29.0 in stage 444.0 (TID 152, localhost, executor driver, partition 29, ANY, 5003 bytes)
2018-05-01 17:49:48.951  INFO 16044 --- [Executor task launch worker for task 152] org.apache.spark.executor.Executor       : Running task 29.0 in stage 444.0 (TID 152)
2018-05-01 17:49:48.966  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 28.0 in stage 444.0 (TID 151) in 544 ms on localhost (executor driver) (29/66)
2018-05-01 17:49:49.500  INFO 16044 --- [Executor task launch worker for task 152] org.apache.spark.executor.Executor       : Finished task 29.0 in stage 444.0 (TID 152). 432490 bytes result sent to driver
2018-05-01 17:49:49.501  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 30.0 in stage 444.0 (TID 153, localhost, executor driver, partition 30, ANY, 5003 bytes)
2018-05-01 17:49:49.502  INFO 16044 --- [Executor task launch worker for task 153] org.apache.spark.executor.Executor       : Running task 30.0 in stage 444.0 (TID 153)
2018-05-01 17:49:49.518  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 29.0 in stage 444.0 (TID 152) in 568 ms on localhost (executor driver) (30/66)
2018-05-01 17:49:50.032  INFO 16044 --- [Executor task launch worker for task 153] org.apache.spark.executor.Executor       : Finished task 30.0 in stage 444.0 (TID 153). 431358 bytes result sent to driver
2018-05-01 17:49:50.033  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 31.0 in stage 444.0 (TID 154, localhost, executor driver, partition 31, ANY, 5003 bytes)
2018-05-01 17:49:50.034  INFO 16044 --- [Executor task launch worker for task 154] org.apache.spark.executor.Executor       : Running task 31.0 in stage 444.0 (TID 154)
2018-05-01 17:49:50.051  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 30.0 in stage 444.0 (TID 153) in 550 ms on localhost (executor driver) (31/66)
2018-05-01 17:49:50.588  INFO 16044 --- [Executor task launch worker for task 154] org.apache.spark.executor.Executor       : Finished task 31.0 in stage 444.0 (TID 154). 434141 bytes result sent to driver
2018-05-01 17:49:50.589  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 32.0 in stage 444.0 (TID 155, localhost, executor driver, partition 32, ANY, 5002 bytes)
2018-05-01 17:49:50.590  INFO 16044 --- [Executor task launch worker for task 155] org.apache.spark.executor.Executor       : Running task 32.0 in stage 444.0 (TID 155)
2018-05-01 17:49:50.606  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 31.0 in stage 444.0 (TID 154) in 574 ms on localhost (executor driver) (32/66)
2018-05-01 17:49:51.127  INFO 16044 --- [Executor task launch worker for task 155] org.apache.spark.executor.Executor       : Finished task 32.0 in stage 444.0 (TID 155). 432053 bytes result sent to driver
2018-05-01 17:49:51.127  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 33.0 in stage 444.0 (TID 156, localhost, executor driver, partition 33, ANY, 5002 bytes)
2018-05-01 17:49:51.128  INFO 16044 --- [Executor task launch worker for task 156] org.apache.spark.executor.Executor       : Running task 33.0 in stage 444.0 (TID 156)
2018-05-01 17:49:51.144  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 32.0 in stage 444.0 (TID 155) in 556 ms on localhost (executor driver) (33/66)
2018-05-01 17:49:51.671  INFO 16044 --- [Executor task launch worker for task 156] org.apache.spark.executor.Executor       : Finished task 33.0 in stage 444.0 (TID 156). 433257 bytes result sent to driver
2018-05-01 17:49:51.672  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 34.0 in stage 444.0 (TID 157, localhost, executor driver, partition 34, ANY, 5002 bytes)
2018-05-01 17:49:51.673  INFO 16044 --- [Executor task launch worker for task 157] org.apache.spark.executor.Executor       : Running task 34.0 in stage 444.0 (TID 157)
2018-05-01 17:49:51.688  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 33.0 in stage 444.0 (TID 156) in 561 ms on localhost (executor driver) (34/66)
2018-05-01 17:49:52.233  INFO 16044 --- [Executor task launch worker for task 157] org.apache.spark.executor.Executor       : Finished task 34.0 in stage 444.0 (TID 157). 433019 bytes result sent to driver
2018-05-01 17:49:52.233  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 35.0 in stage 444.0 (TID 158, localhost, executor driver, partition 35, ANY, 5002 bytes)
2018-05-01 17:49:52.235  INFO 16044 --- [Executor task launch worker for task 158] org.apache.spark.executor.Executor       : Running task 35.0 in stage 444.0 (TID 158)
2018-05-01 17:49:52.252  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 34.0 in stage 444.0 (TID 157) in 580 ms on localhost (executor driver) (35/66)
2018-05-01 17:49:52.784  INFO 16044 --- [Executor task launch worker for task 158] org.apache.spark.executor.Executor       : Finished task 35.0 in stage 444.0 (TID 158). 431659 bytes result sent to driver
2018-05-01 17:49:52.785  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 36.0 in stage 444.0 (TID 159, localhost, executor driver, partition 36, ANY, 5002 bytes)
2018-05-01 17:49:52.786  INFO 16044 --- [Executor task launch worker for task 159] org.apache.spark.executor.Executor       : Running task 36.0 in stage 444.0 (TID 159)
2018-05-01 17:49:52.801  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 35.0 in stage 444.0 (TID 158) in 568 ms on localhost (executor driver) (36/66)
2018-05-01 17:49:53.342  INFO 16044 --- [Executor task launch worker for task 159] org.apache.spark.executor.Executor       : Finished task 36.0 in stage 444.0 (TID 159). 435588 bytes result sent to driver
2018-05-01 17:49:53.342  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 37.0 in stage 444.0 (TID 160, localhost, executor driver, partition 37, ANY, 5002 bytes)
2018-05-01 17:49:53.344  INFO 16044 --- [Executor task launch worker for task 160] org.apache.spark.executor.Executor       : Running task 37.0 in stage 444.0 (TID 160)
2018-05-01 17:49:53.361  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 36.0 in stage 444.0 (TID 159) in 576 ms on localhost (executor driver) (37/66)
2018-05-01 17:49:53.883  INFO 16044 --- [Executor task launch worker for task 160] org.apache.spark.executor.Executor       : Finished task 37.0 in stage 444.0 (TID 160). 432592 bytes result sent to driver
2018-05-01 17:49:53.884  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 38.0 in stage 444.0 (TID 161, localhost, executor driver, partition 38, ANY, 5003 bytes)
2018-05-01 17:49:53.885  INFO 16044 --- [Executor task launch worker for task 161] org.apache.spark.executor.Executor       : Running task 38.0 in stage 444.0 (TID 161)
2018-05-01 17:49:53.900  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 37.0 in stage 444.0 (TID 160) in 558 ms on localhost (executor driver) (38/66)
2018-05-01 17:49:54.437  INFO 16044 --- [Executor task launch worker for task 161] org.apache.spark.executor.Executor       : Finished task 38.0 in stage 444.0 (TID 161). 433688 bytes result sent to driver
2018-05-01 17:49:54.437  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 39.0 in stage 444.0 (TID 162, localhost, executor driver, partition 39, ANY, 5003 bytes)
2018-05-01 17:49:54.438  INFO 16044 --- [Executor task launch worker for task 162] org.apache.spark.executor.Executor       : Running task 39.0 in stage 444.0 (TID 162)
2018-05-01 17:49:54.453  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 38.0 in stage 444.0 (TID 161) in 569 ms on localhost (executor driver) (39/66)
2018-05-01 17:49:55.001  INFO 16044 --- [Executor task launch worker for task 162] org.apache.spark.executor.Executor       : Finished task 39.0 in stage 444.0 (TID 162). 430032 bytes result sent to driver
2018-05-01 17:49:55.001  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 40.0 in stage 444.0 (TID 163, localhost, executor driver, partition 40, ANY, 5003 bytes)
2018-05-01 17:49:55.002  INFO 16044 --- [Executor task launch worker for task 163] org.apache.spark.executor.Executor       : Running task 40.0 in stage 444.0 (TID 163)
2018-05-01 17:49:55.018  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 39.0 in stage 444.0 (TID 162) in 581 ms on localhost (executor driver) (40/66)
2018-05-01 17:49:55.538  INFO 16044 --- [Executor task launch worker for task 163] org.apache.spark.executor.Executor       : Finished task 40.0 in stage 444.0 (TID 163). 432889 bytes result sent to driver
2018-05-01 17:49:55.539  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 41.0 in stage 444.0 (TID 164, localhost, executor driver, partition 41, ANY, 5003 bytes)
2018-05-01 17:49:55.540  INFO 16044 --- [Executor task launch worker for task 164] org.apache.spark.executor.Executor       : Running task 41.0 in stage 444.0 (TID 164)
2018-05-01 17:49:55.555  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 40.0 in stage 444.0 (TID 163) in 554 ms on localhost (executor driver) (41/66)
2018-05-01 17:49:56.081  INFO 16044 --- [Executor task launch worker for task 164] org.apache.spark.executor.Executor       : Finished task 41.0 in stage 444.0 (TID 164). 431664 bytes result sent to driver
2018-05-01 17:49:56.082  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 42.0 in stage 444.0 (TID 165, localhost, executor driver, partition 42, ANY, 5003 bytes)
2018-05-01 17:49:56.083  INFO 16044 --- [Executor task launch worker for task 165] org.apache.spark.executor.Executor       : Running task 42.0 in stage 444.0 (TID 165)
2018-05-01 17:49:56.127  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 41.0 in stage 444.0 (TID 164) in 588 ms on localhost (executor driver) (42/66)
2018-05-01 17:49:56.630  INFO 16044 --- [Executor task launch worker for task 165] org.apache.spark.executor.Executor       : Finished task 42.0 in stage 444.0 (TID 165). 432078 bytes result sent to driver
2018-05-01 17:49:56.631  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 43.0 in stage 444.0 (TID 166, localhost, executor driver, partition 43, ANY, 5003 bytes)
2018-05-01 17:49:56.632  INFO 16044 --- [Executor task launch worker for task 166] org.apache.spark.executor.Executor       : Running task 43.0 in stage 444.0 (TID 166)
2018-05-01 17:49:56.648  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 42.0 in stage 444.0 (TID 165) in 566 ms on localhost (executor driver) (43/66)
2018-05-01 17:49:57.167  INFO 16044 --- [Executor task launch worker for task 166] org.apache.spark.executor.Executor       : Finished task 43.0 in stage 444.0 (TID 166). 428926 bytes result sent to driver
2018-05-01 17:49:57.167  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 44.0 in stage 444.0 (TID 167, localhost, executor driver, partition 44, ANY, 5003 bytes)
2018-05-01 17:49:57.168  INFO 16044 --- [Executor task launch worker for task 167] org.apache.spark.executor.Executor       : Running task 44.0 in stage 444.0 (TID 167)
2018-05-01 17:49:57.183  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 43.0 in stage 444.0 (TID 166) in 553 ms on localhost (executor driver) (44/66)
2018-05-01 17:49:57.738  INFO 16044 --- [Executor task launch worker for task 167] org.apache.spark.executor.Executor       : Finished task 44.0 in stage 444.0 (TID 167). 432725 bytes result sent to driver
2018-05-01 17:49:57.738  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 45.0 in stage 444.0 (TID 168, localhost, executor driver, partition 45, ANY, 5003 bytes)
2018-05-01 17:49:57.741  INFO 16044 --- [Executor task launch worker for task 168] org.apache.spark.executor.Executor       : Running task 45.0 in stage 444.0 (TID 168)
2018-05-01 17:49:57.760  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 44.0 in stage 444.0 (TID 167) in 593 ms on localhost (executor driver) (45/66)
2018-05-01 17:49:58.276  INFO 16044 --- [Executor task launch worker for task 168] org.apache.spark.executor.Executor       : Finished task 45.0 in stage 444.0 (TID 168). 430122 bytes result sent to driver
2018-05-01 17:49:58.277  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 46.0 in stage 444.0 (TID 169, localhost, executor driver, partition 46, ANY, 5003 bytes)
2018-05-01 17:49:58.278  INFO 16044 --- [Executor task launch worker for task 169] org.apache.spark.executor.Executor       : Running task 46.0 in stage 444.0 (TID 169)
2018-05-01 17:49:58.300  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 45.0 in stage 444.0 (TID 168) in 562 ms on localhost (executor driver) (46/66)
2018-05-01 17:49:58.802  INFO 16044 --- [Executor task launch worker for task 169] org.apache.spark.executor.Executor       : Finished task 46.0 in stage 444.0 (TID 169). 430137 bytes result sent to driver
2018-05-01 17:49:58.802  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 47.0 in stage 444.0 (TID 170, localhost, executor driver, partition 47, ANY, 5003 bytes)
2018-05-01 17:49:58.803  INFO 16044 --- [Executor task launch worker for task 170] org.apache.spark.executor.Executor       : Running task 47.0 in stage 444.0 (TID 170)
2018-05-01 17:49:58.820  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 46.0 in stage 444.0 (TID 169) in 543 ms on localhost (executor driver) (47/66)
2018-05-01 17:49:59.386  INFO 16044 --- [Executor task launch worker for task 170] org.apache.spark.executor.Executor       : Finished task 47.0 in stage 444.0 (TID 170). 433596 bytes result sent to driver
2018-05-01 17:49:59.387  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 48.0 in stage 444.0 (TID 171, localhost, executor driver, partition 48, ANY, 5003 bytes)
2018-05-01 17:49:59.388  INFO 16044 --- [Executor task launch worker for task 171] org.apache.spark.executor.Executor       : Running task 48.0 in stage 444.0 (TID 171)
2018-05-01 17:49:59.403  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 47.0 in stage 444.0 (TID 170) in 600 ms on localhost (executor driver) (48/66)
2018-05-01 17:49:59.915  INFO 16044 --- [Executor task launch worker for task 171] org.apache.spark.executor.Executor       : Finished task 48.0 in stage 444.0 (TID 171). 431478 bytes result sent to driver
2018-05-01 17:49:59.915  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 49.0 in stage 444.0 (TID 172, localhost, executor driver, partition 49, ANY, 5003 bytes)
2018-05-01 17:49:59.916  INFO 16044 --- [Executor task launch worker for task 172] org.apache.spark.executor.Executor       : Running task 49.0 in stage 444.0 (TID 172)
2018-05-01 17:49:59.931  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 48.0 in stage 444.0 (TID 171) in 545 ms on localhost (executor driver) (49/66)
2018-05-01 17:50:00.449  INFO 16044 --- [Executor task launch worker for task 172] org.apache.spark.executor.Executor       : Finished task 49.0 in stage 444.0 (TID 172). 432786 bytes result sent to driver
2018-05-01 17:50:00.449  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 50.0 in stage 444.0 (TID 173, localhost, executor driver, partition 50, ANY, 5003 bytes)
2018-05-01 17:50:00.451  INFO 16044 --- [Executor task launch worker for task 173] org.apache.spark.executor.Executor       : Running task 50.0 in stage 444.0 (TID 173)
2018-05-01 17:50:00.465  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 49.0 in stage 444.0 (TID 172) in 550 ms on localhost (executor driver) (50/66)
2018-05-01 17:50:01.028  INFO 16044 --- [Executor task launch worker for task 173] org.apache.spark.executor.Executor       : Finished task 50.0 in stage 444.0 (TID 173). 430368 bytes result sent to driver
2018-05-01 17:50:01.029  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 51.0 in stage 444.0 (TID 174, localhost, executor driver, partition 51, ANY, 5002 bytes)
2018-05-01 17:50:01.030  INFO 16044 --- [Executor task launch worker for task 174] org.apache.spark.executor.Executor       : Running task 51.0 in stage 444.0 (TID 174)
2018-05-01 17:50:01.046  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 50.0 in stage 444.0 (TID 173) in 597 ms on localhost (executor driver) (51/66)
2018-05-01 17:50:01.563  INFO 16044 --- [Executor task launch worker for task 174] org.apache.spark.executor.Executor       : Finished task 51.0 in stage 444.0 (TID 174). 435039 bytes result sent to driver
2018-05-01 17:50:01.563  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 52.0 in stage 444.0 (TID 175, localhost, executor driver, partition 52, ANY, 5002 bytes)
2018-05-01 17:50:01.565  INFO 16044 --- [Executor task launch worker for task 175] org.apache.spark.executor.Executor       : Running task 52.0 in stage 444.0 (TID 175)
2018-05-01 17:50:01.581  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 51.0 in stage 444.0 (TID 174) in 552 ms on localhost (executor driver) (52/66)
2018-05-01 17:50:02.095  INFO 16044 --- [Executor task launch worker for task 175] org.apache.spark.executor.Executor       : Finished task 52.0 in stage 444.0 (TID 175). 431702 bytes result sent to driver
2018-05-01 17:50:02.136  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 53.0 in stage 444.0 (TID 176, localhost, executor driver, partition 53, ANY, 5002 bytes)
2018-05-01 17:50:02.137  INFO 16044 --- [Executor task launch worker for task 176] org.apache.spark.executor.Executor       : Running task 53.0 in stage 444.0 (TID 176)
2018-05-01 17:50:02.152  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 52.0 in stage 444.0 (TID 175) in 589 ms on localhost (executor driver) (53/66)
2018-05-01 17:50:02.660  INFO 16044 --- [Executor task launch worker for task 176] org.apache.spark.executor.Executor       : Finished task 53.0 in stage 444.0 (TID 176). 431585 bytes result sent to driver
2018-05-01 17:50:02.661  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 54.0 in stage 444.0 (TID 177, localhost, executor driver, partition 54, ANY, 5002 bytes)
2018-05-01 17:50:02.662  INFO 16044 --- [Executor task launch worker for task 177] org.apache.spark.executor.Executor       : Running task 54.0 in stage 444.0 (TID 177)
2018-05-01 17:50:02.677  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 53.0 in stage 444.0 (TID 176) in 541 ms on localhost (executor driver) (54/66)
2018-05-01 17:50:03.191  INFO 16044 --- [Executor task launch worker for task 177] org.apache.spark.executor.Executor       : Finished task 54.0 in stage 444.0 (TID 177). 428814 bytes result sent to driver
2018-05-01 17:50:03.191  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 55.0 in stage 444.0 (TID 178, localhost, executor driver, partition 55, ANY, 5003 bytes)
2018-05-01 17:50:03.192  INFO 16044 --- [Executor task launch worker for task 178] org.apache.spark.executor.Executor       : Running task 55.0 in stage 444.0 (TID 178)
2018-05-01 17:50:03.207  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 54.0 in stage 444.0 (TID 177) in 546 ms on localhost (executor driver) (55/66)
2018-05-01 17:50:03.758  INFO 16044 --- [Executor task launch worker for task 178] org.apache.spark.executor.Executor       : Finished task 55.0 in stage 444.0 (TID 178). 431970 bytes result sent to driver
2018-05-01 17:50:03.758  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 56.0 in stage 444.0 (TID 179, localhost, executor driver, partition 56, ANY, 5003 bytes)
2018-05-01 17:50:03.759  INFO 16044 --- [Executor task launch worker for task 179] org.apache.spark.executor.Executor       : Running task 56.0 in stage 444.0 (TID 179)
2018-05-01 17:50:03.776  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 55.0 in stage 444.0 (TID 178) in 585 ms on localhost (executor driver) (56/66)
2018-05-01 17:50:04.290  INFO 16044 --- [Executor task launch worker for task 179] org.apache.spark.executor.Executor       : Finished task 56.0 in stage 444.0 (TID 179). 431035 bytes result sent to driver
2018-05-01 17:50:04.290  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 57.0 in stage 444.0 (TID 180, localhost, executor driver, partition 57, ANY, 5003 bytes)
2018-05-01 17:50:04.291  INFO 16044 --- [Executor task launch worker for task 180] org.apache.spark.executor.Executor       : Running task 57.0 in stage 444.0 (TID 180)
2018-05-01 17:50:04.307  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 56.0 in stage 444.0 (TID 179) in 549 ms on localhost (executor driver) (57/66)
2018-05-01 17:50:04.817  INFO 16044 --- [Executor task launch worker for task 180] org.apache.spark.executor.Executor       : Finished task 57.0 in stage 444.0 (TID 180). 434026 bytes result sent to driver
2018-05-01 17:50:04.817  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 58.0 in stage 444.0 (TID 181, localhost, executor driver, partition 58, ANY, 5003 bytes)
2018-05-01 17:50:04.818  INFO 16044 --- [Executor task launch worker for task 181] org.apache.spark.executor.Executor       : Running task 58.0 in stage 444.0 (TID 181)
2018-05-01 17:50:04.833  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 57.0 in stage 444.0 (TID 180) in 543 ms on localhost (executor driver) (58/66)
2018-05-01 17:50:05.395  INFO 16044 --- [Executor task launch worker for task 181] org.apache.spark.executor.Executor       : Finished task 58.0 in stage 444.0 (TID 181). 431075 bytes result sent to driver
2018-05-01 17:50:05.396  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 59.0 in stage 444.0 (TID 182, localhost, executor driver, partition 59, ANY, 5003 bytes)
2018-05-01 17:50:05.397  INFO 16044 --- [Executor task launch worker for task 182] org.apache.spark.executor.Executor       : Running task 59.0 in stage 444.0 (TID 182)
2018-05-01 17:50:05.415  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 58.0 in stage 444.0 (TID 181) in 598 ms on localhost (executor driver) (59/66)
2018-05-01 17:50:05.930  INFO 16044 --- [Executor task launch worker for task 182] org.apache.spark.executor.Executor       : Finished task 59.0 in stage 444.0 (TID 182). 433121 bytes result sent to driver
2018-05-01 17:50:05.931  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 60.0 in stage 444.0 (TID 183, localhost, executor driver, partition 60, ANY, 5003 bytes)
2018-05-01 17:50:05.932  INFO 16044 --- [Executor task launch worker for task 183] org.apache.spark.executor.Executor       : Running task 60.0 in stage 444.0 (TID 183)
2018-05-01 17:50:05.951  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 59.0 in stage 444.0 (TID 182) in 555 ms on localhost (executor driver) (60/66)
2018-05-01 17:50:06.466  INFO 16044 --- [Executor task launch worker for task 183] org.apache.spark.executor.Executor       : Finished task 60.0 in stage 444.0 (TID 183). 432214 bytes result sent to driver
2018-05-01 17:50:06.467  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 61.0 in stage 444.0 (TID 184, localhost, executor driver, partition 61, ANY, 5003 bytes)
2018-05-01 17:50:06.468  INFO 16044 --- [Executor task launch worker for task 184] org.apache.spark.executor.Executor       : Running task 61.0 in stage 444.0 (TID 184)
2018-05-01 17:50:06.484  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 60.0 in stage 444.0 (TID 183) in 554 ms on localhost (executor driver) (61/66)
2018-05-01 17:50:06.996  INFO 16044 --- [Executor task launch worker for task 184] org.apache.spark.executor.Executor       : Finished task 61.0 in stage 444.0 (TID 184). 432524 bytes result sent to driver
2018-05-01 17:50:06.997  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 62.0 in stage 444.0 (TID 185, localhost, executor driver, partition 62, ANY, 5003 bytes)
2018-05-01 17:50:06.998  INFO 16044 --- [Executor task launch worker for task 185] org.apache.spark.executor.Executor       : Running task 62.0 in stage 444.0 (TID 185)
2018-05-01 17:50:07.014  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 61.0 in stage 444.0 (TID 184) in 547 ms on localhost (executor driver) (62/66)
2018-05-01 17:50:07.602  INFO 16044 --- [Executor task launch worker for task 185] org.apache.spark.executor.Executor       : Finished task 62.0 in stage 444.0 (TID 185). 431615 bytes result sent to driver
2018-05-01 17:50:07.602  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 63.0 in stage 444.0 (TID 186, localhost, executor driver, partition 63, ANY, 5003 bytes)
2018-05-01 17:50:07.603  INFO 16044 --- [Executor task launch worker for task 186] org.apache.spark.executor.Executor       : Running task 63.0 in stage 444.0 (TID 186)
2018-05-01 17:50:07.619  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 62.0 in stage 444.0 (TID 185) in 622 ms on localhost (executor driver) (63/66)
2018-05-01 17:50:08.131  INFO 16044 --- [Executor task launch worker for task 186] org.apache.spark.executor.Executor       : Finished task 63.0 in stage 444.0 (TID 186). 429910 bytes result sent to driver
2018-05-01 17:50:08.132  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 64.0 in stage 444.0 (TID 187, localhost, executor driver, partition 64, ANY, 5003 bytes)
2018-05-01 17:50:08.133  INFO 16044 --- [Executor task launch worker for task 187] org.apache.spark.executor.Executor       : Running task 64.0 in stage 444.0 (TID 187)
2018-05-01 17:50:08.149  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 63.0 in stage 444.0 (TID 186) in 547 ms on localhost (executor driver) (64/66)
2018-05-01 17:50:08.671  INFO 16044 --- [Executor task launch worker for task 187] org.apache.spark.executor.Executor       : Finished task 64.0 in stage 444.0 (TID 187). 434975 bytes result sent to driver
2018-05-01 17:50:08.671  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 65.0 in stage 444.0 (TID 188, localhost, executor driver, partition 65, ANY, 4992 bytes)
2018-05-01 17:50:08.672  INFO 16044 --- [Executor task launch worker for task 188] org.apache.spark.executor.Executor       : Running task 65.0 in stage 444.0 (TID 188)
2018-05-01 17:50:08.675  INFO 16044 --- [Executor task launch worker for task 188] org.apache.spark.executor.Executor       : Finished task 65.0 in stage 444.0 (TID 188). 777 bytes result sent to driver
2018-05-01 17:50:08.675  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 65.0 in stage 444.0 (TID 188) in 4 ms on localhost (executor driver) (65/66)
2018-05-01 17:50:08.689  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 64.0 in stage 444.0 (TID 187) in 557 ms on localhost (executor driver) (66/66)
2018-05-01 17:50:08.690  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 444.0, whose tasks have all completed, from pool 
2018-05-01 17:50:08.691  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 444 (collect at RecomendationServiceImpl.java:86) finished in 36.261 s
2018-05-01 17:50:08.691  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 31 finished: collect at RecomendationServiceImpl.java:86, took 36.266965 s
2018-05-01 17:50:08.844  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:240
2018-05-01 17:50:08.844  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 32 (isEmpty at ALS.scala:240) with 1 output partitions
2018-05-01 17:50:08.844  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 445 (isEmpty at ALS.scala:240)
2018-05-01 17:50:08.844  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:50:08.844  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:08.846  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 445 (UnionRDD[240] at union at RecomendationServiceImpl.java:77), which has no missing parents
2018-05-01 17:50:08.847  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_58 stored as values in memory (estimated size 3.3 KB, free 1990.8 MB)
2018-05-01 17:50:08.848  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1990.8 MB)
2018-05-01 17:50:08.848  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_58_piece0 in memory on 172.21.241.193:58620 (size: 2.1 KB, free: 1990.8 MB)
2018-05-01 17:50:08.848  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:08.849  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 445 (UnionRDD[240] at union at RecomendationServiceImpl.java:77) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:08.849  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 445.0 with 1 tasks
2018-05-01 17:50:11.840  WARN 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Stage 445 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:50:11.841  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 445.0 (TID 189, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:50:11.841  INFO 16044 --- [Executor task launch worker for task 189] org.apache.spark.executor.Executor       : Running task 0.0 in stage 445.0 (TID 189)
2018-05-01 17:50:13.316  INFO 16044 --- [Executor task launch worker for task 189] o.a.spark.storage.memory.MemoryStore     : Block rdd_238_0 stored as values in memory (estimated size 36.0 MB, free 1954.8 MB)
2018-05-01 17:50:13.317  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_238_0 in memory on 172.21.241.193:58620 (size: 36.0 MB, free: 1954.8 MB)
2018-05-01 17:50:13.318  INFO 16044 --- [Executor task launch worker for task 189] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 189:
[rdd_238_0]
2018-05-01 17:50:13.318  INFO 16044 --- [Executor task launch worker for task 189] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 445.0 (TID 189). 1551 bytes result sent to driver
2018-05-01 17:50:13.319  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 445.0 (TID 189) in 4470 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:13.319  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 445.0, whose tasks have all completed, from pool 
2018-05-01 17:50:13.319  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 445 (isEmpty at ALS.scala:240) finished in 4.470 s
2018-05-01 17:50:13.320  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 32 finished: isEmpty at ALS.scala:240, took 4.476114 s
2018-05-01 17:50:13.324  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: isEmpty at ALS.scala:843
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 33 (isEmpty at ALS.scala:843) with 1 output partitions
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 446 (isEmpty at ALS.scala:843)
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:13.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 446 (MapPartitionsRDD[241] at map at ALS.scala:256), which has no missing parents
2018-05-01 17:50:13.327  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_59 stored as values in memory (estimated size 3.6 KB, free 1954.8 MB)
2018-05-01 17:50:13.328  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.2 KB, free 1954.8 MB)
2018-05-01 17:50:13.328  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_59_piece0 in memory on 172.21.241.193:58620 (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 17:50:13.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:13.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 446 (MapPartitionsRDD[241] at map at ALS.scala:256) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:13.328  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 446.0 with 1 tasks
2018-05-01 17:50:13.721  INFO 16044 --- [pool-25-thread-1] c.m.spark.connection.MongoClientCache    : Closing MongoClient: [127.0.0.1:27017]
2018-05-01 17:50:13.721  INFO 16044 --- [pool-25-thread-1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:6, serverValue:33}] to 127.0.0.1:27017 because the pool has been closed.
2018-05-01 17:50:16.251  WARN 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Stage 446 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:50:16.252  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 446.0 (TID 190, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427813 bytes)
2018-05-01 17:50:16.252  INFO 16044 --- [Executor task launch worker for task 190] org.apache.spark.executor.Executor       : Running task 0.0 in stage 446.0 (TID 190)
2018-05-01 17:50:16.584  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_58_piece0 on 172.21.241.193:58620 in memory (size: 2.1 KB, free: 1954.8 MB)
2018-05-01 17:50:17.347  INFO 16044 --- [Executor task launch worker for task 190] org.apache.spark.storage.BlockManager    : Found block rdd_238_0 locally
2018-05-01 17:50:17.347  INFO 16044 --- [Executor task launch worker for task 190] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 190:
[rdd_238_0]
2018-05-01 17:50:17.347  INFO 16044 --- [Executor task launch worker for task 190] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 446.0 (TID 190). 1003 bytes result sent to driver
2018-05-01 17:50:17.348  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 446.0 (TID 190) in 4020 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:17.349  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 446.0, whose tasks have all completed, from pool 
2018-05-01 17:50:17.349  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 446 (isEmpty at ALS.scala:843) finished in 4.021 s
2018-05-01 17:50:17.349  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 33 finished: isEmpty at ALS.scala:843, took 4.024945 s
2018-05-01 17:50:17.370  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:857
2018-05-01 17:50:17.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 242 (mapPartitions at ALS.scala:1101)
2018-05-01 17:50:17.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 245 (map at ALS.scala:1344)
2018-05-01 17:50:17.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 34 (count at ALS.scala:857) with 1 output partitions
2018-05-01 17:50:17.371  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 449 (count at ALS.scala:857)
2018-05-01 17:50:17.372  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 448)
2018-05-01 17:50:17.372  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 448)
2018-05-01 17:50:17.373  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 447 (MapPartitionsRDD[242] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-05-01 17:50:17.373  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_60 stored as values in memory (estimated size 5.8 KB, free 1954.8 MB)
2018-05-01 17:50:17.374  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1954.8 MB)
2018-05-01 17:50:17.375  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_60_piece0 in memory on 172.21.241.193:58620 (size: 3.2 KB, free: 1954.8 MB)
2018-05-01 17:50:17.375  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:17.375  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 447 (MapPartitionsRDD[242] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:50:17.376  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 447.0 with 2 tasks
2018-05-01 17:50:19.427  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_59_piece0 on 172.21.241.193:58620 in memory (size: 2.2 KB, free: 1954.8 MB)
2018-05-01 17:50:20.289  WARN 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Stage 447 contains a task of very large size (26784 KB). The maximum recommended task size is 100 KB.
2018-05-01 17:50:20.290  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 447.0 (TID 191, localhost, executor driver, partition 0, PROCESS_LOCAL, 27427802 bytes)
2018-05-01 17:50:20.291  INFO 16044 --- [Executor task launch worker for task 191] org.apache.spark.executor.Executor       : Running task 0.0 in stage 447.0 (TID 191)
2018-05-01 17:50:21.278  INFO 16044 --- [Executor task launch worker for task 191] org.apache.spark.storage.BlockManager    : Found block rdd_238_0 locally
2018-05-01 17:50:21.692  INFO 16044 --- [Executor task launch worker for task 191] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 447.0 (TID 191). 1027 bytes result sent to driver
2018-05-01 17:50:21.693  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 447.0 (TID 192, localhost, executor driver, partition 1, PROCESS_LOCAL, 5072 bytes)
2018-05-01 17:50:21.694  INFO 16044 --- [Executor task launch worker for task 192] org.apache.spark.executor.Executor       : Running task 1.0 in stage 447.0 (TID 192)
2018-05-01 17:50:21.694  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 447.0 (TID 191) in 4318 ms on localhost (executor driver) (1/2)
2018-05-01 17:50:21.709  INFO 16044 --- [Executor task launch worker for task 192] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 447.0 (TID 192). 812 bytes result sent to driver
2018-05-01 17:50:21.710  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 447.0 (TID 192) in 16 ms on localhost (executor driver) (2/2)
2018-05-01 17:50:21.710  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 447.0, whose tasks have all completed, from pool 
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 447 (mapPartitions at ALS.scala:1101) finished in 4.335 s
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 448, ResultStage 449)
2018-05-01 17:50:21.711  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:21.712  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 448 (MapPartitionsRDD[245] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:50:21.713  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_61 stored as values in memory (estimated size 7.1 KB, free 1954.8 MB)
2018-05-01 17:50:21.713  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1954.8 MB)
2018-05-01 17:50:21.713  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_61_piece0 in memory on 172.21.241.193:58620 (size: 3.7 KB, free: 1954.8 MB)
2018-05-01 17:50:21.714  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:21.714  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 448 (MapPartitionsRDD[245] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:50:21.714  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 448.0 with 2 tasks
2018-05-01 17:50:21.715  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 448.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:50:21.715  INFO 16044 --- [Executor task launch worker for task 193] org.apache.spark.executor.Executor       : Running task 0.0 in stage 448.0 (TID 193)
2018-05-01 17:50:21.717  INFO 16044 --- [Executor task launch worker for task 193] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 2 blocks
2018-05-01 17:50:21.717  INFO 16044 --- [Executor task launch worker for task 193] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:21.717  INFO 16044 --- [Executor task launch worker for task 193] o.a.spark.storage.memory.MemoryStore     : Block rdd_244_0 stored as values in memory (estimated size 16.0 B, free 1954.8 MB)
2018-05-01 17:50:21.718  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_244_0 in memory on 172.21.241.193:58620 (size: 16.0 B, free: 1954.8 MB)
2018-05-01 17:50:21.723  INFO 16044 --- [Executor task launch worker for task 193] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 448.0 (TID 193). 1766 bytes result sent to driver
2018-05-01 17:50:21.724  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 448.0 (TID 194, localhost, executor driver, partition 1, ANY, 4610 bytes)
2018-05-01 17:50:21.724  INFO 16044 --- [Executor task launch worker for task 194] org.apache.spark.executor.Executor       : Running task 1.0 in stage 448.0 (TID 194)
2018-05-01 17:50:21.724  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 448.0 (TID 193) in 10 ms on localhost (executor driver) (1/2)
2018-05-01 17:50:21.725  INFO 16044 --- [Executor task launch worker for task 194] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 2 non-empty blocks out of 2 blocks
2018-05-01 17:50:21.725  INFO 16044 --- [Executor task launch worker for task 194] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:21.859  INFO 16044 --- [Executor task launch worker for task 194] o.a.spark.storage.memory.MemoryStore     : Block rdd_244_1 stored as values in memory (estimated size 12.0 MB, free 1942.8 MB)
2018-05-01 17:50:21.859  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_244_1 in memory on 172.21.241.193:58620 (size: 12.0 MB, free: 1942.8 MB)
2018-05-01 17:50:22.125  INFO 16044 --- [Executor task launch worker for task 194] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 448.0 (TID 194). 1938 bytes result sent to driver
2018-05-01 17:50:22.125  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 448.0 (TID 194) in 401 ms on localhost (executor driver) (2/2)
2018-05-01 17:50:22.125  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 448.0, whose tasks have all completed, from pool 
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 448 (map at ALS.scala:1344) finished in 0.411 s
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 449)
2018-05-01 17:50:22.125  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:22.126  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 449 (userOutBlocks MapPartitionsRDD[248] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:50:22.127  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_62 stored as values in memory (estimated size 7.7 KB, free 1942.8 MB)
2018-05-01 17:50:22.128  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1942.8 MB)
2018-05-01 17:50:22.128  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_62_piece0 in memory on 172.21.241.193:58620 (size: 3.9 KB, free: 1942.8 MB)
2018-05-01 17:50:22.129  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:22.129  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 449 (userOutBlocks MapPartitionsRDD[248] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:22.129  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 449.0 with 1 tasks
2018-05-01 17:50:22.129  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 449.0 (TID 195, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:50:22.129  INFO 16044 --- [Executor task launch worker for task 195] org.apache.spark.executor.Executor       : Running task 0.0 in stage 449.0 (TID 195)
2018-05-01 17:50:22.131  INFO 16044 --- [Executor task launch worker for task 195] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:50:22.131  INFO 16044 --- [Executor task launch worker for task 195] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:22.451  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_61_piece0 on 172.21.241.193:58620 in memory (size: 3.7 KB, free: 1942.8 MB)
2018-05-01 17:50:22.452  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_60_piece0 on 172.21.241.193:58620 in memory (size: 3.2 KB, free: 1942.8 MB)
2018-05-01 17:50:22.620  INFO 16044 --- [Executor task launch worker for task 195] o.a.spark.storage.memory.MemoryStore     : Block rdd_247_0 stored as values in memory (estimated size 8.1 MB, free 1934.7 MB)
2018-05-01 17:50:22.620  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_247_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1934.7 MB)
2018-05-01 17:50:22.624  INFO 16044 --- [Executor task launch worker for task 195] o.a.spark.storage.memory.MemoryStore     : Block rdd_248_0 stored as values in memory (estimated size 27.9 KB, free 1934.7 MB)
2018-05-01 17:50:22.624  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_248_0 in memory on 172.21.241.193:58620 (size: 27.9 KB, free: 1934.7 MB)
2018-05-01 17:50:22.624  INFO 16044 --- [Executor task launch worker for task 195] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 449.0 (TID 195). 1877 bytes result sent to driver
2018-05-01 17:50:22.625  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 449.0 (TID 195) in 496 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:22.625  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 449.0, whose tasks have all completed, from pool 
2018-05-01 17:50:22.625  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 449 (count at ALS.scala:857) finished in 0.496 s
2018-05-01 17:50:22.625  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 34 finished: count at ALS.scala:857, took 5.254274 s
2018-05-01 17:50:22.639  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:865
2018-05-01 17:50:22.639  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:22.639  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 250 (map at ALS.scala:1344)
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 35 (count at ALS.scala:865) with 1 output partitions
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 452 (count at ALS.scala:865)
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 451)
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 451)
2018-05-01 17:50:22.640  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 451 (MapPartitionsRDD[250] at map at ALS.scala:1344), which has no missing parents
2018-05-01 17:50:22.641  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_63 stored as values in memory (estimated size 7.3 KB, free 1934.7 MB)
2018-05-01 17:50:22.642  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1934.7 MB)
2018-05-01 17:50:22.642  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_63_piece0 in memory on 172.21.241.193:58620 (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:50:22.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:22.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 2 missing tasks from ShuffleMapStage 451 (MapPartitionsRDD[250] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0, 1))
2018-05-01 17:50:22.643  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 451.0 with 2 tasks
2018-05-01 17:50:22.644  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 451.0 (TID 196, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:50:22.644  INFO 16044 --- [Executor task launch worker for task 196] org.apache.spark.executor.Executor       : Running task 0.0 in stage 451.0 (TID 196)
2018-05-01 17:50:22.645  INFO 16044 --- [Executor task launch worker for task 196] org.apache.spark.storage.BlockManager    : Found block rdd_244_0 locally
2018-05-01 17:50:22.651  INFO 16044 --- [Executor task launch worker for task 196] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 451.0 (TID 196). 725 bytes result sent to driver
2018-05-01 17:50:22.651  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 451.0 (TID 197, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:50:22.651  INFO 16044 --- [Executor task launch worker for task 197] org.apache.spark.executor.Executor       : Running task 1.0 in stage 451.0 (TID 197)
2018-05-01 17:50:22.651  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 451.0 (TID 196) in 7 ms on localhost (executor driver) (1/2)
2018-05-01 17:50:22.652  INFO 16044 --- [Executor task launch worker for task 197] org.apache.spark.storage.BlockManager    : Found block rdd_244_1 locally
2018-05-01 17:50:22.924  INFO 16044 --- [Executor task launch worker for task 197] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 451.0 (TID 197). 897 bytes result sent to driver
2018-05-01 17:50:22.925  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 451.0 (TID 197) in 273 ms on localhost (executor driver) (2/2)
2018-05-01 17:50:22.925  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 451.0, whose tasks have all completed, from pool 
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 451 (map at ALS.scala:1344) finished in 0.281 s
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 452)
2018-05-01 17:50:22.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:22.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 452 (itemOutBlocks MapPartitionsRDD[253] at mapValues at ALS.scala:1381), which has no missing parents
2018-05-01 17:50:22.926  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_64 stored as values in memory (estimated size 7.9 KB, free 1934.7 MB)
2018-05-01 17:50:22.927  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1934.7 MB)
2018-05-01 17:50:22.928  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_64_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1934.7 MB)
2018-05-01 17:50:22.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:22.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 452 (itemOutBlocks MapPartitionsRDD[253] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:22.928  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 452.0 with 1 tasks
2018-05-01 17:50:22.929  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 452.0 (TID 198, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-05-01 17:50:22.929  INFO 16044 --- [Executor task launch worker for task 198] org.apache.spark.executor.Executor       : Running task 0.0 in stage 452.0 (TID 198)
2018-05-01 17:50:22.931  INFO 16044 --- [Executor task launch worker for task 198] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 2 blocks
2018-05-01 17:50:22.931  INFO 16044 --- [Executor task launch worker for task 198] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:23.564  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_63_piece0 on 172.21.241.193:58620 in memory (size: 3.8 KB, free: 1934.7 MB)
2018-05-01 17:50:23.566  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_62_piece0 on 172.21.241.193:58620 in memory (size: 3.9 KB, free: 1934.7 MB)
2018-05-01 17:50:24.122  INFO 16044 --- [Executor task launch worker for task 198] o.a.spark.storage.memory.MemoryStore     : Block rdd_252_0 stored as values in memory (estimated size 8.1 MB, free 1926.6 MB)
2018-05-01 17:50:24.122  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_252_0 in memory on 172.21.241.193:58620 (size: 8.1 MB, free: 1926.6 MB)
2018-05-01 17:50:24.126  INFO 16044 --- [Executor task launch worker for task 198] o.a.spark.storage.memory.MemoryStore     : Block rdd_253_0 stored as values in memory (estimated size 54.9 KB, free 1926.5 MB)
2018-05-01 17:50:24.126  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_253_0 in memory on 172.21.241.193:58620 (size: 54.9 KB, free: 1926.6 MB)
2018-05-01 17:50:24.126  INFO 16044 --- [Executor task launch worker for task 198] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 452.0 (TID 198). 1877 bytes result sent to driver
2018-05-01 17:50:24.127  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 452.0 (TID 198) in 1199 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.127  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 452.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.127  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 452 (count at ALS.scala:865) finished in 1.199 s
2018-05-01 17:50:24.127  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 35 finished: count at ALS.scala:865, took 1.488659 s
2018-05-01 17:50:24.138  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 36 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 455 (aggregate at ALS.scala:1491)
2018-05-01 17:50:24.138  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 454)
2018-05-01 17:50:24.139  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:24.140  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 455 (MapPartitionsRDD[256] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:24.141  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_65 stored as values in memory (estimated size 9.1 KB, free 1926.5 MB)
2018-05-01 17:50:24.141  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.5 MB)
2018-05-01 17:50:24.142  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_65_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.5 MB)
2018-05-01 17:50:24.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 455 (MapPartitionsRDD[256] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.142  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 455.0 with 1 tasks
2018-05-01 17:50:24.143  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 455.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 4621 bytes)
2018-05-01 17:50:24.143  INFO 16044 --- [Executor task launch worker for task 199] org.apache.spark.executor.Executor       : Running task 0.0 in stage 455.0 (TID 199)
2018-05-01 17:50:24.144  INFO 16044 --- [Executor task launch worker for task 199] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:24.151  INFO 16044 --- [Executor task launch worker for task 199] o.a.spark.storage.memory.MemoryStore     : Block rdd_254_0 stored as values in memory (estimated size 416.2 KB, free 1926.1 MB)
2018-05-01 17:50:24.151  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_254_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1926.1 MB)
2018-05-01 17:50:24.153  INFO 16044 --- [Executor task launch worker for task 199] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 455.0 (TID 199). 2165 bytes result sent to driver
2018-05-01 17:50:24.154  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 455.0 (TID 199) in 11 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.154  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 455.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.154  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 455 (aggregate at ALS.scala:1491) finished in 0.011 s
2018-05-01 17:50:24.155  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 36 finished: aggregate at ALS.scala:1491, took 0.017356 s
2018-05-01 17:50:24.169  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 255 from persistence list
2018-05-01 17:50:24.169  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 255
2018-05-01 17:50:24.173  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 254 (map at ALS.scala:1017)
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 260 (flatMap at ALS.scala:1433)
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 37 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 461 (aggregate at ALS.scala:1491)
2018-05-01 17:50:24.174  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 460, ShuffleMapStage 457)
2018-05-01 17:50:24.175  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 460)
2018-05-01 17:50:24.175  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 459 (userFactors-1 MapPartitionsRDD[254] at map at ALS.scala:1017), which has no missing parents
2018-05-01 17:50:24.176  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_66 stored as values in memory (estimated size 7.7 KB, free 1926.1 MB)
2018-05-01 17:50:24.176  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_66_piece0 stored as bytes in memory (estimated size 4.0 KB, free 1926.1 MB)
2018-05-01 17:50:24.177  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_66_piece0 in memory on 172.21.241.193:58620 (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:50:24.177  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.177  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 459 (userFactors-1 MapPartitionsRDD[254] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.177  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 459.0 with 1 tasks
2018-05-01 17:50:24.178  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 459.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-05-01 17:50:24.178  INFO 16044 --- [Executor task launch worker for task 200] org.apache.spark.executor.Executor       : Running task 0.0 in stage 459.0 (TID 200)
2018-05-01 17:50:24.179  INFO 16044 --- [Executor task launch worker for task 200] org.apache.spark.storage.BlockManager    : Found block rdd_254_0 locally
2018-05-01 17:50:24.222  INFO 16044 --- [Executor task launch worker for task 200] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 459.0 (TID 200). 940 bytes result sent to driver
2018-05-01 17:50:24.223  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 459.0 (TID 200) in 46 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.223  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 459.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 459 (map at ALS.scala:1017) finished in 0.046 s
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ShuffleMapStage 460, ResultStage 461)
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:24.223  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 460 (MapPartitionsRDD[260] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:24.224  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_67 stored as values in memory (estimated size 8.8 KB, free 1926.1 MB)
2018-05-01 17:50:24.225  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.3 KB, free 1926.1 MB)
2018-05-01 17:50:24.227  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_67_piece0 in memory on 172.21.241.193:58620 (size: 4.3 KB, free: 1926.1 MB)
2018-05-01 17:50:24.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 67 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 460 (MapPartitionsRDD[260] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.227  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 460.0 with 1 tasks
2018-05-01 17:50:24.228  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 460.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-05-01 17:50:24.228  INFO 16044 --- [Executor task launch worker for task 201] org.apache.spark.executor.Executor       : Running task 0.0 in stage 460.0 (TID 201)
2018-05-01 17:50:24.229  INFO 16044 --- [Executor task launch worker for task 201] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:24.230  INFO 16044 --- [Executor task launch worker for task 201] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:24.230  INFO 16044 --- [Executor task launch worker for task 201] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:24.287  INFO 16044 --- [Executor task launch worker for task 201] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 460.0 (TID 201). 1327 bytes result sent to driver
2018-05-01 17:50:24.288  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 460.0 (TID 201) in 61 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.288  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 460.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 460 (flatMap at ALS.scala:1433) finished in 0.061 s
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 461)
2018-05-01 17:50:24.288  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:24.289  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 461 (MapPartitionsRDD[266] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:24.289  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_68 stored as values in memory (estimated size 12.6 KB, free 1926.1 MB)
2018-05-01 17:50:24.290  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.8 KB, free 1926.1 MB)
2018-05-01 17:50:24.290  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_68_piece0 in memory on 172.21.241.193:58620 (size: 5.8 KB, free: 1926.1 MB)
2018-05-01 17:50:24.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 68 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.291  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 461 (MapPartitionsRDD[266] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.291  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 461.0 with 1 tasks
2018-05-01 17:50:24.291  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 461.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:24.291  INFO 16044 --- [Executor task launch worker for task 202] org.apache.spark.executor.Executor       : Running task 0.0 in stage 461.0 (TID 202)
2018-05-01 17:50:24.293  INFO 16044 --- [Executor task launch worker for task 202] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:24.293  INFO 16044 --- [Executor task launch worker for task 202] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:24.293  INFO 16044 --- [Executor task launch worker for task 202] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:24.614  INFO 16044 --- [Executor task launch worker for task 202] o.a.spark.storage.memory.MemoryStore     : Block rdd_265_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:50:24.614  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_265_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:24.617  INFO 16044 --- [Executor task launch worker for task 202] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 461.0 (TID 202). 2595 bytes result sent to driver
2018-05-01 17:50:24.618  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 461.0 (TID 202) in 327 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.618  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 461.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.618  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 461 (aggregate at ALS.scala:1491) finished in 0.327 s
2018-05-01 17:50:24.618  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 37 finished: aggregate at ALS.scala:1491, took 0.444691 s
2018-05-01 17:50:24.635  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 254 from persistence list
2018-05-01 17:50:24.636  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 254
2018-05-01 17:50:24.641  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 270 (flatMap at ALS.scala:1433)
2018-05-01 17:50:24.642  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 38 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:24.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 468 (aggregate at ALS.scala:1491)
2018-05-01 17:50:24.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 463, ShuffleMapStage 467)
2018-05-01 17:50:24.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 467)
2018-05-01 17:50:24.643  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 467 (MapPartitionsRDD[270] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:24.644  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_69 stored as values in memory (estimated size 11.8 KB, free 1925.7 MB)
2018-05-01 17:50:24.645  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.7 KB, free 1925.7 MB)
2018-05-01 17:50:24.646  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_69_piece0 in memory on 172.21.241.193:58620 (size: 5.7 KB, free: 1925.7 MB)
2018-05-01 17:50:24.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 69 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.646  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 467 (MapPartitionsRDD[270] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.646  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 467.0 with 1 tasks
2018-05-01 17:50:24.647  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 467.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:24.647  INFO 16044 --- [Executor task launch worker for task 203] org.apache.spark.executor.Executor       : Running task 0.0 in stage 467.0 (TID 203)
2018-05-01 17:50:24.649  INFO 16044 --- [Executor task launch worker for task 203] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:24.649  INFO 16044 --- [Executor task launch worker for task 203] org.apache.spark.storage.BlockManager    : Found block rdd_265_0 locally
2018-05-01 17:50:24.683  INFO 16044 --- [Executor task launch worker for task 203] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 467.0 (TID 203). 1069 bytes result sent to driver
2018-05-01 17:50:24.683  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 467.0 (TID 203) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.683  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 467.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.683  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 467 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 17:50:24.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:24.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:24.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 468)
2018-05-01 17:50:24.684  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:24.685  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 468 (MapPartitionsRDD[276] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:24.686  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_70 stored as values in memory (estimated size 14.3 KB, free 1925.6 MB)
2018-05-01 17:50:24.687  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_70_piece0 stored as bytes in memory (estimated size 6.6 KB, free 1925.6 MB)
2018-05-01 17:50:24.688  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_70_piece0 in memory on 172.21.241.193:58620 (size: 6.6 KB, free: 1925.7 MB)
2018-05-01 17:50:24.688  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 70 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.688  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 468 (MapPartitionsRDD[276] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.688  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 468.0 with 1 tasks
2018-05-01 17:50:24.689  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 468.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:24.689  INFO 16044 --- [Executor task launch worker for task 204] org.apache.spark.executor.Executor       : Running task 0.0 in stage 468.0 (TID 204)
2018-05-01 17:50:24.691  INFO 16044 --- [Executor task launch worker for task 204] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:24.691  INFO 16044 --- [Executor task launch worker for task 204] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:24.691  INFO 16044 --- [Executor task launch worker for task 204] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:24.953  INFO 16044 --- [Executor task launch worker for task 204] o.a.spark.storage.memory.MemoryStore     : Block rdd_275_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:50:24.953  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_275_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:50:24.955  INFO 16044 --- [Executor task launch worker for task 204] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 468.0 (TID 204). 2595 bytes result sent to driver
2018-05-01 17:50:24.956  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 468.0 (TID 204) in 267 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:24.956  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 468.0, whose tasks have all completed, from pool 
2018-05-01 17:50:24.956  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 468 (aggregate at ALS.scala:1491) finished in 0.268 s
2018-05-01 17:50:24.956  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 38 finished: aggregate at ALS.scala:1491, took 0.315188 s
2018-05-01 17:50:24.973  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 265 from persistence list
2018-05-01 17:50:24.974  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 265
2018-05-01 17:50:24.979  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:24.979  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:24.979  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:24.980  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 280 (flatMap at ALS.scala:1433)
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 39 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 476 (aggregate at ALS.scala:1491)
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 473, ShuffleMapStage 475)
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 475)
2018-05-01 17:50:24.981  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 475 (MapPartitionsRDD[280] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:24.983  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_71 stored as values in memory (estimated size 13.4 KB, free 1926.0 MB)
2018-05-01 17:50:24.984  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_71_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1926.0 MB)
2018-05-01 17:50:24.984  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_71_piece0 in memory on 172.21.241.193:58620 (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:50:24.984  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 71 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:24.985  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 475 (MapPartitionsRDD[280] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:24.985  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 475.0 with 1 tasks
2018-05-01 17:50:24.985  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 475.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:24.985  INFO 16044 --- [Executor task launch worker for task 205] org.apache.spark.executor.Executor       : Running task 0.0 in stage 475.0 (TID 205)
2018-05-01 17:50:24.987  INFO 16044 --- [Executor task launch worker for task 205] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:24.987  INFO 16044 --- [Executor task launch worker for task 205] org.apache.spark.storage.BlockManager    : Found block rdd_275_0 locally
2018-05-01 17:50:25.029  INFO 16044 --- [Executor task launch worker for task 205] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 475.0 (TID 205). 1069 bytes result sent to driver
2018-05-01 17:50:25.029  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 475.0 (TID 205) in 44 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.029  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 475.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 475 (flatMap at ALS.scala:1433) finished in 0.045 s
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 476)
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:25.030  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 476 (MapPartitionsRDD[286] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:25.031  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_72 stored as values in memory (estimated size 15.8 KB, free 1926.0 MB)
2018-05-01 17:50:25.033  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_72_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1926.0 MB)
2018-05-01 17:50:25.033  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_72_piece0 in memory on 172.21.241.193:58620 (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 17:50:25.033  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 72 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.033  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 476 (MapPartitionsRDD[286] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.033  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 476.0 with 1 tasks
2018-05-01 17:50:25.034  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 476.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:25.035  INFO 16044 --- [Executor task launch worker for task 206] org.apache.spark.executor.Executor       : Running task 0.0 in stage 476.0 (TID 206)
2018-05-01 17:50:25.037  INFO 16044 --- [Executor task launch worker for task 206] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:25.037  INFO 16044 --- [Executor task launch worker for task 206] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:25.037  INFO 16044 --- [Executor task launch worker for task 206] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:25.391  INFO 16044 --- [Executor task launch worker for task 206] o.a.spark.storage.memory.MemoryStore     : Block rdd_285_0 stored as values in memory (estimated size 820.5 KB, free 1925.2 MB)
2018-05-01 17:50:25.391  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_285_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:25.394  INFO 16044 --- [Executor task launch worker for task 206] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 476.0 (TID 206). 2595 bytes result sent to driver
2018-05-01 17:50:25.395  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 476.0 (TID 206) in 361 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.395  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 476.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.395  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 476 (aggregate at ALS.scala:1491) finished in 0.361 s
2018-05-01 17:50:25.396  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 39 finished: aggregate at ALS.scala:1491, took 0.416853 s
2018-05-01 17:50:25.418  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 275 from persistence list
2018-05-01 17:50:25.419  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 275
2018-05-01 17:50:25.423  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:25.424  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:25.424  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:25.425  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 290 (flatMap at ALS.scala:1433)
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 40 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 485 (aggregate at ALS.scala:1491)
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 484, ShuffleMapStage 478)
2018-05-01 17:50:25.426  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 484)
2018-05-01 17:50:25.427  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 484 (MapPartitionsRDD[290] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:25.428  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_73 stored as values in memory (estimated size 14.9 KB, free 1925.6 MB)
2018-05-01 17:50:25.429  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_73_piece0 stored as bytes in memory (estimated size 7.1 KB, free 1925.6 MB)
2018-05-01 17:50:25.429  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_73_piece0 in memory on 172.21.241.193:58620 (size: 7.1 KB, free: 1925.7 MB)
2018-05-01 17:50:25.429  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 73 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.429  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 484 (MapPartitionsRDD[290] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.429  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 484.0 with 1 tasks
2018-05-01 17:50:25.430  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 484.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:25.430  INFO 16044 --- [Executor task launch worker for task 207] org.apache.spark.executor.Executor       : Running task 0.0 in stage 484.0 (TID 207)
2018-05-01 17:50:25.431  INFO 16044 --- [Executor task launch worker for task 207] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:25.432  INFO 16044 --- [Executor task launch worker for task 207] org.apache.spark.storage.BlockManager    : Found block rdd_285_0 locally
2018-05-01 17:50:25.475  INFO 16044 --- [Executor task launch worker for task 207] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 484.0 (TID 207). 1069 bytes result sent to driver
2018-05-01 17:50:25.475  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 484.0 (TID 207) in 45 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.475  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 484.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.475  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 484 (flatMap at ALS.scala:1433) finished in 0.045 s
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 485)
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:25.476  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 485 (MapPartitionsRDD[296] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:25.478  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_74 stored as values in memory (estimated size 17.4 KB, free 1925.6 MB)
2018-05-01 17:50:25.479  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_74_piece0 stored as bytes in memory (estimated size 7.9 KB, free 1925.6 MB)
2018-05-01 17:50:25.479  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_74_piece0 in memory on 172.21.241.193:58620 (size: 7.9 KB, free: 1925.7 MB)
2018-05-01 17:50:25.479  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 74 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.480  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 485 (MapPartitionsRDD[296] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.480  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 485.0 with 1 tasks
2018-05-01 17:50:25.481  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 485.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:25.481  INFO 16044 --- [Executor task launch worker for task 208] org.apache.spark.executor.Executor       : Running task 0.0 in stage 485.0 (TID 208)
2018-05-01 17:50:25.484  INFO 16044 --- [Executor task launch worker for task 208] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:25.484  INFO 16044 --- [Executor task launch worker for task 208] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:25.484  INFO 16044 --- [Executor task launch worker for task 208] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:25.807  INFO 16044 --- [Executor task launch worker for task 208] o.a.spark.storage.memory.MemoryStore     : Block rdd_295_0 stored as values in memory (estimated size 416.2 KB, free 1925.1 MB)
2018-05-01 17:50:25.807  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_295_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:50:25.809  INFO 16044 --- [Executor task launch worker for task 208] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 485.0 (TID 208). 2595 bytes result sent to driver
2018-05-01 17:50:25.810  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 485.0 (TID 208) in 329 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.810  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 485.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.810  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 485 (aggregate at ALS.scala:1491) finished in 0.329 s
2018-05-01 17:50:25.810  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 40 finished: aggregate at ALS.scala:1491, took 0.386827 s
2018-05-01 17:50:25.828  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 285 from persistence list
2018-05-01 17:50:25.828  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 285
2018-05-01 17:50:25.832  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:25.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:25.834  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:25.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:25.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:25.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 300 (flatMap at ALS.scala:1433)
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 41 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 495 (aggregate at ALS.scala:1491)
2018-05-01 17:50:25.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 494, ShuffleMapStage 487)
2018-05-01 17:50:25.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 494)
2018-05-01 17:50:25.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 494 (MapPartitionsRDD[300] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:25.838  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_75 stored as values in memory (estimated size 16.5 KB, free 1925.9 MB)
2018-05-01 17:50:25.839  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_75_piece0 stored as bytes in memory (estimated size 7.8 KB, free 1925.9 MB)
2018-05-01 17:50:25.839  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_75_piece0 in memory on 172.21.241.193:58620 (size: 7.8 KB, free: 1926.1 MB)
2018-05-01 17:50:25.840  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 75 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.840  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 494 (MapPartitionsRDD[300] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.840  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 494.0 with 1 tasks
2018-05-01 17:50:25.840  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 494.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:25.840  INFO 16044 --- [Executor task launch worker for task 209] org.apache.spark.executor.Executor       : Running task 0.0 in stage 494.0 (TID 209)
2018-05-01 17:50:25.842  INFO 16044 --- [Executor task launch worker for task 209] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:25.842  INFO 16044 --- [Executor task launch worker for task 209] org.apache.spark.storage.BlockManager    : Found block rdd_295_0 locally
2018-05-01 17:50:25.867  INFO 16044 --- [Executor task launch worker for task 209] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 494.0 (TID 209). 1069 bytes result sent to driver
2018-05-01 17:50:25.868  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 494.0 (TID 209) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:25.868  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 494.0, whose tasks have all completed, from pool 
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 494 (flatMap at ALS.scala:1433) finished in 0.028 s
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 495)
2018-05-01 17:50:25.868  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:25.869  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 495 (MapPartitionsRDD[306] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:25.870  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_76 stored as values in memory (estimated size 18.9 KB, free 1925.9 MB)
2018-05-01 17:50:25.871  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_76_piece0 stored as bytes in memory (estimated size 8.6 KB, free 1925.9 MB)
2018-05-01 17:50:25.871  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_76_piece0 in memory on 172.21.241.193:58620 (size: 8.6 KB, free: 1926.1 MB)
2018-05-01 17:50:25.871  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 76 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:25.871  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 495 (MapPartitionsRDD[306] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:25.871  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 495.0 with 1 tasks
2018-05-01 17:50:25.872  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 495.0 (TID 210, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:25.872  INFO 16044 --- [Executor task launch worker for task 210] org.apache.spark.executor.Executor       : Running task 0.0 in stage 495.0 (TID 210)
2018-05-01 17:50:25.873  INFO 16044 --- [Executor task launch worker for task 210] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:25.874  INFO 16044 --- [Executor task launch worker for task 210] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:25.874  INFO 16044 --- [Executor task launch worker for task 210] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:26.164  INFO 16044 --- [Executor task launch worker for task 210] o.a.spark.storage.memory.MemoryStore     : Block rdd_305_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 17:50:26.165  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_305_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:26.168  INFO 16044 --- [Executor task launch worker for task 210] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 495.0 (TID 210). 2595 bytes result sent to driver
2018-05-01 17:50:26.168  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 495.0 (TID 210) in 297 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.168  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 495.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 495 (aggregate at ALS.scala:1491) finished in 0.298 s
2018-05-01 17:50:26.169  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 41 finished: aggregate at ALS.scala:1491, took 0.336959 s
2018-05-01 17:50:26.184  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 295 from persistence list
2018-05-01 17:50:26.184  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 295
2018-05-01 17:50:26.188  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:26.188  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:26.188  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:26.188  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:26.189  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:26.189  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:26.189  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:26.190  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 310 (flatMap at ALS.scala:1433)
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 42 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 506 (aggregate at ALS.scala:1491)
2018-05-01 17:50:26.191  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 497, ShuffleMapStage 505)
2018-05-01 17:50:26.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 505)
2018-05-01 17:50:26.192  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 505 (MapPartitionsRDD[310] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:26.193  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_77 stored as values in memory (estimated size 18.0 KB, free 1925.5 MB)
2018-05-01 17:50:26.194  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_77_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1925.5 MB)
2018-05-01 17:50:26.194  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_77_piece0 in memory on 172.21.241.193:58620 (size: 8.4 KB, free: 1925.7 MB)
2018-05-01 17:50:26.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 77 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.194  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 505 (MapPartitionsRDD[310] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.194  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 505.0 with 1 tasks
2018-05-01 17:50:26.195  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 505.0 (TID 211, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:26.195  INFO 16044 --- [Executor task launch worker for task 211] org.apache.spark.executor.Executor       : Running task 0.0 in stage 505.0 (TID 211)
2018-05-01 17:50:26.197  INFO 16044 --- [Executor task launch worker for task 211] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:26.197  INFO 16044 --- [Executor task launch worker for task 211] org.apache.spark.storage.BlockManager    : Found block rdd_305_0 locally
2018-05-01 17:50:26.226  INFO 16044 --- [Executor task launch worker for task 211] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 505.0 (TID 211). 1069 bytes result sent to driver
2018-05-01 17:50:26.226  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 505.0 (TID 211) in 31 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.226  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 505.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 505 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 506)
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:26.227  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 506 (MapPartitionsRDD[316] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:26.228  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_78 stored as values in memory (estimated size 20.5 KB, free 1925.5 MB)
2018-05-01 17:50:26.229  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_78_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1925.4 MB)
2018-05-01 17:50:26.229  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_78_piece0 in memory on 172.21.241.193:58620 (size: 9.3 KB, free: 1925.7 MB)
2018-05-01 17:50:26.230  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 78 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.230  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 506 (MapPartitionsRDD[316] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.230  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 506.0 with 1 tasks
2018-05-01 17:50:26.230  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 506.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:26.230  INFO 16044 --- [Executor task launch worker for task 212] org.apache.spark.executor.Executor       : Running task 0.0 in stage 506.0 (TID 212)
2018-05-01 17:50:26.232  INFO 16044 --- [Executor task launch worker for task 212] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:26.233  INFO 16044 --- [Executor task launch worker for task 212] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:26.233  INFO 16044 --- [Executor task launch worker for task 212] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:26.493  INFO 16044 --- [Executor task launch worker for task 212] o.a.spark.storage.memory.MemoryStore     : Block rdd_315_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 17:50:26.494  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_315_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:50:26.496  INFO 16044 --- [Executor task launch worker for task 212] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 506.0 (TID 212). 2595 bytes result sent to driver
2018-05-01 17:50:26.496  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 506.0 (TID 212) in 266 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.496  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 506.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.497  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 506 (aggregate at ALS.scala:1491) finished in 0.266 s
2018-05-01 17:50:26.497  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 42 finished: aggregate at ALS.scala:1491, took 0.308628 s
2018-05-01 17:50:26.513  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 305 from persistence list
2018-05-01 17:50:26.514  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 305
2018-05-01 17:50:26.520  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:26.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:26.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:26.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:26.521  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:26.522  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 320 (flatMap at ALS.scala:1433)
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 43 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 518 (aggregate at ALS.scala:1491)
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 517, ShuffleMapStage 508)
2018-05-01 17:50:26.523  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 517)
2018-05-01 17:50:26.524  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 517 (MapPartitionsRDD[320] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:26.526  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_79 stored as values in memory (estimated size 19.6 KB, free 1925.8 MB)
2018-05-01 17:50:26.527  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_79_piece0 stored as bytes in memory (estimated size 9.1 KB, free 1925.8 MB)
2018-05-01 17:50:26.528  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_79_piece0 in memory on 172.21.241.193:58620 (size: 9.1 KB, free: 1926.0 MB)
2018-05-01 17:50:26.528  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 79 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.528  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 517 (MapPartitionsRDD[320] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.528  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 517.0 with 1 tasks
2018-05-01 17:50:26.529  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 517.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:26.529  INFO 16044 --- [Executor task launch worker for task 213] org.apache.spark.executor.Executor       : Running task 0.0 in stage 517.0 (TID 213)
2018-05-01 17:50:26.530  INFO 16044 --- [Executor task launch worker for task 213] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:26.531  INFO 16044 --- [Executor task launch worker for task 213] org.apache.spark.storage.BlockManager    : Found block rdd_315_0 locally
2018-05-01 17:50:26.582  INFO 16044 --- [Executor task launch worker for task 213] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 517.0 (TID 213). 1069 bytes result sent to driver
2018-05-01 17:50:26.583  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 517.0 (TID 213) in 54 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.583  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 517.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 517 (flatMap at ALS.scala:1433) finished in 0.055 s
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 518)
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:26.583  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 518 (MapPartitionsRDD[326] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:26.584  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_80 stored as values in memory (estimated size 22.0 KB, free 1925.8 MB)
2018-05-01 17:50:26.585  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_80_piece0 stored as bytes in memory (estimated size 9.8 KB, free 1925.8 MB)
2018-05-01 17:50:26.586  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_80_piece0 in memory on 172.21.241.193:58620 (size: 9.8 KB, free: 1926.0 MB)
2018-05-01 17:50:26.586  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 80 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.586  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 518 (MapPartitionsRDD[326] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.586  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 518.0 with 1 tasks
2018-05-01 17:50:26.586  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 518.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:26.587  INFO 16044 --- [Executor task launch worker for task 214] org.apache.spark.executor.Executor       : Running task 0.0 in stage 518.0 (TID 214)
2018-05-01 17:50:26.588  INFO 16044 --- [Executor task launch worker for task 214] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:26.588  INFO 16044 --- [Executor task launch worker for task 214] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:26.588  INFO 16044 --- [Executor task launch worker for task 214] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:26.898  INFO 16044 --- [Executor task launch worker for task 214] o.a.spark.storage.memory.MemoryStore     : Block rdd_325_0 stored as values in memory (estimated size 820.5 KB, free 1925.0 MB)
2018-05-01 17:50:26.898  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_325_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:50:26.902  INFO 16044 --- [Executor task launch worker for task 214] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 518.0 (TID 214). 2595 bytes result sent to driver
2018-05-01 17:50:26.903  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 518.0 (TID 214) in 317 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.903  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 518.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.903  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 518 (aggregate at ALS.scala:1491) finished in 0.317 s
2018-05-01 17:50:26.904  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 43 finished: aggregate at ALS.scala:1491, took 0.383244 s
2018-05-01 17:50:26.919  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 315 from persistence list
2018-05-01 17:50:26.920  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 315
2018-05-01 17:50:26.925  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:26.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:26.925  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:26.926  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 330 (flatMap at ALS.scala:1433)
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 44 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 531 (aggregate at ALS.scala:1491)
2018-05-01 17:50:26.927  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 520, ShuffleMapStage 530)
2018-05-01 17:50:26.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 530)
2018-05-01 17:50:26.928  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 530 (MapPartitionsRDD[330] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:26.930  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_81 stored as values in memory (estimated size 21.1 KB, free 1925.4 MB)
2018-05-01 17:50:26.931  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_81_piece0 stored as bytes in memory (estimated size 9.7 KB, free 1925.4 MB)
2018-05-01 17:50:26.931  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_81_piece0 in memory on 172.21.241.193:58620 (size: 9.7 KB, free: 1925.6 MB)
2018-05-01 17:50:26.931  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 81 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.932  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 530 (MapPartitionsRDD[330] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.932  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 530.0 with 1 tasks
2018-05-01 17:50:26.932  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 530.0 (TID 215, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:26.934  INFO 16044 --- [Executor task launch worker for task 215] org.apache.spark.executor.Executor       : Running task 0.0 in stage 530.0 (TID 215)
2018-05-01 17:50:26.936  INFO 16044 --- [Executor task launch worker for task 215] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:26.936  INFO 16044 --- [Executor task launch worker for task 215] org.apache.spark.storage.BlockManager    : Found block rdd_325_0 locally
2018-05-01 17:50:26.972  INFO 16044 --- [Executor task launch worker for task 215] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 530.0 (TID 215). 1069 bytes result sent to driver
2018-05-01 17:50:26.972  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 530.0 (TID 215) in 40 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:26.972  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 530.0, whose tasks have all completed, from pool 
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 530 (flatMap at ALS.scala:1433) finished in 0.040 s
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 531)
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:26.973  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 531 (MapPartitionsRDD[336] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:26.975  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_82 stored as values in memory (estimated size 23.6 KB, free 1925.3 MB)
2018-05-01 17:50:26.976  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_82_piece0 stored as bytes in memory (estimated size 10.6 KB, free 1925.3 MB)
2018-05-01 17:50:26.976  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_82_piece0 in memory on 172.21.241.193:58620 (size: 10.6 KB, free: 1925.6 MB)
2018-05-01 17:50:26.977  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 82 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:26.977  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 531 (MapPartitionsRDD[336] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:26.977  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 531.0 with 1 tasks
2018-05-01 17:50:26.977  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 531.0 (TID 216, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:26.978  INFO 16044 --- [Executor task launch worker for task 216] org.apache.spark.executor.Executor       : Running task 0.0 in stage 531.0 (TID 216)
2018-05-01 17:50:26.981  INFO 16044 --- [Executor task launch worker for task 216] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:26.981  INFO 16044 --- [Executor task launch worker for task 216] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:26.981  INFO 16044 --- [Executor task launch worker for task 216] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:27.307  INFO 16044 --- [Executor task launch worker for task 216] o.a.spark.storage.memory.MemoryStore     : Block rdd_335_0 stored as values in memory (estimated size 416.2 KB, free 1924.9 MB)
2018-05-01 17:50:27.308  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added rdd_335_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:50:27.311  INFO 16044 --- [Executor task launch worker for task 216] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 531.0 (TID 216). 2638 bytes result sent to driver
2018-05-01 17:50:27.312  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 531.0 (TID 216) in 335 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:27.312  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 531.0, whose tasks have all completed, from pool 
2018-05-01 17:50:27.313  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 531 (aggregate at ALS.scala:1491) finished in 0.335 s
2018-05-01 17:50:27.313  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 44 finished: aggregate at ALS.scala:1491, took 0.388174 s
2018-05-01 17:50:27.335  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 325 from persistence list
2018-05-01 17:50:27.336  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 325
2018-05-01 17:50:27.340  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:27.340  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:27.341  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:27.342  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 340 (flatMap at ALS.scala:1433)
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 45 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 545 (aggregate at ALS.scala:1491)
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 544, ShuffleMapStage 536)
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 544)
2018-05-01 17:50:27.343  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 544 (MapPartitionsRDD[340] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:27.345  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_83 stored as values in memory (estimated size 22.7 KB, free 1925.7 MB)
2018-05-01 17:50:27.346  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_83_piece0 stored as bytes in memory (estimated size 10.4 KB, free 1925.7 MB)
2018-05-01 17:50:27.346  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_83_piece0 in memory on 172.21.241.193:58620 (size: 10.4 KB, free: 1926.0 MB)
2018-05-01 17:50:27.346  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 83 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:27.347  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 544 (MapPartitionsRDD[340] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:27.347  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 544.0 with 1 tasks
2018-05-01 17:50:27.347  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 544.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:27.347  INFO 16044 --- [Executor task launch worker for task 217] org.apache.spark.executor.Executor       : Running task 0.0 in stage 544.0 (TID 217)
2018-05-01 17:50:27.350  INFO 16044 --- [Executor task launch worker for task 217] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:27.350  INFO 16044 --- [Executor task launch worker for task 217] org.apache.spark.storage.BlockManager    : Found block rdd_335_0 locally
2018-05-01 17:50:27.392  INFO 16044 --- [Executor task launch worker for task 217] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 544.0 (TID 217). 1069 bytes result sent to driver
2018-05-01 17:50:27.392  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 544.0 (TID 217) in 45 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:27.392  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 544.0, whose tasks have all completed, from pool 
2018-05-01 17:50:27.392  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 544 (flatMap at ALS.scala:1433) finished in 0.045 s
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 545)
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:27.393  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 545 (MapPartitionsRDD[346] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:27.395  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_84 stored as values in memory (estimated size 25.1 KB, free 1925.7 MB)
2018-05-01 17:50:27.397  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_84_piece0 stored as bytes in memory (estimated size 11.1 KB, free 1925.7 MB)
2018-05-01 17:50:27.397  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_84_piece0 in memory on 172.21.241.193:58620 (size: 11.1 KB, free: 1926.0 MB)
2018-05-01 17:50:27.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 84 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:27.397  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 545 (MapPartitionsRDD[346] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:27.398  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 545.0 with 1 tasks
2018-05-01 17:50:27.398  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 545.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:27.398  INFO 16044 --- [Executor task launch worker for task 218] org.apache.spark.executor.Executor       : Running task 0.0 in stage 545.0 (TID 218)
2018-05-01 17:50:27.402  INFO 16044 --- [Executor task launch worker for task 218] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:27.402  INFO 16044 --- [Executor task launch worker for task 218] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:27.402  INFO 16044 --- [Executor task launch worker for task 218] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:27.767  INFO 16044 --- [Executor task launch worker for task 218] o.a.spark.storage.memory.MemoryStore     : Block rdd_345_0 stored as values in memory (estimated size 820.5 KB, free 1924.9 MB)
2018-05-01 17:50:27.767  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_345_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:50:27.772  INFO 16044 --- [Executor task launch worker for task 218] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 545.0 (TID 218). 2638 bytes result sent to driver
2018-05-01 17:50:27.772  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 545.0 (TID 218) in 374 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:27.772  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 545.0, whose tasks have all completed, from pool 
2018-05-01 17:50:27.773  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 545 (aggregate at ALS.scala:1491) finished in 0.375 s
2018-05-01 17:50:27.774  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 45 finished: aggregate at ALS.scala:1491, took 0.433616 s
2018-05-01 17:50:27.806  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 335 from persistence list
2018-05-01 17:50:27.807  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 335
2018-05-01 17:50:27.813  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:27.814  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:27.814  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:27.814  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:27.814  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:27.815  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:27.816  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:27.816  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:27.817  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 350 (flatMap at ALS.scala:1433)
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 46 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 560 (aggregate at ALS.scala:1491)
2018-05-01 17:50:27.818  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 547, ShuffleMapStage 559)
2018-05-01 17:50:27.819  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 559)
2018-05-01 17:50:27.819  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 559 (MapPartitionsRDD[350] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:27.820  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_85 stored as values in memory (estimated size 24.2 KB, free 1925.2 MB)
2018-05-01 17:50:27.821  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_85_piece0 stored as bytes in memory (estimated size 11.0 KB, free 1925.2 MB)
2018-05-01 17:50:27.821  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_85_piece0 in memory on 172.21.241.193:58620 (size: 11.0 KB, free: 1925.6 MB)
2018-05-01 17:50:27.822  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 85 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:27.822  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 559 (MapPartitionsRDD[350] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:27.822  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 559.0 with 1 tasks
2018-05-01 17:50:27.822  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 559.0 (TID 219, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:27.823  INFO 16044 --- [Executor task launch worker for task 219] org.apache.spark.executor.Executor       : Running task 0.0 in stage 559.0 (TID 219)
2018-05-01 17:50:27.824  INFO 16044 --- [Executor task launch worker for task 219] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:27.824  INFO 16044 --- [Executor task launch worker for task 219] org.apache.spark.storage.BlockManager    : Found block rdd_345_0 locally
2018-05-01 17:50:27.857  INFO 16044 --- [Executor task launch worker for task 219] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 559.0 (TID 219). 1069 bytes result sent to driver
2018-05-01 17:50:27.857  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 559.0 (TID 219) in 35 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:27.857  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 559.0, whose tasks have all completed, from pool 
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 559 (flatMap at ALS.scala:1433) finished in 0.035 s
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 560)
2018-05-01 17:50:27.857  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:27.858  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 560 (MapPartitionsRDD[356] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:27.860  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_86 stored as values in memory (estimated size 26.7 KB, free 1925.2 MB)
2018-05-01 17:50:27.860  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_86_piece0 stored as bytes in memory (estimated size 11.9 KB, free 1925.2 MB)
2018-05-01 17:50:27.861  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_86_piece0 in memory on 172.21.241.193:58620 (size: 11.9 KB, free: 1925.6 MB)
2018-05-01 17:50:27.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 86 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:27.861  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 560 (MapPartitionsRDD[356] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:27.861  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 560.0 with 1 tasks
2018-05-01 17:50:27.862  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 560.0 (TID 220, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:27.862  INFO 16044 --- [Executor task launch worker for task 220] org.apache.spark.executor.Executor       : Running task 0.0 in stage 560.0 (TID 220)
2018-05-01 17:50:27.863  INFO 16044 --- [Executor task launch worker for task 220] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:27.864  INFO 16044 --- [Executor task launch worker for task 220] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:27.864  INFO 16044 --- [Executor task launch worker for task 220] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:28.137  INFO 16044 --- [Executor task launch worker for task 220] o.a.spark.storage.memory.MemoryStore     : Block rdd_355_0 stored as values in memory (estimated size 416.2 KB, free 1924.8 MB)
2018-05-01 17:50:28.137  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_355_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:50:28.139  INFO 16044 --- [Executor task launch worker for task 220] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 560.0 (TID 220). 2595 bytes result sent to driver
2018-05-01 17:50:28.139  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 560.0 (TID 220) in 278 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.139  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 560.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.140  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 560 (aggregate at ALS.scala:1491) finished in 0.279 s
2018-05-01 17:50:28.140  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 46 finished: aggregate at ALS.scala:1491, took 0.326748 s
2018-05-01 17:50:28.155  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 345 from persistence list
2018-05-01 17:50:28.155  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 345
2018-05-01 17:50:28.160  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:28.160  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:28.160  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:28.161  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:28.161  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:28.163  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:28.163  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:28.163  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:28.164  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 360 (flatMap at ALS.scala:1433)
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 47 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 576 (aggregate at ALS.scala:1491)
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 575, ShuffleMapStage 565)
2018-05-01 17:50:28.165  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 575)
2018-05-01 17:50:28.166  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 575 (MapPartitionsRDD[360] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:28.168  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_87 stored as values in memory (estimated size 25.8 KB, free 1925.6 MB)
2018-05-01 17:50:28.169  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_87_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1925.5 MB)
2018-05-01 17:50:28.169  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_87_piece0 in memory on 172.21.241.193:58620 (size: 11.7 KB, free: 1926.0 MB)
2018-05-01 17:50:28.169  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 87 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.170  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 575 (MapPartitionsRDD[360] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.170  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 575.0 with 1 tasks
2018-05-01 17:50:28.170  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 575.0 (TID 221, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:28.170  INFO 16044 --- [Executor task launch worker for task 221] org.apache.spark.executor.Executor       : Running task 0.0 in stage 575.0 (TID 221)
2018-05-01 17:50:28.172  INFO 16044 --- [Executor task launch worker for task 221] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:28.172  INFO 16044 --- [Executor task launch worker for task 221] org.apache.spark.storage.BlockManager    : Found block rdd_355_0 locally
2018-05-01 17:50:28.207  INFO 16044 --- [Executor task launch worker for task 221] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 575.0 (TID 221). 1026 bytes result sent to driver
2018-05-01 17:50:28.207  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 575.0 (TID 221) in 37 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.207  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 575.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 575 (flatMap at ALS.scala:1433) finished in 0.037 s
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 576)
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:28.208  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 576 (MapPartitionsRDD[366] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:28.210  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_88 stored as values in memory (estimated size 28.2 KB, free 1925.5 MB)
2018-05-01 17:50:28.210  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_88_piece0 stored as bytes in memory (estimated size 12.5 KB, free 1925.5 MB)
2018-05-01 17:50:28.211  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_88_piece0 in memory on 172.21.241.193:58620 (size: 12.5 KB, free: 1925.9 MB)
2018-05-01 17:50:28.212  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 88 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.212  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 576 (MapPartitionsRDD[366] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.212  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 576.0 with 1 tasks
2018-05-01 17:50:28.212  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 576.0 (TID 222, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:28.213  INFO 16044 --- [Executor task launch worker for task 222] org.apache.spark.executor.Executor       : Running task 0.0 in stage 576.0 (TID 222)
2018-05-01 17:50:28.214  INFO 16044 --- [Executor task launch worker for task 222] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:28.214  INFO 16044 --- [Executor task launch worker for task 222] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:28.215  INFO 16044 --- [Executor task launch worker for task 222] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:50:28.515  INFO 16044 --- [Executor task launch worker for task 222] o.a.spark.storage.memory.MemoryStore     : Block rdd_365_0 stored as values in memory (estimated size 820.5 KB, free 1924.7 MB)
2018-05-01 17:50:28.516  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_365_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:50:28.519  INFO 16044 --- [Executor task launch worker for task 222] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 576.0 (TID 222). 2638 bytes result sent to driver
2018-05-01 17:50:28.520  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 576.0 (TID 222) in 308 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.520  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 576.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.520  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 576 (aggregate at ALS.scala:1491) finished in 0.308 s
2018-05-01 17:50:28.520  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 47 finished: aggregate at ALS.scala:1491, took 0.360531 s
2018-05-01 17:50:28.539  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 355 from persistence list
2018-05-01 17:50:28.539  INFO 16044 --- [block-manager-slave-async-thread-pool-2] org.apache.spark.storage.BlockManager    : Removing RDD 355
2018-05-01 17:50:28.543  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:28.543  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:28.544  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:28.545  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 370 (flatMap at ALS.scala:1433)
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 48 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 593 (aggregate at ALS.scala:1491)
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 592, ShuffleMapStage 578)
2018-05-01 17:50:28.546  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 592)
2018-05-01 17:50:28.547  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 592 (MapPartitionsRDD[370] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:28.548  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_89 stored as values in memory (estimated size 27.3 KB, free 1925.1 MB)
2018-05-01 17:50:28.549  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_89_piece0 stored as bytes in memory (estimated size 12.4 KB, free 1925.1 MB)
2018-05-01 17:50:28.549  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_89_piece0 in memory on 172.21.241.193:58620 (size: 12.4 KB, free: 1925.5 MB)
2018-05-01 17:50:28.550  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 89 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.550  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 592 (MapPartitionsRDD[370] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.550  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 592.0 with 1 tasks
2018-05-01 17:50:28.551  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 592.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:28.551  INFO 16044 --- [Executor task launch worker for task 223] org.apache.spark.executor.Executor       : Running task 0.0 in stage 592.0 (TID 223)
2018-05-01 17:50:28.553  INFO 16044 --- [Executor task launch worker for task 223] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:28.553  INFO 16044 --- [Executor task launch worker for task 223] org.apache.spark.storage.BlockManager    : Found block rdd_365_0 locally
2018-05-01 17:50:28.588  INFO 16044 --- [Executor task launch worker for task 223] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 592.0 (TID 223). 1069 bytes result sent to driver
2018-05-01 17:50:28.588  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 592.0 (TID 223) in 38 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.588  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 592.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 592 (flatMap at ALS.scala:1433) finished in 0.038 s
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 593)
2018-05-01 17:50:28.588  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:28.589  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 593 (MapPartitionsRDD[376] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:28.590  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_90 stored as values in memory (estimated size 29.8 KB, free 1925.0 MB)
2018-05-01 17:50:28.591  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_90_piece0 stored as bytes in memory (estimated size 13.2 KB, free 1925.0 MB)
2018-05-01 17:50:28.591  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_90_piece0 in memory on 172.21.241.193:58620 (size: 13.2 KB, free: 1925.5 MB)
2018-05-01 17:50:28.591  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 90 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.591  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 593 (MapPartitionsRDD[376] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.591  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 593.0 with 1 tasks
2018-05-01 17:50:28.593  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 593.0 (TID 224, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:28.593  INFO 16044 --- [Executor task launch worker for task 224] org.apache.spark.executor.Executor       : Running task 0.0 in stage 593.0 (TID 224)
2018-05-01 17:50:28.595  INFO 16044 --- [Executor task launch worker for task 224] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:28.595  INFO 16044 --- [Executor task launch worker for task 224] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:28.595  INFO 16044 --- [Executor task launch worker for task 224] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:28.898  INFO 16044 --- [Executor task launch worker for task 224] o.a.spark.storage.memory.MemoryStore     : Block rdd_375_0 stored as values in memory (estimated size 416.2 KB, free 1924.6 MB)
2018-05-01 17:50:28.898  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_375_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.1 MB)
2018-05-01 17:50:28.900  INFO 16044 --- [Executor task launch worker for task 224] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 593.0 (TID 224). 2595 bytes result sent to driver
2018-05-01 17:50:28.901  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 593.0 (TID 224) in 308 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:28.901  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 593.0, whose tasks have all completed, from pool 
2018-05-01 17:50:28.902  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 593 (aggregate at ALS.scala:1491) finished in 0.308 s
2018-05-01 17:50:28.902  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 48 finished: aggregate at ALS.scala:1491, took 0.358890 s
2018-05-01 17:50:28.923  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 365 from persistence list
2018-05-01 17:50:28.923  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 365
2018-05-01 17:50:28.985  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_79_piece0 on 172.21.241.193:58620 in memory (size: 9.1 KB, free: 1925.9 MB)
2018-05-01 17:50:28.985  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:28.985  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_64_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1925.9 MB)
2018-05-01 17:50:28.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:28.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:28.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:28.986  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_75_piece0 on 172.21.241.193:58620 in memory (size: 7.8 KB, free: 1925.9 MB)
2018-05-01 17:50:28.986  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:28.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:28.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:28.987  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_89_piece0 on 172.21.241.193:58620 in memory (size: 12.4 KB, free: 1926.0 MB)
2018-05-01 17:50:28.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:28.987  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:28.988  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_84_piece0 on 172.21.241.193:58620 in memory (size: 11.1 KB, free: 1926.0 MB)
2018-05-01 17:50:28.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:28.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:28.988  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:28.988  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_70_piece0 on 172.21.241.193:58620 in memory (size: 6.6 KB, free: 1926.0 MB)
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_88_piece0 on 172.21.241.193:58620 in memory (size: 12.5 KB, free: 1926.0 MB)
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_67_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1926.0 MB)
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:28.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 380 (flatMap at ALS.scala:1433)
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 49 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 611 (aggregate at ALS.scala:1491)
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 610, ShuffleMapStage 598)
2018-05-01 17:50:28.992  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_76_piece0 on 172.21.241.193:58620 in memory (size: 8.6 KB, free: 1926.0 MB)
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 610)
2018-05-01 17:50:28.992  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 610 (MapPartitionsRDD[380] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:28.992  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_83_piece0 on 172.21.241.193:58620 in memory (size: 10.4 KB, free: 1926.0 MB)
2018-05-01 17:50:28.993  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_78_piece0 on 172.21.241.193:58620 in memory (size: 9.3 KB, free: 1926.0 MB)
2018-05-01 17:50:28.993  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_77_piece0 on 172.21.241.193:58620 in memory (size: 8.4 KB, free: 1926.0 MB)
2018-05-01 17:50:28.994  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_68_piece0 on 172.21.241.193:58620 in memory (size: 5.8 KB, free: 1926.0 MB)
2018-05-01 17:50:28.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_91 stored as values in memory (estimated size 28.9 KB, free 1925.7 MB)
2018-05-01 17:50:28.995  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_85_piece0 on 172.21.241.193:58620 in memory (size: 11.0 KB, free: 1926.0 MB)
2018-05-01 17:50:28.995  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_91_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1925.8 MB)
2018-05-01 17:50:28.995  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_82_piece0 on 172.21.241.193:58620 in memory (size: 10.6 KB, free: 1926.1 MB)
2018-05-01 17:50:28.996  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_91_piece0 in memory on 172.21.241.193:58620 (size: 13.0 KB, free: 1926.0 MB)
2018-05-01 17:50:28.996  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 91 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:28.996  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_65_piece0 on 172.21.241.193:58620 in memory (size: 4.3 KB, free: 1926.0 MB)
2018-05-01 17:50:28.996  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 610 (MapPartitionsRDD[380] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:28.996  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 610.0 with 1 tasks
2018-05-01 17:50:28.996  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_86_piece0 on 172.21.241.193:58620 in memory (size: 11.9 KB, free: 1926.1 MB)
2018-05-01 17:50:28.997  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 610.0 (TID 225, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:28.997  INFO 16044 --- [Executor task launch worker for task 225] org.apache.spark.executor.Executor       : Running task 0.0 in stage 610.0 (TID 225)
2018-05-01 17:50:28.997  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_74_piece0 on 172.21.241.193:58620 in memory (size: 7.9 KB, free: 1926.1 MB)
2018-05-01 17:50:28.998  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_80_piece0 on 172.21.241.193:58620 in memory (size: 9.8 KB, free: 1926.1 MB)
2018-05-01 17:50:28.999  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_73_piece0 on 172.21.241.193:58620 in memory (size: 7.1 KB, free: 1926.1 MB)
2018-05-01 17:50:28.999  INFO 16044 --- [Executor task launch worker for task 225] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:28.999  INFO 16044 --- [Executor task launch worker for task 225] org.apache.spark.storage.BlockManager    : Found block rdd_375_0 locally
2018-05-01 17:50:29.000  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_66_piece0 on 172.21.241.193:58620 in memory (size: 4.0 KB, free: 1926.1 MB)
2018-05-01 17:50:29.001  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_72_piece0 on 172.21.241.193:58620 in memory (size: 7.3 KB, free: 1926.1 MB)
2018-05-01 17:50:29.002  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_81_piece0 on 172.21.241.193:58620 in memory (size: 9.7 KB, free: 1926.1 MB)
2018-05-01 17:50:29.002  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_90_piece0 on 172.21.241.193:58620 in memory (size: 13.2 KB, free: 1926.1 MB)
2018-05-01 17:50:29.002  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_87_piece0 on 172.21.241.193:58620 in memory (size: 11.7 KB, free: 1926.1 MB)
2018-05-01 17:50:29.003  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_71_piece0 on 172.21.241.193:58620 in memory (size: 6.4 KB, free: 1926.1 MB)
2018-05-01 17:50:29.003  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_69_piece0 on 172.21.241.193:58620 in memory (size: 5.7 KB, free: 1926.1 MB)
2018-05-01 17:50:29.025  INFO 16044 --- [Executor task launch worker for task 225] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 610.0 (TID 225). 1069 bytes result sent to driver
2018-05-01 17:50:29.025  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 610.0 (TID 225) in 28 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.025  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 610.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 610 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 611)
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:29.026  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 611 (MapPartitionsRDD[386] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:29.027  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_92 stored as values in memory (estimated size 31.3 KB, free 1926.1 MB)
2018-05-01 17:50:29.028  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_92_piece0 stored as bytes in memory (estimated size 13.9 KB, free 1926.1 MB)
2018-05-01 17:50:29.028  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_92_piece0 in memory on 172.21.241.193:58620 (size: 13.9 KB, free: 1926.1 MB)
2018-05-01 17:50:29.029  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 92 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.029  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 611 (MapPartitionsRDD[386] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.029  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 611.0 with 1 tasks
2018-05-01 17:50:29.029  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 611.0 (TID 226, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:29.029  INFO 16044 --- [Executor task launch worker for task 226] org.apache.spark.executor.Executor       : Running task 0.0 in stage 611.0 (TID 226)
2018-05-01 17:50:29.032  INFO 16044 --- [Executor task launch worker for task 226] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:29.032  INFO 16044 --- [Executor task launch worker for task 226] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:29.032  INFO 16044 --- [Executor task launch worker for task 226] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:29.301  INFO 16044 --- [Executor task launch worker for task 226] o.a.spark.storage.memory.MemoryStore     : Block rdd_385_0 stored as values in memory (estimated size 820.5 KB, free 1925.3 MB)
2018-05-01 17:50:29.301  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added rdd_385_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:29.305  INFO 16044 --- [Executor task launch worker for task 226] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 611.0 (TID 226). 2595 bytes result sent to driver
2018-05-01 17:50:29.305  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 611.0 (TID 226) in 276 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.305  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 611.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.306  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 611 (aggregate at ALS.scala:1491) finished in 0.276 s
2018-05-01 17:50:29.306  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 49 finished: aggregate at ALS.scala:1491, took 0.320448 s
2018-05-01 17:50:29.320  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 375 from persistence list
2018-05-01 17:50:29.321  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 375
2018-05-01 17:50:29.325  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:29.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:29.325  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:29.326  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:29.327  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 390 (flatMap at ALS.scala:1433)
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 50 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 630 (aggregate at ALS.scala:1491)
2018-05-01 17:50:29.328  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 629, ShuffleMapStage 613)
2018-05-01 17:50:29.329  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 629)
2018-05-01 17:50:29.329  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 629 (MapPartitionsRDD[390] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:29.330  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_93 stored as values in memory (estimated size 30.4 KB, free 1925.6 MB)
2018-05-01 17:50:29.332  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_93_piece0 stored as bytes in memory (estimated size 13.6 KB, free 1925.6 MB)
2018-05-01 17:50:29.332  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_93_piece0 in memory on 172.21.241.193:58620 (size: 13.6 KB, free: 1925.7 MB)
2018-05-01 17:50:29.333  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 93 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.333  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 629 (MapPartitionsRDD[390] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.333  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 629.0 with 1 tasks
2018-05-01 17:50:29.333  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 629.0 (TID 227, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:29.333  INFO 16044 --- [Executor task launch worker for task 227] org.apache.spark.executor.Executor       : Running task 0.0 in stage 629.0 (TID 227)
2018-05-01 17:50:29.336  INFO 16044 --- [Executor task launch worker for task 227] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:29.336  INFO 16044 --- [Executor task launch worker for task 227] org.apache.spark.storage.BlockManager    : Found block rdd_385_0 locally
2018-05-01 17:50:29.365  INFO 16044 --- [Executor task launch worker for task 227] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 629.0 (TID 227). 1069 bytes result sent to driver
2018-05-01 17:50:29.365  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 629.0 (TID 227) in 32 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.365  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 629.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.365  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 629 (flatMap at ALS.scala:1433) finished in 0.032 s
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 630)
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:29.366  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 630 (MapPartitionsRDD[396] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:29.368  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_94 stored as values in memory (estimated size 32.9 KB, free 1925.6 MB)
2018-05-01 17:50:29.369  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_94_piece0 stored as bytes in memory (estimated size 14.6 KB, free 1925.6 MB)
2018-05-01 17:50:29.369  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_94_piece0 in memory on 172.21.241.193:58620 (size: 14.6 KB, free: 1925.7 MB)
2018-05-01 17:50:29.369  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 94 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.370  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 630 (MapPartitionsRDD[396] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.370  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 630.0 with 1 tasks
2018-05-01 17:50:29.370  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 630.0 (TID 228, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:29.370  INFO 16044 --- [Executor task launch worker for task 228] org.apache.spark.executor.Executor       : Running task 0.0 in stage 630.0 (TID 228)
2018-05-01 17:50:29.372  INFO 16044 --- [Executor task launch worker for task 228] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:29.372  INFO 16044 --- [Executor task launch worker for task 228] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:29.372  INFO 16044 --- [Executor task launch worker for task 228] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:29.636  INFO 16044 --- [Executor task launch worker for task 228] o.a.spark.storage.memory.MemoryStore     : Block rdd_395_0 stored as values in memory (estimated size 416.2 KB, free 1925.2 MB)
2018-05-01 17:50:29.636  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added rdd_395_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.3 MB)
2018-05-01 17:50:29.638  INFO 16044 --- [Executor task launch worker for task 228] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 630.0 (TID 228). 2595 bytes result sent to driver
2018-05-01 17:50:29.639  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 630.0 (TID 228) in 269 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.639  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 630.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.639  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 630 (aggregate at ALS.scala:1491) finished in 0.269 s
2018-05-01 17:50:29.639  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 50 finished: aggregate at ALS.scala:1491, took 0.314395 s
2018-05-01 17:50:29.656  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 385 from persistence list
2018-05-01 17:50:29.656  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 385
2018-05-01 17:50:29.660  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:29.661  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:29.662  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:29.663  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 400 (flatMap at ALS.scala:1433)
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 51 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 650 (aggregate at ALS.scala:1491)
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 649, ShuffleMapStage 635)
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 649)
2018-05-01 17:50:29.664  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 649 (MapPartitionsRDD[400] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:29.667  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_95 stored as values in memory (estimated size 32.0 KB, free 1925.9 MB)
2018-05-01 17:50:29.669  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_95_piece0 stored as bytes in memory (estimated size 14.4 KB, free 1925.9 MB)
2018-05-01 17:50:29.670  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_95_piece0 in memory on 172.21.241.193:58620 (size: 14.4 KB, free: 1926.1 MB)
2018-05-01 17:50:29.670  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 95 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.670  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 649 (MapPartitionsRDD[400] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.670  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 649.0 with 1 tasks
2018-05-01 17:50:29.671  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 649.0 (TID 229, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:29.671  INFO 16044 --- [Executor task launch worker for task 229] org.apache.spark.executor.Executor       : Running task 0.0 in stage 649.0 (TID 229)
2018-05-01 17:50:29.673  INFO 16044 --- [Executor task launch worker for task 229] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:29.673  INFO 16044 --- [Executor task launch worker for task 229] org.apache.spark.storage.BlockManager    : Found block rdd_395_0 locally
2018-05-01 17:50:29.699  INFO 16044 --- [Executor task launch worker for task 229] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 649.0 (TID 229). 1069 bytes result sent to driver
2018-05-01 17:50:29.700  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 649.0 (TID 229) in 30 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:29.700  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 649.0, whose tasks have all completed, from pool 
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 649 (flatMap at ALS.scala:1433) finished in 0.030 s
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 650)
2018-05-01 17:50:29.700  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:29.701  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 650 (MapPartitionsRDD[406] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:29.703  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_96 stored as values in memory (estimated size 34.4 KB, free 1925.9 MB)
2018-05-01 17:50:29.705  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_96_piece0 stored as bytes in memory (estimated size 15.5 KB, free 1925.9 MB)
2018-05-01 17:50:29.705  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_96_piece0 in memory on 172.21.241.193:58620 (size: 15.5 KB, free: 1926.1 MB)
2018-05-01 17:50:29.705  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 96 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:29.706  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 650 (MapPartitionsRDD[406] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:29.706  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 650.0 with 1 tasks
2018-05-01 17:50:29.706  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 650.0 (TID 230, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:29.706  INFO 16044 --- [Executor task launch worker for task 230] org.apache.spark.executor.Executor       : Running task 0.0 in stage 650.0 (TID 230)
2018-05-01 17:50:29.709  INFO 16044 --- [Executor task launch worker for task 230] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:29.709  INFO 16044 --- [Executor task launch worker for task 230] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:29.709  INFO 16044 --- [Executor task launch worker for task 230] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:30.010  INFO 16044 --- [Executor task launch worker for task 230] o.a.spark.storage.memory.MemoryStore     : Block rdd_405_0 stored as values in memory (estimated size 820.5 KB, free 1925.1 MB)
2018-05-01 17:50:30.010  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_405_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.3 MB)
2018-05-01 17:50:30.014  INFO 16044 --- [Executor task launch worker for task 230] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 650.0 (TID 230). 2595 bytes result sent to driver
2018-05-01 17:50:30.015  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 650.0 (TID 230) in 309 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.015  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 650.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.015  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 650 (aggregate at ALS.scala:1491) finished in 0.309 s
2018-05-01 17:50:30.016  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 51 finished: aggregate at ALS.scala:1491, took 0.355234 s
2018-05-01 17:50:30.040  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 395 from persistence list
2018-05-01 17:50:30.040  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 395
2018-05-01 17:50:30.047  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:30.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:30.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:30.048  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:30.049  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:30.049  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:30.049  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:30.049  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:30.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:30.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:30.050  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:30.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:30.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:30.051  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:30.052  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 410 (flatMap at ALS.scala:1433)
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 52 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 671 (aggregate at ALS.scala:1491)
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 670, ShuffleMapStage 652)
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 670)
2018-05-01 17:50:30.053  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 670 (MapPartitionsRDD[410] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:30.057  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_97 stored as values in memory (estimated size 33.5 KB, free 1925.4 MB)
2018-05-01 17:50:30.058  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_97_piece0 stored as bytes in memory (estimated size 15.3 KB, free 1925.4 MB)
2018-05-01 17:50:30.058  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_97_piece0 in memory on 172.21.241.193:58620 (size: 15.3 KB, free: 1925.7 MB)
2018-05-01 17:50:30.059  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 97 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.059  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 670 (MapPartitionsRDD[410] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.059  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 670.0 with 1 tasks
2018-05-01 17:50:30.059  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 670.0 (TID 231, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:30.060  INFO 16044 --- [Executor task launch worker for task 231] org.apache.spark.executor.Executor       : Running task 0.0 in stage 670.0 (TID 231)
2018-05-01 17:50:30.062  INFO 16044 --- [Executor task launch worker for task 231] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:30.063  INFO 16044 --- [Executor task launch worker for task 231] org.apache.spark.storage.BlockManager    : Found block rdd_405_0 locally
2018-05-01 17:50:30.109  INFO 16044 --- [Executor task launch worker for task 231] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 670.0 (TID 231). 1069 bytes result sent to driver
2018-05-01 17:50:30.109  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 670.0 (TID 231) in 50 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.109  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 670.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.109  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 670 (flatMap at ALS.scala:1433) finished in 0.050 s
2018-05-01 17:50:30.109  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:30.110  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:30.110  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 671)
2018-05-01 17:50:30.110  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:30.110  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 671 (MapPartitionsRDD[416] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:30.112  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_98 stored as values in memory (estimated size 36.0 KB, free 1925.4 MB)
2018-05-01 17:50:30.113  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_98_piece0 stored as bytes in memory (estimated size 16.3 KB, free 1925.4 MB)
2018-05-01 17:50:30.113  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_98_piece0 in memory on 172.21.241.193:58620 (size: 16.3 KB, free: 1925.6 MB)
2018-05-01 17:50:30.113  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 98 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.113  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 671 (MapPartitionsRDD[416] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.113  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 671.0 with 1 tasks
2018-05-01 17:50:30.114  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 671.0 (TID 232, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:30.114  INFO 16044 --- [Executor task launch worker for task 232] org.apache.spark.executor.Executor       : Running task 0.0 in stage 671.0 (TID 232)
2018-05-01 17:50:30.117  INFO 16044 --- [Executor task launch worker for task 232] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:30.117  INFO 16044 --- [Executor task launch worker for task 232] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:30.117  INFO 16044 --- [Executor task launch worker for task 232] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:30.377  INFO 16044 --- [Executor task launch worker for task 232] o.a.spark.storage.memory.MemoryStore     : Block rdd_415_0 stored as values in memory (estimated size 416.2 KB, free 1925.0 MB)
2018-05-01 17:50:30.377  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_415_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:50:30.379  INFO 16044 --- [Executor task launch worker for task 232] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 671.0 (TID 232). 2595 bytes result sent to driver
2018-05-01 17:50:30.379  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 671.0 (TID 232) in 265 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.379  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 671.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.379  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 671 (aggregate at ALS.scala:1491) finished in 0.266 s
2018-05-01 17:50:30.380  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 52 finished: aggregate at ALS.scala:1491, took 0.332560 s
2018-05-01 17:50:30.394  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 405 from persistence list
2018-05-01 17:50:30.394  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 405
2018-05-01 17:50:30.398  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:30.399  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:30.400  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:30.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:30.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:30.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:30.401  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:30.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:30.402  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:30.404  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 420 (flatMap at ALS.scala:1433)
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 53 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 693 (aggregate at ALS.scala:1491)
2018-05-01 17:50:30.405  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 673, ShuffleMapStage 692)
2018-05-01 17:50:30.407  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 692)
2018-05-01 17:50:30.407  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 692 (MapPartitionsRDD[420] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:30.409  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_99 stored as values in memory (estimated size 35.1 KB, free 1925.7 MB)
2018-05-01 17:50:30.409  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_99_piece0 stored as bytes in memory (estimated size 15.9 KB, free 1925.7 MB)
2018-05-01 17:50:30.410  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_99_piece0 in memory on 172.21.241.193:58620 (size: 15.9 KB, free: 1926.0 MB)
2018-05-01 17:50:30.410  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 99 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.410  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 692 (MapPartitionsRDD[420] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.410  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 692.0 with 1 tasks
2018-05-01 17:50:30.411  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 692.0 (TID 233, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:30.411  INFO 16044 --- [Executor task launch worker for task 233] org.apache.spark.executor.Executor       : Running task 0.0 in stage 692.0 (TID 233)
2018-05-01 17:50:30.413  INFO 16044 --- [Executor task launch worker for task 233] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:30.413  INFO 16044 --- [Executor task launch worker for task 233] org.apache.spark.storage.BlockManager    : Found block rdd_415_0 locally
2018-05-01 17:50:30.438  INFO 16044 --- [Executor task launch worker for task 233] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 692.0 (TID 233). 1112 bytes result sent to driver
2018-05-01 17:50:30.438  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 692.0 (TID 233) in 27 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.438  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 692.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 692 (flatMap at ALS.scala:1433) finished in 0.028 s
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 693)
2018-05-01 17:50:30.438  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:30.439  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 693 (MapPartitionsRDD[426] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:30.440  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_100 stored as values in memory (estimated size 37.5 KB, free 1925.7 MB)
2018-05-01 17:50:30.441  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_100_piece0 stored as bytes in memory (estimated size 16.9 KB, free 1925.7 MB)
2018-05-01 17:50:30.442  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_100_piece0 in memory on 172.21.241.193:58620 (size: 16.9 KB, free: 1926.0 MB)
2018-05-01 17:50:30.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 100 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.442  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 693 (MapPartitionsRDD[426] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.442  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 693.0 with 1 tasks
2018-05-01 17:50:30.443  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 693.0 (TID 234, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:30.443  INFO 16044 --- [Executor task launch worker for task 234] org.apache.spark.executor.Executor       : Running task 0.0 in stage 693.0 (TID 234)
2018-05-01 17:50:30.445  INFO 16044 --- [Executor task launch worker for task 234] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:30.445  INFO 16044 --- [Executor task launch worker for task 234] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:30.445  INFO 16044 --- [Executor task launch worker for task 234] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:30.714  INFO 16044 --- [Executor task launch worker for task 234] o.a.spark.storage.memory.MemoryStore     : Block rdd_425_0 stored as values in memory (estimated size 820.5 KB, free 1924.9 MB)
2018-05-01 17:50:30.714  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added rdd_425_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.2 MB)
2018-05-01 17:50:30.718  INFO 16044 --- [Executor task launch worker for task 234] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 693.0 (TID 234). 2595 bytes result sent to driver
2018-05-01 17:50:30.719  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 693.0 (TID 234) in 277 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.719  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 693.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.719  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 693 (aggregate at ALS.scala:1491) finished in 0.277 s
2018-05-01 17:50:30.719  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 53 finished: aggregate at ALS.scala:1491, took 0.320889 s
2018-05-01 17:50:30.736  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 415 from persistence list
2018-05-01 17:50:30.736  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 415
2018-05-01 17:50:30.741  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:30.741  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:30.742  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:30.743  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:30.744  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:30.745  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:30.746  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:30.747  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 44 is 150 bytes
2018-05-01 17:50:30.747  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 430 (flatMap at ALS.scala:1433)
2018-05-01 17:50:30.748  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 54 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:30.748  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 716 (aggregate at ALS.scala:1491)
2018-05-01 17:50:30.748  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 695, ShuffleMapStage 715)
2018-05-01 17:50:30.749  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 715)
2018-05-01 17:50:30.749  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 715 (MapPartitionsRDD[430] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:30.752  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_101 stored as values in memory (estimated size 36.6 KB, free 1925.2 MB)
2018-05-01 17:50:30.753  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_101_piece0 stored as bytes in memory (estimated size 16.6 KB, free 1925.2 MB)
2018-05-01 17:50:30.753  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_101_piece0 in memory on 172.21.241.193:58620 (size: 16.6 KB, free: 1925.6 MB)
2018-05-01 17:50:30.753  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 101 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.753  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 715 (MapPartitionsRDD[430] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.753  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 715.0 with 1 tasks
2018-05-01 17:50:30.754  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 715.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:30.754  INFO 16044 --- [Executor task launch worker for task 235] org.apache.spark.executor.Executor       : Running task 0.0 in stage 715.0 (TID 235)
2018-05-01 17:50:30.756  INFO 16044 --- [Executor task launch worker for task 235] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:30.756  INFO 16044 --- [Executor task launch worker for task 235] org.apache.spark.storage.BlockManager    : Found block rdd_425_0 locally
2018-05-01 17:50:30.789  INFO 16044 --- [Executor task launch worker for task 235] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 715.0 (TID 235). 1069 bytes result sent to driver
2018-05-01 17:50:30.790  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 715.0 (TID 235) in 36 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:30.790  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 715.0, whose tasks have all completed, from pool 
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 715 (flatMap at ALS.scala:1433) finished in 0.036 s
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 716)
2018-05-01 17:50:30.790  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:30.791  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 716 (MapPartitionsRDD[436] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:30.792  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_102 stored as values in memory (estimated size 39.1 KB, free 1925.2 MB)
2018-05-01 17:50:30.793  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_102_piece0 stored as bytes in memory (estimated size 17.6 KB, free 1925.2 MB)
2018-05-01 17:50:30.793  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_102_piece0 in memory on 172.21.241.193:58620 (size: 17.6 KB, free: 1925.6 MB)
2018-05-01 17:50:30.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 102 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:30.794  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 716 (MapPartitionsRDD[436] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:30.794  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 716.0 with 1 tasks
2018-05-01 17:50:30.794  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 716.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:30.794  INFO 16044 --- [Executor task launch worker for task 236] org.apache.spark.executor.Executor       : Running task 0.0 in stage 716.0 (TID 236)
2018-05-01 17:50:30.797  INFO 16044 --- [Executor task launch worker for task 236] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:30.797  INFO 16044 --- [Executor task launch worker for task 236] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:30.797  INFO 16044 --- [Executor task launch worker for task 236] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:31.070  INFO 16044 --- [Executor task launch worker for task 236] o.a.spark.storage.memory.MemoryStore     : Block rdd_435_0 stored as values in memory (estimated size 416.2 KB, free 1924.8 MB)
2018-05-01 17:50:31.070  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added rdd_435_0 in memory on 172.21.241.193:58620 (size: 416.2 KB, free: 1925.2 MB)
2018-05-01 17:50:31.072  INFO 16044 --- [Executor task launch worker for task 236] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 716.0 (TID 236). 2595 bytes result sent to driver
2018-05-01 17:50:31.072  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 716.0 (TID 236) in 278 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.072  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 716.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.073  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 716 (aggregate at ALS.scala:1491) finished in 0.278 s
2018-05-01 17:50:31.073  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 54 finished: aggregate at ALS.scala:1491, took 0.331969 s
2018-05-01 17:50:31.097  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 425 from persistence list
2018-05-01 17:50:31.097  INFO 16044 --- [block-manager-slave-async-thread-pool-4] org.apache.spark.storage.BlockManager    : Removing RDD 425
2018-05-01 17:50:31.103  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: aggregate at ALS.scala:1491
2018-05-01 17:50:31.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:31.103  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:31.104  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:31.105  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:31.106  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:31.106  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:31.106  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 44 is 150 bytes
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 45 is 150 bytes
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 440 (flatMap at ALS.scala:1433)
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 55 (aggregate at ALS.scala:1491) with 1 output partitions
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 740 (aggregate at ALS.scala:1491)
2018-05-01 17:50:31.108  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 739, ShuffleMapStage 718)
2018-05-01 17:50:31.109  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 739)
2018-05-01 17:50:31.109  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 739 (MapPartitionsRDD[440] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:31.111  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_103 stored as values in memory (estimated size 38.2 KB, free 1925.5 MB)
2018-05-01 17:50:31.112  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_103_piece0 stored as bytes in memory (estimated size 17.2 KB, free 1925.5 MB)
2018-05-01 17:50:31.112  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_103_piece0 in memory on 172.21.241.193:58620 (size: 17.2 KB, free: 1926.0 MB)
2018-05-01 17:50:31.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 103 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.112  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 739 (MapPartitionsRDD[440] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.112  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 739.0 with 1 tasks
2018-05-01 17:50:31.113  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 739.0 (TID 237, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:31.113  INFO 16044 --- [Executor task launch worker for task 237] org.apache.spark.executor.Executor       : Running task 0.0 in stage 739.0 (TID 237)
2018-05-01 17:50:31.115  INFO 16044 --- [Executor task launch worker for task 237] org.apache.spark.storage.BlockManager    : Found block rdd_248_0 locally
2018-05-01 17:50:31.115  INFO 16044 --- [Executor task launch worker for task 237] org.apache.spark.storage.BlockManager    : Found block rdd_435_0 locally
2018-05-01 17:50:31.141  INFO 16044 --- [Executor task launch worker for task 237] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 739.0 (TID 237). 1069 bytes result sent to driver
2018-05-01 17:50:31.142  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 739.0 (TID 237) in 29 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.142  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 739.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 739 (flatMap at ALS.scala:1433) finished in 0.029 s
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 740)
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:31.142  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 740 (MapPartitionsRDD[446] at values at ALS.scala:1491), which has no missing parents
2018-05-01 17:50:31.144  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_104 stored as values in memory (estimated size 40.6 KB, free 1925.5 MB)
2018-05-01 17:50:31.145  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_104_piece0 stored as bytes in memory (estimated size 18.2 KB, free 1925.5 MB)
2018-05-01 17:50:31.145  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_104_piece0 in memory on 172.21.241.193:58620 (size: 18.2 KB, free: 1925.9 MB)
2018-05-01 17:50:31.145  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 104 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.146  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 740 (MapPartitionsRDD[446] at values at ALS.scala:1491) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.146  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 740.0 with 1 tasks
2018-05-01 17:50:31.146  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 740.0 (TID 238, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2018-05-01 17:50:31.146  INFO 16044 --- [Executor task launch worker for task 238] org.apache.spark.executor.Executor       : Running task 0.0 in stage 740.0 (TID 238)
2018-05-01 17:50:31.148  INFO 16044 --- [Executor task launch worker for task 238] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:31.149  INFO 16044 --- [Executor task launch worker for task 238] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:31.149  INFO 16044 --- [Executor task launch worker for task 238] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2018-05-01 17:50:31.415  INFO 16044 --- [Executor task launch worker for task 238] o.a.spark.storage.memory.MemoryStore     : Block rdd_445_0 stored as values in memory (estimated size 820.5 KB, free 1924.7 MB)
2018-05-01 17:50:31.415  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added rdd_445_0 in memory on 172.21.241.193:58620 (size: 820.5 KB, free: 1925.1 MB)
2018-05-01 17:50:31.419  INFO 16044 --- [Executor task launch worker for task 238] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 740.0 (TID 238). 2595 bytes result sent to driver
2018-05-01 17:50:31.419  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 740.0 (TID 238) in 273 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.419  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 740.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.420  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 740 (aggregate at ALS.scala:1491) finished in 0.274 s
2018-05-01 17:50:31.420  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 55 finished: aggregate at ALS.scala:1491, took 0.316564 s
2018-05-01 17:50:31.437  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.rdd.MapPartitionsRDD    : Removing RDD 435 from persistence list
2018-05-01 17:50:31.437  INFO 16044 --- [block-manager-slave-async-thread-pool-5] org.apache.spark.storage.BlockManager    : Removing RDD 435
2018-05-01 17:50:31.453  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:279
2018-05-01 17:50:31.453  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:31.454  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:31.455  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:31.457  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 44 is 150 bytes
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 45 is 150 bytes
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 46 is 150 bytes
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 450 (flatMap at ALS.scala:1433)
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 56 (count at ALS.scala:279) with 1 output partitions
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 765 (count at ALS.scala:279)
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 742, ShuffleMapStage 764)
2018-05-01 17:50:31.458  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 764)
2018-05-01 17:50:31.459  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 764 (MapPartitionsRDD[450] at flatMap at ALS.scala:1433), which has no missing parents
2018-05-01 17:50:31.461  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_105 stored as values in memory (estimated size 39.7 KB, free 1925.0 MB)
2018-05-01 17:50:31.461  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_105_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1925.0 MB)
2018-05-01 17:50:31.462  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_105_piece0 in memory on 172.21.241.193:58620 (size: 18.0 KB, free: 1925.5 MB)
2018-05-01 17:50:31.462  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 105 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.462  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 764 (MapPartitionsRDD[450] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.462  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 764.0 with 1 tasks
2018-05-01 17:50:31.463  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 764.0 (TID 239, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-05-01 17:50:31.463  INFO 16044 --- [Executor task launch worker for task 239] org.apache.spark.executor.Executor       : Running task 0.0 in stage 764.0 (TID 239)
2018-05-01 17:50:31.465  INFO 16044 --- [Executor task launch worker for task 239] org.apache.spark.storage.BlockManager    : Found block rdd_253_0 locally
2018-05-01 17:50:31.465  INFO 16044 --- [Executor task launch worker for task 239] org.apache.spark.storage.BlockManager    : Found block rdd_445_0 locally
2018-05-01 17:50:31.495  INFO 16044 --- [Executor task launch worker for task 239] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 764.0 (TID 239). 1112 bytes result sent to driver
2018-05-01 17:50:31.495  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 764.0 (TID 239) in 33 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.496  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 764.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 764 (flatMap at ALS.scala:1433) finished in 0.034 s
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 765)
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2018-05-01 17:50:31.496  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 765 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:50:31.498  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_106 stored as values in memory (estimated size 41.6 KB, free 1925.0 MB)
2018-05-01 17:50:31.499  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_106_piece0 stored as bytes in memory (estimated size 18.6 KB, free 1924.9 MB)
2018-05-01 17:50:31.499  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_106_piece0 in memory on 172.21.241.193:58620 (size: 18.6 KB, free: 1925.5 MB)
2018-05-01 17:50:31.500  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 106 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.500  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 765 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.500  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 765.0 with 1 tasks
2018-05-01 17:50:31.500  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 765.0 (TID 240, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.500  INFO 16044 --- [Executor task launch worker for task 240] org.apache.spark.executor.Executor       : Running task 0.0 in stage 765.0 (TID 240)
2018-05-01 17:50:31.503  INFO 16044 --- [Executor task launch worker for task 240] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:31.503  INFO 16044 --- [Executor task launch worker for task 240] org.apache.spark.storage.BlockManager    : Found block rdd_247_0 locally
2018-05-01 17:50:31.504  INFO 16044 --- [Executor task launch worker for task 240] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2018-05-01 17:50:31.504  INFO 16044 --- [Executor task launch worker for task 240] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2018-05-01 17:50:31.827  INFO 16044 --- [Executor task launch worker for task 240] o.a.spark.storage.memory.MemoryStore     : Block rdd_466_0 stored as values in memory (estimated size 970.8 KB, free 1924.0 MB)
2018-05-01 17:50:31.828  INFO 16044 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added rdd_466_0 in memory on 172.21.241.193:58620 (size: 970.8 KB, free: 1924.6 MB)
2018-05-01 17:50:31.829  INFO 16044 --- [Executor task launch worker for task 240] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 765.0 (TID 240). 1873 bytes result sent to driver
2018-05-01 17:50:31.829  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 765.0 (TID 240) in 329 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.829  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 765.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.829  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 765 (count at ALS.scala:279) finished in 0.329 s
2018-05-01 17:50:31.829  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 56 finished: count at ALS.scala:279, took 0.376742 s
2018-05-01 17:50:31.831  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: count at ALS.scala:280
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 25 is 161 bytes
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 26 is 161 bytes
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 24 is 161 bytes
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 28 is 150 bytes
2018-05-01 17:50:31.832  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 27 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 29 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 30 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 31 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 32 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 33 is 150 bytes
2018-05-01 17:50:31.833  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 34 is 150 bytes
2018-05-01 17:50:31.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 35 is 150 bytes
2018-05-01 17:50:31.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 36 is 150 bytes
2018-05-01 17:50:31.835  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 37 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 38 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 39 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 40 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 41 is 150 bytes
2018-05-01 17:50:31.836  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 42 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 43 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 44 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 45 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 46 is 150 bytes
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 57 (count at ALS.scala:280) with 1 output partitions
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 789 (count at ALS.scala:280)
2018-05-01 17:50:31.837  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 767, ShuffleMapStage 788)
2018-05-01 17:50:31.838  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:31.838  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 789 (products MapPartitionsRDD[467] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:50:31.840  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_107 stored as values in memory (estimated size 40.1 KB, free 1924.0 MB)
2018-05-01 17:50:31.841  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_107_piece0 stored as bytes in memory (estimated size 18.0 KB, free 1923.9 MB)
2018-05-01 17:50:31.841  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_107_piece0 in memory on 172.21.241.193:58620 (size: 18.0 KB, free: 1924.5 MB)
2018-05-01 17:50:31.841  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 107 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.841  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 789 (products MapPartitionsRDD[467] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.841  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 789.0 with 1 tasks
2018-05-01 17:50:31.842  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 789.0 (TID 241, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.842  INFO 16044 --- [Executor task launch worker for task 241] org.apache.spark.executor.Executor       : Running task 0.0 in stage 789.0 (TID 241)
2018-05-01 17:50:31.844  INFO 16044 --- [Executor task launch worker for task 241] org.apache.spark.storage.BlockManager    : Found block rdd_252_0 locally
2018-05-01 17:50:31.844  INFO 16044 --- [Executor task launch worker for task 241] org.apache.spark.storage.BlockManager    : Found block rdd_445_0 locally
2018-05-01 17:50:31.940  INFO 16044 --- [Executor task launch worker for task 241] o.a.spark.storage.memory.MemoryStore     : Block rdd_467_0 stored as values in memory (estimated size 1914.2 KB, free 1922.1 MB)
2018-05-01 17:50:31.941  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added rdd_467_0 in memory on 172.21.241.193:58620 (size: 1914.2 KB, free: 1922.7 MB)
2018-05-01 17:50:31.942  INFO 16044 --- [Executor task launch worker for task 241] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 789.0 (TID 241). 1615 bytes result sent to driver
2018-05-01 17:50:31.942  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 789.0 (TID 241) in 100 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.942  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 789.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.943  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 789 (count at ALS.scala:280) finished in 0.101 s
2018-05-01 17:50:31.943  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 57 finished: count at ALS.scala:280, took 0.111142 s
2018-05-01 17:50:31.949  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 47 is 150 bytes
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 58 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 814 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 791, ShuffleMapStage 813)
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:31.951  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 814 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:50:31.953  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_108 stored as values in memory (estimated size 41.8 KB, free 1922.0 MB)
2018-05-01 17:50:31.954  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_108_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1922.0 MB)
2018-05-01 17:50:31.954  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_108_piece0 in memory on 172.21.241.193:58620 (size: 18.7 KB, free: 1922.7 MB)
2018-05-01 17:50:31.955  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 108 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.955  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 814 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.955  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 814.0 with 1 tasks
2018-05-01 17:50:31.955  INFO 16044 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 814.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.956  INFO 16044 --- [Executor task launch worker for task 242] org.apache.spark.executor.Executor       : Running task 0.0 in stage 814.0 (TID 242)
2018-05-01 17:50:31.959  INFO 16044 --- [Executor task launch worker for task 242] org.apache.spark.storage.BlockManager    : Found block rdd_466_0 locally
2018-05-01 17:50:31.959  INFO 16044 --- [Executor task launch worker for task 242] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 242:
[rdd_466_0]
2018-05-01 17:50:31.959  INFO 16044 --- [Executor task launch worker for task 242] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 814.0 (TID 242). 909 bytes result sent to driver
2018-05-01 17:50:31.960  INFO 16044 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 814.0 (TID 242) in 5 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.960  INFO 16044 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 814.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.960  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 814 (first at MatrixFactorizationModel.scala:67) finished in 0.005 s
2018-05-01 17:50:31.960  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 58 finished: first at MatrixFactorizationModel.scala:67, took 0.011147 s
2018-05-01 17:50:31.970  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: first at MatrixFactorizationModel.scala:67
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 59 (first at MatrixFactorizationModel.scala:67) with 1 output partitions
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 838 (first at MatrixFactorizationModel.scala:67)
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 837, ShuffleMapStage 816)
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:31.972  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 838 (products MapPartitionsRDD[467] at mapValues at ALS.scala:275), which has no missing parents
2018-05-01 17:50:31.975  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_109 stored as values in memory (estimated size 40.2 KB, free 1922.0 MB)
2018-05-01 17:50:31.976  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_109_piece0 stored as bytes in memory (estimated size 18.1 KB, free 1922.0 MB)
2018-05-01 17:50:31.977  INFO 16044 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_109_piece0 in memory on 172.21.241.193:58620 (size: 18.1 KB, free: 1922.6 MB)
2018-05-01 17:50:31.977  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 109 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.978  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 838 (products MapPartitionsRDD[467] at mapValues at ALS.scala:275) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.978  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 838.0 with 1 tasks
2018-05-01 17:50:31.978  INFO 16044 --- [dispatcher-event-loop-7] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 838.0 (TID 243, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.978  INFO 16044 --- [Executor task launch worker for task 243] org.apache.spark.executor.Executor       : Running task 0.0 in stage 838.0 (TID 243)
2018-05-01 17:50:31.982  INFO 16044 --- [Executor task launch worker for task 243] org.apache.spark.storage.BlockManager    : Found block rdd_467_0 locally
2018-05-01 17:50:31.982  INFO 16044 --- [Executor task launch worker for task 243] org.apache.spark.executor.Executor       : 1 block locks were not released by TID = 243:
[rdd_467_0]
2018-05-01 17:50:31.982  INFO 16044 --- [Executor task launch worker for task 243] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 838.0 (TID 243). 952 bytes result sent to driver
2018-05-01 17:50:31.983  INFO 16044 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 838.0 (TID 243) in 5 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:31.983  INFO 16044 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 838.0, whose tasks have all completed, from pool 
2018-05-01 17:50:31.983  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 838 (first at MatrixFactorizationModel.scala:67) finished in 0.005 s
2018-05-01 17:50:31.984  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 59 finished: first at MatrixFactorizationModel.scala:67, took 0.013525 s
2018-05-01 17:50:31.988  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: lookup at MatrixFactorizationModel.scala:168
2018-05-01 17:50:31.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 60 (lookup at MatrixFactorizationModel.scala:168) with 1 output partitions
2018-05-01 17:50:31.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 863 (lookup at MatrixFactorizationModel.scala:168)
2018-05-01 17:50:31.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 840, ShuffleMapStage 862)
2018-05-01 17:50:31.990  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:31.991  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 863 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271), which has no missing parents
2018-05-01 17:50:31.993  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_110 stored as values in memory (estimated size 41.9 KB, free 1921.9 MB)
2018-05-01 17:50:31.994  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_110_piece0 stored as bytes in memory (estimated size 18.8 KB, free 1921.9 MB)
2018-05-01 17:50:31.995  INFO 16044 --- [dispatcher-event-loop-6] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_110_piece0 in memory on 172.21.241.193:58620 (size: 18.8 KB, free: 1922.6 MB)
2018-05-01 17:50:31.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 110 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:31.995  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 863 (users MapPartitionsRDD[466] at mapValues at ALS.scala:271) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:31.995  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 863.0 with 1 tasks
2018-05-01 17:50:31.995  INFO 16044 --- [dispatcher-event-loop-5] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 863.0 (TID 244, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:31.996  INFO 16044 --- [Executor task launch worker for task 244] org.apache.spark.executor.Executor       : Running task 0.0 in stage 863.0 (TID 244)
2018-05-01 17:50:32.000  INFO 16044 --- [Executor task launch worker for task 244] org.apache.spark.storage.BlockManager    : Found block rdd_466_0 locally
2018-05-01 17:50:32.002  INFO 16044 --- [Executor task launch worker for task 244] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 863.0 (TID 244). 942 bytes result sent to driver
2018-05-01 17:50:32.002  INFO 16044 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 863.0 (TID 244) in 7 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:32.002  INFO 16044 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 863.0, whose tasks have all completed, from pool 
2018-05-01 17:50:32.003  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 863 (lookup at MatrixFactorizationModel.scala:168) finished in 0.008 s
2018-05-01 17:50:32.003  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 60 finished: lookup at MatrixFactorizationModel.scala:168, took 0.015101 s
2018-05-01 17:50:32.010  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.SparkContext            : Starting job: top at MatrixFactorizationModel.scala:259
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 61 (top at MatrixFactorizationModel.scala:259) with 1 output partitions
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 887 (top at MatrixFactorizationModel.scala:259)
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 865, ShuffleMapStage 886)
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2018-05-01 17:50:32.012  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 887 (MapPartitionsRDD[469] at top at MatrixFactorizationModel.scala:259), which has no missing parents
2018-05-01 17:50:32.014  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_111 stored as values in memory (estimated size 41.2 KB, free 1921.9 MB)
2018-05-01 17:50:32.015  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_111_piece0 stored as bytes in memory (estimated size 18.7 KB, free 1921.8 MB)
2018-05-01 17:50:32.015  INFO 16044 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_111_piece0 in memory on 172.21.241.193:58620 (size: 18.7 KB, free: 1922.6 MB)
2018-05-01 17:50:32.016  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 111 from broadcast at DAGScheduler.scala:1006
2018-05-01 17:50:32.016  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 887 (MapPartitionsRDD[469] at top at MatrixFactorizationModel.scala:259) (first 15 tasks are for partitions Vector(0))
2018-05-01 17:50:32.016  INFO 16044 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 887.0 with 1 tasks
2018-05-01 17:50:32.016  INFO 16044 --- [dispatcher-event-loop-4] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 887.0 (TID 245, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-05-01 17:50:32.016  INFO 16044 --- [Executor task launch worker for task 245] org.apache.spark.executor.Executor       : Running task 0.0 in stage 887.0 (TID 245)
2018-05-01 17:50:32.018  INFO 16044 --- [Executor task launch worker for task 245] org.apache.spark.storage.BlockManager    : Found block rdd_467_0 locally
2018-05-01 17:50:32.022  INFO 16044 --- [Executor task launch worker for task 245] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 887.0 (TID 245). 1566 bytes result sent to driver
2018-05-01 17:50:32.022  INFO 16044 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 887.0 (TID 245) in 6 ms on localhost (executor driver) (1/1)
2018-05-01 17:50:32.022  INFO 16044 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 887.0, whose tasks have all completed, from pool 
2018-05-01 17:50:32.022  INFO 16044 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 887 (top at MatrixFactorizationModel.scala:259) finished in 0.006 s
2018-05-01 17:50:32.023  INFO 16044 --- [http-nio-3333-exec-4] org.apache.spark.scheduler.DAGScheduler  : Job 61 finished: top at MatrixFactorizationModel.scala:259, took 0.012563 s
2018-05-01 17:50:32.023  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Recommendations for1
2018-05-01 17:50:32.023  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1214-- Rating : 0.9971559840534798
2018-05-01 17:50:32.026  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1200-- Rating : 0.9553528808073415
2018-05-01 17:50:32.028  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 541-- Rating : 0.9435799010918857
2018-05-01 17:50:32.031  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 1196-- Rating : 0.9396974110427829
2018-05-01 17:50:32.033  INFO 16044 --- [http-nio-3333-exec-4] c.j.p.s.impl.RecomendationServiceImpl    : Product id : 2571-- Rating : 0.9150071477153301
